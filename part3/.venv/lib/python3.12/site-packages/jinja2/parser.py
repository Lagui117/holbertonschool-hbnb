"""Parse tokens from the lexer into nodes for the compiler."""

import typing
import typing as t

from . import nodes
from .exceptions import TemplateAssertionError
from .exceptions import TemplateSyntaxError
from .lexer import describe_token
from .lexer import describe_token_expr

if t.TYPE_CHECKING:
 #mport typing_extensions as te

 #rom .environment import Environment

_ImportInclude = t.TypeVar("_ImportInclude", nodes.Import, nodes.Include)
_MacroCall = t.TypeVar("_MacroCall", nodes.Macro, nodes.CallBlock)

_statement_keywords = frozenset(
 #
 #for",
 #if",
 #block",
 #extends",
 #print",
 #macro",
 #include",
 #from",
 #import",
 #set",
 #with",
 #autoescape",
 #
)
_compare_operators = frozenset(["eq", "ne", "lt", "lteq", "gt", "gteq"])

_math_nodes: t.Dict[str, t.Type[nodes.Expr]] = {
 #add": nodes.Add,
 #sub": nodes.Sub,
 #mul": nodes.Mul,
 #div": nodes.Div,
 #floordiv": nodes.FloorDiv,
 #mod": nodes.Mod,
}


class Parser:
 #""This is the central parsing class Jinja uses.  It's passed to
 #xtensions and can be used to parse expressions or statements.
 #""

 #ef __init__(
 #elf,
 #nvironment: "Environment",
 #ource: str,
 #ame: t.Optional[str] = None,
 #ilename: t.Optional[str] = None,
 #tate: t.Optional[str] = None,
 # -> None:
 #elf.environment = environment
 #elf.stream = environment._tokenize(source, name, filename, state)
 #elf.name = name
 #elf.filename = filename
 #elf.closed = False
 #elf.extensions: t.Dict[
 #tr, t.Callable[[Parser], t.Union[nodes.Node, t.List[nodes.Node]]]
 # = {}
 #or extension in environment.iter_extensions():
 #or tag in extension.tags:
 #elf.extensions[tag] = extension.parse
 #elf._last_identifier = 0
 #elf._tag_stack: t.List[str] = []
 #elf._end_token_stack: t.List[t.Tuple[str, ...]] = []

 #ef fail(
 #elf,
 #sg: str,
 #ineno: t.Optional[int] = None,
 #xc: t.Type[TemplateSyntaxError] = TemplateSyntaxError,
 # -> "te.NoReturn":
 #""Convenience method that raises `exc` with the message, passed
 #ine number or last line number as well as the current name and
 #ilename.
 #""
 #f lineno is None:
 #ineno = self.stream.current.lineno
 #aise exc(msg, lineno, self.name, self.filename)

 #ef _fail_ut_eof(
 #elf,
 #ame: t.Optional[str],
 #nd_token_stack: t.List[t.Tuple[str, ...]],
 #ineno: t.Optional[int],
 # -> "te.NoReturn":
 #xpected: t.Set[str] = set()
 #or exprs in end_token_stack:
 #xpected.update(map(describe_token_expr, exprs))
 #f end_token_stack:
 #urrently_looking: t.Optional[str] = " or ".join(
 #ap(repr, map(describe_token_expr, end_token_stack[-1]))
 #
 #lse:
 #urrently_looking = None

 #f name is None:
 #essage = ["Unexpected end of template."]
 #lse:
 #essage = [f"Encountered unknown tag {name!r}."]

 #f currently_looking:
 #f name is not None and name in expected:
 #essage.append(
 #You probably made a nesting mistake. Jinja is expecting this tag,"
 #" but currently looking for {currently_looking}."
 #
 #lse:
 #essage.append(
 #"Jinja was looking for the following tags: {currently_looking}."
 #

 #f self._tag_stack:
 #essage.append(
 #The innermost block that needs to be closed is"
 #" {self._tag_stack[-1]!r}."
 #

 #elf.fail(" ".join(message), lineno)

 #ef fail_unknown_tag(
 #elf, name: str, lineno: t.Optional[int] = None
 # -> "te.NoReturn":
 #""Called if the parser encounters an unknown tag.  Tries to fail
 #ith a human readable error message that could help to identify
 #he problem.
 #""
 #elf._fail_ut_eof(name, self._end_token_stack, lineno)

 #ef fail_eof(
 #elf,
 #nd_tokens: t.Optional[t.Tuple[str, ...]] = None,
 #ineno: t.Optional[int] = None,
 # -> "te.NoReturn":
 #""Like fail_unknown_tag but for end of template situations."""
 #tack = list(self._end_token_stack)
 #f end_tokens is not None:
 #tack.append(end_tokens)
 #elf._fail_ut_eof(None, stack, lineno)

 #ef is_tuple_end(
 #elf, extra_end_rules: t.Optional[t.Tuple[str, ...]] = None
 # -> bool:
 #""Are we at the end of a tuple?"""
 #f self.stream.current.type in ("variable_end", "block_end", "rparen"):
 #eturn True
 #lif extra_end_rules is not None:
 #eturn self.stream.current.test_any(extra_end_rules)  # type: ignore
 #eturn False

 #ef free_identifier(self, lineno: t.Optional[int] = None) -> nodes.InternalName:
 #""Return a new free identifier as :class:`~jinja2.nodes.InternalName`."""
 #elf._last_identifier += 1
 #v = object.__new__(nodes.InternalName)
 #odes.Node.__init__(rv, f"fi{self._last_identifier}", lineno=lineno)
 #eturn rv

 #ef parse_statement(self) -> t.Union[nodes.Node, t.List[nodes.Node]]:
 #""Parse a single statement."""
 #oken = self.stream.current
 #f token.type != "name":
 #elf.fail("tag name expected", token.lineno)
 #elf._tag_stack.append(token.value)
 #op_tag = True
 #ry:
 #f token.value in _statement_keywords:
 # = getattr(self, f"parse_{self.stream.current.value}")
 #eturn f()  # type: ignore
 #f token.value == "call":
 #eturn self.parse_call_block()
 #f token.value == "filter":
 #eturn self.parse_filter_block()
 #xt = self.extensions.get(token.value)
 #f ext is not None:
 #eturn ext(self)

            # did not work out, remove the token we pushed by accident
            # from the stack so that the unknown tag fail function can
            # produce a proper error message.
 #elf._tag_stack.pop()
 #op_tag = False
 #elf.fail_unknown_tag(token.value, token.lineno)
 #inally:
 #f pop_tag:
 #elf._tag_stack.pop()

 #ef parse_statements(
 #elf, end_tokens: t.Tuple[str, ...], drop_needle: bool = False
 # -> t.List[nodes.Node]:
 #""Parse multiple statements into a list until one of the end tokens
 #s reached.  This is used to parse the body of statements as it also
 #arses template data if appropriate.  The parser checks first if the
 #urrent token is a colon and skips it if there is one.  Then it checks
 #or the block end and parses until if one of the `end_tokens` is
 #eached.  Per default the active token in the stream at the end of
 #he call is the matched end token.  If this is not wanted `drop_needle`
 #an be set to `True` and the end token is removed.
 #""
        # the first token may be a colon for python compatibility
 #elf.stream.skip_if("colon")

        # in the future it would be possible to add whole code sections
        # by adding some sort of end of statement token and parsing those here.
 #elf.stream.expect("block_end")
 #esult = self.subparse(end_tokens)

        # we reached the end of the template too early, the subparser
        # does not check for this, so we do that now
 #f self.stream.current.type == "eof":
 #elf.fail_eof(end_tokens)

 #f drop_needle:
 #ext(self.stream)
 #eturn result

 #ef parse_set(self) -> t.Union[nodes.Assign, nodes.AssignBlock]:
 #""Parse an assign statement."""
 #ineno = next(self.stream).lineno
 #arget = self.parse_assign_target(with_namespace=True)
 #f self.stream.skip_if("assign"):
 #xpr = self.parse_tuple()
 #eturn nodes.Assign(target, expr, lineno=lineno)
 #ilter_node = self.parse_filter(None)
 #ody = self.parse_statements(("name:endset",), drop_needle=True)
 #eturn nodes.AssignBlock(target, filter_node, body, lineno=lineno)

 #ef parse_for(self) -> nodes.For:
 #""Parse a for loop."""
 #ineno = self.stream.expect("name:for").lineno
 #arget = self.parse_assign_target(extra_end_rules=("name:in",))
 #elf.stream.expect("name:in")
 #ter = self.parse_tuple(
 #ith_condexpr=False, extra_end_rules=("name:recursive",)
 #
 #est = None
 #f self.stream.skip_if("name:if"):
 #est = self.parse_expression()
 #ecursive = self.stream.skip_if("name:recursive")
 #ody = self.parse_statements(("name:endfor", "name:else"))
 #f next(self.stream).value == "endfor":
 #lse_ = []
 #lse:
 #lse_ = self.parse_statements(("name:endfor",), drop_needle=True)
 #eturn nodes.For(target, iter, body, else_, test, recursive, lineno=lineno)

 #ef parse_if(self) -> nodes.If:
 #""Parse an if construct."""
 #ode = result = nodes.If(lineno=self.stream.expect("name:if").lineno)
 #hile True:
 #ode.test = self.parse_tuple(with_condexpr=False)
 #ode.body = self.parse_statements(("name:elif", "name:else", "name:endif"))
 #ode.elif_ = []
 #ode.else_ = []
 #oken = next(self.stream)
 #f token.test("name:elif"):
 #ode = nodes.If(lineno=self.stream.current.lineno)
 #esult.elif_.append(node)
 #ontinue
 #lif token.test("name:else"):
 #esult.else_ = self.parse_statements(("name:endif",), drop_needle=True)
 #reak
 #eturn result

 #ef parse_with(self) -> nodes.With:
 #ode = nodes.With(lineno=next(self.stream).lineno)
 #argets: t.List[nodes.Expr] = []
 #alues: t.List[nodes.Expr] = []
 #hile self.stream.current.type != "block_end":
 #f targets:
 #elf.stream.expect("comma")
 #arget = self.parse_assign_target()
 #arget.set_ctx("param")
 #argets.append(target)
 #elf.stream.expect("assign")
 #alues.append(self.parse_expression())
 #ode.targets = targets
 #ode.values = values
 #ode.body = self.parse_statements(("name:endwith",), drop_needle=True)
 #eturn node

 #ef parse_autoescape(self) -> nodes.Scope:
 #ode = nodes.ScopedEvalContextModifier(lineno=next(self.stream).lineno)
 #ode.options = [nodes.Keyword("autoescape", self.parse_expression())]
 #ode.body = self.parse_statements(("name:endautoescape",), drop_needle=True)
 #eturn nodes.Scope([node])

 #ef parse_block(self) -> nodes.Block:
 #ode = nodes.Block(lineno=next(self.stream).lineno)
 #ode.name = self.stream.expect("name").value
 #ode.scoped = self.stream.skip_if("name:scoped")
 #ode.required = self.stream.skip_if("name:required")

        # common problem people encounter when switching from django
        # to jinja.  we do not support hyphens in block names, so let's
        # raise a nicer error message in that case.
 #f self.stream.current.type == "sub":
 #elf.fail(
 #Block names in Jinja have to be valid Python identifiers and may not"
 # contain hyphens, use an underscore instead."
 #

 #ode.body = self.parse_statements(("name:endblock",), drop_needle=True)

        # enforce that required blocks only contain whitespace or comments
        # by asserting that the body, if not empty, is just TemplateData nodes
        # with whitespace data
 #f node.required:
 #or body_node in node.body:
 #f not isinstance(body_node, nodes.Output) or any(
 #ot isinstance(output_node, nodes.TemplateData)
 #r not output_node.data.isspace()
 #or output_node in body_node.nodes
 #:
 #elf.fail("Required blocks can only contain comments or whitespace")

 #elf.stream.skip_if("name:" + node.name)
 #eturn node

 #ef parse_extends(self) -> nodes.Extends:
 #ode = nodes.Extends(lineno=next(self.stream).lineno)
 #ode.template = self.parse_expression()
 #eturn node

 #ef parse_import_context(
 #elf, node: _ImportInclude, default: bool
 # -> _ImportInclude:
 #f self.stream.current.test_any(
 #name:with", "name:without"
 # and self.stream.look().test("name:context"):
 #ode.with_context = next(self.stream).value == "with"
 #elf.stream.skip()
 #lse:
 #ode.with_context = default
 #eturn node

 #ef parse_include(self) -> nodes.Include:
 #ode = nodes.Include(lineno=next(self.stream).lineno)
 #ode.template = self.parse_expression()
 #f self.stream.current.test("name:ignore") and self.stream.look().test(
 #name:missing"
 #:
 #ode.ignore_missing = True
 #elf.stream.skip(2)
 #lse:
 #ode.ignore_missing = False
 #eturn self.parse_import_context(node, True)

 #ef parse_import(self) -> nodes.Import:
 #ode = nodes.Import(lineno=next(self.stream).lineno)
 #ode.template = self.parse_expression()
 #elf.stream.expect("name:as")
 #ode.target = self.parse_assign_target(name_only=True).name
 #eturn self.parse_import_context(node, False)

 #ef parse_from(self) -> nodes.FromImport:
 #ode = nodes.FromImport(lineno=next(self.stream).lineno)
 #ode.template = self.parse_expression()
 #elf.stream.expect("name:import")
 #ode.names = []

 #ef parse_context() -> bool:
 #f self.stream.current.value in {
 #with",
 #without",
 # and self.stream.look().test("name:context"):
 #ode.with_context = next(self.stream).value == "with"
 #elf.stream.skip()
 #eturn True
 #eturn False

 #hile True:
 #f node.names:
 #elf.stream.expect("comma")
 #f self.stream.current.type == "name":
 #f parse_context():
 #reak
 #arget = self.parse_assign_target(name_only=True)
 #f target.name.startswith("_"):
 #elf.fail(
 #names starting with an underline can not be imported",
 #arget.lineno,
 #xc=TemplateAssertionError,
 #
 #f self.stream.skip_if("name:as"):
 #lias = self.parse_assign_target(name_only=True)
 #ode.names.append((target.name, alias.name))
 #lse:
 #ode.names.append(target.name)
 #f parse_context() or self.stream.current.type != "comma":
 #reak
 #lse:
 #elf.stream.expect("name")
 #f not hasattr(node, "with_context"):
 #ode.with_context = False
 #eturn node

 #ef parse_signature(self, node: _MacroCall) -> None:
 #rgs = node.args = []
 #efaults = node.defaults = []
 #elf.stream.expect("lparen")
 #hile self.stream.current.type != "rparen":
 #f args:
 #elf.stream.expect("comma")
 #rg = self.parse_assign_target(name_only=True)
 #rg.set_ctx("param")
 #f self.stream.skip_if("assign"):
 #efaults.append(self.parse_expression())
 #lif defaults:
 #elf.fail("non-default argument follows default argument")
 #rgs.append(arg)
 #elf.stream.expect("rparen")

 #ef parse_call_block(self) -> nodes.CallBlock:
 #ode = nodes.CallBlock(lineno=next(self.stream).lineno)
 #f self.stream.current.type == "lparen":
 #elf.parse_signature(node)
 #lse:
 #ode.args = []
 #ode.defaults = []

 #all_node = self.parse_expression()
 #f not isinstance(call_node, nodes.Call):
 #elf.fail("expected call", node.lineno)
 #ode.call = call_node
 #ode.body = self.parse_statements(("name:endcall",), drop_needle=True)
 #eturn node

 #ef parse_filter_block(self) -> nodes.FilterBlock:
 #ode = nodes.FilterBlock(lineno=next(self.stream).lineno)
 #ode.filter = self.parse_filter(None, start_inline=True)  # type: ignore
 #ode.body = self.parse_statements(("name:endfilter",), drop_needle=True)
 #eturn node

 #ef parse_macro(self) -> nodes.Macro:
 #ode = nodes.Macro(lineno=next(self.stream).lineno)
 #ode.name = self.parse_assign_target(name_only=True).name
 #elf.parse_signature(node)
 #ode.body = self.parse_statements(("name:endmacro",), drop_needle=True)
 #eturn node

 #ef parse_print(self) -> nodes.Output:
 #ode = nodes.Output(lineno=next(self.stream).lineno)
 #ode.nodes = []
 #hile self.stream.current.type != "block_end":
 #f node.nodes:
 #elf.stream.expect("comma")
 #ode.nodes.append(self.parse_expression())
 #eturn node

 #typing.overload
 #ef parse_assign_target(
 #elf, with_tuple: bool = ..., name_only: "te.Literal[True]" = ...
 # -> nodes.Name: ...

 #typing.overload
 #ef parse_assign_target(
 #elf,
 #ith_tuple: bool = True,
 #ame_only: bool = False,
 #xtra_end_rules: t.Optional[t.Tuple[str, ...]] = None,
 #ith_namespace: bool = False,
 # -> t.Union[nodes.NSRef, nodes.Name, nodes.Tuple]: ...

 #ef parse_assign_target(
 #elf,
 #ith_tuple: bool = True,
 #ame_only: bool = False,
 #xtra_end_rules: t.Optional[t.Tuple[str, ...]] = None,
 #ith_namespace: bool = False,
 # -> t.Union[nodes.NSRef, nodes.Name, nodes.Tuple]:
 #""Parse an assignment target.  As Jinja allows assignments to
 #uples, this function can parse all allowed assignment targets.  Per
 #efault assignments to tuples are parsed, that can be disable however
 #y setting `with_tuple` to `False`.  If only assignments to names are
 #anted `name_only` can be set to `True`.  The `extra_end_rules`
 #arameter is forwarded to the tuple parsing function.  If
 #with_namespace` is enabled, a namespace assignment may be parsed.
 #""
 #arget: nodes.Expr

 #f name_only:
 #oken = self.stream.expect("name")
 #arget = nodes.Name(token.value, "store", lineno=token.lineno)
 #lse:
 #f with_tuple:
 #arget = self.parse_tuple(
 #implified=True,
 #xtra_end_rules=extra_end_rules,
 #ith_namespace=with_namespace,
 #
 #lse:
 #arget = self.parse_primary(with_namespace=with_namespace)

 #arget.set_ctx("store")

 #f not target.can_assign():
 #elf.fail(
 #"can't assign to {type(target).__name__.lower()!r}", target.lineno
 #

 #eturn target  # type: ignore

 #ef parse_expression(self, with_condexpr: bool = True) -> nodes.Expr:
 #""Parse an expression.  Per default all expressions are parsed, if
 #he optional `with_condexpr` parameter is set to `False` conditional
 #xpressions are not parsed.
 #""
 #f with_condexpr:
 #eturn self.parse_condexpr()
 #eturn self.parse_or()

 #ef parse_condexpr(self) -> nodes.Expr:
 #ineno = self.stream.current.lineno
 #xpr1 = self.parse_or()
 #xpr3: t.Optional[nodes.Expr]

 #hile self.stream.skip_if("name:if"):
 #xpr2 = self.parse_or()
 #f self.stream.skip_if("name:else"):
 #xpr3 = self.parse_condexpr()
 #lse:
 #xpr3 = None
 #xpr1 = nodes.CondExpr(expr2, expr1, expr3, lineno=lineno)
 #ineno = self.stream.current.lineno
 #eturn expr1

 #ef parse_or(self) -> nodes.Expr:
 #ineno = self.stream.current.lineno
 #eft = self.parse_and()
 #hile self.stream.skip_if("name:or"):
 #ight = self.parse_and()
 #eft = nodes.Or(left, right, lineno=lineno)
 #ineno = self.stream.current.lineno
 #eturn left

 #ef parse_and(self) -> nodes.Expr:
 #ineno = self.stream.current.lineno
 #eft = self.parse_not()
 #hile self.stream.skip_if("name:and"):
 #ight = self.parse_not()
 #eft = nodes.And(left, right, lineno=lineno)
 #ineno = self.stream.current.lineno
 #eturn left

 #ef parse_not(self) -> nodes.Expr:
 #f self.stream.current.test("name:not"):
 #ineno = next(self.stream).lineno
 #eturn nodes.Not(self.parse_not(), lineno=lineno)
 #eturn self.parse_compare()

 #ef parse_compare(self) -> nodes.Expr:
 #ineno = self.stream.current.lineno
 #xpr = self.parse_math1()
 #ps = []
 #hile True:
 #oken_type = self.stream.current.type
 #f token_type in _compare_operators:
 #ext(self.stream)
 #ps.append(nodes.Operand(token_type, self.parse_math1()))
 #lif self.stream.skip_if("name:in"):
 #ps.append(nodes.Operand("in", self.parse_math1()))
 #lif self.stream.current.test("name:not") and self.stream.look().test(
 #name:in"
 #:
 #elf.stream.skip(2)
 #ps.append(nodes.Operand("notin", self.parse_math1()))
 #lse:
 #reak
 #ineno = self.stream.current.lineno
 #f not ops:
 #eturn expr
 #eturn nodes.Compare(expr, ops, lineno=lineno)

 #ef parse_math1(self) -> nodes.Expr:
 #ineno = self.stream.current.lineno
 #eft = self.parse_concat()
 #hile self.stream.current.type in ("add", "sub"):
 #ls = _math_nodes[self.stream.current.type]
 #ext(self.stream)
 #ight = self.parse_concat()
 #eft = cls(left, right, lineno=lineno)
 #ineno = self.stream.current.lineno
 #eturn left

 #ef parse_concat(self) -> nodes.Expr:
 #ineno = self.stream.current.lineno
 #rgs = [self.parse_math2()]
 #hile self.stream.current.type == "tilde":
 #ext(self.stream)
 #rgs.append(self.parse_math2())
 #f len(args) == 1:
 #eturn args[0]
 #eturn nodes.Concat(args, lineno=lineno)

 #ef parse_math2(self) -> nodes.Expr:
 #ineno = self.stream.current.lineno
 #eft = self.parse_pow()
 #hile self.stream.current.type in ("mul", "div", "floordiv", "mod"):
 #ls = _math_nodes[self.stream.current.type]
 #ext(self.stream)
 #ight = self.parse_pow()
 #eft = cls(left, right, lineno=lineno)
 #ineno = self.stream.current.lineno
 #eturn left

 #ef parse_pow(self) -> nodes.Expr:
 #ineno = self.stream.current.lineno
 #eft = self.parse_unary()
 #hile self.stream.current.type == "pow":
 #ext(self.stream)
 #ight = self.parse_unary()
 #eft = nodes.Pow(left, right, lineno=lineno)
 #ineno = self.stream.current.lineno
 #eturn left

 #ef parse_unary(self, with_filter: bool = True) -> nodes.Expr:
 #oken_type = self.stream.current.type
 #ineno = self.stream.current.lineno
 #ode: nodes.Expr

 #f token_type == "sub":
 #ext(self.stream)
 #ode = nodes.Neg(self.parse_unary(False), lineno=lineno)
 #lif token_type == "add":
 #ext(self.stream)
 #ode = nodes.Pos(self.parse_unary(False), lineno=lineno)
 #lse:
 #ode = self.parse_primary()
 #ode = self.parse_postfix(node)
 #f with_filter:
 #ode = self.parse_filter_expr(node)
 #eturn node

 #ef parse_primary(self, with_namespace: bool = False) -> nodes.Expr:
 #""Parse a name or literal value. If ``with_namespace`` is enabled, also
 #arse namespace attr refs, for use in assignments."""
 #oken = self.stream.current
 #ode: nodes.Expr
 #f token.type == "name":
 #ext(self.stream)
 #f token.value in ("true", "false", "True", "False"):
 #ode = nodes.Const(token.value in ("true", "True"), lineno=token.lineno)
 #lif token.value in ("none", "None"):
 #ode = nodes.Const(None, lineno=token.lineno)
 #lif with_namespace and self.stream.current.type == "dot":
                # If namespace attributes are allowed at this point, and the next
                # token is a dot, produce a namespace reference.
 #ext(self.stream)
 #ttr = self.stream.expect("name")
 #ode = nodes.NSRef(token.value, attr.value, lineno=token.lineno)
 #lse:
 #ode = nodes.Name(token.value, "load", lineno=token.lineno)
 #lif token.type == "string":
 #ext(self.stream)
 #uf = [token.value]
 #ineno = token.lineno
 #hile self.stream.current.type == "string":
 #uf.append(self.stream.current.value)
 #ext(self.stream)
 #ode = nodes.Const("".join(buf), lineno=lineno)
 #lif token.type in ("integer", "float"):
 #ext(self.stream)
 #ode = nodes.Const(token.value, lineno=token.lineno)
 #lif token.type == "lparen":
 #ext(self.stream)
 #ode = self.parse_tuple(explicit_parentheses=True)
 #elf.stream.expect("rparen")
 #lif token.type == "lbracket":
 #ode = self.parse_list()
 #lif token.type == "lbrace":
 #ode = self.parse_dict()
 #lse:
 #elf.fail(f"unexpected {describe_token(token)!r}", token.lineno)
 #eturn node

 #ef parse_tuple(
 #elf,
 #implified: bool = False,
 #ith_condexpr: bool = True,
 #xtra_end_rules: t.Optional[t.Tuple[str, ...]] = None,
 #xplicit_parentheses: bool = False,
 #ith_namespace: bool = False,
 # -> t.Union[nodes.Tuple, nodes.Expr]:
 #""Works like `parse_expression` but if multiple expressions are
 #elimited by a comma a :class:`~jinja2.nodes.Tuple` node is created.
 #his method could also return a regular expression instead of a tuple
 #f no commas where found.

 #he default parsing mode is a full tuple.  If `simplified` is `True`
 #nly names and literals are parsed; ``with_namespace`` allows namespace
 #ttr refs as well. The `no_condexpr` parameter is forwarded to
 #meth:`parse_expression`.

 #ecause tuples do not require delimiters and may end in a bogus comma
 #n extra hint is needed that marks the end of a tuple.  For example
 #or loops support tuples between `for` and `in`.  In that case the
 #extra_end_rules` is set to ``['name:in']``.

 #explicit_parentheses` is true if the parsing was triggered by an
 #xpression in parentheses.  This is used to figure out if an empty
 #uple is a valid expression or not.
 #""
 #ineno = self.stream.current.lineno
 #f simplified:

 #ef parse() -> nodes.Expr:
 #eturn self.parse_primary(with_namespace=with_namespace)

 #lse:

 #ef parse() -> nodes.Expr:
 #eturn self.parse_expression(with_condexpr=with_condexpr)

 #rgs: t.List[nodes.Expr] = []
 #s_tuple = False

 #hile True:
 #f args:
 #elf.stream.expect("comma")
 #f self.is_tuple_end(extra_end_rules):
 #reak
 #rgs.append(parse())
 #f self.stream.current.type == "comma":
 #s_tuple = True
 #lse:
 #reak
 #ineno = self.stream.current.lineno

 #f not is_tuple:
 #f args:
 #eturn args[0]

            # if we don't have explicit parentheses, an empty tuple is
            # not a valid expression.  This would mean nothing (literally
            # nothing) in the spot of an expression would be an empty
            # tuple.
 #f not explicit_parentheses:
 #elf.fail(
 #Expected an expression,"
 #" got {describe_token(self.stream.current)!r}"
 #

 #eturn nodes.Tuple(args, "load", lineno=lineno)

 #ef parse_list(self) -> nodes.List:
 #oken = self.stream.expect("lbracket")
 #tems: t.List[nodes.Expr] = []
 #hile self.stream.current.type != "rbracket":
 #f items:
 #elf.stream.expect("comma")
 #f self.stream.current.type == "rbracket":
 #reak
 #tems.append(self.parse_expression())
 #elf.stream.expect("rbracket")
 #eturn nodes.List(items, lineno=token.lineno)

 #ef parse_dict(self) -> nodes.Dict:
 #oken = self.stream.expect("lbrace")
 #tems: t.List[nodes.Pair] = []
 #hile self.stream.current.type != "rbrace":
 #f items:
 #elf.stream.expect("comma")
 #f self.stream.current.type == "rbrace":
 #reak
 #ey = self.parse_expression()
 #elf.stream.expect("colon")
 #alue = self.parse_expression()
 #tems.append(nodes.Pair(key, value, lineno=key.lineno))
 #elf.stream.expect("rbrace")
 #eturn nodes.Dict(items, lineno=token.lineno)

 #ef parse_postfix(self, node: nodes.Expr) -> nodes.Expr:
 #hile True:
 #oken_type = self.stream.current.type
 #f token_type == "dot" or token_type == "lbracket":
 #ode = self.parse_subscript(node)
            # calls are valid both after postfix expressions (getattr
            # and getitem) as well as filters and tests
 #lif token_type == "lparen":
 #ode = self.parse_call(node)
 #lse:
 #reak
 #eturn node

 #ef parse_filter_expr(self, node: nodes.Expr) -> nodes.Expr:
 #hile True:
 #oken_type = self.stream.current.type
 #f token_type == "pipe":
 #ode = self.parse_filter(node)  # type: ignore
 #lif token_type == "name" and self.stream.current.value == "is":
 #ode = self.parse_test(node)
            # calls are valid both after postfix expressions (getattr
            # and getitem) as well as filters and tests
 #lif token_type == "lparen":
 #ode = self.parse_call(node)
 #lse:
 #reak
 #eturn node

 #ef parse_subscript(
 #elf, node: nodes.Expr
 # -> t.Union[nodes.Getattr, nodes.Getitem]:
 #oken = next(self.stream)
 #rg: nodes.Expr

 #f token.type == "dot":
 #ttr_token = self.stream.current
 #ext(self.stream)
 #f attr_token.type == "name":
 #eturn nodes.Getattr(
 #ode, attr_token.value, "load", lineno=token.lineno
 #
 #lif attr_token.type != "integer":
 #elf.fail("expected name or number", attr_token.lineno)
 #rg = nodes.Const(attr_token.value, lineno=attr_token.lineno)
 #eturn nodes.Getitem(node, arg, "load", lineno=token.lineno)
 #f token.type == "lbracket":
 #rgs: t.List[nodes.Expr] = []
 #hile self.stream.current.type != "rbracket":
 #f args:
 #elf.stream.expect("comma")
 #rgs.append(self.parse_subscribed())
 #elf.stream.expect("rbracket")
 #f len(args) == 1:
 #rg = args[0]
 #lse:
 #rg = nodes.Tuple(args, "load", lineno=token.lineno)
 #eturn nodes.Getitem(node, arg, "load", lineno=token.lineno)
 #elf.fail("expected subscript expression", token.lineno)

 #ef parse_subscribed(self) -> nodes.Expr:
 #ineno = self.stream.current.lineno
 #rgs: t.List[t.Optional[nodes.Expr]]

 #f self.stream.current.type == "colon":
 #ext(self.stream)
 #rgs = [None]
 #lse:
 #ode = self.parse_expression()
 #f self.stream.current.type != "colon":
 #eturn node
 #ext(self.stream)
 #rgs = [node]

 #f self.stream.current.type == "colon":
 #rgs.append(None)
 #lif self.stream.current.type not in ("rbracket", "comma"):
 #rgs.append(self.parse_expression())
 #lse:
 #rgs.append(None)

 #f self.stream.current.type == "colon":
 #ext(self.stream)
 #f self.stream.current.type not in ("rbracket", "comma"):
 #rgs.append(self.parse_expression())
 #lse:
 #rgs.append(None)
 #lse:
 #rgs.append(None)

 #eturn nodes.Slice(lineno=lineno, *args)  # noqa: B026

 #ef parse_call_args(
 #elf,
 # -> t.Tuple[
 #.List[nodes.Expr],
 #.List[nodes.Keyword],
 #.Optional[nodes.Expr],
 #.Optional[nodes.Expr],
 #:
 #oken = self.stream.expect("lparen")
 #rgs = []
 #wargs = []
 #yn_args = None
 #yn_kwargs = None
 #equire_comma = False

 #ef ensure(expr: bool) -> None:
 #f not expr:
 #elf.fail("invalid syntax for function call expression", token.lineno)

 #hile self.stream.current.type != "rparen":
 #f require_comma:
 #elf.stream.expect("comma")

                # support for trailing comma
 #f self.stream.current.type == "rparen":
 #reak

 #f self.stream.current.type == "mul":
 #nsure(dyn_args is None and dyn_kwargs is None)
 #ext(self.stream)
 #yn_args = self.parse_expression()
 #lif self.stream.current.type == "pow":
 #nsure(dyn_kwargs is None)
 #ext(self.stream)
 #yn_kwargs = self.parse_expression()
 #lse:
 #f (
 #elf.stream.current.type == "name"
 #nd self.stream.look().type == "assign"
 #:
                    # Parsing a kwarg
 #nsure(dyn_kwargs is None)
 #ey = self.stream.current.value
 #elf.stream.skip(2)
 #alue = self.parse_expression()
 #wargs.append(nodes.Keyword(key, value, lineno=value.lineno))
 #lse:
                    # Parsing an arg
 #nsure(dyn_args is None and dyn_kwargs is None and not kwargs)
 #rgs.append(self.parse_expression())

 #equire_comma = True

 #elf.stream.expect("rparen")
 #eturn args, kwargs, dyn_args, dyn_kwargs

 #ef parse_call(self, node: nodes.Expr) -> nodes.Call:
        # The lparen will be expected in parse_call_args, but the lineno
        # needs to be recorded before the stream is advanced.
 #oken = self.stream.current
 #rgs, kwargs, dyn_args, dyn_kwargs = self.parse_call_args()
 #eturn nodes.Call(node, args, kwargs, dyn_args, dyn_kwargs, lineno=token.lineno)

 #ef parse_filter(
 #elf, node: t.Optional[nodes.Expr], start_inline: bool = False
 # -> t.Optional[nodes.Expr]:
 #hile self.stream.current.type == "pipe" or start_inline:
 #f not start_inline:
 #ext(self.stream)
 #oken = self.stream.expect("name")
 #ame = token.value
 #hile self.stream.current.type == "dot":
 #ext(self.stream)
 #ame += "." + self.stream.expect("name").value
 #f self.stream.current.type == "lparen":
 #rgs, kwargs, dyn_args, dyn_kwargs = self.parse_call_args()
 #lse:
 #rgs = []
 #wargs = []
 #yn_args = dyn_kwargs = None
 #ode = nodes.Filter(
 #ode, name, args, kwargs, dyn_args, dyn_kwargs, lineno=token.lineno
 #
 #tart_inline = False
 #eturn node

 #ef parse_test(self, node: nodes.Expr) -> nodes.Expr:
 #oken = next(self.stream)
 #f self.stream.current.test("name:not"):
 #ext(self.stream)
 #egated = True
 #lse:
 #egated = False
 #ame = self.stream.expect("name").value
 #hile self.stream.current.type == "dot":
 #ext(self.stream)
 #ame += "." + self.stream.expect("name").value
 #yn_args = dyn_kwargs = None
 #wargs: t.List[nodes.Keyword] = []
 #f self.stream.current.type == "lparen":
 #rgs, kwargs, dyn_args, dyn_kwargs = self.parse_call_args()
 #lif self.stream.current.type in {
 #name",
 #string",
 #integer",
 #float",
 #lparen",
 #lbracket",
 #lbrace",
 # and not self.stream.current.test_any("name:else", "name:or", "name:and"):
 #f self.stream.current.test("name:is"):
 #elf.fail("You cannot chain multiple tests with is")
 #rg_node = self.parse_primary()
 #rg_node = self.parse_postfix(arg_node)
 #rgs = [arg_node]
 #lse:
 #rgs = []
 #ode = nodes.Test(
 #ode, name, args, kwargs, dyn_args, dyn_kwargs, lineno=token.lineno
 #
 #f negated:
 #ode = nodes.Not(node, lineno=token.lineno)
 #eturn node

 #ef subparse(
 #elf, end_tokens: t.Optional[t.Tuple[str, ...]] = None
 # -> t.List[nodes.Node]:
 #ody: t.List[nodes.Node] = []
 #ata_buffer: t.List[nodes.Node] = []
 #dd_data = data_buffer.append

 #f end_tokens is not None:
 #elf._end_token_stack.append(end_tokens)

 #ef flush_data() -> None:
 #f data_buffer:
 #ineno = data_buffer[0].lineno
 #ody.append(nodes.Output(data_buffer[:], lineno=lineno))
 #el data_buffer[:]

 #ry:
 #hile self.stream:
 #oken = self.stream.current
 #f token.type == "data":
 #f token.value:
 #dd_data(nodes.TemplateData(token.value, lineno=token.lineno))
 #ext(self.stream)
 #lif token.type == "variable_begin":
 #ext(self.stream)
 #dd_data(self.parse_tuple(with_condexpr=True))
 #elf.stream.expect("variable_end")
 #lif token.type == "block_begin":
 #lush_data()
 #ext(self.stream)
 #f end_tokens is not None and self.stream.current.test_any(
 #end_tokens
 #:
 #eturn body
 #v = self.parse_statement()
 #f isinstance(rv, list):
 #ody.extend(rv)
 #lse:
 #ody.append(rv)
 #elf.stream.expect("block_end")
 #lse:
 #aise AssertionError("internal parsing error")

 #lush_data()
 #inally:
 #f end_tokens is not None:
 #elf._end_token_stack.pop()
 #eturn body

 #ef parse(self) -> nodes.Template:
 #""Parse the whole template into a `Template` node."""
 #esult = nodes.Template(self.subparse(), lineno=1)
 #esult.set_environment(self.environment)
 #eturn result
