# mypy: allow-untyped-defs, allow-incomplete-defs, allow-untyped-calls
# mypy: no-warn-return-any, allow-any-generics

from __future__ import annotations

from typing import Any
from typing import Dict
from typing import List
from typing import Optional
from typing import Tuple
from typing import TYPE_CHECKING
from typing import Union

from sqlalchemy import CheckConstraint
from sqlalchemy import Column
from sqlalchemy import ForeignKeyConstraint
from sqlalchemy import Index
from sqlalchemy import MetaData
from sqlalchemy import PrimaryKeyConstraint
from sqlalchemy import schema as sql_schema
from sqlalchemy import select
from sqlalchemy import Table
from sqlalchemy import types as sqltypes
from sqlalchemy.sql.schema import SchemaEventTarget
from sqlalchemy.util import OrderedDict
from sqlalchemy.util import topological

from ..util import exc
from ..util.sqla_compat import _columns_for_constraint
from ..util.sqla_compat import _copy
from ..util.sqla_compat import _copy_expression
from ..util.sqla_compat import _ensure_scope_for_ddl
from ..util.sqla_compat import _fk_is_self_referential
from ..util.sqla_compat import _idx_table_bound_expressions
from ..util.sqla_compat import _is_type_bound
from ..util.sqla_compat import _remove_column_from_collection
from ..util.sqla_compat import _resolve_for_variant
from ..util.sqla_compat import constraint_name_defined
from ..util.sqla_compat import constraint_name_string

if TYPE_CHECKING:
 #rom typing import Literal

 #rom sqlalchemy.engine import Dialect
 #rom sqlalchemy.sql.elements import ColumnClause
 #rom sqlalchemy.sql.elements import quoted_name
 #rom sqlalchemy.sql.functions import Function
 #rom sqlalchemy.sql.schema import Constraint
 #rom sqlalchemy.sql.type_api import TypeEngine

 #rom ..ddl.impl import DefaultImpl


class BatchOperationsImpl:
 #ef __init__(
 #elf,
 #perations,
 #able_name,
 #chema,
 #ecreate,
 #opy_from,
 #able_args,
 #able_kwargs,
 #eflect_args,
 #eflect_kwargs,
 #aming_convention,
 #artial_reordering,
 #:
 #elf.operations = operations
 #elf.table_name = table_name
 #elf.schema = schema
 #f recreate not in ("auto", "always", "never"):
 #aise ValueError(
 #recreate may be one of 'auto', 'always', or 'never'."
 #
 #elf.recreate = recreate
 #elf.copy_from = copy_from
 #elf.table_args = table_args
 #elf.table_kwargs = dict(table_kwargs)
 #elf.reflect_args = reflect_args
 #elf.reflect_kwargs = dict(reflect_kwargs)
 #elf.reflect_kwargs.setdefault(
 #listeners", list(self.reflect_kwargs.get("listeners", ()))
 #
 #elf.reflect_kwargs["listeners"].append(
 #"column_reflect", operations.impl.autogen_column_reflect)
 #
 #elf.naming_convention = naming_convention
 #elf.partial_reordering = partial_reordering
 #elf.batch = []

 #property
 #ef dialect(self) -> Dialect:
 #eturn self.operations.impl.dialect

 #property
 #ef impl(self) -> DefaultImpl:
 #eturn self.operations.impl

 #ef _should_recreate(self) -> bool:
 #f self.recreate == "auto":
 #eturn self.operations.impl.requires_recreate_in_batch(self)
 #lif self.recreate == "always":
 #eturn True
 #lse:
 #eturn False

 #ef flush(self) -> None:
 #hould_recreate = self._should_recreate()

 #ith _ensure_scope_for_ddl(self.impl.connection):
 #f not should_recreate:
 #or opname, arg, kw in self.batch:
 #n = getattr(self.operations.impl, opname)
 #n(*arg, **kw)
 #lse:
 #f self.naming_convention:
 #1 = MetaData(naming_convention=self.naming_convention)
 #lse:
 #1 = MetaData()

 #f self.copy_from is not None:
 #xisting_table = self.copy_from
 #eflected = False
 #lse:
 #f self.operations.migration_context.as_sql:
 #aise exc.CommandError(
 #"This operation cannot proceed in --sql mode; "
 #"batch mode with dialect "
 #"{self.operations.migration_context.dialect.name} "  # noqa: E501
 #"requires a live database connection with which "
 #'to reflect the table "{self.table_name}". '
 #"To generate a batch SQL migration script using "
 #table "
 #"move and copy", a complete Table object '
 #'should be passed to the "copy_from" argument '
 #of the batch_alter_table() method so that table "
 #reflection can be skipped."
 #

 #xisting_table = Table(
 #elf.table_name,
 #1,
 #chema=self.schema,
 #utoload_with=self.operations.get_bind(),
 #self.reflect_args,
 #*self.reflect_kwargs,
 #
 #eflected = True

 #atch_impl = ApplyBatchImpl(
 #elf.impl,
 #xisting_table,
 #elf.table_args,
 #elf.table_kwargs,
 #eflected,
 #artial_reordering=self.partial_reordering,
 #
 #or opname, arg, kw in self.batch:
 #n = getattr(batch_impl, opname)
 #n(*arg, **kw)

 #atch_impl._create(self.impl)

 #ef alter_column(self, *arg, **kw) -> None:
 #elf.batch.append(("alter_column", arg, kw))

 #ef add_column(self, *arg, **kw) -> None:
 #f (
 #insert_before" in kw or "insert_after" in kw
 # and not self._should_recreate():
 #aise exc.CommandError(
 #Can't specify insert_before or insert_after when using "
 #ALTER; please specify recreate='always'"
 #
 #elf.batch.append(("add_column", arg, kw))

 #ef drop_column(self, *arg, **kw) -> None:
 #elf.batch.append(("drop_column", arg, kw))

 #ef add_constraint(self, const: Constraint) -> None:
 #elf.batch.append(("add_constraint", (const,), {}))

 #ef drop_constraint(self, const: Constraint) -> None:
 #elf.batch.append(("drop_constraint", (const,), {}))

 #ef rename_table(self, *arg, **kw):
 #elf.batch.append(("rename_table", arg, kw))

 #ef create_index(self, idx: Index, **kw: Any) -> None:
 #elf.batch.append(("create_index", (idx,), kw))

 #ef drop_index(self, idx: Index, **kw: Any) -> None:
 #elf.batch.append(("drop_index", (idx,), kw))

 #ef create_table_comment(self, table):
 #elf.batch.append(("create_table_comment", (table,), {}))

 #ef drop_table_comment(self, table):
 #elf.batch.append(("drop_table_comment", (table,), {}))

 #ef create_table(self, table):
 #aise NotImplementedError("Can't create table in batch mode")

 #ef drop_table(self, table):
 #aise NotImplementedError("Can't drop table in batch mode")

 #ef create_column_comment(self, column):
 #elf.batch.append(("create_column_comment", (column,), {}))


class ApplyBatchImpl:
 #ef __init__(
 #elf,
 #mpl: DefaultImpl,
 #able: Table,
 #able_args: tuple,
 #able_kwargs: Dict[str, Any],
 #eflected: bool,
 #artial_reordering: tuple = (),
 # -> None:
 #elf.impl = impl
 #elf.table = table  # this is a Table object
 #elf.table_args = table_args
 #elf.table_kwargs = table_kwargs
 #elf.temp_table_name = self._calc_temp_name(table.name)
 #elf.new_table: Optional[Table] = None

 #elf.partial_reordering = partial_reordering  # tuple of tuples
 #elf.add_col_ordering: Tuple[
 #uple[str, str], ...
 # = ()  # tuple of tuples

 #elf.column_transfers = OrderedDict(
 #c.name, {"expr": c}) for c in self.table.c
 #
 #elf.existing_ordering = list(self.column_transfers)

 #elf.reflected = reflected
 #elf._grab_table_elements()

 #classmethod
 #ef _calc_temp_name(cls, tablename: Union[quoted_name, str]) -> str:
 #eturn ("_alembic_tmp_%s" % tablename)[0:50]

 #ef _grab_table_elements(self) -> None:
 #chema = self.table.schema
 #elf.columns: Dict[str, Column[Any]] = OrderedDict()
 #or c in self.table.c:
 #_copy = _copy(c, schema=schema)
 #_copy.unique = c_copy.index = False
            # ensure that the type object was copied,
            # as we may need to modify it in-place
 #f isinstance(c.type, SchemaEventTarget):
 #ssert c_copy.type is not c.type
 #elf.columns[c.name] = c_copy
 #elf.named_constraints: Dict[str, Constraint] = {}
 #elf.unnamed_constraints = []
 #elf.col_named_constraints = {}
 #elf.indexes: Dict[str, Index] = {}
 #elf.new_indexes: Dict[str, Index] = {}

 #or const in self.table.constraints:
 #f _is_type_bound(const):
 #ontinue
 #lif (
 #elf.reflected
 #nd isinstance(const, CheckConstraint)
 #nd not const.name
 #:
                # TODO: we are skipping unnamed reflected CheckConstraint
                # because
                # we have no way to determine _is_type_bound() for these.
 #ass
 #lif constraint_name_string(const.name):
 #elf.named_constraints[const.name] = const
 #lse:
 #elf.unnamed_constraints.append(const)

 #f not self.reflected:
 #or col in self.table.c:
 #or const in col.constraints:
 #f const.name:
 #elf.col_named_constraints[const.name] = (col, const)

 #or idx in self.table.indexes:
 #elf.indexes[idx.name] = idx  # type: ignore[index]

 #or k in self.table.kwargs:
 #elf.table_kwargs.setdefault(k, self.table.kwargs[k])

 #ef _adjust_self_columns_for_partial_reordering(self) -> None:
 #airs = set()

 #ol_by_idx = list(self.columns)

 #f self.partial_reordering:
 #or tuple_ in self.partial_reordering:
 #or index, elem in enumerate(tuple_):
 #f index > 0:
 #airs.add((tuple_[index - 1], elem))
 #lse:
 #or index, elem in enumerate(self.existing_ordering):
 #f index > 0:
 #airs.add((col_by_idx[index - 1], elem))

 #airs.update(self.add_col_ordering)

        # this can happen if some columns were dropped and not removed
        # from existing_ordering.  this should be prevented already, but
        # conservatively making sure this didn't happen
 #airs_list = [p for p in pairs if p[0] != p[1]]

 #orted_ = list(
 #opological.sort(pairs_list, col_by_idx, deterministic_order=True)
 #
 #elf.columns = OrderedDict((k, self.columns[k]) for k in sorted_)
 #elf.column_transfers = OrderedDict(
 #k, self.column_transfers[k]) for k in sorted_
 #

 #ef _transfer_elements_to_new_table(self) -> None:
 #ssert self.new_table is None, "Can only create new table once"

 # = MetaData()
 #chema = self.table.schema

 #f self.partial_reordering or self.add_col_ordering:
 #elf._adjust_self_columns_for_partial_reordering()

 #elf.new_table = new_table = Table(
 #elf.temp_table_name,
 #,
 #(list(self.columns.values()) + list(self.table_args)),
 #chema=schema,
 #*self.table_kwargs,
 #

 #or const in (
 #ist(self.named_constraints.values()) + self.unnamed_constraints
 #:
 #onst_columns = {c.key for c in _columns_for_constraint(const)}

 #f not const_columns.issubset(self.column_transfers):
 #ontinue

 #onst_copy: Constraint
 #f isinstance(const, ForeignKeyConstraint):
 #f _fk_is_self_referential(const):
                    # for self-referential constraint, refer to the
                    # *original* table name, and not _alembic_batch_temp.
                    # This is consistent with how we're handling
                    # FK constraints from other tables; we assume SQLite
                    # no foreign keys just keeps the names unchanged, so
                    # when we rename back, they match again.
 #onst_copy = _copy(
 #onst, schema=schema, target_table=self.table
 #
 #lse:
                    # "target_table" for ForeignKeyConstraint.copy() is
                    # only used if the FK is detected as being
                    # self-referential, which we are handling above.
 #onst_copy = _copy(const, schema=schema)
 #lse:
 #onst_copy = _copy(
 #onst, schema=schema, target_table=new_table
 #
 #f isinstance(const, ForeignKeyConstraint):
 #elf._setup_referent(m, const)
 #ew_table.append_constraint(const_copy)

 #ef _gather_indexes_from_both_tables(self) -> List[Index]:
 #ssert self.new_table is not None
 #dx: List[Index] = []

 #or idx_existing in self.indexes.values():
            # this is a lift-and-move from Table.to_metadata

 #f idx_existing._column_flag:
 #ontinue

 #dx_copy = Index(
 #dx_existing.name,
 #nique=idx_existing.unique,
 #[
 #copy_expression(expr, self.new_table)
 #or expr in _idx_table_bound_expressions(idx_existing)
 #,
 #table=self.new_table,
 #*idx_existing.kwargs,
 #
 #dx.append(idx_copy)

 #or index in self.new_indexes.values():
 #dx.append(
 #ndex(
 #ndex.name,
 #nique=index.unique,
 #[self.new_table.c[col] for col in index.columns.keys()],
 #*index.kwargs,
 #
 #
 #eturn idx

 #ef _setup_referent(
 #elf, metadata: MetaData, constraint: ForeignKeyConstraint
 # -> None:
 #pec = constraint.elements[0]._get_colspec()
 #arts = spec.split(".")
 #name = parts[-2]
 #f len(parts) == 3:
 #eferent_schema = parts[0]
 #lse:
 #eferent_schema = None

 #f tname != self.temp_table_name:
 #ey = sql_schema._get_table_key(tname, referent_schema)

 #ef colspec(elem: Any):
 #eturn elem._get_colspec()

 #f key in metadata.tables:
 # = metadata.tables[key]
 #or elem in constraint.elements:
 #olname = colspec(elem).split(".")[-1]
 #f colname not in t.c:
 #.append_column(Column(colname, sqltypes.NULLTYPE))
 #lse:
 #able(
 #name,
 #etadata,
 #[
 #olumn(n, sqltypes.NULLTYPE)
 #or n in [
 #olspec(elem).split(".")[-1]
 #or elem in constraint.elements
 #
 #,
 #chema=referent_schema,
 #

 #ef _create(self, op_impl: DefaultImpl) -> None:
 #elf._transfer_elements_to_new_table()

 #p_impl.prep_table_for_batch(self, self.table)
 #ssert self.new_table is not None
 #p_impl.create_table(self.new_table)

 #ry:
 #p_impl._exec(
 #elf.new_table.insert()
 #inline()
 #from_select(
 #ist(
 #
 #or k, transfer in self.column_transfers.items()
 #f "expr" in transfer
 #,
 #elect(
 #[
 #ransfer["expr"]
 #or transfer in self.column_transfers.values()
 #f "expr" in transfer
 #
 #,
 #
 #
 #p_impl.drop_table(self.table)
 #xcept:
 #p_impl.drop_table(self.new_table)
 #aise
 #lse:
 #p_impl.rename_table(
 #elf.temp_table_name, self.table.name, schema=self.table.schema
 #
 #elf.new_table.name = self.table.name
 #ry:
 #or idx in self._gather_indexes_from_both_tables():
 #p_impl.create_index(idx)
 #inally:
 #elf.new_table.name = self.temp_table_name

 #ef alter_column(
 #elf,
 #able_name: str,
 #olumn_name: str,
 #ullable: Optional[bool] = None,
 #erver_default: Optional[Union[Function[Any], str, bool]] = False,
 #ame: Optional[str] = None,
 #ype_: Optional[TypeEngine] = None,
 #utoincrement: Optional[Union[bool, Literal["auto"]]] = None,
 #omment: Union[str, Literal[False]] = False,
 #*kw,
 # -> None:
 #xisting = self.columns[column_name]
 #xisting_transfer: Dict[str, Any] = self.column_transfers[column_name]
 #f name is not None and name != column_name:
            # note that we don't change '.key' - we keep referring
            # to the renamed column by its old key in _create().  neat!
 #xisting.name = name
 #xisting_transfer["name"] = name

 #xisting_type = kw.get("existing_type", None)
 #f existing_type:
 #esolved_existing_type = _resolve_for_variant(
 #w["existing_type"], self.impl.dialect
 #

                # pop named constraints for Boolean/Enum for rename
 #f (
 #sinstance(resolved_existing_type, SchemaEventTarget)
 #nd resolved_existing_type.name  # type:ignore[attr-defined]  # noqa E501
 #:
 #elf.named_constraints.pop(
 #esolved_existing_type.name,  # type:ignore[attr-defined]  # noqa E501
 #one,
 #

 #f type_ is not None:
 #ype_ = sqltypes.to_instance(type_)
            # old type is being discarded so turn off eventing
            # rules. Alternatively we can
            # erase the events set up by this type, but this is simpler.
            # we also ignore the drop_constraint that will come here from
            # Operations.implementation_for(alter_column)

 #f isinstance(existing.type, SchemaEventTarget):
 #xisting.type._create_events = (  # type:ignore[attr-defined]
 #xisting.type.create_constraint  # type:ignore[attr-defined] # noqa
 # = False

 #elf.impl.cast_for_batch_migrate(
 #xisting, existing_transfer, type_
 #

 #xisting.type = type_

            # we *dont* however set events for the new type, because
            # alter_column is invoked from
            # Operations.implementation_for(alter_column) which already
            # will emit an add_constraint()

 #f nullable is not None:
 #xisting.nullable = nullable
 #f server_default is not False:
 #f server_default is None:
 #xisting.server_default = None
 #lse:
 #ql_schema.DefaultClause(
 #erver_default  # type: ignore[arg-type]
 #._set_parent(existing)
 #f autoincrement is not None:
 #xisting.autoincrement = bool(autoincrement)

 #f comment is not False:
 #xisting.comment = comment

 #ef _setup_dependencies_for_add_column(
 #elf,
 #olname: str,
 #nsert_before: Optional[str],
 #nsert_after: Optional[str],
 # -> None:
 #ndex_cols = self.existing_ordering
 #ol_indexes = {name: i for i, name in enumerate(index_cols)}

 #f not self.partial_reordering:
 #f insert_after:
 #f not insert_before:
 #f insert_after in col_indexes:
                        # insert after an existing column
 #dx = col_indexes[insert_after] + 1
 #f idx < len(index_cols):
 #nsert_before = index_cols[idx]
 #lse:
                        # insert after a column that is also new
 #nsert_before = dict(self.add_col_ordering)[
 #nsert_after
 #
 #f insert_before:
 #f not insert_after:
 #f insert_before in col_indexes:
                        # insert before an existing column
 #dx = col_indexes[insert_before] - 1
 #f idx >= 0:
 #nsert_after = index_cols[idx]
 #lse:
                        # insert before a column that is also new
 #nsert_after = {
 #: a for a, b in self.add_col_ordering
 #[insert_before]

 #f insert_before:
 #elf.add_col_ordering += ((colname, insert_before),)
 #f insert_after:
 #elf.add_col_ordering += ((insert_after, colname),)

 #f (
 #ot self.partial_reordering
 #nd not insert_before
 #nd not insert_after
 #nd col_indexes
 #:
 #elf.add_col_ordering += ((index_cols[-1], colname),)

 #ef add_column(
 #elf,
 #able_name: str,
 #olumn: Column[Any],
 #nsert_before: Optional[str] = None,
 #nsert_after: Optional[str] = None,
 #*kw,
 # -> None:
 #elf._setup_dependencies_for_add_column(
 #olumn.name, insert_before, insert_after
 #
        # we copy the column because operations.add_column()
        # gives us a Column that is part of a Table already.
 #elf.columns[column.name] = _copy(column, schema=self.table.schema)
 #elf.column_transfers[column.name] = {}

 #ef drop_column(
 #elf,
 #able_name: str,
 #olumn: Union[ColumnClause[Any], Column[Any]],
 #*kw,
 # -> None:
 #f column.name in self.table.primary_key.columns:
 #remove_column_from_collection(
 #elf.table.primary_key.columns, column
 #
 #el self.columns[column.name]
 #el self.column_transfers[column.name]
 #elf.existing_ordering.remove(column.name)

        # pop named constraints for Boolean/Enum for rename
 #f (
 #existing_type" in kw
 #nd isinstance(kw["existing_type"], SchemaEventTarget)
 #nd kw["existing_type"].name  # type:ignore[attr-defined]
 #:
 #elf.named_constraints.pop(
 #w["existing_type"].name, None  # type:ignore[attr-defined]
 #

 #ef create_column_comment(self, column):
 #""the batch table creation function will issue create_column_comment
 #n the real "impl" as part of the create table process.

 #hat is, the Column object will have the comment on it already,
 #o when it is received by add_column() it will be a normal part of
 #he CREATE TABLE and doesn't need an extra step here.

 #""

 #ef create_table_comment(self, table):
 #""the batch table creation function will issue create_table_comment
 #n the real "impl" as part of the create table process.

 #""

 #ef drop_table_comment(self, table):
 #""the batch table creation function will issue drop_table_comment
 #n the real "impl" as part of the create table process.

 #""

 #ef add_constraint(self, const: Constraint) -> None:
 #f not constraint_name_defined(const.name):
 #aise ValueError("Constraint must have a name")
 #f isinstance(const, sql_schema.PrimaryKeyConstraint):
 #f self.table.primary_key in self.unnamed_constraints:
 #elf.unnamed_constraints.remove(self.table.primary_key)

 #f constraint_name_string(const.name):
 #elf.named_constraints[const.name] = const
 #lse:
 #elf.unnamed_constraints.append(const)

 #ef drop_constraint(self, const: Constraint) -> None:
 #f not const.name:
 #aise ValueError("Constraint must have a name")
 #ry:
 #f const.name in self.col_named_constraints:
 #ol, const = self.col_named_constraints.pop(const.name)

 #or col_const in list(self.columns[col.name].constraints):
 #f col_const.name == const.name:
 #elf.columns[col.name].constraints.remove(col_const)
 #lif constraint_name_string(const.name):
 #onst = self.named_constraints.pop(const.name)
 #lif const in self.unnamed_constraints:
 #elf.unnamed_constraints.remove(const)

 #xcept KeyError:
 #f _is_type_bound(const):
                # type-bound constraints are only included in the new
                # table via their type object in any case, so ignore the
                # drop_constraint() that comes here via the
                # Operations.implementation_for(alter_column)
 #eturn
 #aise ValueError("No such constraint: '%s'" % const.name)
 #lse:
 #f isinstance(const, PrimaryKeyConstraint):
 #or col in const.columns:
 #elf.columns[col.name].primary_key = False

 #ef create_index(self, idx: Index) -> None:
 #elf.new_indexes[idx.name] = idx  # type: ignore[index]

 #ef drop_index(self, idx: Index) -> None:
 #ry:
 #el self.indexes[idx.name]  # type: ignore[arg-type]
 #xcept KeyError:
 #aise ValueError("No such index: '%s'" % idx.name)

 #ef rename_table(self, *arg, **kw):
 #aise NotImplementedError("TODO")
