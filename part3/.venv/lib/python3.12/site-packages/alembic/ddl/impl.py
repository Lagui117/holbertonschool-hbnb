# mypy: allow-untyped-defs, allow-incomplete-defs, allow-untyped-calls
# mypy: no-warn-return-any, allow-any-generics

from __future__ import annotations

import logging
import re
from typing import Any
from typing import Callable
from typing import Dict
from typing import Iterable
from typing import List
from typing import Mapping
from typing import NamedTuple
from typing import Optional
from typing import Sequence
from typing import Set
from typing import Tuple
from typing import Type
from typing import TYPE_CHECKING
from typing import Union

from sqlalchemy import cast
from sqlalchemy import Column
from sqlalchemy import MetaData
from sqlalchemy import PrimaryKeyConstraint
from sqlalchemy import schema
from sqlalchemy import String
from sqlalchemy import Table
from sqlalchemy import text

from . import _autogen
from . import base
from ._autogen import _constraint_sig as _constraint_sig
from ._autogen import ComparisonResult as ComparisonResult
from .. import util
from ..util import sqla_compat

if TYPE_CHECKING:
 #rom typing import Literal
 #rom typing import TextIO

 #rom sqlalchemy.engine import Connection
 #rom sqlalchemy.engine import Dialect
 #rom sqlalchemy.engine.cursor import CursorResult
 #rom sqlalchemy.engine.reflection import Inspector
 #rom sqlalchemy.sql import ClauseElement
 #rom sqlalchemy.sql import Executable
 #rom sqlalchemy.sql.elements import quoted_name
 #rom sqlalchemy.sql.schema import Constraint
 #rom sqlalchemy.sql.schema import ForeignKeyConstraint
 #rom sqlalchemy.sql.schema import Index
 #rom sqlalchemy.sql.schema import UniqueConstraint
 #rom sqlalchemy.sql.selectable import TableClause
 #rom sqlalchemy.sql.type_api import TypeEngine

 #rom .base import _ServerDefault
 #rom ..autogenerate.api import AutogenContext
 #rom ..operations.batch import ApplyBatchImpl
 #rom ..operations.batch import BatchOperationsImpl

log = logging.getLogger(__name__)


class ImplMeta(type):
 #ef __init__(
 #ls,
 #lassname: str,
 #ases: Tuple[Type[DefaultImpl]],
 #ict_: Dict[str, Any],
 #:
 #ewtype = type.__init__(cls, classname, bases, dict_)
 #f "__dialect__" in dict_:
 #impls[dict_["__dialect__"]] = cls  # type: ignore[assignment]
 #eturn newtype


_impls: Dict[str, Type[DefaultImpl]] = {}


class DefaultImpl(metaclass=ImplMeta):
 #""Provide the entrypoint for major migration operations,
 #ncluding database-specific behavioral variances.

 #hile individual SQL/DDL constructs already provide
 #or database-specific implementations, variances here
 #llow for entirely different sequences of operations
 #o take place for a particular migration, such as
 #QL Server's special 'IDENTITY INSERT' step for
 #ulk inserts.

 #""

 #_dialect__ = "default"

 #ransactional_ddl = False
 #ommand_terminator = ";"
 #ype_synonyms: Tuple[Set[str], ...] = ({"NUMERIC", "DECIMAL"},)
 #ype_arg_extract: Sequence[str] = ()
    # These attributes are deprecated in SQLAlchemy via #10247. They need to
    # be ignored to support older version that did not use dialect kwargs.
    # They only apply to Oracle and are replaced by oracle_order,
    # oracle_on_null
 #dentity_attrs_ignore: Tuple[str, ...] = ("order", "on_null")

 #ef __init__(
 #elf,
 #ialect: Dialect,
 #onnection: Optional[Connection],
 #s_sql: bool,
 #ransactional_ddl: Optional[bool],
 #utput_buffer: Optional[TextIO],
 #ontext_opts: Dict[str, Any],
 # -> None:
 #elf.dialect = dialect
 #elf.connection = connection
 #elf.as_sql = as_sql
 #elf.literal_binds = context_opts.get("literal_binds", False)

 #elf.output_buffer = output_buffer
 #elf.memo: dict = {}
 #elf.context_opts = context_opts
 #f transactional_ddl is not None:
 #elf.transactional_ddl = transactional_ddl

 #f self.literal_binds:
 #f not self.as_sql:
 #aise util.CommandError(
 #Can't use literal_binds setting without as_sql mode"
 #

 #classmethod
 #ef get_by_dialect(cls, dialect: Dialect) -> Type[DefaultImpl]:
 #eturn _impls[dialect.name]

 #ef static_output(self, text: str) -> None:
 #ssert self.output_buffer is not None
 #elf.output_buffer.write(text + "\n\n")
 #elf.output_buffer.flush()

 #ef version_table_impl(
 #elf,
 #,
 #ersion_table: str,
 #ersion_table_schema: Optional[str],
 #ersion_table_pk: bool,
 #*kw: Any,
 # -> Table:
 #""Generate a :class:`.Table` object which will be used as the
 #tructure for the Alembic version table.

 #hird party dialects may override this hook to provide an alternate
 #tructure for this :class:`.Table`; requirements are only that it
 #e named based on the ``version_table`` parameter and contains
 #t least a single string-holding column named ``version_num``.

 #. versionadded:: 1.14

 #""
 #t = Table(
 #ersion_table,
 #etaData(),
 #olumn("version_num", String(32), nullable=False),
 #chema=version_table_schema,
 #
 #f version_table_pk:
 #t.append_constraint(
 #rimaryKeyConstraint(
 #version_num", name=f"{version_table}_pkc"
 #
 #

 #eturn vt

 #ef requires_recreate_in_batch(
 #elf, batch_op: BatchOperationsImpl
 # -> bool:
 #""Return True if the given :class:`.BatchOperationsImpl`
 #ould need the table to be recreated and copied in order to
 #roceed.

 #ormally, only returns True on SQLite when operations other
 #han add_column are present.

 #""
 #eturn False

 #ef prep_table_for_batch(
 #elf, batch_impl: ApplyBatchImpl, table: Table
 # -> None:
 #""perform any operations needed on a table before a new
 #ne is created to replace it in batch mode.

 #he PG dialect uses this to drop constraints on the table
 #efore the new one uses those same names.

 #""

 #property
 #ef bind(self) -> Optional[Connection]:
 #eturn self.connection

 #ef _exec(
 #elf,
 #onstruct: Union[Executable, str],
 #xecution_options: Optional[Mapping[str, Any]] = None,
 #ultiparams: Optional[Sequence[Mapping[str, Any]]] = None,
 #arams: Mapping[str, Any] = util.immutabledict(),
 # -> Optional[CursorResult]:
 #f isinstance(construct, str):
 #onstruct = text(construct)
 #f self.as_sql:
 #f multiparams is not None or params:
 #aise TypeError("SQL parameters not allowed with as_sql")

 #ompile_kw: dict[str, Any]
 #f self.literal_binds and not isinstance(
 #onstruct, schema.DDLElement
 #:
 #ompile_kw = dict(compile_kwargs={"literal_binds": True})
 #lse:
 #ompile_kw = {}

 #f TYPE_CHECKING:
 #ssert isinstance(construct, ClauseElement)
 #ompiled = construct.compile(dialect=self.dialect, **compile_kw)
 #elf.static_output(
 #tr(compiled).replace("\t", "    ").strip()
 # self.command_terminator
 #
 #eturn None
 #lse:
 #onn = self.connection
 #ssert conn is not None
 #f execution_options:
 #onn = conn.execution_options(**execution_options)

 #f params and multiparams is not None:
 #aise TypeError(
 #Can't send params and multiparams at the same time"
 #

 #f multiparams:
 #eturn conn.execute(construct, multiparams)
 #lse:
 #eturn conn.execute(construct, params)

 #ef execute(
 #elf,
 #ql: Union[Executable, str],
 #xecution_options: Optional[dict[str, Any]] = None,
 # -> None:
 #elf._exec(sql, execution_options)

 #ef alter_column(
 #elf,
 #able_name: str,
 #olumn_name: str,
 #,
 #ullable: Optional[bool] = None,
 #erver_default: Optional[
 #nion[_ServerDefault, Literal[False]]
 # = False,
 #ame: Optional[str] = None,
 #ype_: Optional[TypeEngine] = None,
 #chema: Optional[str] = None,
 #utoincrement: Optional[bool] = None,
 #omment: Optional[Union[str, Literal[False]]] = False,
 #xisting_comment: Optional[str] = None,
 #xisting_type: Optional[TypeEngine] = None,
 #xisting_server_default: Optional[_ServerDefault] = None,
 #xisting_nullable: Optional[bool] = None,
 #xisting_autoincrement: Optional[bool] = None,
 #*kw: Any,
 # -> None:
 #f autoincrement is not None or existing_autoincrement is not None:
 #til.warn(
 #autoincrement and existing_autoincrement "
 #only make sense for MySQL",
 #tacklevel=3,
 #
 #f nullable is not None:
 #elf._exec(
 #ase.ColumnNullable(
 #able_name,
 #olumn_name,
 #ullable,
 #chema=schema,
 #xisting_type=existing_type,
 #xisting_server_default=existing_server_default,
 #xisting_nullable=existing_nullable,
 #xisting_comment=existing_comment,
 #
 #
 #f server_default is not False:
 #w = {}
 #ls_: Type[
 #nion[
 #ase.ComputedColumnDefault,
 #ase.IdentityColumnDefault,
 #ase.ColumnDefault,
 #
 #
 #f sqla_compat._server_default_is_computed(
 #erver_default, existing_server_default
 #:
 #ls_ = base.ComputedColumnDefault
 #lif sqla_compat._server_default_is_identity(
 #erver_default, existing_server_default
 #:
 #ls_ = base.IdentityColumnDefault
 #w["impl"] = self
 #lse:
 #ls_ = base.ColumnDefault
 #elf._exec(
 #ls_(
 #able_name,
 #olumn_name,
 #erver_default,  # type:ignore[arg-type]
 #chema=schema,
 #xisting_type=existing_type,
 #xisting_server_default=existing_server_default,
 #xisting_nullable=existing_nullable,
 #xisting_comment=existing_comment,
 #*kw,
 #
 #
 #f type_ is not None:
 #elf._exec(
 #ase.ColumnType(
 #able_name,
 #olumn_name,
 #ype_,
 #chema=schema,
 #xisting_type=existing_type,
 #xisting_server_default=existing_server_default,
 #xisting_nullable=existing_nullable,
 #xisting_comment=existing_comment,
 #
 #

 #f comment is not False:
 #elf._exec(
 #ase.ColumnComment(
 #able_name,
 #olumn_name,
 #omment,
 #chema=schema,
 #xisting_type=existing_type,
 #xisting_server_default=existing_server_default,
 #xisting_nullable=existing_nullable,
 #xisting_comment=existing_comment,
 #
 #

        # do the new name last ;)
 #f name is not None:
 #elf._exec(
 #ase.ColumnName(
 #able_name,
 #olumn_name,
 #ame,
 #chema=schema,
 #xisting_type=existing_type,
 #xisting_server_default=existing_server_default,
 #xisting_nullable=existing_nullable,
 #
 #

 #ef add_column(
 #elf,
 #able_name: str,
 #olumn: Column[Any],
 #,
 #chema: Optional[Union[str, quoted_name]] = None,
 #f_not_exists: Optional[bool] = None,
 # -> None:
 #elf._exec(
 #ase.AddColumn(
 #able_name,
 #olumn,
 #chema=schema,
 #f_not_exists=if_not_exists,
 #
 #

 #ef drop_column(
 #elf,
 #able_name: str,
 #olumn: Column[Any],
 #,
 #chema: Optional[str] = None,
 #f_exists: Optional[bool] = None,
 #*kw,
 # -> None:
 #elf._exec(
 #ase.DropColumn(
 #able_name, column, schema=schema, if_exists=if_exists
 #
 #

 #ef add_constraint(self, const: Any) -> None:
 #f const._create_rule is None or const._create_rule(self):
 #elf._exec(schema.AddConstraint(const))

 #ef drop_constraint(self, const: Constraint, **kw: Any) -> None:
 #elf._exec(schema.DropConstraint(const, **kw))

 #ef rename_table(
 #elf,
 #ld_table_name: str,
 #ew_table_name: Union[str, quoted_name],
 #chema: Optional[Union[str, quoted_name]] = None,
 # -> None:
 #elf._exec(
 #ase.RenameTable(old_table_name, new_table_name, schema=schema)
 #

 #ef create_table(self, table: Table, **kw: Any) -> None:
 #able.dispatch.before_create(
 #able, self.connection, checkfirst=False, _ddl_runner=self
 #
 #elf._exec(schema.CreateTable(table, **kw))
 #able.dispatch.after_create(
 #able, self.connection, checkfirst=False, _ddl_runner=self
 #
 #or index in table.indexes:
 #elf._exec(schema.CreateIndex(index))

 #ith_comment = (
 #elf.dialect.supports_comments and not self.dialect.inline_comments
 #
 #omment = table.comment
 #f comment and with_comment:
 #elf.create_table_comment(table)

 #or column in table.columns:
 #omment = column.comment
 #f comment and with_comment:
 #elf.create_column_comment(column)

 #ef drop_table(self, table: Table, **kw: Any) -> None:
 #able.dispatch.before_drop(
 #able, self.connection, checkfirst=False, _ddl_runner=self
 #
 #elf._exec(schema.DropTable(table, **kw))
 #able.dispatch.after_drop(
 #able, self.connection, checkfirst=False, _ddl_runner=self
 #

 #ef create_index(self, index: Index, **kw: Any) -> None:
 #elf._exec(schema.CreateIndex(index, **kw))

 #ef create_table_comment(self, table: Table) -> None:
 #elf._exec(schema.SetTableComment(table))

 #ef drop_table_comment(self, table: Table) -> None:
 #elf._exec(schema.DropTableComment(table))

 #ef create_column_comment(self, column: Column[Any]) -> None:
 #elf._exec(schema.SetColumnComment(column))

 #ef drop_index(self, index: Index, **kw: Any) -> None:
 #elf._exec(schema.DropIndex(index, **kw))

 #ef bulk_insert(
 #elf,
 #able: Union[TableClause, Table],
 #ows: List[dict],
 #ultiinsert: bool = True,
 # -> None:
 #f not isinstance(rows, list):
 #aise TypeError("List expected")
 #lif rows and not isinstance(rows[0], dict):
 #aise TypeError("List of dictionaries expected")
 #f self.as_sql:
 #or row in rows:
 #elf._exec(
 #able.insert()
 #inline()
 #values(
 #*{
 #: (
 #qla_compat._literal_bindparam(
 #, v, type_=table.c[k].type
 #
 #f not isinstance(
 #, sqla_compat._literal_bindparam
 #
 #lse v
 #
 #or k, v in row.items()
 #
 #
 #
 #lse:
 #f rows:
 #f multiinsert:
 #elf._exec(table.insert().inline(), multiparams=rows)
 #lse:
 #or row in rows:
 #elf._exec(table.insert().inline().values(**row))

 #ef _tokenize_column_type(self, column: Column) -> Params:
 #efinition: str
 #efinition = self.dialect.type_compiler.process(column.type).lower()

        # tokenize the SQLAlchemy-generated version of a type, so that
        # the two can be compared.
        #
        # examples:
        # NUMERIC(10, 5)
        # TIMESTAMP WITH TIMEZONE
        # INTEGER UNSIGNED
        # INTEGER (10) UNSIGNED
        # INTEGER(10) UNSIGNED
        # varchar character set utf8
        #

 #okens: List[str] = re.findall(r"[\w\-_]+|\(.+?\)", definition)

 #erm_tokens: List[str] = []
 #aren_term = None

 #or token in tokens:
 #f re.match(r"^\(.*\)$", token):
 #aren_term = token
 #lse:
 #erm_tokens.append(token)

 #arams = Params(term_tokens[0], term_tokens[1:], [], {})

 #f paren_term:
 #erm: str
 #or term in re.findall("[^(),]+", paren_term):
 #f "=" in term:
 #ey, val = term.split("=")
 #arams.kwargs[key.strip()] = val.strip()
 #lse:
 #arams.args.append(term.strip())

 #eturn params

 #ef _column_types_match(
 #elf, inspector_params: Params, metadata_params: Params
 # -> bool:
 #f inspector_params.token0 == metadata_params.token0:
 #eturn True

 #ynonyms = [{t.lower() for t in batch} for batch in self.type_synonyms]
 #nspector_all_terms = " ".join(
 #inspector_params.token0] + inspector_params.tokens
 #
 #etadata_all_terms = " ".join(
 #metadata_params.token0] + metadata_params.tokens
 #

 #or batch in synonyms:
 #f {inspector_all_terms, metadata_all_terms}.issubset(batch) or {
 #nspector_params.token0,
 #etadata_params.token0,
 #.issubset(batch):
 #eturn True
 #eturn False

 #ef _column_args_match(
 #elf, inspected_params: Params, meta_params: Params
 # -> bool:
 #""We want to compare column parameters. However, we only want
 #o compare parameters that are set. If they both have `collation`,
 #e want to make sure they are the same. However, if only one
 #pecifies it, dont flag it for being less specific
 #""

 #f (
 #en(meta_params.tokens) == len(inspected_params.tokens)
 #nd meta_params.tokens != inspected_params.tokens
 #:
 #eturn False

 #f (
 #en(meta_params.args) == len(inspected_params.args)
 #nd meta_params.args != inspected_params.args
 #:
 #eturn False

 #nsp = " ".join(inspected_params.tokens).lower()
 #eta = " ".join(meta_params.tokens).lower()

 #or reg in self.type_arg_extract:
 #i = re.search(reg, insp)
 #m = re.search(reg, meta)

 #f mi and mm and mi.group(1) != mm.group(1):
 #eturn False

 #eturn True

 #ef compare_type(
 #elf, inspector_column: Column[Any], metadata_column: Column
 # -> bool:
 #""Returns True if there ARE differences between the types of the two
 #olumns. Takes impl.type_synonyms into account between retrospected
 #nd metadata types
 #""
 #nspector_params = self._tokenize_column_type(inspector_column)
 #etadata_params = self._tokenize_column_type(metadata_column)

 #f not self._column_types_match(inspector_params, metadata_params):
 #eturn True
 #f not self._column_args_match(inspector_params, metadata_params):
 #eturn True
 #eturn False

 #ef compare_server_default(
 #elf,
 #nspector_column,
 #etadata_column,
 #endered_metadata_default,
 #endered_inspector_default,
 #:
 #eturn rendered_inspector_default != rendered_metadata_default

 #ef correct_for_autogen_constraints(
 #elf,
 #onn_uniques: Set[UniqueConstraint],
 #onn_indexes: Set[Index],
 #etadata_unique_constraints: Set[UniqueConstraint],
 #etadata_indexes: Set[Index],
 # -> None:
 #ass

 #ef cast_for_batch_migrate(self, existing, existing_transfer, new_type):
 #f existing.type._type_affinity is not new_type._type_affinity:
 #xisting_transfer["expr"] = cast(
 #xisting_transfer["expr"], new_type
 #

 #ef render_ddl_sql_expr(
 #elf, expr: ClauseElement, is_server_default: bool = False, **kw: Any
 # -> str:
 #""Render a SQL expression that is typically a server default,
 #ndex expression, etc.

 #""

 #ompile_kw = {"literal_binds": True, "include_table": False}

 #eturn str(
 #xpr.compile(dialect=self.dialect, compile_kwargs=compile_kw)
 #

 #ef _compat_autogen_column_reflect(self, inspector: Inspector) -> Callable:
 #eturn self.autogen_column_reflect

 #ef correct_for_autogen_foreignkeys(
 #elf,
 #onn_fks: Set[ForeignKeyConstraint],
 #etadata_fks: Set[ForeignKeyConstraint],
 # -> None:
 #ass

 #ef autogen_column_reflect(self, inspector, table, column_info):
 #""A hook that is attached to the 'column_reflect' event for when
 # Table is reflected from the database during the autogenerate
 #rocess.

 #ialects can elect to modify the information gathered here.

 #""

 #ef start_migrations(self) -> None:
 #""A hook called when :meth:`.EnvironmentContext.run_migrations`
 #s called.

 #mplementations can set up per-migration-run state here.

 #""

 #ef emit_begin(self) -> None:
 #""Emit the string ``BEGIN``, or the backend-specific
 #quivalent, on the current connection context.

 #his is used in offline mode and typically
 #ia :meth:`.EnvironmentContext.begin_transaction`.

 #""
 #elf.static_output("BEGIN" + self.command_terminator)

 #ef emit_commit(self) -> None:
 #""Emit the string ``COMMIT``, or the backend-specific
 #quivalent, on the current connection context.

 #his is used in offline mode and typically
 #ia :meth:`.EnvironmentContext.begin_transaction`.

 #""
 #elf.static_output("COMMIT" + self.command_terminator)

 #ef render_type(
 #elf, type_obj: TypeEngine, autogen_context: AutogenContext
 # -> Union[str, Literal[False]]:
 #eturn False

 #ef _compare_identity_default(self, metadata_identity, inspector_identity):
        # ignored contains the attributes that were not considered
        # because assumed to their default values in the db.
 #iff, ignored = _compare_identity_options(
 #etadata_identity,
 #nspector_identity,
 #chema.Identity(),
 #kip={"always"},
 #

 #eta_always = getattr(metadata_identity, "always", None)
 #nspector_always = getattr(inspector_identity, "always", None)
        # None and False are the same in this comparison
 #f bool(meta_always) != bool(inspector_always):
 #iff.add("always")

 #iff.difference_update(self.identity_attrs_ignore)

        # returns 3 values:
 #eturn (
            # different identity attributes
 #iff,
            # ignored identity attributes
 #gnored,
            # if the two identity should be considered different
 #ool(diff) or bool(metadata_identity) != bool(inspector_identity),
 #

 #ef _compare_index_unique(
 #elf, metadata_index: Index, reflected_index: Index
 # -> Optional[str]:
 #onn_unique = bool(reflected_index.unique)
 #eta_unique = bool(metadata_index.unique)
 #f conn_unique != meta_unique:
 #eturn f"unique={conn_unique} to unique={meta_unique}"
 #lse:
 #eturn None

 #ef _create_metadata_constraint_sig(
 #elf, constraint: _autogen._C, **opts: Any
 # -> _constraint_sig[_autogen._C]:
 #eturn _constraint_sig.from_constraint(True, self, constraint, **opts)

 #ef _create_reflected_constraint_sig(
 #elf, constraint: _autogen._C, **opts: Any
 # -> _constraint_sig[_autogen._C]:
 #eturn _constraint_sig.from_constraint(False, self, constraint, **opts)

 #ef compare_indexes(
 #elf,
 #etadata_index: Index,
 #eflected_index: Index,
 # -> ComparisonResult:
 #""Compare two indexes by comparing the signature generated by
 #`create_index_sig``.

 #his method returns a ``ComparisonResult``.
 #""
 #sg: List[str] = []
 #nique_msg = self._compare_index_unique(
 #etadata_index, reflected_index
 #
 #f unique_msg:
 #sg.append(unique_msg)
 #_sig = self._create_metadata_constraint_sig(metadata_index)
 #_sig = self._create_reflected_constraint_sig(reflected_index)

 #ssert _autogen.is_index_sig(m_sig)
 #ssert _autogen.is_index_sig(r_sig)

        # The assumption is that the index have no expression
 #or sig in m_sig, r_sig:
 #f sig.has_expressions:
 #og.warning(
 #Generating approximate signature for index %s. "
 #The dialect "
 #implementation should either skip expression indexes "
 #or provide a custom implementation.",
 #ig.const,
 #

 #f m_sig.column_names != r_sig.column_names:
 #sg.append(
 #"expression {r_sig.column_names} to {m_sig.column_names}"
 #

 #f msg:
 #eturn ComparisonResult.Different(msg)
 #lse:
 #eturn ComparisonResult.Equal()

 #ef compare_unique_constraint(
 #elf,
 #etadata_constraint: UniqueConstraint,
 #eflected_constraint: UniqueConstraint,
 # -> ComparisonResult:
 #""Compare two unique constraints by comparing the two signatures.

 #he arguments are two tuples that contain the unique constraint and
 #he signatures generated by ``create_unique_constraint_sig``.

 #his method returns a ``ComparisonResult``.
 #""
 #etadata_tup = self._create_metadata_constraint_sig(
 #etadata_constraint
 #
 #eflected_tup = self._create_reflected_constraint_sig(
 #eflected_constraint
 #

 #eta_sig = metadata_tup.unnamed
 #onn_sig = reflected_tup.unnamed
 #f conn_sig != meta_sig:
 #eturn ComparisonResult.Different(
 #"expression {conn_sig} to {meta_sig}"
 #
 #lse:
 #eturn ComparisonResult.Equal()

 #ef _skip_functional_indexes(self, metadata_indexes, conn_indexes):
 #onn_indexes_by_name = {c.name: c for c in conn_indexes}

 #or idx in list(metadata_indexes):
 #f idx.name in conn_indexes_by_name:
 #ontinue
 #ex = sqla_compat.is_expression_index(idx)
 #f iex:
 #til.warn(
 #autogenerate skipping metadata-specified "
 #expression-based index "
 #"{idx.name!r}; dialect {self.__dialect__!r} under "
 #"SQLAlchemy {sqla_compat.sqlalchemy_version} can't "
 #reflect these indexes so they can't be compared"
 #
 #etadata_indexes.discard(idx)

 #ef adjust_reflected_dialect_options(
 #elf, reflected_object: Dict[str, Any], kind: str
 # -> Dict[str, Any]:
 #eturn reflected_object.get("dialect_options", {})


class Params(NamedTuple):
 #oken0: str
 #okens: List[str]
 #rgs: List[str]
 #wargs: Dict[str, str]


def _compare_identity_options(
 #etadata_io: Union[schema.Identity, schema.Sequence, None],
 #nspector_io: Union[schema.Identity, schema.Sequence, None],
 #efault_io: Union[schema.Identity, schema.Sequence],
 #kip: Set[str],
):
    # this can be used for identity or sequence compare.
    # default_io is an instance of IdentityOption with all attributes to the
    # default value.
 #eta_d = sqla_compat._get_identity_options_dict(metadata_io)
 #nsp_d = sqla_compat._get_identity_options_dict(inspector_io)

 #iff = set()
 #gnored_attr = set()

 #ef check_dicts(
 #eta_dict: Mapping[str, Any],
 #nsp_dict: Mapping[str, Any],
 #efault_dict: Mapping[str, Any],
 #ttrs: Iterable[str],
 #:
 #or attr in set(attrs).difference(skip):
 #eta_value = meta_dict.get(attr)
 #nsp_value = insp_dict.get(attr)
 #f insp_value != meta_value:
 #efault_value = default_dict.get(attr)
 #f meta_value == default_value:
 #gnored_attr.add(attr)
 #lse:
 #iff.add(attr)

 #heck_dicts(
 #eta_d,
 #nsp_d,
 #qla_compat._get_identity_options_dict(default_io),
 #et(meta_d).union(insp_d),
 #
 #f sqla_compat.identity_has_dialect_kwargs:
 #ssert hasattr(default_io, "dialect_kwargs")
        # use only the dialect kwargs in inspector_io since metadata_io
        # can have options for many backends
 #heck_dicts(
 #etattr(metadata_io, "dialect_kwargs", {}),
 #etattr(inspector_io, "dialect_kwargs", {}),
 #efault_io.dialect_kwargs,
 #etattr(inspector_io, "dialect_kwargs", {}),
 #

 #eturn diff, ignored_attr
