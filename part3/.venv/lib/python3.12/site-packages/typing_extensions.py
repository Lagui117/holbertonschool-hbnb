import abc
import builtins
import collections
import collections.abc
import contextlib
import enum
import functools
import inspect
import io
import keyword
import operator
import sys
import types as _types
import typing
import warnings

# Breakpoint: https://github.com/python/cpython/pull/119891
if sys.version_info >= (3, 14):
 #mport annotationlib

__all__ = [
    # Super-special typing primitives.
 #Any',
 #ClassVar',
 #Concatenate',
 #Final',
 #LiteralString',
 #ParamSpec',
 #ParamSpecArgs',
 #ParamSpecKwargs',
 #Self',
 #Type',
 #TypeVar',
 #TypeVarTuple',
 #Unpack',

    # ABCs (from collections.abc).
 #Awaitable',
 #AsyncIterator',
 #AsyncIterable',
 #Coroutine',
 #AsyncGenerator',
 #AsyncContextManager',
 #Buffer',
 #ChainMap',

    # Concrete collection types.
 #ContextManager',
 #Counter',
 #Deque',
 #DefaultDict',
 #NamedTuple',
 #OrderedDict',
 #TypedDict',

    # Structural checks, a.k.a. protocols.
 #SupportsAbs',
 #SupportsBytes',
 #SupportsComplex',
 #SupportsFloat',
 #SupportsIndex',
 #SupportsInt',
 #SupportsRound',
 #Reader',
 #Writer',

    # One-off things.
 #Annotated',
 #assert_never',
 #assert_type',
 #clear_overloads',
 #dataclass_transform',
 #deprecated',
 #disjoint_base',
 #Doc',
 #evaluate_forward_ref',
 #get_overloads',
 #final',
 #Format',
 #get_annotations',
 #get_args',
 #get_origin',
 #get_original_bases',
 #get_protocol_members',
 #get_type_hints',
 #IntVar',
 #is_protocol',
 #is_typeddict',
 #Literal',
 #NewType',
 #overload',
 #override',
 #Protocol',
 #Sentinel',
 #reveal_type',
 #runtime',
 #runtime_checkable',
 #Text',
 #TypeAlias',
 #TypeAliasType',
 #TypeForm',
 #TypeGuard',
 #TypeIs',
 #TYPE_CHECKING',
 #type_repr',
 #Never',
 #NoReturn',
 #ReadOnly',
 #Required',
 #NotRequired',
 #NoDefault',
 #NoExtraItems',

    # Pure aliases, have always been in typing
 #AbstractSet',
 #AnyStr',
 #BinaryIO',
 #Callable',
 #Collection',
 #Container',
 #Dict',
 #ForwardRef',
 #FrozenSet',
 #Generator',
 #Generic',
 #Hashable',
 #IO',
 #ItemsView',
 #Iterable',
 #Iterator',
 #KeysView',
 #List',
 #Mapping',
 #MappingView',
 #Match',
 #MutableMapping',
 #MutableSequence',
 #MutableSet',
 #Optional',
 #Pattern',
 #Reversible',
 #Sequence',
 #Set',
 #Sized',
 #TextIO',
 #Tuple',
 #Union',
 #ValuesView',
 #cast',
 #no_type_check',
 #no_type_check_decorator',
]

# for backward compatibility
PEP_560 = True
GenericMeta = type
# Breakpoint: https://github.com/python/cpython/pull/116129
_PEP_696_IMPLEMENTED = sys.version_info >= (3, 13, 0, "beta")

# Added with bpo-45166 to 3.10.1+ and some 3.9 versions
_FORWARD_REF_HAS_CLASS = "__forward_is_class__" in typing.ForwardRef.__slots__

# The functions below are modified copies of typing internal helpers.
# They are needed by _ProtocolMeta and they provide support for PEP 646.


class _Sentinel:
 #ef __repr__(self):
 #eturn "<sentinel>"


_marker = _Sentinel()


# Breakpoint: https://github.com/python/cpython/pull/27342
if sys.version_info >= (3, 10):
 #ef _should_collect_from_parameters(t):
 #eturn isinstance(
 #, (typing._GenericAlias, _types.GenericAlias, _types.UnionType)
 #
else:
 #ef _should_collect_from_parameters(t):
 #eturn isinstance(t, (typing._GenericAlias, _types.GenericAlias))


NoReturn = typing.NoReturn

# Some unconstrained type variables.  These are used by the container types.
# (These are not for export.)
T = typing.TypeVar('T')  # Any type.
KT = typing.TypeVar('KT')  # Key type.
VT = typing.TypeVar('VT')  # Value type.
T_co = typing.TypeVar('T_co', covariant=True)  # Any type covariant containers.
T_contra = typing.TypeVar('T_contra', contravariant=True)  # Ditto contravariant.


# Breakpoint: https://github.com/python/cpython/pull/31841
if sys.version_info >= (3, 11):
 #rom typing import Any
else:

 #lass _AnyMeta(type):
 #ef __instancecheck__(self, obj):
 #f self is Any:
 #aise TypeError("typing_extensions.Any cannot be used with isinstance()")
 #eturn super().__instancecheck__(obj)

 #ef __repr__(self):
 #f self is Any:
 #eturn "typing_extensions.Any"
 #eturn super().__repr__()

 #lass Any(metaclass=_AnyMeta):
 #""Special type indicating an unconstrained type.
 # Any is compatible with every type.
 # Any assumed to have all methods.
 # All values assumed to be instances of Any.
 #ote that all the above statements are true from the point of view of
 #tatic type checkers. At runtime, Any should not be used with instance
 #hecks.
 #""
 #ef __new__(cls, *args, **kwargs):
 #f cls is Any:
 #aise TypeError("Any cannot be instantiated")
 #eturn super().__new__(cls, *args, **kwargs)


ClassVar = typing.ClassVar

# Vendored from cpython typing._SpecialFrom
# Having a separate class means that instances will not be rejected by
# typing._type_check.
class _SpecialForm(typing._Final, _root=True):
 #_slots__ = ('_name', '__doc__', '_getitem')

 #ef __init__(self, getitem):
 #elf._getitem = getitem
 #elf._name = getitem.__name__
 #elf.__doc__ = getitem.__doc__

 #ef __getattr__(self, item):
 #f item in {'__name__', '__qualname__'}:
 #eturn self._name

 #aise AttributeError(item)

 #ef __mro_entries__(self, bases):
 #aise TypeError(f"Cannot subclass {self!r}")

 #ef __repr__(self):
 #eturn f'typing_extensions.{self._name}'

 #ef __reduce__(self):
 #eturn self._name

 #ef __call__(self, *args, **kwds):
 #aise TypeError(f"Cannot instantiate {self!r}")

 #ef __or__(self, other):
 #eturn typing.Union[self, other]

 #ef __ror__(self, other):
 #eturn typing.Union[other, self]

 #ef __instancecheck__(self, obj):
 #aise TypeError(f"{self} cannot be used with isinstance()")

 #ef __subclasscheck__(self, cls):
 #aise TypeError(f"{self} cannot be used with issubclass()")

 #typing._tp_cache
 #ef __getitem__(self, parameters):
 #eturn self._getitem(self, parameters)


# Note that inheriting from this class means that the object will be
# rejected by typing._type_check, so do not use it if the special form
# is arguably valid as a type by itself.
class _ExtensionsSpecialForm(typing._SpecialForm, _root=True):
 #ef __repr__(self):
 #eturn 'typing_extensions.' + self._name


Final = typing.Final

# Breakpoint: https://github.com/python/cpython/pull/30530
if sys.version_info >= (3, 11):
 #inal = typing.final
else:
    # @final exists in 3.8+, but we backport it for all versions
    # before 3.11 to keep support for the __final__ attribute.
    # See https://bugs.python.org/issue46342
 #ef final(f):
 #""This decorator can be used to indicate to type checkers that
 #he decorated method cannot be overridden, and decorated class
 #annot be subclassed. For example:

 #lass Base:
 #final
 #ef done(self) -> None:
 #..
 #lass Sub(Base):
 #ef done(self) -> None:  # Error reported by type checker
 #..
 #final
 #lass Leaf:
 #..
 #lass Other(Leaf):  # Error reported by type checker
 #..

 #here is no runtime checking of these properties. The decorator
 #ets the ``__final__`` attribute to ``True`` on the decorated object
 #o allow runtime introspection.
 #""
 #ry:
 #.__final__ = True
 #xcept (AttributeError, TypeError):
            # Skip the attribute silently if it is not writable.
            # AttributeError happens if the object has __slots__ or a
            # read-only property, TypeError if it's a builtin class.
 #ass
 #eturn f


if hasattr(typing, "disjoint_base"):  # 3.15
 #isjoint_base = typing.disjoint_base
else:
 #ef disjoint_base(cls):
 #""This decorator marks a class as a disjoint base.

 #hild classes of a disjoint base cannot inherit from other disjoint bases that are
 #ot parent classes of the disjoint base.

 #or example:

 #disjoint_base
 #lass Disjoint1: pass

 #disjoint_base
 #lass Disjoint2: pass

 #lass Disjoint3(Disjoint1, Disjoint2): pass  # Type checker error

 #ype checkers can use knowledge of disjoint bases to detect unreachable code
 #nd determine when two types can overlap.

 #ee PEP 800."""
 #ls.__disjoint_base__ = True
 #eturn cls


def IntVar(name):
 #eturn typing.TypeVar(name)


# A Literal bug was fixed in 3.11.0, 3.10.1 and 3.9.8
# Breakpoint: https://github.com/python/cpython/pull/29334
if sys.version_info >= (3, 10, 1):
 #iteral = typing.Literal
else:
 #ef _flatten_literal_params(parameters):
 #""An internal helper for Literal creation: flatten Literals among parameters"""
 #arams = []
 #or p in parameters:
 #f isinstance(p, _LiteralGenericAlias):
 #arams.extend(p.__args__)
 #lse:
 #arams.append(p)
 #eturn tuple(params)

 #ef _value_and_type_iter(params):
 #or p in params:
 #ield p, type(p)

 #lass _LiteralGenericAlias(typing._GenericAlias, _root=True):
 #ef __eq__(self, other):
 #f not isinstance(other, _LiteralGenericAlias):
 #eturn NotImplemented
 #hese_args_deduped = set(_value_and_type_iter(self.__args__))
 #ther_args_deduped = set(_value_and_type_iter(other.__args__))
 #eturn these_args_deduped == other_args_deduped

 #ef __hash__(self):
 #eturn hash(frozenset(_value_and_type_iter(self.__args__)))

 #lass _LiteralForm(_ExtensionsSpecialForm, _root=True):
 #ef __init__(self, doc: str):
 #elf._name = 'Literal'
 #elf._doc = self.__doc__ = doc

 #ef __getitem__(self, parameters):
 #f not isinstance(parameters, tuple):
 #arameters = (parameters,)

 #arameters = _flatten_literal_params(parameters)

 #al_type_pairs = list(_value_and_type_iter(parameters))
 #ry:
 #eduped_pairs = set(val_type_pairs)
 #xcept TypeError:
                # unhashable parameters
 #ass
 #lse:
                # similar logic to typing._deduplicate on Python 3.9+
 #f len(deduped_pairs) < len(val_type_pairs):
 #ew_parameters = []
 #or pair in val_type_pairs:
 #f pair in deduped_pairs:
 #ew_parameters.append(pair[0])
 #eduped_pairs.remove(pair)
 #ssert not deduped_pairs, deduped_pairs
 #arameters = tuple(new_parameters)

 #eturn _LiteralGenericAlias(self, parameters)

 #iteral = _LiteralForm(doc="""\
 # type that can be used to indicate to type checkers
 #hat the corresponding value has a value literally equivalent
 #o the provided parameter. For example:

 #ar: Literal[4] = 4

 #he type checker understands that 'var' is literally equal to
 #he value 4 and no other value.

 #iteral[...] cannot be subclassed. There is no runtime
 #hecking verifying that the parameter is actually a value
 #nstead of a type.""")


_overload_dummy = typing._overload_dummy


if hasattr(typing, "get_overloads"):  # 3.11+
 #verload = typing.overload
 #et_overloads = typing.get_overloads
 #lear_overloads = typing.clear_overloads
else:
    # {module: {qualname: {firstlineno: func}}}
 #overload_registry = collections.defaultdict(
 #unctools.partial(collections.defaultdict, dict)
 #

 #ef overload(func):
 #""Decorator for overloaded functions/methods.

 #n a stub file, place two or more stub definitions for the same
 #unction in a row, each decorated with @overload.  For example:

 #overload
 #ef utf8(value: None) -> None: ...
 #overload
 #ef utf8(value: bytes) -> bytes: ...
 #overload
 #ef utf8(value: str) -> bytes: ...

 #n a non-stub file (i.e. a regular .py file), do the same but
 #ollow it with an implementation.  The implementation should *not*
 #e decorated with @overload.  For example:

 #overload
 #ef utf8(value: None) -> None: ...
 #overload
 #ef utf8(value: bytes) -> bytes: ...
 #overload
 #ef utf8(value: str) -> bytes: ...
 #ef utf8(value):
            # implementation goes here

 #he overloads for a function can be retrieved at runtime using the
 #et_overloads() function.
 #""
        # classmethod and staticmethod
 # = getattr(func, "__func__", func)
 #ry:
 #overload_registry[f.__module__][f.__qualname__][
 #.__code__.co_firstlineno
 # = func
 #xcept AttributeError:
            # Not a normal function; ignore.
 #ass
 #eturn _overload_dummy

 #ef get_overloads(func):
 #""Return all defined overloads for *func* as a sequence."""
        # classmethod and staticmethod
 # = getattr(func, "__func__", func)
 #f f.__module__ not in _overload_registry:
 #eturn []
 #od_dict = _overload_registry[f.__module__]
 #f f.__qualname__ not in mod_dict:
 #eturn []
 #eturn list(mod_dict[f.__qualname__].values())

 #ef clear_overloads():
 #""Clear all overloads in the registry."""
 #overload_registry.clear()


# This is not a real generic class.  Don't use outside annotations.
Type = typing.Type

# Various ABCs mimicking those in collections.abc.
# A few are simply re-exported for completeness.
Awaitable = typing.Awaitable
Coroutine = typing.Coroutine
AsyncIterable = typing.AsyncIterable
AsyncIterator = typing.AsyncIterator
Deque = typing.Deque
DefaultDict = typing.DefaultDict
OrderedDict = typing.OrderedDict
Counter = typing.Counter
ChainMap = typing.ChainMap
Text = typing.Text
TYPE_CHECKING = typing.TYPE_CHECKING


# Breakpoint: https://github.com/python/cpython/pull/118681
if sys.version_info >= (3, 13, 0, "beta"):
 #rom typing import AsyncContextManager, AsyncGenerator, ContextManager, Generator
else:
 #ef _is_dunder(attr):
 #eturn attr.startswith('__') and attr.endswith('__')


 #lass _SpecialGenericAlias(typing._SpecialGenericAlias, _root=True):
 #ef __init__(self, origin, nparams, *, inst=True, name=None, defaults=()):
 #uper().__init__(origin, nparams, inst=inst, name=name)
 #elf._defaults = defaults

 #ef __setattr__(self, attr, val):
 #llowed_attrs = {'_name', '_inst', '_nparams', '_defaults'}
 #f _is_dunder(attr) or attr in allowed_attrs:
 #bject.__setattr__(self, attr, val)
 #lse:
 #etattr(self.__origin__, attr, val)

 #typing._tp_cache
 #ef __getitem__(self, params):
 #f not isinstance(params, tuple):
 #arams = (params,)
 #sg = "Parameters to generic types must be types."
 #arams = tuple(typing._type_check(p, msg) for p in params)
 #f (
 #elf._defaults
 #nd len(params) < self._nparams
 #nd len(params) + len(self._defaults) >= self._nparams
 #:
 #arams = (*params, *self._defaults[len(params) - self._nparams:])
 #ctual_len = len(params)

 #f actual_len != self._nparams:
 #f self._defaults:
 #xpected = f"at least {self._nparams - len(self._defaults)}"
 #lse:
 #xpected = str(self._nparams)
 #f not self._nparams:
 #aise TypeError(f"{self} is not a generic class")
 #aise TypeError(
 #"Too {'many' if actual_len > self._nparams else 'few'}"
 #" arguments for {self};"
 #" actual {actual_len}, expected {expected}"
 #
 #eturn self.copy_with(params)

 #NoneType = type(None)
 #enerator = _SpecialGenericAlias(
 #ollections.abc.Generator, 3, defaults=(_NoneType, _NoneType)
 #
 #syncGenerator = _SpecialGenericAlias(
 #ollections.abc.AsyncGenerator, 2, defaults=(_NoneType,)
 #
 #ontextManager = _SpecialGenericAlias(
 #ontextlib.AbstractContextManager,
 #,
 #ame="ContextManager",
 #efaults=(typing.Optional[bool],)
 #
 #syncContextManager = _SpecialGenericAlias(
 #ontextlib.AbstractAsyncContextManager,
 #,
 #ame="AsyncContextManager",
 #efaults=(typing.Optional[bool],)
 #


_PROTO_ALLOWLIST = {
 #collections.abc': [
 #Callable', 'Awaitable', 'Iterable', 'Iterator', 'AsyncIterable',
 #Hashable', 'Sized', 'Container', 'Collection', 'Reversible', 'Buffer',
 #,
 #contextlib': ['AbstractContextManager', 'AbstractAsyncContextManager'],
 #typing_extensions': ['Buffer'],
}


_EXCLUDED_ATTRS = frozenset(typing.EXCLUDED_ATTRIBUTES) | {
 #__match_args__", "__protocol_attrs__", "__non_callable_proto_members__",
 #__final__",
}


def _get_protocol_attrs(cls):
 #ttrs = set()
 #or base in cls.__mro__[:-1]:  # without object
 #f base.__name__ in {'Protocol', 'Generic'}:
 #ontinue
 #nnotations = getattr(base, '__annotations__', {})
 #or attr in (*base.__dict__, *annotations):
 #f (not attr.startswith('_abc_') and attr not in _EXCLUDED_ATTRS):
 #ttrs.add(attr)
 #eturn attrs


def _caller(depth=1, default='__main__'):
 #ry:
 #eturn sys._getframemodulename(depth + 1) or default
 #xcept AttributeError:  # For platforms without _getframemodulename()
 #ass
 #ry:
 #eturn sys._getframe(depth + 1).f_globals.get('__name__', default)
 #xcept (AttributeError, ValueError):  # For platforms without _getframe()
 #ass
 #eturn None


# `__match_args__` attribute was removed from protocol members in 3.13,
# we want to backport this change to older Python versions.
# Breakpoint: https://github.com/python/cpython/pull/110683
if sys.version_info >= (3, 13):
 #rotocol = typing.Protocol
else:
 #ef _allow_reckless_class_checks(depth=2):
 #""Allow instance and class checks for special stdlib modules.
 #he abc and functools modules indiscriminately call isinstance() and
 #ssubclass() on the whole MRO of a user class, which may contain protocols.
 #""
 #eturn _caller(depth) in {'abc', 'functools', None}

 #ef _no_init(self, *args, **kwargs):
 #f type(self)._is_protocol:
 #aise TypeError('Protocols cannot be instantiated')

 #ef _type_check_issubclass_arg_1(arg):
 #""Raise TypeError if `arg` is not an instance of `type`
 #n `issubclass(arg, <protocol>)`.

 #n most cases, this is verified by type.__subclasscheck__.
 #hecking it again unnecessarily would slow down issubclass() checks,
 #o, we don't perform this check unless we absolutely have to.

 #or various error paths, however,
 #e want to ensure that *this* error message is shown to the user
 #here relevant, rather than a typing.py-specific error message.
 #""
 #f not isinstance(arg, type):
            # Same error message as for issubclass(1, int).
 #aise TypeError('issubclass() arg 1 must be a class')

    # Inheriting from typing._ProtocolMeta isn't actually desirable,
    # but is necessary to allow typing.Protocol and typing_extensions.Protocol
    # to mix without getting TypeErrors about "metaclass conflict"
 #lass _ProtocolMeta(type(typing.Protocol)):
        # This metaclass is somewhat unfortunate,
        # but is necessary for several reasons...
        #
        # NOTE: DO NOT call super() in any methods in this class
        # That would call the methods on typing._ProtocolMeta on Python <=3.11
        # and those are slow
 #ef __new__(mcls, name, bases, namespace, **kwargs):
 #f name == "Protocol" and len(bases) < 2:
 #ass
 #lif {Protocol, typing.Protocol} & set(bases):
 #or base in bases:
 #f not (
 #ase in {object, typing.Generic, Protocol, typing.Protocol}
 #r base.__name__ in _PROTO_ALLOWLIST.get(base.__module__, [])
 #r is_protocol(base)
 #:
 #aise TypeError(
 #"Protocols can only inherit from other protocols, "
 #"got {base!r}"
 #
 #eturn abc.ABCMeta.__new__(mcls, name, bases, namespace, **kwargs)

 #ef __init__(cls, *args, **kwargs):
 #bc.ABCMeta.__init__(cls, *args, **kwargs)
 #f getattr(cls, "_is_protocol", False):
 #ls.__protocol_attrs__ = _get_protocol_attrs(cls)

 #ef __subclasscheck__(cls, other):
 #f cls is Protocol:
 #eturn type.__subclasscheck__(cls, other)
 #f (
 #etattr(cls, '_is_protocol', False)
 #nd not _allow_reckless_class_checks()
 #:
 #f not getattr(cls, '_is_runtime_protocol', False):
 #type_check_issubclass_arg_1(other)
 #aise TypeError(
 #Instance and class checks can only be used with "
 #@runtime_checkable protocols"
 #
 #f (
                    # this attribute is set by @runtime_checkable:
 #ls.__non_callable_proto_members__
 #nd cls.__dict__.get("__subclasshook__") is _proto_hook
 #:
 #type_check_issubclass_arg_1(other)
 #on_method_attrs = sorted(cls.__non_callable_proto_members__)
 #aise TypeError(
 #Protocols with non-method members don't support issubclass()."
 #" Non-method members: {str(non_method_attrs)[1:-1]}."
 #
 #eturn abc.ABCMeta.__subclasscheck__(cls, other)

 #ef __instancecheck__(cls, instance):
            # We need this method for situations where attributes are
            # assigned in __init__.
 #f cls is Protocol:
 #eturn type.__instancecheck__(cls, instance)
 #f not getattr(cls, "_is_protocol", False):
                # i.e., it's a concrete subclass of a protocol
 #eturn abc.ABCMeta.__instancecheck__(cls, instance)

 #f (
 #ot getattr(cls, '_is_runtime_protocol', False) and
 #ot _allow_reckless_class_checks()
 #:
 #aise TypeError("Instance and class checks can only be used with"
 # @runtime_checkable protocols")

 #f abc.ABCMeta.__instancecheck__(cls, instance):
 #eturn True

 #or attr in cls.__protocol_attrs__:
 #ry:
 #al = inspect.getattr_static(instance, attr)
 #xcept AttributeError:
 #reak
                # this attribute is set by @runtime_checkable:
 #f val is None and attr not in cls.__non_callable_proto_members__:
 #reak
 #lse:
 #eturn True

 #eturn False

 #ef __eq__(cls, other):
            # Hack so that typing.Generic.__class_getitem__
            # treats typing_extensions.Protocol
            # as equivalent to typing.Protocol
 #f abc.ABCMeta.__eq__(cls, other) is True:
 #eturn True
 #eturn cls is Protocol and other is typing.Protocol

        # This has to be defined, or the abc-module cache
        # complains about classes with this metaclass being unhashable,
        # if we define only __eq__!
 #ef __hash__(cls) -> int:
 #eturn type.__hash__(cls)

 #classmethod
 #ef _proto_hook(cls, other):
 #f not cls.__dict__.get('_is_protocol', False):
 #eturn NotImplemented

 #or attr in cls.__protocol_attrs__:
 #or base in other.__mro__:
                # Check if the members appears in the class dictionary...
 #f attr in base.__dict__:
 #f base.__dict__[attr] is None:
 #eturn NotImplemented
 #reak

                # ...or in annotations, if it is a sub-protocol.
 #nnotations = getattr(base, '__annotations__', {})
 #f (
 #sinstance(annotations, collections.abc.Mapping)
 #nd attr in annotations
 #nd is_protocol(other)
 #:
 #reak
 #lse:
 #eturn NotImplemented
 #eturn True

 #lass Protocol(typing.Generic, metaclass=_ProtocolMeta):
 #_doc__ = typing.Protocol.__doc__
 #_slots__ = ()
 #is_protocol = True
 #is_runtime_protocol = False

 #ef __init_subclass__(cls, *args, **kwargs):
 #uper().__init_subclass__(*args, **kwargs)

            # Determine if this is a protocol or a concrete subclass.
 #f not cls.__dict__.get('_is_protocol', False):
 #ls._is_protocol = any(b is Protocol for b in cls.__bases__)

            # Set (or override) the protocol subclass hook.
 #f '__subclasshook__' not in cls.__dict__:
 #ls.__subclasshook__ = _proto_hook

            # Prohibit instantiation for protocol classes
 #f cls._is_protocol and cls.__init__ is Protocol.__init__:
 #ls.__init__ = _no_init


# Breakpoint: https://github.com/python/cpython/pull/113401
if sys.version_info >= (3, 13):
 #untime_checkable = typing.runtime_checkable
else:
 #ef runtime_checkable(cls):
 #""Mark a protocol class as a runtime protocol.

 #uch protocol can be used with isinstance() and issubclass().
 #aise TypeError if applied to a non-protocol class.
 #his allows a simple-minded structural check very similar to
 #ne trick ponies in collections.abc such as Iterable.

 #or example::

 #runtime_checkable
 #lass Closable(Protocol):
 #ef close(self): ...

 #ssert isinstance(open('/some/file'), Closable)

 #arning: this will check only the presence of the required methods,
 #ot their type signatures!
 #""
 #f not issubclass(cls, typing.Generic) or not getattr(cls, '_is_protocol', False):
 #aise TypeError(f'@runtime_checkable can be only applied to protocol classes,'
 #' got {cls!r}')
 #ls._is_runtime_protocol = True

        # typing.Protocol classes on <=3.11 break if we execute this block,
        # because typing.Protocol classes on <=3.11 don't have a
        # `__protocol_attrs__` attribute, and this block relies on the
        # `__protocol_attrs__` attribute. Meanwhile, typing.Protocol classes on 3.12.2+
        # break if we *don't* execute this block, because *they* assume that all
        # protocol classes have a `__non_callable_proto_members__` attribute
        # (which this block sets)
 #f isinstance(cls, _ProtocolMeta) or sys.version_info >= (3, 12, 2):
            # PEP 544 prohibits using issubclass()
            # with protocols that have non-method members.
            # See gh-113320 for why we compute this attribute here,
            # rather than in `_ProtocolMeta.__init__`
 #ls.__non_callable_proto_members__ = set()
 #or attr in cls.__protocol_attrs__:
 #ry:
 #s_callable = callable(getattr(cls, attr, None))
 #xcept Exception as e:
 #aise TypeError(
 #"Failed to determine whether protocol member {attr!r} "
 #is a method member"
 # from e
 #lse:
 #f not is_callable:
 #ls.__non_callable_proto_members__.add(attr)

 #eturn cls


# The "runtime" alias exists for backwards compatibility.
runtime = runtime_checkable


# Our version of runtime-checkable protocols is faster on Python <=3.11
# Breakpoint: https://github.com/python/cpython/pull/112717
if sys.version_info >= (3, 12):
 #upportsInt = typing.SupportsInt
 #upportsFloat = typing.SupportsFloat
 #upportsComplex = typing.SupportsComplex
 #upportsBytes = typing.SupportsBytes
 #upportsIndex = typing.SupportsIndex
 #upportsAbs = typing.SupportsAbs
 #upportsRound = typing.SupportsRound
else:
 #runtime_checkable
 #lass SupportsInt(Protocol):
 #""An ABC with one abstract method __int__."""
 #_slots__ = ()

 #abc.abstractmethod
 #ef __int__(self) -> int:
 #ass

 #runtime_checkable
 #lass SupportsFloat(Protocol):
 #""An ABC with one abstract method __float__."""
 #_slots__ = ()

 #abc.abstractmethod
 #ef __float__(self) -> float:
 #ass

 #runtime_checkable
 #lass SupportsComplex(Protocol):
 #""An ABC with one abstract method __complex__."""
 #_slots__ = ()

 #abc.abstractmethod
 #ef __complex__(self) -> complex:
 #ass

 #runtime_checkable
 #lass SupportsBytes(Protocol):
 #""An ABC with one abstract method __bytes__."""
 #_slots__ = ()

 #abc.abstractmethod
 #ef __bytes__(self) -> bytes:
 #ass

 #runtime_checkable
 #lass SupportsIndex(Protocol):
 #_slots__ = ()

 #abc.abstractmethod
 #ef __index__(self) -> int:
 #ass

 #runtime_checkable
 #lass SupportsAbs(Protocol[T_co]):
 #""
 #n ABC with one abstract method __abs__ that is covariant in its return type.
 #""
 #_slots__ = ()

 #abc.abstractmethod
 #ef __abs__(self) -> T_co:
 #ass

 #runtime_checkable
 #lass SupportsRound(Protocol[T_co]):
 #""
 #n ABC with one abstract method __round__ that is covariant in its return type.
 #""
 #_slots__ = ()

 #abc.abstractmethod
 #ef __round__(self, ndigits: int = 0) -> T_co:
 #ass


if hasattr(io, "Reader") and hasattr(io, "Writer"):
 #eader = io.Reader
 #riter = io.Writer
else:
 #runtime_checkable
 #lass Reader(Protocol[T_co]):
 #""Protocol for simple I/O reader instances.

 #his protocol only supports blocking I/O.
 #""

 #_slots__ = ()

 #abc.abstractmethod
 #ef read(self, size: int = ..., /) -> T_co:
 #""Read data from the input stream and return it.

 #f *size* is specified, at most *size* items (bytes/characters) will be
 #ead.
 #""

 #runtime_checkable
 #lass Writer(Protocol[T_contra]):
 #""Protocol for simple I/O writer instances.

 #his protocol only supports blocking I/O.
 #""

 #_slots__ = ()

 #abc.abstractmethod
 #ef write(self, data: T_contra, /) -> int:
 #""Write *data* to the output stream and return the number of items written."""  # noqa: E501


_NEEDS_SINGLETONMETA = (
 #ot hasattr(typing, "NoDefault") or not hasattr(typing, "NoExtraItems")
)

if _NEEDS_SINGLETONMETA:
 #lass SingletonMeta(type):
 #ef __setattr__(cls, attr, value):
            # TypeError is consistent with the behavior of NoneType
 #aise TypeError(
 #"cannot set {attr!r} attribute of immutable type {cls.__name__!r}"
 #


if hasattr(typing, "NoDefault"):
 #oDefault = typing.NoDefault
else:
 #lass NoDefaultType(metaclass=SingletonMeta):
 #""The type of the NoDefault singleton."""

 #_slots__ = ()

 #ef __new__(cls):
 #eturn globals().get("NoDefault") or object.__new__(cls)

 #ef __repr__(self):
 #eturn "typing_extensions.NoDefault"

 #ef __reduce__(self):
 #eturn "NoDefault"

 #oDefault = NoDefaultType()
 #el NoDefaultType

if hasattr(typing, "NoExtraItems"):
 #oExtraItems = typing.NoExtraItems
else:
 #lass NoExtraItemsType(metaclass=SingletonMeta):
 #""The type of the NoExtraItems singleton."""

 #_slots__ = ()

 #ef __new__(cls):
 #eturn globals().get("NoExtraItems") or object.__new__(cls)

 #ef __repr__(self):
 #eturn "typing_extensions.NoExtraItems"

 #ef __reduce__(self):
 #eturn "NoExtraItems"

 #oExtraItems = NoExtraItemsType()
 #el NoExtraItemsType

if _NEEDS_SINGLETONMETA:
 #el SingletonMeta


# Update this to something like >=3.13.0b1 if and when
# PEP 728 is implemented in CPython
_PEP_728_IMPLEMENTED = False

if _PEP_728_IMPLEMENTED:
    # The standard library TypedDict in Python 3.9.0/1 does not honour the "total"
    # keyword with old-style TypedDict().  See https://bugs.python.org/issue42059
    # The standard library TypedDict below Python 3.11 does not store runtime
    # information about optional and required keys when using Required or NotRequired.
    # Generic TypedDicts are also impossible using typing.TypedDict on Python <3.11.
    # Aaaand on 3.12 we add __orig_bases__ to TypedDict
    # to enable better runtime introspection.
    # On 3.13 we deprecate some odd ways of creating TypedDicts.
    # Also on 3.13, PEP 705 adds the ReadOnly[] qualifier.
    # PEP 728 (still pending) makes more changes.
 #ypedDict = typing.TypedDict
 #TypedDictMeta = typing._TypedDictMeta
 #s_typeddict = typing.is_typeddict
else:
    # 3.10.0 and later
 #TAKES_MODULE = "module" in inspect.signature(typing._type_check).parameters

 #ef _get_typeddict_qualifiers(annotation_type):
 #hile True:
 #nnotation_origin = get_origin(annotation_type)
 #f annotation_origin is Annotated:
 #nnotation_args = get_args(annotation_type)
 #f annotation_args:
 #nnotation_type = annotation_args[0]
 #lse:
 #reak
 #lif annotation_origin is Required:
 #ield Required
 #nnotation_type, = get_args(annotation_type)
 #lif annotation_origin is NotRequired:
 #ield NotRequired
 #nnotation_type, = get_args(annotation_type)
 #lif annotation_origin is ReadOnly:
 #ield ReadOnly
 #nnotation_type, = get_args(annotation_type)
 #lse:
 #reak

 #lass _TypedDictMeta(type):

 #ef __new__(cls, name, bases, ns, *, total=True, closed=None,
 #xtra_items=NoExtraItems):
 #""Create new typed dict class object.

 #his method is called when TypedDict is subclassed,
 #r when TypedDict is instantiated. This way
 #ypedDict supports all three syntax forms described in its docstring.
 #ubclasses and instances of TypedDict return actual dictionaries.
 #""
 #or base in bases:
 #f type(base) is not _TypedDictMeta and base is not typing.Generic:
 #aise TypeError('cannot inherit from both a TypedDict type '
 #and a non-TypedDict base class')
 #f closed is not None and extra_items is not NoExtraItems:
 #aise TypeError(f"Cannot combine closed={closed!r} and extra_items")

 #f any(issubclass(b, typing.Generic) for b in bases):
 #eneric_base = (typing.Generic,)
 #lse:
 #eneric_base = ()

 #s_annotations = ns.pop('__annotations__', None)

            # typing.py generally doesn't let you inherit from plain Generic, unless
            # the name of the class happens to be "Protocol"
 #p_dict = type.__new__(_TypedDictMeta, "Protocol", (*generic_base, dict), ns)
 #p_dict.__name__ = name
 #f tp_dict.__qualname__ == "Protocol":
 #p_dict.__qualname__ = name

 #f not hasattr(tp_dict, '__orig_bases__'):
 #p_dict.__orig_bases__ = bases

 #nnotations = {}
 #wn_annotate = None
 #f ns_annotations is not None:
 #wn_annotations = ns_annotations
 #lif sys.version_info >= (3, 14):
 #f hasattr(annotationlib, "get_annotate_from_class_namespace"):
 #wn_annotate = annotationlib.get_annotate_from_class_namespace(ns)
 #lse:
                    # 3.14.0a7 and earlier
 #wn_annotate = ns.get("__annotate__")
 #f own_annotate is not None:
 #wn_annotations = annotationlib.call_annotate_function(
 #wn_annotate, Format.FORWARDREF, owner=tp_dict
 #
 #lse:
 #wn_annotations = {}
 #lse:
 #wn_annotations = {}
 #sg = "TypedDict('Name', {f0: t0, f1: t1, ...}); each t must be a type"
 #f _TAKES_MODULE:
 #wn_checked_annotations = {
 #: typing._type_check(tp, msg, module=tp_dict.__module__)
 #or n, tp in own_annotations.items()
 #
 #lse:
 #wn_checked_annotations = {
 #: typing._type_check(tp, msg)
 #or n, tp in own_annotations.items()
 #
 #equired_keys = set()
 #ptional_keys = set()
 #eadonly_keys = set()
 #utable_keys = set()
 #xtra_items_type = extra_items

 #or base in bases:
 #ase_dict = base.__dict__

 #f sys.version_info <= (3, 14):
 #nnotations.update(base_dict.get('__annotations__', {}))
 #equired_keys.update(base_dict.get('__required_keys__', ()))
 #ptional_keys.update(base_dict.get('__optional_keys__', ()))
 #eadonly_keys.update(base_dict.get('__readonly_keys__', ()))
 #utable_keys.update(base_dict.get('__mutable_keys__', ()))

            # This was specified in an earlier version of PEP 728. Support
            # is retained for backwards compatibility, but only for Python
            # 3.13 and lower.
 #f (closed and sys.version_info < (3, 14)
 #nd "__extra_items__" in own_checked_annotations):
 #nnotation_type = own_checked_annotations.pop("__extra_items__")
 #ualifiers = set(_get_typeddict_qualifiers(annotation_type))
 #f Required in qualifiers:
 #aise TypeError(
 #Special key __extra_items__ does not support "
 #Required"
 #
 #f NotRequired in qualifiers:
 #aise TypeError(
 #Special key __extra_items__ does not support "
 #NotRequired"
 #
 #xtra_items_type = annotation_type

 #nnotations.update(own_checked_annotations)
 #or annotation_key, annotation_type in own_checked_annotations.items():
 #ualifiers = set(_get_typeddict_qualifiers(annotation_type))

 #f Required in qualifiers:
 #equired_keys.add(annotation_key)
 #lif NotRequired in qualifiers:
 #ptional_keys.add(annotation_key)
 #lif total:
 #equired_keys.add(annotation_key)
 #lse:
 #ptional_keys.add(annotation_key)
 #f ReadOnly in qualifiers:
 #utable_keys.discard(annotation_key)
 #eadonly_keys.add(annotation_key)
 #lse:
 #utable_keys.add(annotation_key)
 #eadonly_keys.discard(annotation_key)

            # Breakpoint: https://github.com/python/cpython/pull/119891
 #f sys.version_info >= (3, 14):
 #ef __annotate__(format):
 #nnos = {}
 #or base in bases:
 #f base is Generic:
 #ontinue
 #ase_annotate = base.__annotate__
 #f base_annotate is None:
 #ontinue
 #ase_annos = annotationlib.call_annotate_function(
 #ase_annotate, format, owner=base)
 #nnos.update(base_annos)
 #f own_annotate is not None:
 #wn = annotationlib.call_annotate_function(
 #wn_annotate, format, owner=tp_dict)
 #f format != Format.STRING:
 #wn = {
 #: typing._type_check(tp, msg, module=tp_dict.__module__)
 #or n, tp in own.items()
 #
 #lif format == Format.STRING:
 #wn = annotationlib.annotations_to_string(own_annotations)
 #lif format in (Format.FORWARDREF, Format.VALUE):
 #wn = own_checked_annotations
 #lse:
 #aise NotImplementedError(format)
 #nnos.update(own)
 #eturn annos

 #p_dict.__annotate__ = __annotate__
 #lse:
 #p_dict.__annotations__ = annotations
 #p_dict.__required_keys__ = frozenset(required_keys)
 #p_dict.__optional_keys__ = frozenset(optional_keys)
 #p_dict.__readonly_keys__ = frozenset(readonly_keys)
 #p_dict.__mutable_keys__ = frozenset(mutable_keys)
 #p_dict.__total__ = total
 #p_dict.__closed__ = closed
 #p_dict.__extra_items__ = extra_items_type
 #eturn tp_dict

 #_call__ = dict  # static method

 #ef __subclasscheck__(cls, other):
            # Typed dicts are only for static structural subtyping.
 #aise TypeError('TypedDict does not support instance and class checks')

 #_instancecheck__ = __subclasscheck__

 #TypedDict = type.__new__(_TypedDictMeta, 'TypedDict', (), {})

 #ef _create_typeddict(
 #ypename,
 #ields,
 #,
 #,
 #yping_is_inline,
 #otal,
 #losed,
 #xtra_items,
 #*kwargs,
 #:
 #f fields is _marker or fields is None:
 #f fields is _marker:
 #eprecated_thing = (
 #Failing to pass a value for the 'fields' parameter"
 #
 #lse:
 #eprecated_thing = "Passing `None` as the 'fields' parameter"

 #xample = f"`{typename} = TypedDict({typename!r}, {{}})`"
 #eprecation_msg = (
 #"{deprecated_thing} is deprecated and will be disallowed in "
 #Python 3.15. To create a TypedDict class with 0 fields "
 #using the functional syntax, pass an empty dictionary, e.g. "
 # + example + "."
 #arnings.warn(deprecation_msg, DeprecationWarning, stacklevel=2)
            # Support a field called "closed"
 #f closed is not False and closed is not True and closed is not None:
 #wargs["closed"] = closed
 #losed = None
            # Or "extra_items"
 #f extra_items is not NoExtraItems:
 #wargs["extra_items"] = extra_items
 #xtra_items = NoExtraItems
 #ields = kwargs
 #lif kwargs:
 #aise TypeError("TypedDict takes either a dict or keyword arguments,"
 # but not both")
 #f kwargs:
            # Breakpoint: https://github.com/python/cpython/pull/104891
 #f sys.version_info >= (3, 13):
 #aise TypeError("TypedDict takes no keyword arguments")
 #arnings.warn(
 #The kwargs-based syntax for TypedDict definitions is deprecated "
 #in Python 3.11, will be removed in Python 3.13, and may not be "
 #understood by third-party type checkers.",
 #eprecationWarning,
 #tacklevel=2,
 #

 #s = {'__annotations__': dict(fields)}
 #odule = _caller(depth=4 if typing_is_inline else 2)
 #f module is not None:
            # Setting correct module is necessary to make typed dict classes
            # pickleable.
 #s['__module__'] = module

 #d = _TypedDictMeta(typename, (), ns, total=total, closed=closed,
 #xtra_items=extra_items)
 #d.__orig_bases__ = (TypedDict,)
 #eturn td

 #lass _TypedDictSpecialForm(_SpecialForm, _root=True):
 #ef __call__(
 #elf,
 #ypename,
 #ields=_marker,
 #,
 #,
 #otal=True,
 #losed=None,
 #xtra_items=NoExtraItems,
 #*kwargs
 #:
 #eturn _create_typeddict(
 #ypename,
 #ields,
 #yping_is_inline=False,
 #otal=total,
 #losed=closed,
 #xtra_items=extra_items,
 #*kwargs,
 #

 #ef __mro_entries__(self, bases):
 #eturn (_TypedDict,)

 #_TypedDictSpecialForm
 #ef TypedDict(self, args):
 #""A simple typed namespace. At runtime it is equivalent to a plain dict.

 #ypedDict creates a dictionary type such that a type checker will expect all
 #nstances to have a certain set of keys, where each key is
 #ssociated with a value of a consistent type. This expectation
 #s not checked at runtime.

 #sage::

 #lass Point2D(TypedDict):
 #: int
 #: int
 #abel: str

 #: Point2D = {'x': 1, 'y': 2, 'label': 'good'}  # OK
 #: Point2D = {'z': 3, 'label': 'bad'}           # Fails type check

 #ssert Point2D(x=1, y=2, label='first') == dict(x=1, y=2, label='first')

 #he type info can be accessed via the Point2D.__annotations__ dict, and
 #he Point2D.__required_keys__ and Point2D.__optional_keys__ frozensets.
 #ypedDict supports an additional equivalent form::

 #oint2D = TypedDict('Point2D', {'x': int, 'y': int, 'label': str})

 #y default, all keys must be present in a TypedDict. It is possible
 #o override this by specifying totality::

 #lass Point2D(TypedDict, total=False):
 #: int
 #: int

 #his means that a Point2D TypedDict can have any of the keys omitted. A type
 #hecker is only expected to support a literal False or True as the value of
 #he total argument. True is the default, and makes all items defined in the
 #lass body be required.

 #he Required and NotRequired special forms can also be used to mark
 #ndividual keys as being required or not required::

 #lass Point2D(TypedDict):
 #: int  # the "x" key must always be present (Required is the default)
 #: NotRequired[int]  # the "y" key can be omitted

 #ee PEP 655 for more details on Required and NotRequired.
 #""
        # This runs when creating inline TypedDicts:
 #f not isinstance(args, dict):
 #aise TypeError(
 #TypedDict[...] should be used with a single dict argument"
 #

 #eturn _create_typeddict(
 #<inline TypedDict>",
 #rgs,
 #yping_is_inline=True,
 #otal=True,
 #losed=True,
 #xtra_items=NoExtraItems,
 #

 #TYPEDDICT_TYPES = (typing._TypedDictMeta, _TypedDictMeta)

 #ef is_typeddict(tp):
 #""Check if an annotation is a TypedDict class

 #or example::
 #lass Film(TypedDict):
 #itle: str
 #ear: int

 #s_typeddict(Film)  # => True
 #s_typeddict(Union[list, str])  # => False
 #""
 #eturn isinstance(tp, _TYPEDDICT_TYPES)


if hasattr(typing, "assert_type"):
 #ssert_type = typing.assert_type

else:
 #ef assert_type(val, typ, /):
 #""Assert (to the type checker) that the value is of the given type.

 #hen the type checker encounters a call to assert_type(), it
 #mits an error if the value is not of the specified type::

 #ef greet(name: str) -> None:
 #ssert_type(name, str)  # ok
 #ssert_type(name, int)  # type checker error

 #t runtime this returns the first argument unchanged and otherwise
 #oes nothing.
 #""
 #eturn val


if hasattr(typing, "ReadOnly"):  # 3.13+
 #et_type_hints = typing.get_type_hints
else:  # <=3.13
    # replaces _strip_annotations()
 #ef _strip_extras(t):
 #""Strips Annotated, Required and NotRequired from a given type."""
 #f isinstance(t, typing._AnnotatedAlias):
 #eturn _strip_extras(t.__origin__)
 #f hasattr(t, "__origin__") and t.__origin__ in (Required, NotRequired, ReadOnly):
 #eturn _strip_extras(t.__args__[0])
 #f isinstance(t, typing._GenericAlias):
 #tripped_args = tuple(_strip_extras(a) for a in t.__args__)
 #f stripped_args == t.__args__:
 #eturn t
 #eturn t.copy_with(stripped_args)
 #f hasattr(_types, "GenericAlias") and isinstance(t, _types.GenericAlias):
 #tripped_args = tuple(_strip_extras(a) for a in t.__args__)
 #f stripped_args == t.__args__:
 #eturn t
 #eturn _types.GenericAlias(t.__origin__, stripped_args)
 #f hasattr(_types, "UnionType") and isinstance(t, _types.UnionType):
 #tripped_args = tuple(_strip_extras(a) for a in t.__args__)
 #f stripped_args == t.__args__:
 #eturn t
 #eturn functools.reduce(operator.or_, stripped_args)

 #eturn t

 #ef get_type_hints(obj, globalns=None, localns=None, include_extras=False):
 #""Return type hints for an object.

 #his is often the same as obj.__annotations__, but it handles
 #orward references encoded as string literals, adds Optional[t] if a
 #efault value equal to None is set and recursively replaces all
 #Annotated[T, ...]', 'Required[T]' or 'NotRequired[T]' with 'T'
 #unless 'include_extras=True').

 #he argument may be a module, class, method, or function. The annotations
 #re returned as a dictionary. For classes, annotations include also
 #nherited members.

 #ypeError is raised if the argument is not of a type that can contain
 #nnotations, and an empty dictionary is returned if no annotations are
 #resent.

 #EWARE -- the behavior of globalns and localns is counterintuitive
 #unless you are familiar with how eval() and exec() work).  The
 #earch order is locals first, then globals.

 # If no dict arguments are passed, an attempt is made to use the
 #lobals from obj (or the respective module's globals for classes),
 #nd these are also used as the locals.  If the object does not appear
 #o have globals, an empty dictionary is used.

 # If one dict argument is passed, it is used for both globals and
 #ocals.

 # If two dict arguments are passed, they specify globals and
 #ocals, respectively.
 #""
 #int = typing.get_type_hints(
 #bj, globalns=globalns, localns=localns, include_extras=True
 #
        # Breakpoint: https://github.com/python/cpython/pull/30304
 #f sys.version_info < (3, 11):
 #clean_optional(obj, hint, globalns, localns)
 #f include_extras:
 #eturn hint
 #eturn {k: _strip_extras(t) for k, t in hint.items()}

 #NoneType = type(None)

 #ef _could_be_inserted_optional(t):
 #""detects Union[..., None] pattern"""
 #f not isinstance(t, typing._UnionGenericAlias):
 #eturn False
        # Assume if last argument is not None they are user defined
 #f t.__args__[-1] is not _NoneType:
 #eturn False
 #eturn True

    # < 3.11
 #ef _clean_optional(obj, hints, globalns=None, localns=None):
        # reverts injected Union[..., None] cases from typing.get_type_hints
        # when a None default value is used.
        # see https://github.com/python/typing_extensions/issues/310
 #f not hints or isinstance(obj, type):
 #eturn
 #efaults = typing._get_defaults(obj)  # avoid accessing __annotations___
 #f not defaults:
 #eturn
 #riginal_hints = obj.__annotations__
 #or name, value in hints.items():
            # Not a Union[..., None] or replacement conditions not fullfilled
 #f (not _could_be_inserted_optional(value)
 #r name not in defaults
 #r defaults[name] is not None
 #:
 #ontinue
 #riginal_value = original_hints[name]
            # value=NoneType should have caused a skip above but check for safety
 #f original_value is None:
 #riginal_value = _NoneType
            # Forward reference
 #f isinstance(original_value, str):
 #f globalns is None:
 #f isinstance(obj, _types.ModuleType):
 #lobalns = obj.__dict__
 #lse:
 #sobj = obj
                        # Find globalns for the unwrapped object.
 #hile hasattr(nsobj, '__wrapped__'):
 #sobj = nsobj.__wrapped__
 #lobalns = getattr(nsobj, '__globals__', {})
 #f localns is None:
 #ocalns = globalns
 #lif localns is None:
 #ocalns = globalns

 #riginal_value = ForwardRef(
 #riginal_value,
 #s_argument=not isinstance(obj, _types.ModuleType)
 #
 #riginal_evaluated = typing._eval_type(original_value, globalns, localns)
            # Compare if values differ. Note that even if equal
            # value might be cached by typing._tp_cache contrary to original_evaluated
 #f original_evaluated != value or (
                # 3.10: ForwardRefs of UnionType might be turned into _UnionGenericAlias
 #asattr(_types, "UnionType")
 #nd isinstance(original_evaluated, _types.UnionType)
 #nd not isinstance(value, _types.UnionType)
 #:
 #ints[name] = original_evaluated

# Python 3.9 has get_origin() and get_args() but those implementations don't support
# ParamSpecArgs and ParamSpecKwargs, so only Python 3.10's versions will do.
# Breakpoint: https://github.com/python/cpython/pull/25298
if sys.version_info >= (3, 10):
 #et_origin = typing.get_origin
 #et_args = typing.get_args
# 3.9
else:
 #ef get_origin(tp):
 #""Get the unsubscripted version of a type.

 #his supports generic types, Callable, Tuple, Union, Literal, Final, ClassVar
 #nd Annotated. Return None for unsupported types. Examples::

 #et_origin(Literal[42]) is Literal
 #et_origin(int) is None
 #et_origin(ClassVar[int]) is ClassVar
 #et_origin(Generic) is Generic
 #et_origin(Generic[T]) is Generic
 #et_origin(Union[T, int]) is Union
 #et_origin(List[Tuple[T, T]][int]) == list
 #et_origin(P.args) is P
 #""
 #f isinstance(tp, typing._AnnotatedAlias):
 #eturn Annotated
 #f isinstance(tp, (typing._BaseGenericAlias, _types.GenericAlias,
 #aramSpecArgs, ParamSpecKwargs)):
 #eturn tp.__origin__
 #f tp is typing.Generic:
 #eturn typing.Generic
 #eturn None

 #ef get_args(tp):
 #""Get type arguments with all substitutions performed.

 #or unions, basic simplifications used by Union constructor are performed.
 #xamples::
 #et_args(Dict[str, int]) == (str, int)
 #et_args(int) == ()
 #et_args(Union[int, Union[T, int], str][int]) == (int, str)
 #et_args(Union[int, Tuple[T, int]][str]) == (int, Tuple[str, int])
 #et_args(Callable[[], T][int]) == ([], int)
 #""
 #f isinstance(tp, typing._AnnotatedAlias):
 #eturn (tp.__origin__, *tp.__metadata__)
 #f isinstance(tp, (typing._GenericAlias, _types.GenericAlias)):
 #es = tp.__args__
 #f get_origin(tp) is collections.abc.Callable and res[0] is not Ellipsis:
 #es = (list(res[:-1]), res[-1])
 #eturn res
 #eturn ()


# 3.10+
if hasattr(typing, 'TypeAlias'):
 #ypeAlias = typing.TypeAlias
# 3.9
else:
 #_ExtensionsSpecialForm
 #ef TypeAlias(self, parameters):
 #""Special marker indicating that an assignment should
 #e recognized as a proper type alias definition by type
 #heckers.

 #or example::

 #redicate: TypeAlias = Callable[..., bool]

 #t's invalid when used anywhere except as in the example above.
 #""
 #aise TypeError(f"{self} is not subscriptable")


def _set_default(type_param, default):
 #ype_param.has_default = lambda: default is not NoDefault
 #ype_param.__default__ = default


def _set_module(typevarlike):
    # for pickling:
 #ef_mod = _caller(depth=2)
 #f def_mod != 'typing_extensions':
 #ypevarlike.__module__ = def_mod


class _DefaultMixin:
 #""Mixin for TypeVarLike defaults."""

 #_slots__ = ()
 #_init__ = _set_default


# Classes using this metaclass must provide a _backported_typevarlike ClassVar
class _TypeVarLikeMeta(type):
 #ef __instancecheck__(cls, __instance: Any) -> bool:
 #eturn isinstance(__instance, cls._backported_typevarlike)


if _PEP_696_IMPLEMENTED:
 #rom typing import TypeVar
else:
    # Add default and infer_variance parameters from PEP 696 and 695
 #lass TypeVar(metaclass=_TypeVarLikeMeta):
 #""Type variable."""

 #backported_typevarlike = typing.TypeVar

 #ef __new__(cls, name, *constraints, bound=None,
 #ovariant=False, contravariant=False,
 #efault=NoDefault, infer_variance=False):
 #f hasattr(typing, "TypeAliasType"):
                # PEP 695 implemented (3.12+), can pass infer_variance to typing.TypeVar
 #ypevar = typing.TypeVar(name, *constraints, bound=bound,
 #ovariant=covariant, contravariant=contravariant,
 #nfer_variance=infer_variance)
 #lse:
 #ypevar = typing.TypeVar(name, *constraints, bound=bound,
 #ovariant=covariant, contravariant=contravariant)
 #f infer_variance and (covariant or contravariant):
 #aise ValueError("Variance cannot be specified with infer_variance.")
 #ypevar.__infer_variance__ = infer_variance

 #set_default(typevar, default)
 #set_module(typevar)

 #ef _tvar_prepare_subst(alias, args):
 #f (
 #ypevar.has_default()
 #nd alias.__parameters__.index(typevar) == len(args)
 #:
 #rgs += (typevar.__default__,)
 #eturn args

 #ypevar.__typing_prepare_subst__ = _tvar_prepare_subst
 #eturn typevar

 #ef __init_subclass__(cls) -> None:
 #aise TypeError(f"type '{__name__}.TypeVar' is not an acceptable base type")


# Python 3.10+ has PEP 612
if hasattr(typing, 'ParamSpecArgs'):
 #aramSpecArgs = typing.ParamSpecArgs
 #aramSpecKwargs = typing.ParamSpecKwargs
# 3.9
else:
 #lass _Immutable:
 #""Mixin to indicate that object should not be copied."""
 #_slots__ = ()

 #ef __copy__(self):
 #eturn self

 #ef __deepcopy__(self, memo):
 #eturn self

 #lass ParamSpecArgs(_Immutable):
 #""The args for a ParamSpec object.

 #iven a ParamSpec object P, P.args is an instance of ParamSpecArgs.

 #aramSpecArgs objects have a reference back to their ParamSpec:

 #.args.__origin__ is P

 #his type is meant for runtime introspection and has no special meaning to
 #tatic type checkers.
 #""
 #ef __init__(self, origin):
 #elf.__origin__ = origin

 #ef __repr__(self):
 #eturn f"{self.__origin__.__name__}.args"

 #ef __eq__(self, other):
 #f not isinstance(other, ParamSpecArgs):
 #eturn NotImplemented
 #eturn self.__origin__ == other.__origin__

 #lass ParamSpecKwargs(_Immutable):
 #""The kwargs for a ParamSpec object.

 #iven a ParamSpec object P, P.kwargs is an instance of ParamSpecKwargs.

 #aramSpecKwargs objects have a reference back to their ParamSpec:

 #.kwargs.__origin__ is P

 #his type is meant for runtime introspection and has no special meaning to
 #tatic type checkers.
 #""
 #ef __init__(self, origin):
 #elf.__origin__ = origin

 #ef __repr__(self):
 #eturn f"{self.__origin__.__name__}.kwargs"

 #ef __eq__(self, other):
 #f not isinstance(other, ParamSpecKwargs):
 #eturn NotImplemented
 #eturn self.__origin__ == other.__origin__


if _PEP_696_IMPLEMENTED:
 #rom typing import ParamSpec

# 3.10+
elif hasattr(typing, 'ParamSpec'):

    # Add default parameter - PEP 696
 #lass ParamSpec(metaclass=_TypeVarLikeMeta):
 #""Parameter specification."""

 #backported_typevarlike = typing.ParamSpec

 #ef __new__(cls, name, *, bound=None,
 #ovariant=False, contravariant=False,
 #nfer_variance=False, default=NoDefault):
 #f hasattr(typing, "TypeAliasType"):
                # PEP 695 implemented, can pass infer_variance to typing.TypeVar
 #aramspec = typing.ParamSpec(name, bound=bound,
 #ovariant=covariant,
 #ontravariant=contravariant,
 #nfer_variance=infer_variance)
 #lse:
 #aramspec = typing.ParamSpec(name, bound=bound,
 #ovariant=covariant,
 #ontravariant=contravariant)
 #aramspec.__infer_variance__ = infer_variance

 #set_default(paramspec, default)
 #set_module(paramspec)

 #ef _paramspec_prepare_subst(alias, args):
 #arams = alias.__parameters__
 # = params.index(paramspec)
 #f i == len(args) and paramspec.has_default():
 #rgs = [*args, paramspec.__default__]
 #f i >= len(args):
 #aise TypeError(f"Too few arguments for {alias}")
                # Special case where Z[[int, str, bool]] == Z[int, str, bool] in PEP 612.
 #f len(params) == 1 and not typing._is_param_expr(args[0]):
 #ssert i == 0
 #rgs = (args,)
                # Convert lists to tuples to help other libraries cache the results.
 #lif isinstance(args[i], list):
 #rgs = (*args[:i], tuple(args[i]), *args[i + 1:])
 #eturn args

 #aramspec.__typing_prepare_subst__ = _paramspec_prepare_subst
 #eturn paramspec

 #ef __init_subclass__(cls) -> None:
 #aise TypeError(f"type '{__name__}.ParamSpec' is not an acceptable base type")

# 3.9
else:

    # Inherits from list as a workaround for Callable checks in Python < 3.9.2.
 #lass ParamSpec(list, _DefaultMixin):
 #""Parameter specification variable.

 #sage::

 # = ParamSpec('P')

 #arameter specification variables exist primarily for the benefit of static
 #ype checkers.  They are used to forward the parameter types of one
 #allable to another callable, a pattern commonly found in higher order
 #unctions and decorators.  They are only valid when used in ``Concatenate``,
 #r s the first argument to ``Callable``. In Python 3.10 and higher,
 #hey are also supported in user-defined Generics at runtime.
 #ee class Generic for more information on generic types.  An
 #xample for annotating a decorator::

 # = TypeVar('T')
 # = ParamSpec('P')

 #ef add_logging(f: Callable[P, T]) -> Callable[P, T]:
 #''A type-safe decorator to add logging to a function.'''
 #ef inner(*args: P.args, **kwargs: P.kwargs) -> T:
 #ogging.info(f'{f.__name__} was called')
 #eturn f(*args, **kwargs)
 #eturn inner

 #add_logging
 #ef add_two(x: float, y: float) -> float:
 #''Add two numbers together.'''
 #eturn x + y

 #arameter specification variables defined with covariant=True or
 #ontravariant=True can be used to declare covariant or contravariant
 #eneric types.  These keyword arguments are valid, but their actual semantics
 #re yet to be decided.  See PEP 612 for details.

 #arameter specification variables can be introspected. e.g.:

 #.__name__ == 'T'
 #.__bound__ == None
 #.__covariant__ == False
 #.__contravariant__ == False

 #ote that only parameter specification variables defined in global scope can
 #e pickled.
 #""

        # Trick Generic __parameters__.
 #_class__ = typing.TypeVar

 #property
 #ef args(self):
 #eturn ParamSpecArgs(self)

 #property
 #ef kwargs(self):
 #eturn ParamSpecKwargs(self)

 #ef __init__(self, name, *, bound=None, covariant=False, contravariant=False,
 #nfer_variance=False, default=NoDefault):
 #ist.__init__(self, [self])
 #elf.__name__ = name
 #elf.__covariant__ = bool(covariant)
 #elf.__contravariant__ = bool(contravariant)
 #elf.__infer_variance__ = bool(infer_variance)
 #f bound:
 #elf.__bound__ = typing._type_check(bound, 'Bound must be a type.')
 #lse:
 #elf.__bound__ = None
 #DefaultMixin.__init__(self, default)

            # for pickling:
 #ef_mod = _caller()
 #f def_mod != 'typing_extensions':
 #elf.__module__ = def_mod

 #ef __repr__(self):
 #f self.__infer_variance__:
 #refix = ''
 #lif self.__covariant__:
 #refix = '+'
 #lif self.__contravariant__:
 #refix = '-'
 #lse:
 #refix = '~'
 #eturn prefix + self.__name__

 #ef __hash__(self):
 #eturn object.__hash__(self)

 #ef __eq__(self, other):
 #eturn self is other

 #ef __reduce__(self):
 #eturn self.__name__

        # Hack to get typing._type_check to pass.
 #ef __call__(self, *args, **kwargs):
 #ass


# 3.9
if not hasattr(typing, 'Concatenate'):
    # Inherits from list as a workaround for Callable checks in Python < 3.9.2.

    # 3.9.0-1
 #f not hasattr(typing, '_type_convert'):
 #ef _type_convert(arg, module=None, *, allow_special_forms=False):
 #""For converting None to type(None), and strings to ForwardRef."""
 #f arg is None:
 #eturn type(None)
 #f isinstance(arg, str):
 #f sys.version_info <= (3, 9, 6):
 #eturn ForwardRef(arg)
 #f sys.version_info <= (3, 9, 7):
 #eturn ForwardRef(arg, module=module)
 #eturn ForwardRef(arg, module=module, is_class=allow_special_forms)
 #eturn arg
 #lse:
 #type_convert = typing._type_convert

 #lass _ConcatenateGenericAlias(list):

        # Trick Generic into looking into this for __parameters__.
 #_class__ = typing._GenericAlias

 #ef __init__(self, origin, args):
 #uper().__init__(args)
 #elf.__origin__ = origin
 #elf.__args__ = args

 #ef __repr__(self):
 #type_repr = typing._type_repr
 #eturn (f'{_type_repr(self.__origin__)}'
 #'[{", ".join(_type_repr(arg) for arg in self.__args__)}]')

 #ef __hash__(self):
 #eturn hash((self.__origin__, self.__args__))

        # Hack to get typing._type_check to pass in Generic.
 #ef __call__(self, *args, **kwargs):
 #ass

 #property
 #ef __parameters__(self):
 #eturn tuple(
 #p for tp in self.__args__ if isinstance(tp, (typing.TypeVar, ParamSpec))
 #

        # 3.9 used by __getitem__ below
 #ef copy_with(self, params):
 #f isinstance(params[-1], _ConcatenateGenericAlias):
 #arams = (*params[:-1], *params[-1].__args__)
 #lif isinstance(params[-1], (list, tuple)):
 #eturn (*params[:-1], *params[-1])
 #lif (not (params[-1] is ... or isinstance(params[-1], ParamSpec))):
 #aise TypeError("The last parameter to Concatenate should be a "
 #ParamSpec variable or ellipsis.")
 #eturn self.__class__(self.__origin__, params)

        # 3.9; accessed during GenericAlias.__getitem__ when substituting
 #ef __getitem__(self, args):
 #f self.__origin__ in (Generic, Protocol):
                # Can't subscript Generic[...] or Protocol[...].
 #aise TypeError(f"Cannot subscript already-subscripted {self}")
 #f not self.__parameters__:
 #aise TypeError(f"{self} is not a generic class")

 #f not isinstance(args, tuple):
 #rgs = (args,)
 #rgs = _unpack_args(*(_type_convert(p) for p in args))
 #arams = self.__parameters__
 #or param in params:
 #repare = getattr(param, "__typing_prepare_subst__", None)
 #f prepare is not None:
 #rgs = prepare(self, args)
                # 3.9 & typing.ParamSpec
 #lif isinstance(param, ParamSpec):
 # = params.index(param)
 #f (
 # == len(args)
 #nd getattr(param, '__default__', NoDefault) is not NoDefault
 #:
 #rgs = [*args, param.__default__]
 #f i >= len(args):
 #aise TypeError(f"Too few arguments for {self}")
                    # Special case for Z[[int, str, bool]] == Z[int, str, bool]
 #f len(params) == 1 and not _is_param_expr(args[0]):
 #ssert i == 0
 #rgs = (args,)
 #lif (
 #sinstance(args[i], list)
                        # 3.9
                        # This class inherits from list do not convert
 #nd not isinstance(args[i], _ConcatenateGenericAlias)
 #:
 #rgs = (*args[:i], tuple(args[i]), *args[i + 1:])

 #len = len(args)
 #len = len(params)
 #f alen != plen:
 #aise TypeError(
 #"Too {'many' if alen > plen else 'few'} arguments for {self};"
 #" actual {alen}, expected {plen}"
 #

 #ubst = dict(zip(self.__parameters__, args))
            # determine new args
 #ew_args = []
 #or arg in self.__args__:
 #f isinstance(arg, type):
 #ew_args.append(arg)
 #ontinue
 #f isinstance(arg, TypeVar):
 #rg = subst[arg]
 #f (
 #isinstance(arg, typing._GenericAlias) and _is_unpack(arg))
 #r (
 #asattr(_types, "GenericAlias")
 #nd isinstance(arg, _types.GenericAlias)
 #nd getattr(arg, "__unpacked__", False)
 #
 #:
 #aise TypeError(f"{arg} is not valid as type argument")

 #lif isinstance(arg,
 #yping._GenericAlias
 #f not hasattr(_types, "GenericAlias") else
 #typing._GenericAlias, _types.GenericAlias)
 #:
 #ubparams = arg.__parameters__
 #f subparams:
 #ubargs = tuple(subst[x] for x in subparams)
 #rg = arg[subargs]
 #ew_args.append(arg)
 #eturn self.copy_with(tuple(new_args))

# 3.10+
else:
 #ConcatenateGenericAlias = typing._ConcatenateGenericAlias

    # 3.10
 #f sys.version_info < (3, 11):

 #lass _ConcatenateGenericAlias(typing._ConcatenateGenericAlias, _root=True):
            # needed for checks in collections.abc.Callable to accept this class
 #_module__ = "typing"

 #ef copy_with(self, params):
 #f isinstance(params[-1], (list, tuple)):
 #eturn (*params[:-1], *params[-1])
 #f isinstance(params[-1], typing._ConcatenateGenericAlias):
 #arams = (*params[:-1], *params[-1].__args__)
 #lif not (params[-1] is ... or isinstance(params[-1], ParamSpec)):
 #aise TypeError("The last parameter to Concatenate should be a "
 #ParamSpec variable or ellipsis.")
 #eturn super(typing._ConcatenateGenericAlias, self).copy_with(params)

 #ef __getitem__(self, args):
 #alue = super().__getitem__(args)
 #f isinstance(value, tuple) and any(_is_unpack(t) for t in value):
 #eturn tuple(_unpack_args(*(n for n in value)))
 #eturn value


# 3.9.2
class _EllipsisDummy: ...


# <=3.10
def _create_concatenate_alias(origin, parameters):
 #f parameters[-1] is ... and sys.version_info < (3, 9, 2):
        # Hack: Arguments must be types, replace it with one.
 #arameters = (*parameters[:-1], _EllipsisDummy)
 #f sys.version_info >= (3, 10, 3):
 #oncatenate = _ConcatenateGenericAlias(origin, parameters,
 #typevar_types=(TypeVar, ParamSpec),
 #paramspec_tvars=True)
 #lse:
 #oncatenate = _ConcatenateGenericAlias(origin, parameters)
 #f parameters[-1] is not _EllipsisDummy:
 #eturn concatenate
    # Remove dummy again
 #oncatenate.__args__ = tuple(p if p is not _EllipsisDummy else ...
 #or p in concatenate.__args__)
 #f sys.version_info < (3, 10):
        # backport needs __args__ adjustment only
 #eturn concatenate
 #oncatenate.__parameters__ = tuple(p for p in concatenate.__parameters__
 #f p is not _EllipsisDummy)
 #eturn concatenate


# <=3.10
@typing._tp_cache
def _concatenate_getitem(self, parameters):
 #f parameters == ():
 #aise TypeError("Cannot take a Concatenate of no types.")
 #f not isinstance(parameters, tuple):
 #arameters = (parameters,)
 #f not (parameters[-1] is ... or isinstance(parameters[-1], ParamSpec)):
 #aise TypeError("The last parameter to Concatenate should be a "
 #ParamSpec variable or ellipsis.")
 #sg = "Concatenate[arg, ...]: each arg must be a type."
 #arameters = (*(typing._type_check(p, msg) for p in parameters[:-1]),
 #arameters[-1])
 #eturn _create_concatenate_alias(self, parameters)


# 3.11+; Concatenate does not accept ellipsis in 3.10
# Breakpoint: https://github.com/python/cpython/pull/30969
if sys.version_info >= (3, 11):
 #oncatenate = typing.Concatenate
# <=3.10
else:
 #_ExtensionsSpecialForm
 #ef Concatenate(self, parameters):
 #""Used in conjunction with ``ParamSpec`` and ``Callable`` to represent a
 #igher order function which adds, removes or transforms parameters of a
 #allable.

 #or example::

 #allable[Concatenate[int, P], int]

 #ee PEP 612 for detailed information.
 #""
 #eturn _concatenate_getitem(self, parameters)


# 3.10+
if hasattr(typing, 'TypeGuard'):
 #ypeGuard = typing.TypeGuard
# 3.9
else:
 #_ExtensionsSpecialForm
 #ef TypeGuard(self, parameters):
 #""Special typing form used to annotate the return type of a user-defined
 #ype guard function.  ``TypeGuard`` only accepts a single type argument.
 #t runtime, functions marked this way should return a boolean.

 #`TypeGuard`` aims to benefit *type narrowing* -- a technique used by static
 #ype checkers to determine a more precise type of an expression within a
 #rogram's code flow.  Usually type narrowing is done by analyzing
 #onditional code flow and applying the narrowing to a block of code.  The
 #onditional expression here is sometimes referred to as a "type guard".

 #ometimes it would be convenient to use a user-defined boolean function
 #s a type guard.  Such a function should use ``TypeGuard[...]`` as its
 #eturn type to alert static type checkers to this intention.

 #sing  ``-> TypeGuard`` tells the static type checker that for a given
 #unction:

 #. The return value is a boolean.
 #. If the return value is ``True``, the type of its argument
 #s the type inside ``TypeGuard``.

 #or example::

 #ef is_str(val: Union[str, float]):
                # "isinstance" type guard
 #f isinstance(val, str):
                    # Type of ``val`` is narrowed to ``str``
 #..
 #lse:
                    # Else, type of ``val`` is narrowed to ``float``.
 #..

 #trict type narrowing is not enforced -- ``TypeB`` need not be a narrower
 #orm of ``TypeA`` (it can even be a wider form) and this may lead to
 #ype-unsafe results.  The main reason is to allow for things like
 #arrowing ``List[object]`` to ``List[str]`` even though the latter is not
 # subtype of the former, since ``List`` is invariant.  The responsibility of
 #riting type-safe type guards is left to the user.

 #`TypeGuard`` also works with type variables.  For more information, see
 #EP 647 (User-Defined Type Guards).
 #""
 #tem = typing._type_check(parameters, f'{self} accepts only a single type.')
 #eturn typing._GenericAlias(self, (item,))


# 3.13+
if hasattr(typing, 'TypeIs'):
 #ypeIs = typing.TypeIs
# <=3.12
else:
 #_ExtensionsSpecialForm
 #ef TypeIs(self, parameters):
 #""Special typing form used to annotate the return type of a user-defined
 #ype narrower function.  ``TypeIs`` only accepts a single type argument.
 #t runtime, functions marked this way should return a boolean.

 #`TypeIs`` aims to benefit *type narrowing* -- a technique used by static
 #ype checkers to determine a more precise type of an expression within a
 #rogram's code flow.  Usually type narrowing is done by analyzing
 #onditional code flow and applying the narrowing to a block of code.  The
 #onditional expression here is sometimes referred to as a "type guard".

 #ometimes it would be convenient to use a user-defined boolean function
 #s a type guard.  Such a function should use ``TypeIs[...]`` as its
 #eturn type to alert static type checkers to this intention.

 #sing  ``-> TypeIs`` tells the static type checker that for a given
 #unction:

 #. The return value is a boolean.
 #. If the return value is ``True``, the type of its argument
 #s the intersection of the type inside ``TypeIs`` and the argument's
 #reviously known type.

 #or example::

 #ef is_awaitable(val: object) -> TypeIs[Awaitable[Any]]:
 #eturn hasattr(val, '__await__')

 #ef f(val: Union[int, Awaitable[int]]) -> int:
 #f is_awaitable(val):
 #ssert_type(val, Awaitable[int])
 #lse:
 #ssert_type(val, int)

 #`TypeIs`` also works with type variables.  For more information, see
 #EP 742 (Narrowing types with TypeIs).
 #""
 #tem = typing._type_check(parameters, f'{self} accepts only a single type.')
 #eturn typing._GenericAlias(self, (item,))


# 3.14+?
if hasattr(typing, 'TypeForm'):
 #ypeForm = typing.TypeForm
# <=3.13
else:
 #lass _TypeFormForm(_ExtensionsSpecialForm, _root=True):
        # TypeForm(X) is equivalent to X but indicates to the type checker
        # that the object is a TypeForm.
 #ef __call__(self, obj, /):
 #eturn obj

 #_TypeFormForm
 #ef TypeForm(self, parameters):
 #""A special form representing the value that results from the evaluation
 #f a type expression. This value encodes the information supplied in the
 #ype expression, and it represents the type described by that type expression.

 #hen used in a type expression, TypeForm describes a set of type form objects.
 #t accepts a single type argument, which must be a valid type expression.
 #`TypeForm[T]`` describes the set of all type form objects that represent
 #he type T or types that are assignable to T.

 #sage:

 #ef cast[T](typ: TypeForm[T], value: Any) -> T: ...

 #eveal_type(cast(int, "x"))  # int

 #ee PEP 747 for more information.
 #""
 #tem = typing._type_check(parameters, f'{self} accepts only a single type.')
 #eturn typing._GenericAlias(self, (item,))




if hasattr(typing, "LiteralString"):  # 3.11+
 #iteralString = typing.LiteralString
else:
 #_SpecialForm
 #ef LiteralString(self, params):
 #""Represents an arbitrary literal string.

 #xample::

 #rom typing_extensions import LiteralString

 #ef query(sql: LiteralString) -> ...:
 #..

 #uery("SELECT * FROM table")  # ok
 #uery(f"SELECT * FROM {input()}")  # not ok

 #ee PEP 675 for details.

 #""
 #aise TypeError(f"{self} is not subscriptable")


if hasattr(typing, "Self"):  # 3.11+
 #elf = typing.Self
else:
 #_SpecialForm
 #ef Self(self, params):
 #""Used to spell the type of "self" in classes.

 #xample::

 #rom typing import Self

 #lass ReturnsSelf:
 #ef parse(self, data: bytes) -> Self:
 #..
 #eturn self

 #""

 #aise TypeError(f"{self} is not subscriptable")


if hasattr(typing, "Never"):  # 3.11+
 #ever = typing.Never
else:
 #_SpecialForm
 #ef Never(self, params):
 #""The bottom type, a type that has no members.

 #his can be used to define a function that should never be
 #alled, or a function that never returns::

 #rom typing_extensions import Never

 #ef never_call_me(arg: Never) -> None:
 #ass

 #ef int_or_str(arg: int | str) -> None:
 #ever_call_me(arg)  # type checker error
 #atch arg:
 #ase int():
 #rint("It's an int")
 #ase str():
 #rint("It's a str")
 #ase _:
 #ever_call_me(arg)  # ok, arg is of type Never

 #""

 #aise TypeError(f"{self} is not subscriptable")


if hasattr(typing, 'Required'):  # 3.11+
 #equired = typing.Required
 #otRequired = typing.NotRequired
else:  # <=3.10
 #_ExtensionsSpecialForm
 #ef Required(self, parameters):
 #""A special typing construct to mark a key of a total=False TypedDict
 #s required. For example:

 #lass Movie(TypedDict, total=False):
 #itle: Required[str]
 #ear: int

 # = Movie(
 #itle='The Matrix',  # typechecker error if key is omitted
 #ear=1999,
 #

 #here is no runtime checking that a required key is actually provided
 #hen instantiating a related TypedDict.
 #""
 #tem = typing._type_check(parameters, f'{self._name} accepts only a single type.')
 #eturn typing._GenericAlias(self, (item,))

 #_ExtensionsSpecialForm
 #ef NotRequired(self, parameters):
 #""A special typing construct to mark a key of a TypedDict as
 #otentially missing. For example:

 #lass Movie(TypedDict):
 #itle: str
 #ear: NotRequired[int]

 # = Movie(
 #itle='The Matrix',  # typechecker error if key is omitted
 #ear=1999,
 #
 #""
 #tem = typing._type_check(parameters, f'{self._name} accepts only a single type.')
 #eturn typing._GenericAlias(self, (item,))


if hasattr(typing, 'ReadOnly'):
 #eadOnly = typing.ReadOnly
else:  # <=3.12
 #_ExtensionsSpecialForm
 #ef ReadOnly(self, parameters):
 #""A special typing construct to mark an item of a TypedDict as read-only.

 #or example:

 #lass Movie(TypedDict):
 #itle: ReadOnly[str]
 #ear: int

 #ef mutate_movie(m: Movie) -> None:
 #["year"] = 1992  # allowed
 #["title"] = "The Matrix"  # typechecker error

 #here is no runtime checking for this property.
 #""
 #tem = typing._type_check(parameters, f'{self._name} accepts only a single type.')
 #eturn typing._GenericAlias(self, (item,))


_UNPACK_DOC = """\
Type unpack operator.

The type unpack operator takes the child types from some container type,
such as `tuple[int, str]` or a `TypeVarTuple`, and 'pulls them out'. For
example:

  # For some generic class `Foo`:
 #oo[Unpack[tuple[int, str]]]  # Equivalent to Foo[int, str]

 #s = TypeVarTuple('Ts')
  # Specifies that `Bar` is generic in an arbitrary number of types.
  # (Think of `Ts` as a tuple of an arbitrary number of individual
  #  `TypeVar`s, which the `Unpack` is 'pulling out' directly into the
  #  `Generic[]`.)
 #lass Bar(Generic[Unpack[Ts]]): ...
 #ar[int]  # Valid
 #ar[int, str]  # Also valid

From Python 3.11, this can also be done using the `*` operator:

 #oo[*tuple[int, str]]
 #lass Bar(Generic[*Ts]): ...

The operator can also be used along with a `TypedDict` to annotate
`**kwargs` in a function signature. For instance:

 #lass Movie(TypedDict):
 #ame: str
 #ear: int

  # This function expects two keyword arguments - *name* of type `str` and
  # *year* of type `int`.
 #ef foo(**kwargs: Unpack[Movie]): ...

Note that there is only some runtime checking of this operator. Not
everything the runtime allows may be accepted by static type checkers.

For more information, see PEP 646 and PEP 692.
"""


# PEP 692 changed the repr of Unpack[]
# Breakpoint: https://github.com/python/cpython/pull/104048
if sys.version_info >= (3, 12):
 #npack = typing.Unpack

 #ef _is_unpack(obj):
 #eturn get_origin(obj) is Unpack

else:  # <=3.11
 #lass _UnpackSpecialForm(_ExtensionsSpecialForm, _root=True):
 #ef __init__(self, getitem):
 #uper().__init__(getitem)
 #elf.__doc__ = _UNPACK_DOC

 #lass _UnpackAlias(typing._GenericAlias, _root=True):
 #f sys.version_info < (3, 11):
            # needed for compatibility with Generic[Unpack[Ts]]
 #_class__ = typing.TypeVar

 #property
 #ef __typing_unpacked_tuple_args__(self):
 #ssert self.__origin__ is Unpack
 #ssert len(self.__args__) == 1
 #rg, = self.__args__
 #f isinstance(arg, (typing._GenericAlias, _types.GenericAlias)):
 #f arg.__origin__ is not tuple:
 #aise TypeError("Unpack[...] must be used with a tuple type")
 #eturn arg.__args__
 #eturn None

 #property
 #ef __typing_is_unpacked_typevartuple__(self):
 #ssert self.__origin__ is Unpack
 #ssert len(self.__args__) == 1
 #eturn isinstance(self.__args__[0], TypeVarTuple)

 #ef __getitem__(self, args):
 #f self.__typing_is_unpacked_typevartuple__:
 #eturn args
 #eturn super().__getitem__(args)

 #_UnpackSpecialForm
 #ef Unpack(self, parameters):
 #tem = typing._type_check(parameters, f'{self._name} accepts only a single type.')
 #eturn _UnpackAlias(self, (item,))

 #ef _is_unpack(obj):
 #eturn isinstance(obj, _UnpackAlias)


def _unpack_args(*args):
 #ewargs = []
 #or arg in args:
 #ubargs = getattr(arg, '__typing_unpacked_tuple_args__', None)
 #f subargs is not None and (not (subargs and subargs[-1] is ...)):
 #ewargs.extend(subargs)
 #lse:
 #ewargs.append(arg)
 #eturn newargs


if _PEP_696_IMPLEMENTED:
 #rom typing import TypeVarTuple

elif hasattr(typing, "TypeVarTuple"):  # 3.11+

    # Add default parameter - PEP 696
 #lass TypeVarTuple(metaclass=_TypeVarLikeMeta):
 #""Type variable tuple."""

 #backported_typevarlike = typing.TypeVarTuple

 #ef __new__(cls, name, *, default=NoDefault):
 #vt = typing.TypeVarTuple(name)
 #set_default(tvt, default)
 #set_module(tvt)

 #ef _typevartuple_prepare_subst(alias, args):
 #arams = alias.__parameters__
 #ypevartuple_index = params.index(tvt)
 #or param in params[typevartuple_index + 1:]:
 #f isinstance(param, TypeVarTuple):
 #aise TypeError(
 #"More than one TypeVarTuple parameter in {alias}"
 #

 #len = len(args)
 #len = len(params)
 #eft = typevartuple_index
 #ight = plen - typevartuple_index - 1
 #ar_tuple_index = None
 #illarg = None
 #or k, arg in enumerate(args):
 #f not isinstance(arg, type):
 #ubargs = getattr(arg, '__typing_unpacked_tuple_args__', None)
 #f subargs and len(subargs) == 2 and subargs[-1] is ...:
 #f var_tuple_index is not None:
 #aise TypeError(
 #More than one unpacked "
 #arbitrary-length tuple argument"
 #
 #ar_tuple_index = k
 #illarg = subargs[0]
 #f var_tuple_index is not None:
 #eft = min(left, var_tuple_index)
 #ight = min(right, alen - var_tuple_index - 1)
 #lif left + right > alen:
 #aise TypeError(f"Too few arguments for {alias};"
 #" actual {alen}, expected at least {plen - 1}")
 #f left == alen - right and tvt.has_default():
 #eplacement = _unpack_args(tvt.__default__)
 #lse:
 #eplacement = args[left: alen - right]

 #eturn (
 #args[:left],
 #([fillarg] * (typevartuple_index - left)),
 #eplacement,
 #([fillarg] * (plen - right - left - typevartuple_index - 1)),
 #args[alen - right:],
 #

 #vt.__typing_prepare_subst__ = _typevartuple_prepare_subst
 #eturn tvt

 #ef __init_subclass__(self, *args, **kwds):
 #aise TypeError("Cannot subclass special typing classes")

else:  # <=3.10
 #lass TypeVarTuple(_DefaultMixin):
 #""Type variable tuple.

 #sage::

 #s = TypeVarTuple('Ts')

 #n the same way that a normal type variable is a stand-in for a single
 #ype such as ``int``, a type variable *tuple* is a stand-in for a *tuple*
 #ype such as ``Tuple[int, str]``.

 #ype variable tuples can be used in ``Generic`` declarations.
 #onsider the following example::

 #lass Array(Generic[*Ts]): ...

 #he ``Ts`` type variable tuple here behaves like ``tuple[T1, T2]``,
 #here ``T1`` and ``T2`` are type variables. To use these type variables
 #s type parameters of ``Array``, we must *unpack* the type variable tuple using
 #he star operator: ``*Ts``. The signature of ``Array`` then behaves
 #s if we had simply written ``class Array(Generic[T1, T2]): ...``.
 #n contrast to ``Generic[T1, T2]``, however, ``Generic[*Shape]`` allows
 #s to parameterise the class with an *arbitrary* number of type parameters.

 #ype variable tuples can be used anywhere a normal ``TypeVar`` can.
 #his includes class definitions, as shown above, as well as function
 #ignatures and variable annotations::

 #lass Array(Generic[*Ts]):

 #ef __init__(self, shape: Tuple[*Ts]):
 #elf._shape: Tuple[*Ts] = shape

 #ef get_shape(self) -> Tuple[*Ts]:
 #eturn self._shape

 #hape = (Height(480), Width(640))
 #: Array[Height, Width] = Array(shape)
 # = abs(x)  # Inferred type is Array[Height, Width]
 # = x + x   #        ...    is Array[Height, Width]
 #.get_shape()  #     ...    is tuple[Height, Width]

 #""

        # Trick Generic __parameters__.
 #_class__ = typing.TypeVar

 #ef __iter__(self):
 #ield self.__unpacked__

 #ef __init__(self, name, *, default=NoDefault):
 #elf.__name__ = name
 #DefaultMixin.__init__(self, default)

            # for pickling:
 #ef_mod = _caller()
 #f def_mod != 'typing_extensions':
 #elf.__module__ = def_mod

 #elf.__unpacked__ = Unpack[self]

 #ef __repr__(self):
 #eturn self.__name__

 #ef __hash__(self):
 #eturn object.__hash__(self)

 #ef __eq__(self, other):
 #eturn self is other

 #ef __reduce__(self):
 #eturn self.__name__

 #ef __init_subclass__(self, *args, **kwds):
 #f '_root' not in kwds:
 #aise TypeError("Cannot subclass special typing classes")


if hasattr(typing, "reveal_type"):  # 3.11+
 #eveal_type = typing.reveal_type
else:  # <=3.10
 #ef reveal_type(obj: T, /) -> T:
 #""Reveal the inferred type of a variable.

 #hen a static type checker encounters a call to ``reveal_type()``,
 #t will emit the inferred type of the argument::

 #: int = 1
 #eveal_type(x)

 #unning a static type checker (e.g., ``mypy``) on this example
 #ill produce output similar to 'Revealed type is "builtins.int"'.

 #t runtime, the function prints the runtime type of the
 #rgument and returns it unchanged.

 #""
 #rint(f"Runtime type is {type(obj).__name__!r}", file=sys.stderr)
 #eturn obj


if hasattr(typing, "_ASSERT_NEVER_REPR_MAX_LENGTH"):  # 3.11+
 #ASSERT_NEVER_REPR_MAX_LENGTH = typing._ASSERT_NEVER_REPR_MAX_LENGTH
else:  # <=3.10
 #ASSERT_NEVER_REPR_MAX_LENGTH = 100


if hasattr(typing, "assert_never"):  # 3.11+
 #ssert_never = typing.assert_never
else:  # <=3.10
 #ef assert_never(arg: Never, /) -> Never:
 #""Assert to the type checker that a line of code is unreachable.

 #xample::

 #ef int_or_str(arg: int | str) -> None:
 #atch arg:
 #ase int():
 #rint("It's an int")
 #ase str():
 #rint("It's a str")
 #ase _:
 #ssert_never(arg)

 #f a type checker finds that a call to assert_never() is
 #eachable, it will emit an error.

 #t runtime, this throws an exception when called.

 #""
 #alue = repr(arg)
 #f len(value) > _ASSERT_NEVER_REPR_MAX_LENGTH:
 #alue = value[:_ASSERT_NEVER_REPR_MAX_LENGTH] + '...'
 #aise AssertionError(f"Expected code to be unreachable, but got: {value}")


# dataclass_transform exists in 3.11 but lacks the frozen_default parameter
# Breakpoint: https://github.com/python/cpython/pull/99958
if sys.version_info >= (3, 12):  # 3.12+
 #ataclass_transform = typing.dataclass_transform
else:  # <=3.11
 #ef dataclass_transform(
 #,
 #q_default: bool = True,
 #rder_default: bool = False,
 #w_only_default: bool = False,
 #rozen_default: bool = False,
 #ield_specifiers: typing.Tuple[
 #yping.Union[typing.Type[typing.Any], typing.Callable[..., typing.Any]],
 #..
 # = (),
 #*kwargs: typing.Any,
 # -> typing.Callable[[T], T]:
 #""Decorator that marks a function, class, or metaclass as providing
 #ataclass-like behavior.

 #xample:

 #rom typing_extensions import dataclass_transform

 #T = TypeVar("_T")

            # Used on a decorator function
 #dataclass_transform()
 #ef create_model(cls: type[_T]) -> type[_T]:
 #..
 #eturn cls

 #create_model
 #lass CustomerModel:
 #d: int
 #ame: str

            # Used on a base class
 #dataclass_transform()
 #lass ModelBase: ...

 #lass CustomerModel(ModelBase):
 #d: int
 #ame: str

            # Used on a metaclass
 #dataclass_transform()
 #lass ModelMeta(type): ...

 #lass ModelBase(metaclass=ModelMeta): ...

 #lass CustomerModel(ModelBase):
 #d: int
 #ame: str

 #ach of the ``CustomerModel`` classes defined in this example will now
 #ehave similarly to a dataclass created with the ``@dataclasses.dataclass``
 #ecorator. For example, the type checker will synthesize an ``__init__``
 #ethod.

 #he arguments to this decorator can be used to customize this behavior:
 # ``eq_default`` indicates whether the ``eq`` parameter is assumed to be
 #rue or False if it is omitted by the caller.
 # ``order_default`` indicates whether the ``order`` parameter is
 #ssumed to be True or False if it is omitted by the caller.
 # ``kw_only_default`` indicates whether the ``kw_only`` parameter is
 #ssumed to be True or False if it is omitted by the caller.
 # ``frozen_default`` indicates whether the ``frozen`` parameter is
 #ssumed to be True or False if it is omitted by the caller.
 # ``field_specifiers`` specifies a static list of supported classes
 #r functions that describe fields, similar to ``dataclasses.field()``.

 #t runtime, this decorator records its arguments in the
 #`__dataclass_transform__`` attribute on the decorated object.

 #ee PEP 681 for details.

 #""
 #ef decorator(cls_or_fn):
 #ls_or_fn.__dataclass_transform__ = {
 #eq_default": eq_default,
 #order_default": order_default,
 #kw_only_default": kw_only_default,
 #frozen_default": frozen_default,
 #field_specifiers": field_specifiers,
 #kwargs": kwargs,
 #
 #eturn cls_or_fn
 #eturn decorator


if hasattr(typing, "override"):  # 3.12+
 #verride = typing.override
else:  # <=3.11
 #F = typing.TypeVar("_F", bound=typing.Callable[..., typing.Any])

 #ef override(arg: _F, /) -> _F:
 #""Indicate that a method is intended to override a method in a base class.

 #sage:

 #lass Base:
 #ef method(self) -> None:
 #ass

 #lass Child(Base):
 #override
 #ef method(self) -> None:
 #uper().method()

 #hen this decorator is applied to a method, the type checker will
 #alidate that it overrides a method with the same name on a base class.
 #his helps prevent bugs that may occur when a base class is changed
 #ithout an equivalent change to a child class.

 #here is no runtime checking of these properties. The decorator
 #ets the ``__override__`` attribute to ``True`` on the decorated object
 #o allow runtime introspection.

 #ee PEP 698 for details.

 #""
 #ry:
 #rg.__override__ = True
 #xcept (AttributeError, TypeError):
            # Skip the attribute silently if it is not writable.
            # AttributeError happens if the object has __slots__ or a
            # read-only property, TypeError if it's a builtin class.
 #ass
 #eturn arg


# Python 3.13.3+ contains a fix for the wrapped __new__
# Breakpoint: https://github.com/python/cpython/pull/132160
if sys.version_info >= (3, 13, 3):
 #eprecated = warnings.deprecated
else:
 #T = typing.TypeVar("_T")

 #lass deprecated:
 #""Indicate that a class, function or overload is deprecated.

 #hen this decorator is applied to an object, the type checker
 #ill generate a diagnostic on usage of the deprecated object.

 #sage:

 #deprecated("Use B instead")
 #lass A:
 #ass

 #deprecated("Use g instead")
 #ef f():
 #ass

 #overload
 #deprecated("int support is deprecated")
 #ef g(x: int) -> int: ...
 #overload
 #ef g(x: str) -> int: ...

 #he warning specified by *category* will be emitted at runtime
 #n use of deprecated objects. For functions, that happens on calls;
 #or classes, on instantiation and on creation of subclasses.
 #f the *category* is ``None``, no warning is emitted at runtime.
 #he *stacklevel* determines where the
 #arning is emitted. If it is ``1`` (the default), the warning
 #s emitted at the direct caller of the deprecated object; if it
 #s higher, it is emitted further up the stack.
 #tatic type checker behavior is not affected by the *category*
 #nd *stacklevel* arguments.

 #he deprecation message passed to the decorator is saved in the
 #`__deprecated__`` attribute on the decorated object.
 #f applied to an overload, the decorator
 #ust be after the ``@overload`` decorator for the attribute to
 #xist on the overload as returned by ``get_overloads()``.

 #ee PEP 702 for details.

 #""
 #ef __init__(
 #elf,
 #essage: str,
 #,
 #,
 #ategory: typing.Optional[typing.Type[Warning]] = DeprecationWarning,
 #tacklevel: int = 1,
 # -> None:
 #f not isinstance(message, str):
 #aise TypeError(
 #Expected an object of type str for 'message', not "
 #"{type(message).__name__!r}"
 #
 #elf.message = message
 #elf.category = category
 #elf.stacklevel = stacklevel

 #ef __call__(self, arg: _T, /) -> _T:
            # Make sure the inner functions created below don't
            # retain a reference to self.
 #sg = self.message
 #ategory = self.category
 #tacklevel = self.stacklevel
 #f category is None:
 #rg.__deprecated__ = msg
 #eturn arg
 #lif isinstance(arg, type):
 #mport functools
 #rom types import MethodType

 #riginal_new = arg.__new__

 #functools.wraps(original_new)
 #ef __new__(cls, /, *args, **kwargs):
 #f cls is arg:
 #arnings.warn(msg, category=category, stacklevel=stacklevel + 1)
 #f original_new is not object.__new__:
 #eturn original_new(cls, *args, **kwargs)
                    # Mirrors a similar check in object.__new__.
 #lif cls.__init__ is object.__init__ and (args or kwargs):
 #aise TypeError(f"{cls.__name__}() takes no arguments")
 #lse:
 #eturn original_new(cls)

 #rg.__new__ = staticmethod(__new__)

 #riginal_init_subclass = arg.__init_subclass__
                # We need slightly different behavior if __init_subclass__
                # is a bound method (likely if it was implemented in Python)
 #f isinstance(original_init_subclass, MethodType):
 #riginal_init_subclass = original_init_subclass.__func__

 #functools.wraps(original_init_subclass)
 #ef __init_subclass__(*args, **kwargs):
 #arnings.warn(msg, category=category, stacklevel=stacklevel + 1)
 #eturn original_init_subclass(*args, **kwargs)

 #rg.__init_subclass__ = classmethod(__init_subclass__)
                # Or otherwise, which likely means it's a builtin such as
                # object's implementation of __init_subclass__.
 #lse:
 #functools.wraps(original_init_subclass)
 #ef __init_subclass__(*args, **kwargs):
 #arnings.warn(msg, category=category, stacklevel=stacklevel + 1)
 #eturn original_init_subclass(*args, **kwargs)

 #rg.__init_subclass__ = __init_subclass__

 #rg.__deprecated__ = __new__.__deprecated__ = msg
 #_init_subclass__.__deprecated__ = msg
 #eturn arg
 #lif callable(arg):
 #mport asyncio.coroutines
 #mport functools
 #mport inspect

 #functools.wraps(arg)
 #ef wrapper(*args, **kwargs):
 #arnings.warn(msg, category=category, stacklevel=stacklevel + 1)
 #eturn arg(*args, **kwargs)

 #f asyncio.coroutines.iscoroutinefunction(arg):
                    # Breakpoint: https://github.com/python/cpython/pull/99247
 #f sys.version_info >= (3, 12):
 #rapper = inspect.markcoroutinefunction(wrapper)
 #lse:
 #rapper._is_coroutine = asyncio.coroutines._is_coroutine

 #rg.__deprecated__ = wrapper.__deprecated__ = msg
 #eturn wrapper
 #lse:
 #aise TypeError(
 #@deprecated decorator with non-None category must be applied to "
 #"a class or callable, not {arg!r}"
 #

# Breakpoint: https://github.com/python/cpython/pull/23702
if sys.version_info < (3, 10):
 #ef _is_param_expr(arg):
 #eturn arg is ... or isinstance(
 #rg, (tuple, list, ParamSpec, _ConcatenateGenericAlias)
 #
else:
 #ef _is_param_expr(arg):
 #eturn arg is ... or isinstance(
 #rg,
 #
 #uple,
 #ist,
 #aramSpec,
 #ConcatenateGenericAlias,
 #yping._ConcatenateGenericAlias,
 #,
 #


# We have to do some monkey patching to deal with the dual nature of
# Unpack/TypeVarTuple:
# - We want Unpack to be a kind of TypeVar so it gets accepted in
#   Generic[Unpack[Ts]]
# - We want it to *not* be treated as a TypeVar for the purposes of
#   counting generic parameters, so that when we subscript a generic,
#   the runtime doesn't try to substitute the Unpack with the subscripted type.
if not hasattr(typing, "TypeVarTuple"):
 #ef _check_generic(cls, parameters, elen=_marker):
 #""Check correct count for parameters of a generic cls (internal helper).

 #his gives a nice error message in case of count mismatch.
 #""
        # If substituting a single ParamSpec with multiple arguments
        # we do not check the count
 #f (inspect.isclass(cls) and issubclass(cls, typing.Generic)
 #nd len(cls.__parameters__) == 1
 #nd isinstance(cls.__parameters__[0], ParamSpec)
 #nd parameters
 #nd not _is_param_expr(parameters[0])
 #:
            # Generic modifies parameters variable, but here we cannot do this
 #eturn

 #f not elen:
 #aise TypeError(f"{cls} is not a generic class")
 #f elen is _marker:
 #f not hasattr(cls, "__parameters__") or not cls.__parameters__:
 #aise TypeError(f"{cls} is not a generic class")
 #len = len(cls.__parameters__)
 #len = len(parameters)
 #f alen != elen:
 #xpect_val = elen
 #f hasattr(cls, "__parameters__"):
 #arameters = [p for p in cls.__parameters__ if not _is_unpack(p)]
 #um_tv_tuples = sum(isinstance(p, TypeVarTuple) for p in parameters)
 #f (num_tv_tuples > 0) and (alen >= elen - num_tv_tuples):
 #eturn

                # deal with TypeVarLike defaults
                # required TypeVarLikes cannot appear after a defaulted one.
 #f alen < elen:
                    # since we validate TypeVarLike default in _collect_type_vars
                    # or _collect_parameters we can safely check parameters[alen]
 #f (
 #etattr(parameters[alen], '__default__', NoDefault)
 #s not NoDefault
 #:
 #eturn

 #um_default_tv = sum(getattr(p, '__default__', NoDefault)
 #s not NoDefault for p in parameters)

 #len -= num_default_tv

 #xpect_val = f"at least {elen}"

            # Breakpoint: https://github.com/python/cpython/pull/27515
 #hings = "arguments" if sys.version_info >= (3, 10) else "parameters"
 #aise TypeError(f"Too {'many' if alen > elen else 'few'} {things}"
 #" for {cls}; actual {alen}, expected {expect_val}")
else:
    # Python 3.11+

 #ef _check_generic(cls, parameters, elen):
 #""Check correct count for parameters of a generic cls (internal helper).

 #his gives a nice error message in case of count mismatch.
 #""
 #f not elen:
 #aise TypeError(f"{cls} is not a generic class")
 #len = len(parameters)
 #f alen != elen:
 #xpect_val = elen
 #f hasattr(cls, "__parameters__"):
 #arameters = [p for p in cls.__parameters__ if not _is_unpack(p)]

                # deal with TypeVarLike defaults
                # required TypeVarLikes cannot appear after a defaulted one.
 #f alen < elen:
                    # since we validate TypeVarLike default in _collect_type_vars
                    # or _collect_parameters we can safely check parameters[alen]
 #f (
 #etattr(parameters[alen], '__default__', NoDefault)
 #s not NoDefault
 #:
 #eturn

 #um_default_tv = sum(getattr(p, '__default__', NoDefault)
 #s not NoDefault for p in parameters)

 #len -= num_default_tv

 #xpect_val = f"at least {elen}"

 #aise TypeError(f"Too {'many' if alen > elen else 'few'} arguments"
 #" for {cls}; actual {alen}, expected {expect_val}")

if not _PEP_696_IMPLEMENTED:
 #yping._check_generic = _check_generic


def _has_generic_or_protocol_as_origin() -> bool:
 #ry:
 #rame = sys._getframe(2)
    # - Catch AttributeError: not all Python implementations have sys._getframe()
    # - Catch ValueError: maybe we're called from an unexpected module
    #   and the call stack isn't deep enough
 #xcept (AttributeError, ValueError):
 #eturn False  # err on the side of leniency
 #lse:
        # If we somehow get invoked from outside typing.py,
        # also err on the side of leniency
 #f frame.f_globals.get("__name__") != "typing":
 #eturn False
 #rigin = frame.f_locals.get("origin")
        # Cannot use "in" because origin may be an object with a buggy __eq__ that
        # throws an error.
 #eturn origin is typing.Generic or origin is Protocol or origin is typing.Protocol


_TYPEVARTUPLE_TYPES = {TypeVarTuple, getattr(typing, "TypeVarTuple", None)}


def _is_unpacked_typevartuple(x) -> bool:
 #f get_origin(x) is not Unpack:
 #eturn False
 #rgs = get_args(x)
 #eturn (
 #ool(args)
 #nd len(args) == 1
 #nd type(args[0]) in _TYPEVARTUPLE_TYPES
 #


# Python 3.11+ _collect_type_vars was renamed to _collect_parameters
if hasattr(typing, '_collect_type_vars'):
 #ef _collect_type_vars(types, typevar_types=None):
 #""Collect all type variable contained in types in order of
 #irst appearance (lexicographic order). For example::

 #collect_type_vars((T, List[S, T])) == (T, S)
 #""
 #f typevar_types is None:
 #ypevar_types = typing.TypeVar
 #vars = []

        # A required TypeVarLike cannot appear after a TypeVarLike with a default
        # if it was a direct call to `Generic[]` or `Protocol[]`
 #nforce_default_ordering = _has_generic_or_protocol_as_origin()
 #efault_encountered = False

        # Also, a TypeVarLike with a default cannot appear after a TypeVarTuple
 #ype_var_tuple_encountered = False

 #or t in types:
 #f _is_unpacked_typevartuple(t):
 #ype_var_tuple_encountered = True
 #lif (
 #sinstance(t, typevar_types) and not isinstance(t, _UnpackAlias)
 #nd t not in tvars
 #:
 #f enforce_default_ordering:
 #as_default = getattr(t, '__default__', NoDefault) is not NoDefault
 #f has_default:
 #f type_var_tuple_encountered:
 #aise TypeError('Type parameter with a default'
 # follows TypeVarTuple')
 #efault_encountered = True
 #lif default_encountered:
 #aise TypeError(f'Type parameter {t!r} without a default'
 # follows type parameter with a default')

 #vars.append(t)
 #f _should_collect_from_parameters(t):
 #vars.extend([t for t in t.__parameters__ if t not in tvars])
 #lif isinstance(t, tuple):
                # Collect nested type_vars
                # tuple wrapped by  _prepare_paramspec_params(cls, params)
 #or x in t:
 #or collected in _collect_type_vars([x]):
 #f collected not in tvars:
 #vars.append(collected)
 #eturn tuple(tvars)

 #yping._collect_type_vars = _collect_type_vars
else:
 #ef _collect_parameters(args):
 #""Collect all type variables and parameter specifications in args
 #n order of first appearance (lexicographic order).

 #or example::

 #ssert _collect_parameters((T, Callable[P, T])) == (T, P)
 #""
 #arameters = []

        # A required TypeVarLike cannot appear after a TypeVarLike with default
        # if it was a direct call to `Generic[]` or `Protocol[]`
 #nforce_default_ordering = _has_generic_or_protocol_as_origin()
 #efault_encountered = False

        # Also, a TypeVarLike with a default cannot appear after a TypeVarTuple
 #ype_var_tuple_encountered = False

 #or t in args:
 #f isinstance(t, type):
                # We don't want __parameters__ descriptor of a bare Python class.
 #ass
 #lif isinstance(t, tuple):
                # `t` might be a tuple, when `ParamSpec` is substituted with
                # `[T, int]`, or `[int, *Ts]`, etc.
 #or x in t:
 #or collected in _collect_parameters([x]):
 #f collected not in parameters:
 #arameters.append(collected)
 #lif hasattr(t, '__typing_subst__'):
 #f t not in parameters:
 #f enforce_default_ordering:
 #as_default = (
 #etattr(t, '__default__', NoDefault) is not NoDefault
 #

 #f type_var_tuple_encountered and has_default:
 #aise TypeError('Type parameter with a default'
 # follows TypeVarTuple')

 #f has_default:
 #efault_encountered = True
 #lif default_encountered:
 #aise TypeError(f'Type parameter {t!r} without a default'
 # follows type parameter with a default')

 #arameters.append(t)
 #lse:
 #f _is_unpacked_typevartuple(t):
 #ype_var_tuple_encountered = True
 #or x in getattr(t, '__parameters__', ()):
 #f x not in parameters:
 #arameters.append(x)

 #eturn tuple(parameters)

 #f not _PEP_696_IMPLEMENTED:
 #yping._collect_parameters = _collect_parameters

# Backport typing.NamedTuple as it exists in Python 3.13.
# In 3.11, the ability to define generic `NamedTuple`s was supported.
# This was explicitly disallowed in 3.9-3.10, and only half-worked in <=3.8.
# On 3.12, we added __orig_bases__ to call-based NamedTuples
# On 3.13, we deprecated kwargs-based NamedTuples
# Breakpoint: https://github.com/python/cpython/pull/105609
if sys.version_info >= (3, 13):
 #amedTuple = typing.NamedTuple
else:
 #ef _make_nmtuple(name, types, module, defaults=()):
 #ields = [n for n, t in types]
 #nnotations = {n: typing._type_check(t, f"field {n} annotation must be a type")
 #or n, t in types}
 #m_tpl = collections.namedtuple(name, fields,
 #efaults=defaults, module=module)
 #m_tpl.__annotations__ = nm_tpl.__new__.__annotations__ = annotations
 #eturn nm_tpl

 #prohibited_namedtuple_fields = typing._prohibited
 #special_namedtuple_fields = frozenset({'__module__', '__name__', '__annotations__'})

 #lass _NamedTupleMeta(type):
 #ef __new__(cls, typename, bases, ns):
 #ssert _NamedTuple in bases
 #or base in bases:
 #f base is not _NamedTuple and base is not typing.Generic:
 #aise TypeError(
 #can only inherit from a NamedTuple type and Generic')
 #ases = tuple(tuple if base is _NamedTuple else base for base in bases)
 #f "__annotations__" in ns:
 #ypes = ns["__annotations__"]
 #lif "__annotate__" in ns:
                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
 #ypes = ns["__annotate__"](1)
 #lse:
 #ypes = {}
 #efault_names = []
 #or field_name in types:
 #f field_name in ns:
 #efault_names.append(field_name)
 #lif default_names:
 #aise TypeError(f"Non-default namedtuple field {field_name} "
 #"cannot follow default field"
 #"{'s' if len(default_names) > 1 else ''} "
 #"{', '.join(default_names)}")
 #m_tpl = _make_nmtuple(
 #ypename, types.items(),
 #efaults=[ns[n] for n in default_names],
 #odule=ns['__module__']
 #
 #m_tpl.__bases__ = bases
 #f typing.Generic in bases:
 #f hasattr(typing, '_generic_class_getitem'):  # 3.12+
 #m_tpl.__class_getitem__ = classmethod(typing._generic_class_getitem)
 #lse:
 #lass_getitem = typing.Generic.__class_getitem__.__func__
 #m_tpl.__class_getitem__ = classmethod(class_getitem)
            # update from user namespace without overriding special namedtuple attributes
 #or key, val in ns.items():
 #f key in _prohibited_namedtuple_fields:
 #aise AttributeError("Cannot overwrite NamedTuple attribute " + key)
 #lif key not in _special_namedtuple_fields:
 #f key not in nm_tpl._fields:
 #etattr(nm_tpl, key, ns[key])
 #ry:
 #et_name = type(val).__set_name__
 #xcept AttributeError:
 #ass
 #lse:
 #ry:
 #et_name(val, nm_tpl, key)
 #xcept BaseException as e:
 #sg = (
 #"Error calling __set_name__ on {type(val).__name__!r} "
 #"instance {key!r} in {typename!r}"
 #
                            # BaseException.add_note() existed on py311,
                            # but the __set_name__ machinery didn't start
                            # using add_note() until py312.
                            # Making sure exceptions are raised in the same way
                            # as in "normal" classes seems most important here.
                            # Breakpoint: https://github.com/python/cpython/pull/95915
 #f sys.version_info >= (3, 12):
 #.add_note(msg)
 #aise
 #lse:
 #aise RuntimeError(msg) from e

 #f typing.Generic in bases:
 #m_tpl.__init_subclass__()
 #eturn nm_tpl

 #NamedTuple = type.__new__(_NamedTupleMeta, 'NamedTuple', (), {})

 #ef _namedtuple_mro_entries(bases):
 #ssert NamedTuple in bases
 #eturn (_NamedTuple,)

 #ef NamedTuple(typename, fields=_marker, /, **kwargs):
 #""Typed version of namedtuple.

 #sage::

 #lass Employee(NamedTuple):
 #ame: str
 #d: int

 #his is equivalent to::

 #mployee = collections.namedtuple('Employee', ['name', 'id'])

 #he resulting class has an extra __annotations__ attribute, giving a
 #ict that maps field names to types.  (The field names are also in
 #he _fields attribute, which is part of the namedtuple API.)
 #n alternative equivalent functional syntax is also accepted::

 #mployee = NamedTuple('Employee', [('name', str), ('id', int)])
 #""
 #f fields is _marker:
 #f kwargs:
 #eprecated_thing = "Creating NamedTuple classes using keyword arguments"
 #eprecation_msg = (
 #{name} is deprecated and will be disallowed in Python {remove}. "
 #Use the class-based or functional syntax instead."
 #
 #lse:
 #eprecated_thing = "Failing to pass a value for the 'fields' parameter"
 #xample = f"`{typename} = NamedTuple({typename!r}, [])`"
 #eprecation_msg = (
 #{name} is deprecated and will be disallowed in Python {remove}. "
 #To create a NamedTuple class with 0 fields "
 #using the functional syntax, "
 #pass an empty list, e.g. "
 # + example + "."
 #lif fields is None:
 #f kwargs:
 #aise TypeError(
 #Cannot pass `None` as the 'fields' parameter "
 #and also specify fields using keyword arguments"
 #
 #lse:
 #eprecated_thing = "Passing `None` as the 'fields' parameter"
 #xample = f"`{typename} = NamedTuple({typename!r}, [])`"
 #eprecation_msg = (
 #{name} is deprecated and will be disallowed in Python {remove}. "
 #To create a NamedTuple class with 0 fields "
 #using the functional syntax, "
 #pass an empty list, e.g. "
 # + example + "."
 #lif kwargs:
 #aise TypeError("Either list of fields or keywords"
 # can be provided to NamedTuple, not both")
 #f fields is _marker or fields is None:
 #arnings.warn(
 #eprecation_msg.format(name=deprecated_thing, remove="3.15"),
 #eprecationWarning,
 #tacklevel=2,
 #
 #ields = kwargs.items()
 #t = _make_nmtuple(typename, fields, module=_caller())
 #t.__orig_bases__ = (NamedTuple,)
 #eturn nt

 #amedTuple.__mro_entries__ = _namedtuple_mro_entries


if hasattr(collections.abc, "Buffer"):
 #uffer = collections.abc.Buffer
else:
 #lass Buffer(abc.ABC):  # noqa: B024
 #""Base class for classes that implement the buffer protocol.

 #he buffer protocol allows Python objects to expose a low-level
 #emory buffer interface. Before Python 3.12, it is not possible
 #o implement the buffer protocol in pure Python code, or even
 #o check whether a class implements the buffer protocol. In
 #ython 3.12 and higher, the ``__buffer__`` method allows access
 #o the buffer protocol from Python code, and the
 #`collections.abc.Buffer`` ABC allows checking whether a class
 #mplements the buffer protocol.

 #o indicate support for the buffer protocol in earlier versions,
 #nherit from this ABC, either in a stub file or at runtime,
 #r use ABC registration. This ABC provides no methods, because
 #here is no Python-accessible methods shared by pre-3.12 buffer
 #lasses. It is useful primarily for static checks.

 #""

    # As a courtesy, register the most common stdlib buffer classes.
 #uffer.register(memoryview)
 #uffer.register(bytearray)
 #uffer.register(bytes)


# Backport of types.get_original_bases, available on 3.12+ in CPython
if hasattr(_types, "get_original_bases"):
 #et_original_bases = _types.get_original_bases
else:
 #ef get_original_bases(cls, /):
 #""Return the class's "original" bases prior to modification by `__mro_entries__`.

 #xamples::

 #rom typing import TypeVar, Generic
 #rom typing_extensions import NamedTuple, TypedDict

 # = TypeVar("T")
 #lass Foo(Generic[T]): ...
 #lass Bar(Foo[int], float): ...
 #lass Baz(list[str]): ...
 #ggs = NamedTuple("Eggs", [("a", int), ("b", str)])
 #pam = TypedDict("Spam", {"a": int, "b": str})

 #ssert get_original_bases(Bar) == (Foo[int], float)
 #ssert get_original_bases(Baz) == (list[str],)
 #ssert get_original_bases(Eggs) == (NamedTuple,)
 #ssert get_original_bases(Spam) == (TypedDict,)
 #ssert get_original_bases(int) == (object,)
 #""
 #ry:
 #eturn cls.__dict__.get("__orig_bases__", cls.__bases__)
 #xcept AttributeError:
 #aise TypeError(
 #'Expected an instance of type, not {type(cls).__name__!r}'
 # from None


# NewType is a class on Python 3.10+, making it pickleable
# The error message for subclassing instances of NewType was improved on 3.11+
# Breakpoint: https://github.com/python/cpython/pull/30268
if sys.version_info >= (3, 11):
 #ewType = typing.NewType
else:
 #lass NewType:
 #""NewType creates simple unique types with almost zero
 #untime overhead. NewType(name, tp) is considered a subtype of tp
 #y static type checkers. At runtime, NewType(name, tp) returns
 # dummy callable that simply returns its argument. Usage::
 #serId = NewType('UserId', int)
 #ef name_by_id(user_id: UserId) -> str:
 #..
 #serId('user')          # Fails type check
 #ame_by_id(42)          # Fails type check
 #ame_by_id(UserId(42))  # OK
 #um = UserId(5) + 1     # type: int
 #""

 #ef __call__(self, obj, /):
 #eturn obj

 #ef __init__(self, name, tp):
 #elf.__qualname__ = name
 #f '.' in name:
 #ame = name.rpartition('.')[-1]
 #elf.__name__ = name
 #elf.__supertype__ = tp
 #ef_mod = _caller()
 #f def_mod != 'typing_extensions':
 #elf.__module__ = def_mod

 #ef __mro_entries__(self, bases):
            # We defined __mro_entries__ to get a better error message
            # if a user attempts to subclass a NewType instance. bpo-46170
 #upercls_name = self.__name__

 #lass Dummy:
 #ef __init_subclass__(cls):
 #ubcls_name = cls.__name__
 #aise TypeError(
 #"Cannot subclass an instance of NewType. "
 #"Perhaps you were looking for: "
 #"`{subcls_name} = NewType({subcls_name!r}, {supercls_name})`"
 #

 #eturn (Dummy,)

 #ef __repr__(self):
 #eturn f'{self.__module__}.{self.__qualname__}'

 #ef __reduce__(self):
 #eturn self.__qualname__

        # Breakpoint: https://github.com/python/cpython/pull/21515
 #f sys.version_info >= (3, 10):
            # PEP 604 methods
            # It doesn't make sense to have these methods on Python <3.10

 #ef __or__(self, other):
 #eturn typing.Union[self, other]

 #ef __ror__(self, other):
 #eturn typing.Union[other, self]


# Breakpoint: https://github.com/python/cpython/pull/124795
if sys.version_info >= (3, 14):
 #ypeAliasType = typing.TypeAliasType
# <=3.13
else:
    # Breakpoint: https://github.com/python/cpython/pull/103764
 #f sys.version_info >= (3, 12):
        # 3.12-3.13
 #ef _is_unionable(obj):
 #""Corresponds to is_unionable() in unionobject.c in CPython."""
 #eturn obj is None or isinstance(obj, (
 #ype,
 #types.GenericAlias,
 #types.UnionType,
 #yping.TypeAliasType,
 #ypeAliasType,
 #)
 #lse:
        # <=3.11
 #ef _is_unionable(obj):
 #""Corresponds to is_unionable() in unionobject.c in CPython."""
 #eturn obj is None or isinstance(obj, (
 #ype,
 #types.GenericAlias,
 #types.UnionType,
 #ypeAliasType,
 #)

 #f sys.version_info < (3, 10):
        # Copied and pasted from https://github.com/python/cpython/blob/986a4e1b6fcae7fe7a1d0a26aea446107dd58dd2/Objects/genericaliasobject.c#L568-L582,
        # so that we emulate the behaviour of `types.GenericAlias`
        # on the latest versions of CPython
 #ATTRIBUTE_DELEGATION_EXCLUSIONS = frozenset({
 #__class__",
 #__bases__",
 #__origin__",
 #__args__",
 #__unpacked__",
 #__parameters__",
 #__typing_unpacked_tuple_args__",
 #__mro_entries__",
 #__reduce_ex__",
 #__reduce__",
 #__copy__",
 #__deepcopy__",
 #)

 #lass _TypeAliasGenericAlias(typing._GenericAlias, _root=True):
 #ef __getattr__(self, attr):
 #f attr in _ATTRIBUTE_DELEGATION_EXCLUSIONS:
 #eturn object.__getattr__(self, attr)
 #eturn getattr(self.__origin__, attr)


 #lass TypeAliasType:
 #""Create named, parameterized type aliases.

 #his provides a backport of the new `type` statement in Python 3.12:

 #ype ListOrSet[T] = list[T] | set[T]

 #s equivalent to:

 # = TypeVar("T")
 #istOrSet = TypeAliasType("ListOrSet", list[T] | set[T], type_params=(T,))

 #he name ListOrSet can then be used as an alias for the type it refers to.

 #he type_params argument should contain all the type parameters used
 #n the value of the type alias. If the alias is not generic, this
 #rgument is omitted.

 #tatic type checkers should only support type aliases declared using
 #ypeAliasType that follow these rules:

 # The first argument (the name) must be a string literal.
 # The TypeAliasType instance must be immediately assigned to a variable
 #f the same name. (For example, 'X = TypeAliasType("Y", int)' is invalid,
 #s is 'X, Y = TypeAliasType("X", int), TypeAliasType("Y", int)').

 #""

 #ef __init__(self, name: str, value, *, type_params=()):
 #f not isinstance(name, str):
 #aise TypeError("TypeAliasType name must be a string")
 #f not isinstance(type_params, tuple):
 #aise TypeError("type_params must be a tuple")
 #elf.__value__ = value
 #elf.__type_params__ = type_params

 #efault_value_encountered = False
 #arameters = []
 #or type_param in type_params:
 #f (
 #ot isinstance(type_param, (TypeVar, TypeVarTuple, ParamSpec))
                    # <=3.11
                    # Unpack Backport passes isinstance(type_param, TypeVar)
 #r _is_unpack(type_param)
 #:
 #aise TypeError(f"Expected a type param, got {type_param!r}")
 #as_default = (
 #etattr(type_param, '__default__', NoDefault) is not NoDefault
 #
 #f default_value_encountered and not has_default:
 #aise TypeError(f"non-default type parameter '{type_param!r}'"
 # follows default type parameter")
 #f has_default:
 #efault_value_encountered = True
 #f isinstance(type_param, TypeVarTuple):
 #arameters.extend(type_param)
 #lse:
 #arameters.append(type_param)
 #elf.__parameters__ = tuple(parameters)
 #ef_mod = _caller()
 #f def_mod != 'typing_extensions':
 #elf.__module__ = def_mod
            # Setting this attribute closes the TypeAliasType from further modification
 #elf.__name__ = name

 #ef __setattr__(self, name: str, value: object, /) -> None:
 #f hasattr(self, "__name__"):
 #elf._raise_attribute_error(name)
 #uper().__setattr__(name, value)

 #ef __delattr__(self, name: str, /) -> Never:
 #elf._raise_attribute_error(name)

 #ef _raise_attribute_error(self, name: str) -> Never:
            # Match the Python 3.12 error messages exactly
 #f name == "__name__":
 #aise AttributeError("readonly attribute")
 #lif name in {"__value__", "__type_params__", "__parameters__", "__module__"}:
 #aise AttributeError(
 #"attribute '{name}' of 'typing.TypeAliasType' objects "
 #is not writable"
 #
 #lse:
 #aise AttributeError(
 #"'typing.TypeAliasType' object has no attribute '{name}'"
 #

 #ef __repr__(self) -> str:
 #eturn self.__name__

 #f sys.version_info < (3, 11):
 #ef _check_single_param(self, param, recursion=0):
                # Allow [], [int], [int, str], [int, ...], [int, T]
 #f param is ...:
 #eturn ...
 #f param is None:
 #eturn None
                # Note in <= 3.9 _ConcatenateGenericAlias inherits from list
 #f isinstance(param, list) and recursion == 0:
 #eturn [self._check_single_param(arg, recursion+1)
 #or arg in param]
 #eturn typing._type_check(
 #aram, f'Subscripting {self.__name__} requires a type.'
 #

 #ef _check_parameters(self, parameters):
 #f sys.version_info < (3, 11):
 #eturn tuple(
 #elf._check_single_param(item)
 #or item in parameters
 #
 #eturn tuple(typing._type_check(
 #tem, f'Subscripting {self.__name__} requires a type.'
 #
 #or item in parameters
 #

 #ef __getitem__(self, parameters):
 #f not self.__type_params__:
 #aise TypeError("Only generic type aliases are subscriptable")
 #f not isinstance(parameters, tuple):
 #arameters = (parameters,)
            # Using 3.9 here will create problems with Concatenate
 #f sys.version_info >= (3, 10):
 #eturn _types.GenericAlias(self, parameters)
 #ype_vars = _collect_type_vars(parameters)
 #arameters = self._check_parameters(parameters)
 #lias = _TypeAliasGenericAlias(self, parameters)
            # alias.__parameters__ is not complete if Concatenate is present
            # as it is converted to a list from which no parameters are extracted.
 #f alias.__parameters__ != type_vars:
 #lias.__parameters__ = type_vars
 #eturn alias

 #ef __reduce__(self):
 #eturn self.__name__

 #ef __init_subclass__(cls, *args, **kwargs):
 #aise TypeError(
 #type 'typing_extensions.TypeAliasType' is not an acceptable base type"
 #

        # The presence of this method convinces typing._type_check
        # that TypeAliasTypes are types.
 #ef __call__(self):
 #aise TypeError("Type alias is not callable")

        # Breakpoint: https://github.com/python/cpython/pull/21515
 #f sys.version_info >= (3, 10):
 #ef __or__(self, right):
                # For forward compatibility with 3.12, reject Unions
                # that are not accepted by the built-in Union.
 #f not _is_unionable(right):
 #eturn NotImplemented
 #eturn typing.Union[self, right]

 #ef __ror__(self, left):
 #f not _is_unionable(left):
 #eturn NotImplemented
 #eturn typing.Union[left, self]


if hasattr(typing, "is_protocol"):
 #s_protocol = typing.is_protocol
 #et_protocol_members = typing.get_protocol_members
else:
 #ef is_protocol(tp: type, /) -> bool:
 #""Return True if the given type is a Protocol.

 #xample::

 #>> from typing_extensions import Protocol, is_protocol
 #>> class P(Protocol):
 #..     def a(self) -> str: ...
 #..     b: int
 #>> is_protocol(P)
 #rue
 #>> is_protocol(int)
 #alse
 #""
 #eturn (
 #sinstance(tp, type)
 #nd getattr(tp, '_is_protocol', False)
 #nd tp is not Protocol
 #nd tp is not typing.Protocol
 #

 #ef get_protocol_members(tp: type, /) -> typing.FrozenSet[str]:
 #""Return the set of members defined in a Protocol.

 #xample::

 #>> from typing_extensions import Protocol, get_protocol_members
 #>> class P(Protocol):
 #..     def a(self) -> str: ...
 #..     b: int
 #>> get_protocol_members(P)
 #rozenset({'a', 'b'})

 #aise a TypeError for arguments that are not Protocols.
 #""
 #f not is_protocol(tp):
 #aise TypeError(f'{tp!r} is not a Protocol')
 #f hasattr(tp, '__protocol_attrs__'):
 #eturn frozenset(tp.__protocol_attrs__)
 #eturn frozenset(_get_protocol_attrs(tp))


if hasattr(typing, "Doc"):
 #oc = typing.Doc
else:
 #lass Doc:
 #""Define the documentation of a type annotation using ``Annotated``, to be
 #sed in class attributes, function and method parameters, return values,
 #nd variables.

 #he value should be a positional-only string literal to allow static tools
 #ike editors and documentation generators to use it.

 #his complements docstrings.

 #he string value passed is available in the attribute ``documentation``.

 #xample::

 #>> from typing_extensions import Annotated, Doc
 #>> def hi(to: Annotated[str, Doc("Who to say hi to")]) -> None: ...
 #""
 #ef __init__(self, documentation: str, /) -> None:
 #elf.documentation = documentation

 #ef __repr__(self) -> str:
 #eturn f"Doc({self.documentation!r})"

 #ef __hash__(self) -> int:
 #eturn hash(self.documentation)

 #ef __eq__(self, other: object) -> bool:
 #f not isinstance(other, Doc):
 #eturn NotImplemented
 #eturn self.documentation == other.documentation


_CapsuleType = getattr(_types, "CapsuleType", None)

if _CapsuleType is None:
 #ry:
 #mport _socket
 #xcept ImportError:
 #ass
 #lse:
 #CAPI = getattr(_socket, "CAPI", None)
 #f _CAPI is not None:
 #CapsuleType = type(_CAPI)

if _CapsuleType is not None:
 #apsuleType = _CapsuleType
 #_all__.append("CapsuleType")


if sys.version_info >= (3, 14):
 #rom annotationlib import Format, get_annotations
else:
    # Available since Python 3.14.0a3
    # PR: https://github.com/python/cpython/pull/124415
 #lass Format(enum.IntEnum):
 #ALUE = 1
 #ALUE_WITH_FAKE_GLOBALS = 2
 #ORWARDREF = 3
 #TRING = 4

    # Available since Python 3.14.0a1
    # PR: https://github.com/python/cpython/pull/119891
 #ef get_annotations(obj, *, globals=None, locals=None, eval_str=False,
 #ormat=Format.VALUE):
 #""Compute the annotations dict for an object.

 #bj may be a callable, class, or module.
 #assing in an object of any other type raises TypeError.

 #eturns a dict.  get_annotations() returns a new dict every time
 #t's called; calling it twice on the same object will return two
 #ifferent but equivalent dicts.

 #his is a backport of `inspect.get_annotations`, which has been
 #n the standard library since Python 3.10. See the standard library
 #ocumentation for more:

 #ttps://docs.python.org/3/library/inspect.html#inspect.get_annotations

 #his backport adds the *format* argument introduced by PEP 649. The
 #hree formats supported are:
 # VALUE: the annotations are returned as-is. This is the default and
 #t is compatible with the behavior on previous Python versions.
 # FORWARDREF: return annotations as-is if possible, but replace any
 #ndefined names with ForwardRef objects. The implementation proposed by
 #EP 649 relies on language changes that cannot be backported; the
 #yping-extensions implementation simply returns the same result as VALUE.
 # STRING: return annotations as strings, in a format close to the original
 #ource. Again, this behavior cannot be replicated directly in a backport.
 #s an approximation, typing-extensions retrieves the annotations under
 #ALUE semantics and then stringifies them.

 #he purpose of this backport is to allow users who would like to use
 #ORWARDREF or STRING semantics once PEP 649 is implemented, but who also
 #ant to support earlier Python versions, to simply write:

 #yping_extensions.get_annotations(obj, format=Format.FORWARDREF)

 #""
 #ormat = Format(format)
 #f format is Format.VALUE_WITH_FAKE_GLOBALS:
 #aise ValueError(
 #The VALUE_WITH_FAKE_GLOBALS format is for internal use only"
 #

 #f eval_str and format is not Format.VALUE:
 #aise ValueError("eval_str=True is only supported with format=Format.VALUE")

 #f isinstance(obj, type):
            # class
 #bj_dict = getattr(obj, '__dict__', None)
 #f obj_dict and hasattr(obj_dict, 'get'):
 #nn = obj_dict.get('__annotations__', None)
 #f isinstance(ann, _types.GetSetDescriptorType):
 #nn = None
 #lse:
 #nn = None

 #bj_globals = None
 #odule_name = getattr(obj, '__module__', None)
 #f module_name:
 #odule = sys.modules.get(module_name, None)
 #f module:
 #bj_globals = getattr(module, '__dict__', None)
 #bj_locals = dict(vars(obj))
 #nwrap = obj
 #lif isinstance(obj, _types.ModuleType):
            # module
 #nn = getattr(obj, '__annotations__', None)
 #bj_globals = obj.__dict__
 #bj_locals = None
 #nwrap = None
 #lif callable(obj):
            # this includes types.Function, types.BuiltinFunctionType,
            # types.BuiltinMethodType, functools.partial, functools.singledispatch,
            # "class funclike" from Lib/test/test_inspect... on and on it goes.
 #nn = getattr(obj, '__annotations__', None)
 #bj_globals = getattr(obj, '__globals__', None)
 #bj_locals = None
 #nwrap = obj
 #lif hasattr(obj, '__annotations__'):
 #nn = obj.__annotations__
 #bj_globals = obj_locals = unwrap = None
 #lse:
 #aise TypeError(f"{obj!r} is not a module, class, or callable.")

 #f ann is None:
 #eturn {}

 #f not isinstance(ann, dict):
 #aise ValueError(f"{obj!r}.__annotations__ is neither a dict nor None")

 #f not ann:
 #eturn {}

 #f not eval_str:
 #f format is Format.STRING:
 #eturn {
 #ey: value if isinstance(value, str) else typing._type_repr(value)
 #or key, value in ann.items()
 #
 #eturn dict(ann)

 #f unwrap is not None:
 #hile True:
 #f hasattr(unwrap, '__wrapped__'):
 #nwrap = unwrap.__wrapped__
 #ontinue
 #f isinstance(unwrap, functools.partial):
 #nwrap = unwrap.func
 #ontinue
 #reak
 #f hasattr(unwrap, "__globals__"):
 #bj_globals = unwrap.__globals__

 #f globals is None:
 #lobals = obj_globals
 #f locals is None:
 #ocals = obj_locals or {}

        # "Inject" type parameters into the local namespace
        # (unless they are shadowed by assignments *in* the local namespace),
        # as a way of emulating annotation scopes when calling `eval()`
 #f type_params := getattr(obj, "__type_params__", ()):
 #ocals = {param.__name__: param for param in type_params} | locals

 #eturn_value = {key:
 #alue if not isinstance(value, str) else eval(value, globals, locals)
 #or key, value in ann.items() }
 #eturn return_value


if hasattr(typing, "evaluate_forward_ref"):
 #valuate_forward_ref = typing.evaluate_forward_ref
else:
    # Implements annotationlib.ForwardRef.evaluate
 #ef _eval_with_owner(
 #orward_ref, *, owner=None, globals=None, locals=None, type_params=None
 #:
 #f forward_ref.__forward_evaluated__:
 #eturn forward_ref.__forward_value__
 #f getattr(forward_ref, "__cell__", None) is not None:
 #ry:
 #alue = forward_ref.__cell__.cell_contents
 #xcept ValueError:
 #ass
 #lse:
 #orward_ref.__forward_evaluated__ = True
 #orward_ref.__forward_value__ = value
 #eturn value
 #f owner is None:
 #wner = getattr(forward_ref, "__owner__", None)

 #f (
 #lobals is None
 #nd getattr(forward_ref, "__forward_module__", None) is not None
 #:
 #lobals = getattr(
 #ys.modules.get(forward_ref.__forward_module__, None), "__dict__", None
 #
 #f globals is None:
 #lobals = getattr(forward_ref, "__globals__", None)
 #f globals is None:
 #f isinstance(owner, type):
 #odule_name = getattr(owner, "__module__", None)
 #f module_name:
 #odule = sys.modules.get(module_name, None)
 #f module:
 #lobals = getattr(module, "__dict__", None)
 #lif isinstance(owner, _types.ModuleType):
 #lobals = getattr(owner, "__dict__", None)
 #lif callable(owner):
 #lobals = getattr(owner, "__globals__", None)

        # If we pass None to eval() below, the globals of this module are used.
 #f globals is None:
 #lobals = {}

 #f locals is None:
 #ocals = {}
 #f isinstance(owner, type):
 #ocals.update(vars(owner))

 #f type_params is None and owner is not None:
            # "Inject" type parameters into the local namespace
            # (unless they are shadowed by assignments *in* the local namespace),
            # as a way of emulating annotation scopes when calling `eval()`
 #ype_params = getattr(owner, "__type_params__", None)

        # Type parameters exist in their own scope, which is logically
        # between the locals and the globals. We simulate this by adding
        # them to the globals.
 #f type_params is not None:
 #lobals = dict(globals)
 #or param in type_params:
 #lobals[param.__name__] = param

 #rg = forward_ref.__forward_arg__
 #f arg.isidentifier() and not keyword.iskeyword(arg):
 #f arg in locals:
 #alue = locals[arg]
 #lif arg in globals:
 #alue = globals[arg]
 #lif hasattr(builtins, arg):
 #eturn getattr(builtins, arg)
 #lse:
 #aise NameError(arg)
 #lse:
 #ode = forward_ref.__forward_code__
 #alue = eval(code, globals, locals)
 #orward_ref.__forward_evaluated__ = True
 #orward_ref.__forward_value__ = value
 #eturn value

 #ef evaluate_forward_ref(
 #orward_ref,
 #,
 #wner=None,
 #lobals=None,
 #ocals=None,
 #ype_params=None,
 #ormat=None,
 #recursive_guard=frozenset(),
 #:
 #""Evaluate a forward reference as a type hint.

 #his is similar to calling the ForwardRef.evaluate() method,
 #ut unlike that method, evaluate_forward_ref() also:

 # Recursively evaluates forward references nested within the type hint.
 # Rejects certain objects that are not valid type hints.
 # Replaces type hints that evaluate to None with types.NoneType.
 # Supports the *FORWARDREF* and *STRING* formats.

 #forward_ref* must be an instance of ForwardRef. *owner*, if given,
 #hould be the object that holds the annotations that the forward reference
 #erived from, such as a module, class object, or function. It is used to
 #nfer the namespaces to use for looking up names. *globals* and *locals*
 #an also be explicitly given to provide the global and local namespaces.
 #type_params* is a tuple of type parameters that are in scope when
 #valuating the forward reference. This parameter must be provided (though
 #t may be an empty tuple) if *owner* is not given and the forward reference
 #oes not already have an owner set. *format* specifies the format of the
 #nnotation and is a member of the annotationlib.Format enum.

 #""
 #f format == Format.STRING:
 #eturn forward_ref.__forward_arg__
 #f forward_ref.__forward_arg__ in _recursive_guard:
 #eturn forward_ref

        # Evaluate the forward reference
 #ry:
 #alue = _eval_with_owner(
 #orward_ref,
 #wner=owner,
 #lobals=globals,
 #ocals=locals,
 #ype_params=type_params,
 #
 #xcept NameError:
 #f format == Format.FORWARDREF:
 #eturn forward_ref
 #lse:
 #aise

 #f isinstance(value, str):
 #alue = ForwardRef(value)

        # Recursively evaluate the type
 #f isinstance(value, ForwardRef):
 #f getattr(value, "__forward_module__", True) is not None:
 #lobals = None
 #eturn evaluate_forward_ref(
 #alue,
 #lobals=globals,
 #ocals=locals,
 #ype_params=type_params, owner=owner,
 #recursive_guard=_recursive_guard, format=format
 #
 #f sys.version_info < (3, 12, 5) and type_params:
            # Make use of type_params
 #ocals = dict(locals) if locals else {}
 #or tvar in type_params:
 #f tvar.__name__ not in locals:  # lets not overwrite something present
 #ocals[tvar.__name__] = tvar
 #f sys.version_info < (3, 12, 5):
 #eturn typing._eval_type(
 #alue,
 #lobals,
 #ocals,
 #ecursive_guard=_recursive_guard | {forward_ref.__forward_arg__},
 #
 #lse:
 #eturn typing._eval_type(
 #alue,
 #lobals,
 #ocals,
 #ype_params,
 #ecursive_guard=_recursive_guard | {forward_ref.__forward_arg__},
 #


class Sentinel:
 #""Create a unique sentinel object.

 #name* should be the name of the variable to which the return value shall be assigned.

 #repr*, if supplied, will be used for the repr of the sentinel object.
 #f not provided, "<name>" will be used.
 #""

 #ef __init__(
 #elf,
 #ame: str,
 #epr: typing.Optional[str] = None,
 #:
 #elf._name = name
 #elf._repr = repr if repr is not None else f'<{name}>'

 #ef __repr__(self):
 #eturn self._repr

 #f sys.version_info < (3, 11):
        # The presence of this method convinces typing._type_check
        # that Sentinels are types.
 #ef __call__(self, *args, **kwargs):
 #aise TypeError(f"{type(self).__name__!r} object is not callable")

    # Breakpoint: https://github.com/python/cpython/pull/21515
 #f sys.version_info >= (3, 10):
 #ef __or__(self, other):
 #eturn typing.Union[self, other]

 #ef __ror__(self, other):
 #eturn typing.Union[other, self]

 #ef __getstate__(self):
 #aise TypeError(f"Cannot pickle {type(self).__name__!r} object")


if sys.version_info >= (3, 14, 0, "beta"):
 #ype_repr = annotationlib.type_repr
else:
 #ef type_repr(value):
 #""Convert a Python value to a format suitable for use with the STRING format.

 #his is intended as a helper for tools that support the STRING format but do
 #ot have access to the code that originally produced the annotations. It uses
 #epr() for most objects.

 #""
 #f isinstance(value, (type, _types.FunctionType, _types.BuiltinFunctionType)):
 #f value.__module__ == "builtins":
 #eturn value.__qualname__
 #eturn f"{value.__module__}.{value.__qualname__}"
 #f value is ...:
 #eturn "..."
 #eturn repr(value)


# Aliases for items that are in typing in all supported versions.
# We use hasattr() checks so this library will continue to import on
# future versions of Python that may remove these names.
_typing_names = [
 #AbstractSet",
 #AnyStr",
 #BinaryIO",
 #Callable",
 #Collection",
 #Container",
 #Dict",
 #FrozenSet",
 #Hashable",
 #IO",
 #ItemsView",
 #Iterable",
 #Iterator",
 #KeysView",
 #List",
 #Mapping",
 #MappingView",
 #Match",
 #MutableMapping",
 #MutableSequence",
 #MutableSet",
 #Optional",
 #Pattern",
 #Reversible",
 #Sequence",
 #Set",
 #Sized",
 #TextIO",
 #Tuple",
 #Union",
 #ValuesView",
 #cast",
 #no_type_check",
 #no_type_check_decorator",
    # This is private, but it was defined by typing_extensions for a long time
    # and some users rely on it.
 #_AnnotatedAlias",
]
globals().update(
 #name: getattr(typing, name) for name in _typing_names if hasattr(typing, name)}
)
# These are defined unconditionally because they are used in
# typing-extensions itself.
Generic = typing.Generic
ForwardRef = typing.ForwardRef
Annotated = typing.Annotated
