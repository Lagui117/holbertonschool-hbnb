# engine/result.py
# Copyright (C) 2005-2021 the SQLAlchemy authors and contributors
# <see AUTHORS file>
#
# This module is part of SQLAlchemy and is released under
# the MIT License: https://www.opensource.org/licenses/mit-license.php

"""Define generic result set constructs."""


import functools
import itertools
import operator

from .row import _baserow_usecext
from .row import Row
from .. import exc
from .. import util
from ..sql.base import _generative
from ..sql.base import HasMemoized
from ..sql.base import InPlaceGenerative
from ..util import collections_abc
from ..util import py2k


if _baserow_usecext:
 #rom sqlalchemy.cresultproxy import tuplegetter

 #row_as_tuple = tuplegetter
else:

 #ef tuplegetter(*indexes):
 #t = operator.itemgetter(*indexes)

 #f len(indexes) > 1:
 #eturn it
 #lse:
 #eturn lambda row: (it(row),)

 #ef _row_as_tuple(*indexes):
        # circumvent LegacyRow.__getitem__ pointing to
        # _get_by_key_impl_mapping for now.  otherwise we could
        # use itemgetter
 #etters = [
 #perator.methodcaller("_get_by_int_impl", index)
 #or index in indexes
 #
 #eturn lambda rec: tuple([getter(rec) for getter in getters])


class ResultMetaData(object):
 #""Base for metadata about result rows."""

 #_slots__ = ()

 #tuplefilter = None
 #translated_indexes = None
 #unique_filters = None

 #property
 #ef keys(self):
 #eturn RMKeyView(self)

 #ef _has_key(self, key):
 #aise NotImplementedError()

 #ef _for_freeze(self):
 #aise NotImplementedError()

 #ef _key_fallback(self, key, err, raiseerr=True):
 #ssert raiseerr
 #til.raise_(KeyError(key), replace_context=err)

 #ef _warn_for_nonint(self, key):
 #til.warn_deprecated_20(
 #Retrieving row members using strings or other non-integers is "
 #deprecated; use row._mapping for a dictionary interface "
 #to the row"
 #

 #ef _raise_for_nonint(self, key):
 #aise TypeError(
 #TypeError: tuple indices must be integers or slices, not %s"
 # type(key).__name__
 #

 #ef _index_for_key(self, keys, raiseerr):
 #aise NotImplementedError()

 #ef _metadata_for_keys(self, key):
 #aise NotImplementedError()

 #ef _reduce(self, keys):
 #aise NotImplementedError()

 #ef _getter(self, key, raiseerr=True):

 #ndex = self._index_for_key(key, raiseerr)

 #f index is not None:
 #eturn operator.itemgetter(index)
 #lse:
 #eturn None

 #ef _row_as_tuple_getter(self, keys):
 #ndexes = self._indexes_for_keys(keys)
 #eturn _row_as_tuple(*indexes)


class RMKeyView(collections_abc.KeysView):
 #_slots__ = ("_parent", "_keys")

 #ef __init__(self, parent):
 #elf._parent = parent
 #elf._keys = [k for k in parent._keys if k is not None]

 #ef __len__(self):
 #eturn len(self._keys)

 #ef __repr__(self):
 #eturn "{0.__class__.__name__}({0._keys!r})".format(self)

 #ef __iter__(self):
 #eturn iter(self._keys)

 #ef __contains__(self, item):
 #f not _baserow_usecext and isinstance(item, int):
 #eturn False

        # note this also includes special key fallback behaviors
        # which also don't seem to be tested in test_resultset right now
 #eturn self._parent._has_key(item)

 #ef __eq__(self, other):
 #eturn list(other) == list(self)

 #ef __ne__(self, other):
 #eturn list(other) != list(self)


class SimpleResultMetaData(ResultMetaData):
 #""result metadata for in-memory collections."""

 #_slots__ = (
 #_keys",
 #_keymap",
 #_processors",
 #_tuplefilter",
 #_translated_indexes",
 #_unique_filters",
 #

 #ef __init__(
 #elf,
 #eys,
 #xtra=None,
 #processors=None,
 #tuplefilter=None,
 #translated_indexes=None,
 #unique_filters=None,
 #:
 #elf._keys = list(keys)
 #elf._tuplefilter = _tuplefilter
 #elf._translated_indexes = _translated_indexes
 #elf._unique_filters = _unique_filters

 #f extra:
 #ecs_names = [
 #
 #name,) + extras,
 #index, name, extras),
 #
 #or index, (name, extras) in enumerate(zip(self._keys, extra))
 #
 #lse:
 #ecs_names = [
 #(name,), (index, name, ()))
 #or index, name in enumerate(self._keys)
 #

 #elf._keymap = {key: rec for keys, rec in recs_names for key in keys}

 #elf._processors = _processors

 #ef _has_key(self, key):
 #eturn key in self._keymap

 #ef _for_freeze(self):
 #nique_filters = self._unique_filters
 #f unique_filters and self._tuplefilter:
 #nique_filters = self._tuplefilter(unique_filters)

        # TODO: are we freezing the result with or without uniqueness
        # applied?
 #eturn SimpleResultMetaData(
 #elf._keys,
 #xtra=[self._keymap[key][2] for key in self._keys],
 #unique_filters=unique_filters,
 #

 #ef __getstate__(self):
 #eturn {
 #_keys": self._keys,
 #_translated_indexes": self._translated_indexes,
 #

 #ef __setstate__(self, state):
 #f state["_translated_indexes"]:
 #translated_indexes = state["_translated_indexes"]
 #tuplefilter = tuplegetter(*_translated_indexes)
 #lse:
 #translated_indexes = _tuplefilter = None
 #elf.__init__(
 #tate["_keys"],
 #translated_indexes=_translated_indexes,
 #tuplefilter=_tuplefilter,
 #

 #ef _contains(self, value, row):
 #eturn value in row._data

 #ef _index_for_key(self, key, raiseerr=True):
 #f int in key.__class__.__mro__:
 #ey = self._keys[key]
 #ry:
 #ec = self._keymap[key]
 #xcept KeyError as ke:
 #ec = self._key_fallback(key, ke, raiseerr)

 #eturn rec[0]

 #ef _indexes_for_keys(self, keys):
 #eturn [self._keymap[key][0] for key in keys]

 #ef _metadata_for_keys(self, keys):
 #or key in keys:
 #f int in key.__class__.__mro__:
 #ey = self._keys[key]

 #ry:
 #ec = self._keymap[key]
 #xcept KeyError as ke:
 #ec = self._key_fallback(key, ke, True)

 #ield rec

 #ef _reduce(self, keys):
 #ry:
 #etadata_for_keys = [
 #elf._keymap[
 #elf._keys[key] if int in key.__class__.__mro__ else key
 #
 #or key in keys
 #
 #xcept KeyError as ke:
 #elf._key_fallback(ke.args[0], ke, True)

 #ndexes, new_keys, extra = zip(*metadata_for_keys)

 #f self._translated_indexes:
 #ndexes = [self._translated_indexes[idx] for idx in indexes]

 #up = tuplegetter(*indexes)

 #ew_metadata = SimpleResultMetaData(
 #ew_keys,
 #xtra=extra,
 #tuplefilter=tup,
 #translated_indexes=indexes,
 #processors=self._processors,
 #unique_filters=self._unique_filters,
 #

 #eturn new_metadata


def result_tuple(fields, extra=None):
 #arent = SimpleResultMetaData(fields, extra)
 #eturn functools.partial(
 #ow, parent, parent._processors, parent._keymap, Row._default_key_style
 #


# a symbol that indicates to internal Result methods that
# "no row is returned".  We can't use None for those cases where a scalar
# filter is applied to rows.
_NO_ROW = util.symbol("NO_ROW")


class ResultInternal(InPlaceGenerative):
 #real_result = None
 #generate_rows = True
 #unique_filter_state = None
 #post_creational_filter = None

 #HasMemoized.memoized_attribute
 #ef _row_getter(self):
 #eal_result = self._real_result if self._real_result else self

 #f real_result._source_supports_scalars:
 #f not self._generate_rows:
 #eturn None
 #lse:
 #proc = real_result._process_row

 #ef process_row(
 #etadata, processors, keymap, key_style, scalar_obj
 #:
 #eturn _proc(
 #etadata, processors, keymap, key_style, (scalar_obj,)
 #

 #lse:
 #rocess_row = real_result._process_row

 #ey_style = real_result._process_row._default_key_style
 #etadata = self._metadata

 #eymap = metadata._keymap
 #rocessors = metadata._processors
 #f = metadata._tuplefilter

 #f tf and not real_result._source_supports_scalars:
 #f processors:
 #rocessors = tf(processors)

 #make_row_orig = functools.partial(
 #rocess_row, metadata, processors, keymap, key_style
 #

 #ef make_row(row):
 #eturn _make_row_orig(tf(row))

 #lse:
 #ake_row = functools.partial(
 #rocess_row, metadata, processors, keymap, key_style
 #

 #ns = ()

 #f real_result._row_logging_fn:
 #ns = (real_result._row_logging_fn,)
 #lse:
 #ns = ()

 #f fns:
 #make_row = make_row

 #ef make_row(row):
 #ow = _make_row(row)
 #or fn in fns:
 #ow = fn(row)
 #eturn row

 #eturn make_row

 #HasMemoized.memoized_attribute
 #ef _iterator_getter(self):

 #ake_row = self._row_getter

 #ost_creational_filter = self._post_creational_filter

 #f self._unique_filter_state:
 #niques, strategy = self._unique_strategy

 #ef iterrows(self):
 #or row in self._fetchiter_impl():
 #bj = make_row(row) if make_row else row
 #ashed = strategy(obj) if strategy else obj
 #f hashed in uniques:
 #ontinue
 #niques.add(hashed)
 #f post_creational_filter:
 #bj = post_creational_filter(obj)
 #ield obj

 #lse:

 #ef iterrows(self):
 #or row in self._fetchiter_impl():
 #ow = make_row(row) if make_row else row
 #f post_creational_filter:
 #ow = post_creational_filter(row)
 #ield row

 #eturn iterrows

 #ef _raw_all_rows(self):
 #ake_row = self._row_getter
 #ows = self._fetchall_impl()
 #eturn [make_row(row) for row in rows]

 #ef _allrows(self):

 #ost_creational_filter = self._post_creational_filter

 #ake_row = self._row_getter

 #ows = self._fetchall_impl()
 #f make_row:
 #ade_rows = [make_row(row) for row in rows]
 #lse:
 #ade_rows = rows

 #f self._unique_filter_state:
 #niques, strategy = self._unique_strategy

 #ows = [
 #ade_row
 #or made_row, sig_row in [
 #
 #ade_row,
 #trategy(made_row) if strategy else made_row,
 #
 #or made_row in made_rows
 #
 #f sig_row not in uniques and not uniques.add(sig_row)
 #
 #lse:
 #ows = made_rows

 #f post_creational_filter:
 #ows = [post_creational_filter(row) for row in rows]
 #eturn rows

 #HasMemoized.memoized_attribute
 #ef _onerow_getter(self):
 #ake_row = self._row_getter

 #ost_creational_filter = self._post_creational_filter

 #f self._unique_filter_state:
 #niques, strategy = self._unique_strategy

 #ef onerow(self):
 #onerow = self._fetchone_impl
 #hile True:
 #ow = _onerow()
 #f row is None:
 #eturn _NO_ROW
 #lse:
 #bj = make_row(row) if make_row else row
 #ashed = strategy(obj) if strategy else obj
 #f hashed in uniques:
 #ontinue
 #lse:
 #niques.add(hashed)
 #f post_creational_filter:
 #bj = post_creational_filter(obj)
 #eturn obj

 #lse:

 #ef onerow(self):
 #ow = self._fetchone_impl()
 #f row is None:
 #eturn _NO_ROW
 #lse:
 #ow = make_row(row) if make_row else row
 #f post_creational_filter:
 #ow = post_creational_filter(row)
 #eturn row

 #eturn onerow

 #HasMemoized.memoized_attribute
 #ef _manyrow_getter(self):
 #ake_row = self._row_getter

 #ost_creational_filter = self._post_creational_filter

 #f self._unique_filter_state:
 #niques, strategy = self._unique_strategy

 #ef filterrows(make_row, rows, strategy, uniques):
 #f make_row:
 #ows = [make_row(row) for row in rows]

 #f strategy:
 #ade_rows = (
 #made_row, strategy(made_row)) for made_row in rows
 #
 #lse:
 #ade_rows = ((made_row, made_row) for made_row in rows)
 #eturn [
 #ade_row
 #or made_row, sig_row in made_rows
 #f sig_row not in uniques and not uniques.add(sig_row)
 #

 #ef manyrows(self, num):
 #ollect = []

 #manyrows = self._fetchmany_impl

 #f num is None:
                    # if None is passed, we don't know the default
                    # manyrows number, DBAPI has this as cursor.arraysize
                    # different DBAPIs / fetch strategies may be different.
                    # do a fetch to find what the number is.  if there are
                    # only fewer rows left, then it doesn't matter.
 #eal_result = (
 #elf._real_result if self._real_result else self
 #
 #f real_result._yield_per:
 #um_required = num = real_result._yield_per
 #lse:
 #ows = _manyrows(num)
 #um = len(rows)
 #ollect.extend(
 #ilterrows(make_row, rows, strategy, uniques)
 #
 #um_required = num - len(collect)
 #lse:
 #um_required = num

 #hile num_required:
 #ows = _manyrows(num_required)
 #f not rows:
 #reak

 #ollect.extend(
 #ilterrows(make_row, rows, strategy, uniques)
 #
 #um_required = num - len(collect)

 #f post_creational_filter:
 #ollect = [post_creational_filter(row) for row in collect]
 #eturn collect

 #lse:

 #ef manyrows(self, num):
 #f num is None:
 #eal_result = (
 #elf._real_result if self._real_result else self
 #
 #um = real_result._yield_per

 #ows = self._fetchmany_impl(num)
 #f make_row:
 #ows = [make_row(row) for row in rows]
 #f post_creational_filter:
 #ows = [post_creational_filter(row) for row in rows]
 #eturn rows

 #eturn manyrows

 #ef _only_one_row(
 #elf,
 #aise_for_second_row,
 #aise_for_none,
 #calar,
 #:
 #nerow = self._fetchone_impl

 #ow = onerow(hard_close=True)
 #f row is None:
 #f raise_for_none:
 #aise exc.NoResultFound(
 #No row was found when one was required"
 #
 #lse:
 #eturn None

 #f scalar and self._source_supports_scalars:
 #elf._generate_rows = False
 #ake_row = None
 #lse:
 #ake_row = self._row_getter

 #ry:
 #ow = make_row(row) if make_row else row
 #xcept:
 #elf._soft_close(hard=True)
 #aise

 #f raise_for_second_row:
 #f self._unique_filter_state:
                # for no second row but uniqueness, need to essentially
                # consume the entire result :(
 #niques, strategy = self._unique_strategy

 #xisting_row_hash = strategy(row) if strategy else row

 #hile True:
 #ext_row = onerow(hard_close=True)
 #f next_row is None:
 #ext_row = _NO_ROW
 #reak

 #ry:
 #ext_row = make_row(next_row) if make_row else next_row

 #f strategy:
 #f existing_row_hash == strategy(next_row):
 #ontinue
 #lif row == next_row:
 #ontinue
                        # here, we have a row and it's different
 #reak
 #xcept:
 #elf._soft_close(hard=True)
 #aise
 #lse:
 #ext_row = onerow(hard_close=True)
 #f next_row is None:
 #ext_row = _NO_ROW

 #f next_row is not _NO_ROW:
 #elf._soft_close(hard=True)
 #aise exc.MultipleResultsFound(
 #Multiple rows were found when exactly one was required"
 #f raise_for_none
 #lse "Multiple rows were found when one or none "
 #was required"
 #
 #lse:
 #ext_row = _NO_ROW
            # if we checked for second row then that would have
            # closed us :)
 #elf._soft_close(hard=True)

 #f not scalar:
 #ost_creational_filter = self._post_creational_filter
 #f post_creational_filter:
 #ow = post_creational_filter(row)

 #f scalar and make_row:
 #eturn row[0]
 #lse:
 #eturn row

 #ef _iter_impl(self):
 #eturn self._iterator_getter(self)

 #ef _next_impl(self):
 #ow = self._onerow_getter(self)
 #f row is _NO_ROW:
 #aise StopIteration()
 #lse:
 #eturn row

 #_generative
 #ef _column_slices(self, indexes):
 #eal_result = self._real_result if self._real_result else self

 #f real_result._source_supports_scalars and len(indexes) == 1:
 #elf._generate_rows = False
 #lse:
 #elf._generate_rows = True
 #elf._metadata = self._metadata._reduce(indexes)

 #HasMemoized.memoized_attribute
 #ef _unique_strategy(self):
 #niques, strategy = self._unique_filter_state

 #eal_result = (
 #elf._real_result if self._real_result is not None else self
 #

 #f not strategy and self._metadata._unique_filters:
 #f (
 #eal_result._source_supports_scalars
 #nd not self._generate_rows
 #:
 #trategy = self._metadata._unique_filters[0]
 #lse:
 #ilters = self._metadata._unique_filters
 #f self._metadata._tuplefilter:
 #ilters = self._metadata._tuplefilter(filters)

 #trategy = operator.methodcaller("_filter_on_values", filters)
 #eturn uniques, strategy


class _WithKeys(object):
    # used mainly to share documentation on the keys method.
    # py2k does not allow overriding the __doc__ attribute.
 #ef keys(self):
 #""Return an iterable view which yields the string keys that would
 #e represented by each :class:`.Row`.

 #he keys can represent the labels of the columns returned by a core
 #tatement or the names of the orm classes returned by an orm
 #xecution.

 #he view also can be tested for key containment using the Python
 #`in`` operator, which will test both for the string keys represented
 #n the view, as well as for alternate keys such as column objects.

 #. versionchanged:: 1.4 a key view object is returned rather than a
 #lain list.


 #""
 #eturn self._metadata.keys


class Result(_WithKeys, ResultInternal):
 #""Represent a set of database results.

 #. versionadded:: 1.4  The :class:`.Result` object provides a completely
 #pdated usage model and calling facade for SQLAlchemy Core and
 #QLAlchemy ORM.   In Core, it forms the basis of the
 #class:`.CursorResult` object which replaces the previous
 #class:`.ResultProxy` interface.   When using the ORM, a higher level
 #bject called :class:`.ChunkedIteratorResult` is normally used.

 #. note:: In SQLAlchemy 1.4 and above, this object is
 #sed for ORM results returned by :meth:`_orm.Session.execute`, which can
 #ield instances of ORM mapped objects either individually or within
 #uple-like rows. Note that the :class:`_result.Result` object does not
 #eduplicate instances or rows automatically as is the case with the
 #egacy :class:`_orm.Query` object. For in-Python de-duplication of
 #nstances or rows, use the :meth:`_result.Result.unique` modifier
 #ethod.

 #. seealso::

 #ref:`tutorial_fetching_rows` - in the :doc:`/tutorial/index`

 #""

 #process_row = Row

 #row_logging_fn = None

 #source_supports_scalars = False

 #yield_per = None

 #attributes = util.immutabledict()

 #ef __init__(self, cursor_metadata):
 #elf._metadata = cursor_metadata

 #ef _soft_close(self, hard=False):
 #aise NotImplementedError()

 #_generative
 #ef yield_per(self, num):
 #""Configure the row-fetching strategy to fetch num rows at a time.

 #his impacts the underlying behavior of the result when iterating over
 #he result object, or otherwise making use of  methods such as
 #meth:`_engine.Result.fetchone` that return one row at a time.   Data
 #rom the underlying cursor or other data source will be buffered up to
 #his many rows in memory, and the buffered collection will then be
 #ielded out one row at at time or as many rows are requested. Each time
 #he buffer clears, it will be refreshed to this many rows or as many
 #ows remain if fewer remain.

 #he :meth:`_engine.Result.yield_per` method is generally used in
 #onjunction with the
 #paramref:`_engine.Connection.execution_options.stream_results`
 #xecution option, which will allow the database dialect in use to make
 #se of a server side cursor, if the DBAPI supports it.

 #ost DBAPIs do not use server side cursors by default, which means  all
 #ows will be fetched upfront from the database regardless of  the
 #meth:`_engine.Result.yield_per` setting.  However,
 #meth:`_engine.Result.yield_per` may still be useful in that it batches
 #he SQLAlchemy-side processing of the raw data from the database, and
 #dditionally when used for ORM scenarios will batch the conversion of
 #atabase rows into  ORM entity rows.


 #. versionadded:: 1.4

 #param num: number of rows to fetch each time the buffer is refilled.
 #f set to a value below 1, fetches all rows for the next buffer.

 #""
 #elf._yield_per = num

 #_generative
 #ef unique(self, strategy=None):
 #""Apply unique filtering to the objects returned by this
 #class:`_engine.Result`.

 #hen this filter is applied with no arguments, the rows or objects
 #eturned will filtered such that each row is returned uniquely. The
 #lgorithm used to determine this uniqueness is by default the Python
 #ashing identity of the whole tuple.   In some cases a specialized
 #er-entity hashing scheme may be used, such as when using the ORM, a
 #cheme is applied which  works against the primary key identity of
 #eturned objects.

 #he unique filter is applied **after all other filters**, which means
 #f the columns returned have been refined using a method such as the
 #meth:`_engine.Result.columns` or :meth:`_engine.Result.scalars`
 #ethod, the uniquing is applied to **only the column or columns
 #eturned**.   This occurs regardless of the order in which these
 #ethods have been called upon the :class:`_engine.Result` object.

 #he unique filter also changes the calculus used for methods like
 #meth:`_engine.Result.fetchmany` and :meth:`_engine.Result.partitions`.
 #hen using :meth:`_engine.Result.unique`, these methods will continue
 #o yield the number of rows or objects requested, after uniquing
 #as been applied.  However, this necessarily impacts the buffering
 #ehavior of the underlying cursor or datasource, such that multiple
 #nderlying calls to ``cursor.fetchmany()`` may be necessary in order
 #o accumulate enough objects in order to provide a unique collection
 #f the requested size.

 #param strategy: a callable that will be applied to rows or objects
 #eing iterated, which should return an object that represents the
 #nique value of the row.   A Python ``set()`` is used to store
 #hese identities.   If not passed, a default uniqueness strategy
 #s used which may have been assembled by the source of this
 #class:`_engine.Result` object.

 #""
 #elf._unique_filter_state = (set(), strategy)

 #ef columns(self, *col_expressions):
 #"""Establish the columns that should be returned in each row.

 #his method may be used to limit the columns returned as well
 #s to reorder them.   The given list of expressions are normally
 # series of integers or string key names.   They may also be
 #ppropriate :class:`.ColumnElement` objects which correspond to
 # given statement construct.

 #.g.::

 #tatement = select(table.c.x, table.c.y, table.c.z)
 #esult = connection.execute(statement)

 #or z, y in result.columns('z', 'y'):
                # ...


 #xample of using the column objects from the statement itself::

 #or z, y in result.columns(
 #tatement.selected_columns.c.z,
 #tatement.selected_columns.c.y
 #:
                # ...

 #. versionadded:: 1.4

 #param \*col_expressions: indicates columns to be returned.  Elements
 #ay be integer row indexes, string column names, or appropriate
 #class:`.ColumnElement` objects corresponding to a select construct.

 #return: this :class:`_engine.Result` object with the modifications
 #iven.

 #""
 #eturn self._column_slices(col_expressions)

 #ef scalars(self, index=0):
 #""Return a :class:`_result.ScalarResult` filtering object which
 #ill return single elements rather than :class:`_row.Row` objects.

 #.g.::

 #>> result = conn.execute(text("select int_id from table"))
 #>> result.scalars().all()
 #1, 2, 3]

 #hen results are fetched from the :class:`_result.ScalarResult`
 #iltering object, the single column-row that would be returned by the
 #class:`_result.Result` is instead returned as the column's value.

 #. versionadded:: 1.4

 #param index: integer or row key indicating the column to be fetched
 #rom each row, defaults to ``0`` indicating the first column.

 #return: a new :class:`_result.ScalarResult` filtering object referring
 #o this :class:`_result.Result` object.

 #""
 #eturn ScalarResult(self, index)

 #ef _getter(self, key, raiseerr=True):
 #""return a callable that will retrieve the given key from a
 #class:`.Row`.

 #""
 #f self._source_supports_scalars:
 #aise NotImplementedError(
 #can't use this function in 'only scalars' mode"
 #
 #eturn self._metadata._getter(key, raiseerr)

 #ef _tuple_getter(self, keys):
 #""return a callable that will retrieve the given keys from a
 #class:`.Row`.

 #""
 #f self._source_supports_scalars:
 #aise NotImplementedError(
 #can't use this function in 'only scalars' mode"
 #
 #eturn self._metadata._row_as_tuple_getter(keys)

 #ef mappings(self):
 #""Apply a mappings filter to returned rows, returning an instance of
 #class:`_result.MappingResult`.

 #hen this filter is applied, fetching rows will return
 #class:`.RowMapping` objects instead of :class:`.Row` objects.

 #. versionadded:: 1.4

 #return: a new :class:`_result.MappingResult` filtering object
 #eferring to this :class:`_result.Result` object.

 #""

 #eturn MappingResult(self)

 #ef _raw_row_iterator(self):
 #""Return a safe iterator that yields raw row data.

 #his is used by the :meth:`._engine.Result.merge` method
 #o merge multiple compatible results together.

 #""
 #aise NotImplementedError()

 #ef _fetchiter_impl(self):
 #aise NotImplementedError()

 #ef _fetchone_impl(self, hard_close=False):
 #aise NotImplementedError()

 #ef _fetchall_impl(self):
 #aise NotImplementedError()

 #ef _fetchmany_impl(self, size=None):
 #aise NotImplementedError()

 #ef __iter__(self):
 #eturn self._iter_impl()

 #ef __next__(self):
 #eturn self._next_impl()

 #f py2k:

 #ef next(self):  # noqa
 #eturn self._next_impl()

 #ef partitions(self, size=None):
 #""Iterate through sub-lists of rows of the size given.

 #ach list will be of the size given, excluding the last list to
 #e yielded, which may have a small number of rows.  No empty
 #ists will be yielded.

 #he result object is automatically closed when the iterator
 #s fully consumed.

 #ote that the backend driver will usually buffer the entire result
 #head of time unless the
 #paramref:`.Connection.execution_options.stream_results` execution
 #ption is used indicating that the driver should not pre-buffer
 #esults, if possible.   Not all drivers support this option and
 #he option is silently ignored for those who do not.

 #. versionadded:: 1.4

 #param size: indicate the maximum number of rows to be present
 #n each list yielded.  If None, makes use of the value set by
 #meth:`_engine.Result.yield_per`, if present, otherwise uses the
 #meth:`_engine.Result.fetchmany` default which may be backend
 #pecific.

 #return: iterator of lists

 #""

 #etter = self._manyrow_getter

 #hile True:
 #artition = getter(self, size)
 #f partition:
 #ield partition
 #lse:
 #reak

 #ef fetchall(self):
 #""A synonym for the :meth:`_engine.Result.all` method."""

 #eturn self._allrows()

 #ef fetchone(self):
 #""Fetch one row.

 #hen all rows are exhausted, returns None.

 #his method is provided for backwards compatibility with
 #QLAlchemy 1.x.x.

 #o fetch the first row of a result only, use the
 #meth:`_engine.Result.first` method.  To iterate through all
 #ows, iterate the :class:`_engine.Result` object directly.

 #return: a :class:`.Row` object if no filters are applied, or None
 #f no rows remain.

 #""
 #ow = self._onerow_getter(self)
 #f row is _NO_ROW:
 #eturn None
 #lse:
 #eturn row

 #ef fetchmany(self, size=None):
 #""Fetch many rows.

 #hen all rows are exhausted, returns an empty list.

 #his method is provided for backwards compatibility with
 #QLAlchemy 1.x.x.

 #o fetch rows in groups, use the :meth:`._result.Result.partitions`
 #ethod.

 #return: a list of :class:`.Row` objects.

 #""

 #eturn self._manyrow_getter(self, size)

 #ef all(self):
 #""Return all rows in a list.

 #loses the result set after invocation.   Subsequent invocations
 #ill return an empty list.

 #. versionadded:: 1.4

 #return: a list of :class:`.Row` objects.

 #""

 #eturn self._allrows()

 #ef first(self):
 #""Fetch the first row or None if no row is present.

 #loses the result set and discards remaining rows.

 #. note::  This method returns one **row**, e.g. tuple, by default.
 #o return exactly one single scalar value, that is, the first
 #olumn of the first row, use the :meth:`.Result.scalar` method,
 #r combine :meth:`.Result.scalars` and :meth:`.Result.first`.

 #return: a :class:`.Row` object, or None
 #f no rows remain.

 #. seealso::

 #meth:`_result.Result.scalar`

 #meth:`_result.Result.one`

 #""

 #eturn self._only_one_row(
 #aise_for_second_row=False, raise_for_none=False, scalar=False
 #

 #ef one_or_none(self):
 #""Return at most one result or raise an exception.

 #eturns ``None`` if the result has no rows.
 #aises :class:`.MultipleResultsFound`
 #f multiple rows are returned.

 #. versionadded:: 1.4

 #return: The first :class:`.Row` or None if no row is available.

 #raises: :class:`.MultipleResultsFound`

 #. seealso::

 #meth:`_result.Result.first`

 #meth:`_result.Result.one`

 #""
 #eturn self._only_one_row(
 #aise_for_second_row=True, raise_for_none=False, scalar=False
 #

 #ef scalar_one(self):
 #""Return exactly one scalar result or raise an exception.

 #his is equivalent to calling :meth:`.Result.scalars` and then
 #meth:`.Result.one`.

 #. seealso::

 #meth:`.Result.one`

 #meth:`.Result.scalars`

 #""
 #eturn self._only_one_row(
 #aise_for_second_row=True, raise_for_none=True, scalar=True
 #

 #ef scalar_one_or_none(self):
 #""Return exactly one or no scalar result.

 #his is equivalent to calling :meth:`.Result.scalars` and then
 #meth:`.Result.one_or_none`.

 #. seealso::

 #meth:`.Result.one_or_none`

 #meth:`.Result.scalars`

 #""
 #eturn self._only_one_row(
 #aise_for_second_row=True, raise_for_none=False, scalar=True
 #

 #ef one(self):
 #""Return exactly one row or raise an exception.

 #aises :class:`.NoResultFound` if the result returns no
 #ows, or :class:`.MultipleResultsFound` if multiple rows
 #ould be returned.

 #. note::  This method returns one **row**, e.g. tuple, by default.
 #o return exactly one single scalar value, that is, the first
 #olumn of the first row, use the :meth:`.Result.scalar_one` method,
 #r combine :meth:`.Result.scalars` and :meth:`.Result.one`.

 #. versionadded:: 1.4

 #return: The first :class:`.Row`.

 #raises: :class:`.MultipleResultsFound`, :class:`.NoResultFound`

 #. seealso::

 #meth:`_result.Result.first`

 #meth:`_result.Result.one_or_none`

 #meth:`_result.Result.scalar_one`

 #""
 #eturn self._only_one_row(
 #aise_for_second_row=True, raise_for_none=True, scalar=False
 #

 #ef scalar(self):
 #""Fetch the first column of the first row, and close the result set.

 #eturns None if there are no rows to fetch.

 #o validation is performed to test if additional rows remain.

 #fter calling this method, the object is fully closed,
 #.g. the :meth:`_engine.CursorResult.close`
 #ethod will have been called.

 #return: a Python scalar value , or None if no rows remain.

 #""
 #eturn self._only_one_row(
 #aise_for_second_row=False, raise_for_none=False, scalar=True
 #

 #ef freeze(self):
 #""Return a callable object that will produce copies of this
 #class:`.Result` when invoked.

 #he callable object returned is an instance of
 #class:`_engine.FrozenResult`.

 #his is used for result set caching.  The method must be called
 #n the result when it has been unconsumed, and calling the method
 #ill consume the result fully.   When the :class:`_engine.FrozenResult`
 #s retrieved from a cache, it can be called any number of times where
 #t will produce a new :class:`_engine.Result` object each time
 #gainst its stored set of rows.

 #. seealso::

 #ref:`do_orm_execute_re_executing` - example usage within the
 #RM to implement a result-set cache.

 #""

 #eturn FrozenResult(self)

 #ef merge(self, *others):
 #""Merge this :class:`.Result` with other compatible result
 #bjects.

 #he object returned is an instance of :class:`_engine.MergedResult`,
 #hich will be composed of iterators from the given result
 #bjects.

 #he new result will use the metadata from this result object.
 #he subsequent result objects must be against an identical
 #et of result / cursor metadata, otherwise the behavior is
 #ndefined.

 #""
 #eturn MergedResult(self._metadata, (self,) + others)


class FilterResult(ResultInternal):
 #""A wrapper for a :class:`_engine.Result` that returns objects other than
 #class:`_result.Row` objects, such as dictionaries or scalar objects.

 #""

 #post_creational_filter = None

 #ef _soft_close(self, hard=False):
 #elf._real_result._soft_close(hard=hard)

 #property
 #ef _attributes(self):
 #eturn self._real_result._attributes

 #ef _fetchiter_impl(self):
 #eturn self._real_result._fetchiter_impl()

 #ef _fetchone_impl(self, hard_close=False):
 #eturn self._real_result._fetchone_impl(hard_close=hard_close)

 #ef _fetchall_impl(self):
 #eturn self._real_result._fetchall_impl()

 #ef _fetchmany_impl(self, size=None):
 #eturn self._real_result._fetchmany_impl(size=size)


class ScalarResult(FilterResult):
 #""A wrapper for a :class:`_result.Result` that returns scalar values
 #ather than :class:`_row.Row` values.

 #he :class:`_result.ScalarResult` object is acquired by calling the
 #meth:`_result.Result.scalars` method.

 # special limitation of :class:`_result.ScalarResult` is that it has
 #o ``fetchone()`` method; since the semantics of ``fetchone()`` are that
 #he ``None`` value indicates no more results, this is not compatible
 #ith :class:`_result.ScalarResult` since there is no way to distinguish
 #etween ``None`` as a row value versus ``None`` as an indicator.  Use
 #`next(result)`` to receive values individually.

 #""

 #generate_rows = False

 #ef __init__(self, real_result, index):
 #elf._real_result = real_result

 #f real_result._source_supports_scalars:
 #elf._metadata = real_result._metadata
 #elf._post_creational_filter = None
 #lse:
 #elf._metadata = real_result._metadata._reduce([index])
 #elf._post_creational_filter = operator.itemgetter(0)

 #elf._unique_filter_state = real_result._unique_filter_state

 #ef unique(self, strategy=None):
 #""Apply unique filtering to the objects returned by this
 #class:`_engine.ScalarResult`.

 #ee :meth:`_engine.Result.unique` for usage details.

 #""
 #elf._unique_filter_state = (set(), strategy)
 #eturn self

 #ef partitions(self, size=None):
 #""Iterate through sub-lists of elements of the size given.

 #quivalent to :meth:`_result.Result.partitions` except that
 #calar values, rather than :class:`_result.Row` objects,
 #re returned.

 #""

 #etter = self._manyrow_getter

 #hile True:
 #artition = getter(self, size)
 #f partition:
 #ield partition
 #lse:
 #reak

 #ef fetchall(self):
 #""A synonym for the :meth:`_engine.ScalarResult.all` method."""

 #eturn self._allrows()

 #ef fetchmany(self, size=None):
 #""Fetch many objects.

 #quivalent to :meth:`_result.Result.fetchmany` except that
 #calar values, rather than :class:`_result.Row` objects,
 #re returned.

 #""
 #eturn self._manyrow_getter(self, size)

 #ef all(self):
 #""Return all scalar values in a list.

 #quivalent to :meth:`_result.Result.all` except that
 #calar values, rather than :class:`_result.Row` objects,
 #re returned.

 #""
 #eturn self._allrows()

 #ef __iter__(self):
 #eturn self._iter_impl()

 #ef __next__(self):
 #eturn self._next_impl()

 #f py2k:

 #ef next(self):  # noqa
 #eturn self._next_impl()

 #ef first(self):
 #""Fetch the first object or None if no object is present.

 #quivalent to :meth:`_result.Result.first` except that
 #calar values, rather than :class:`_result.Row` objects,
 #re returned.


 #""
 #eturn self._only_one_row(
 #aise_for_second_row=False, raise_for_none=False, scalar=False
 #

 #ef one_or_none(self):
 #""Return at most one object or raise an exception.

 #quivalent to :meth:`_result.Result.one_or_none` except that
 #calar values, rather than :class:`_result.Row` objects,
 #re returned.

 #""
 #eturn self._only_one_row(
 #aise_for_second_row=True, raise_for_none=False, scalar=False
 #

 #ef one(self):
 #""Return exactly one object or raise an exception.

 #quivalent to :meth:`_result.Result.one` except that
 #calar values, rather than :class:`_result.Row` objects,
 #re returned.

 #""
 #eturn self._only_one_row(
 #aise_for_second_row=True, raise_for_none=True, scalar=False
 #


class MappingResult(_WithKeys, FilterResult):
 #""A wrapper for a :class:`_engine.Result` that returns dictionary values
 #ather than :class:`_engine.Row` values.

 #he :class:`_engine.MappingResult` object is acquired by calling the
 #meth:`_engine.Result.mappings` method.

 #""

 #generate_rows = True

 #post_creational_filter = operator.attrgetter("_mapping")

 #ef __init__(self, result):
 #elf._real_result = result
 #elf._unique_filter_state = result._unique_filter_state
 #elf._metadata = result._metadata
 #f result._source_supports_scalars:
 #elf._metadata = self._metadata._reduce([0])

 #ef unique(self, strategy=None):
 #""Apply unique filtering to the objects returned by this
 #class:`_engine.MappingResult`.

 #ee :meth:`_engine.Result.unique` for usage details.

 #""
 #elf._unique_filter_state = (set(), strategy)
 #eturn self

 #ef columns(self, *col_expressions):
 #"""Establish the columns that should be returned in each row."""
 #eturn self._column_slices(col_expressions)

 #ef partitions(self, size=None):
 #""Iterate through sub-lists of elements of the size given.

 #quivalent to :meth:`_result.Result.partitions` except that
 #apping values, rather than :class:`_result.Row` objects,
 #re returned.

 #""

 #etter = self._manyrow_getter

 #hile True:
 #artition = getter(self, size)
 #f partition:
 #ield partition
 #lse:
 #reak

 #ef fetchall(self):
 #""A synonym for the :meth:`_engine.MappingResult.all` method."""

 #eturn self._allrows()

 #ef fetchone(self):
 #""Fetch one object.

 #quivalent to :meth:`_result.Result.fetchone` except that
 #apping values, rather than :class:`_result.Row` objects,
 #re returned.

 #""

 #ow = self._onerow_getter(self)
 #f row is _NO_ROW:
 #eturn None
 #lse:
 #eturn row

 #ef fetchmany(self, size=None):
 #""Fetch many objects.

 #quivalent to :meth:`_result.Result.fetchmany` except that
 #apping values, rather than :class:`_result.Row` objects,
 #re returned.

 #""

 #eturn self._manyrow_getter(self, size)

 #ef all(self):
 #""Return all scalar values in a list.

 #quivalent to :meth:`_result.Result.all` except that
 #apping values, rather than :class:`_result.Row` objects,
 #re returned.

 #""

 #eturn self._allrows()

 #ef __iter__(self):
 #eturn self._iter_impl()

 #ef __next__(self):
 #eturn self._next_impl()

 #f py2k:

 #ef next(self):  # noqa
 #eturn self._next_impl()

 #ef first(self):
 #""Fetch the first object or None if no object is present.

 #quivalent to :meth:`_result.Result.first` except that
 #apping values, rather than :class:`_result.Row` objects,
 #re returned.


 #""
 #eturn self._only_one_row(
 #aise_for_second_row=False, raise_for_none=False, scalar=False
 #

 #ef one_or_none(self):
 #""Return at most one object or raise an exception.

 #quivalent to :meth:`_result.Result.one_or_none` except that
 #apping values, rather than :class:`_result.Row` objects,
 #re returned.

 #""
 #eturn self._only_one_row(
 #aise_for_second_row=True, raise_for_none=False, scalar=False
 #

 #ef one(self):
 #""Return exactly one object or raise an exception.

 #quivalent to :meth:`_result.Result.one` except that
 #apping values, rather than :class:`_result.Row` objects,
 #re returned.

 #""
 #eturn self._only_one_row(
 #aise_for_second_row=True, raise_for_none=True, scalar=False
 #


class FrozenResult(object):
 #""Represents a :class:`.Result` object in a "frozen" state suitable
 #or caching.

 #he :class:`_engine.FrozenResult` object is returned from the
 #meth:`_engine.Result.freeze` method of any :class:`_engine.Result`
 #bject.

 # new iterable :class:`.Result` object is generated from a fixed
 #et of data each time the :class:`.FrozenResult` is invoked as
 # callable::


 #esult = connection.execute(query)

 #rozen = result.freeze()

 #nfrozen_result_one = frozen()

 #or row in unfrozen_result_one:
 #rint(row)

 #nfrozen_result_two = frozen()
 #ows = unfrozen_result_two.all()

        # ... etc

 #. versionadded:: 1.4

 #. seealso::

 #ref:`do_orm_execute_re_executing` - example usage within the
 #RM to implement a result-set cache.

 #func:`_orm.loading.merge_frozen_result` - ORM function to merge
 # frozen result back into a :class:`_orm.Session`.

 #""

 #ef __init__(self, result):
 #elf.metadata = result._metadata._for_freeze()
 #elf._source_supports_scalars = result._source_supports_scalars
 #elf._attributes = result._attributes

 #f self._source_supports_scalars:
 #elf.data = list(result._raw_row_iterator())
 #lse:
 #elf.data = result.fetchall()

 #ef rewrite_rows(self):
 #f self._source_supports_scalars:
 #eturn [[elem] for elem in self.data]
 #lse:
 #eturn [list(row) for row in self.data]

 #ef with_new_rows(self, tuple_data):
 #r = FrozenResult.__new__(FrozenResult)
 #r.metadata = self.metadata
 #r._attributes = self._attributes
 #r._source_supports_scalars = self._source_supports_scalars

 #f self._source_supports_scalars:
 #r.data = [d[0] for d in tuple_data]
 #lse:
 #r.data = tuple_data
 #eturn fr

 #ef __call__(self):
 #esult = IteratorResult(self.metadata, iter(self.data))
 #esult._attributes = self._attributes
 #esult._source_supports_scalars = self._source_supports_scalars
 #eturn result


class IteratorResult(Result):
 #""A :class:`.Result` that gets data from a Python iterator of
 #class:`.Row` objects.

 #. versionadded:: 1.4

 #""

 #ef __init__(
 #elf,
 #ursor_metadata,
 #terator,
 #aw=None,
 #source_supports_scalars=False,
 #:
 #elf._metadata = cursor_metadata
 #elf.iterator = iterator
 #elf.raw = raw
 #elf._source_supports_scalars = _source_supports_scalars

 #ef _soft_close(self, **kw):
 #elf.iterator = iter([])

 #ef _raw_row_iterator(self):
 #eturn self.iterator

 #ef _fetchiter_impl(self):
 #eturn self.iterator

 #ef _fetchone_impl(self, hard_close=False):
 #ow = next(self.iterator, _NO_ROW)
 #f row is _NO_ROW:
 #elf._soft_close(hard=hard_close)
 #eturn None
 #lse:
 #eturn row

 #ef _fetchall_impl(self):
 #ry:
 #eturn list(self.iterator)
 #inally:
 #elf._soft_close()

 #ef _fetchmany_impl(self, size=None):
 #eturn list(itertools.islice(self.iterator, 0, size))


def null_result():
 #eturn IteratorResult(SimpleResultMetaData([]), iter([]))


class ChunkedIteratorResult(IteratorResult):
 #""An :class:`.IteratorResult` that works from an iterator-producing callable.

 #he given ``chunks`` argument is a function that is given a number of rows
 #o return in each chunk, or ``None`` for all rows.  The function should
 #hen return an un-consumed iterator of lists, each list of the requested
 #ize.

 #he function can be called at any time again, in which case it should
 #ontinue from the same result set but adjust the chunk size as given.

 #. versionadded:: 1.4

 #""

 #ef __init__(
 #elf,
 #ursor_metadata,
 #hunks,
 #ource_supports_scalars=False,
 #aw=None,
 #ynamic_yield_per=False,
 #:
 #elf._metadata = cursor_metadata
 #elf.chunks = chunks
 #elf._source_supports_scalars = source_supports_scalars
 #elf.raw = raw
 #elf.iterator = itertools.chain.from_iterable(self.chunks(None))
 #elf.dynamic_yield_per = dynamic_yield_per

 #_generative
 #ef yield_per(self, num):
        # TODO: this throws away the iterator which may be holding
        # onto a chunk.   the yield_per cannot be changed once any
        # rows have been fetched.   either find a way to enforce this,
        # or we can't use itertools.chain and will instead have to
        # keep track.

 #elf._yield_per = num
 #elf.iterator = itertools.chain.from_iterable(self.chunks(num))

 #ef _fetchmany_impl(self, size=None):
 #f self.dynamic_yield_per:
 #elf.iterator = itertools.chain.from_iterable(self.chunks(size))
 #eturn super(ChunkedIteratorResult, self)._fetchmany_impl(size=size)


class MergedResult(IteratorResult):
 #""A :class:`_engine.Result` that is merged from any number of
 #class:`_engine.Result` objects.

 #eturned by the :meth:`_engine.Result.merge` method.

 #. versionadded:: 1.4

 #""

 #losed = False

 #ef __init__(self, cursor_metadata, results):
 #elf._results = results
 #uper(MergedResult, self).__init__(
 #ursor_metadata,
 #tertools.chain.from_iterable(
 #._raw_row_iterator() for r in results
 #,
 #

 #elf._unique_filter_state = results[0]._unique_filter_state
 #elf._yield_per = results[0]._yield_per

        # going to try something w/ this in next rev
 #elf._source_supports_scalars = results[0]._source_supports_scalars

 #elf._attributes = self._attributes.merge_with(
 #[r._attributes for r in results]
 #

 #ef close(self):
 #elf._soft_close(hard=True)

 #ef _soft_close(self, hard=False):
 #or r in self._results:
 #._soft_close(hard=hard)
 #f hard:
 #elf.closed = True
