# engine/create.py
# Copyright (C) 2005-2021 the SQLAlchemy authors and contributors
# <see AUTHORS file>
#
# This module is part of SQLAlchemy and is released under
# the MIT License: https://www.opensource.org/licenses/mit-license.php


from . import base
from . import url as _url
from .mock import create_mock_engine
from .. import event
from .. import exc
from .. import pool as poollib
from .. import util
from ..sql import compiler


@util.deprecated_params(
 #trategy=(
 #1.4",
 #The :paramref:`_sa.create_engine.strategy` keyword is deprecated, "
 #and the only argument accepted is 'mock'; please use "
 #:func:`.create_mock_engine` going forward.  For general "
 #customization of create_engine which may have been accomplished "
 #using strategies, see :class:`.CreateEnginePlugin`.",
 #,
 #mpty_in_strategy=(
 #1.4",
 #The :paramref:`_sa.create_engine.empty_in_strategy` keyword is "
 #deprecated, and no longer has any effect.  All IN expressions "
 #are now rendered using "
 #the "expanding parameter" strategy which renders a set of bound'
 #expressions, or an "empty set" SELECT, at statement execution'
 #time.",
 #,
 #ase_sensitive=(
 #1.4",
 #The :paramref:`_sa.create_engine.case_sensitive` parameter "
 #is deprecated and will be removed in a future release. "
 #Applications should work with result column names in a case "
 #sensitive fashion.",
 #,
)
def create_engine(url, **kwargs):
 #""Create a new :class:`_engine.Engine` instance.

 #he standard calling form is to send the :ref:`URL <database_urls>` as the
 #irst positional argument, usually a string
 #hat indicates database dialect and connection arguments::

 #ngine = create_engine("postgresql://scott:tiger@localhost/test")

 #. note::

 #lease review :ref:`database_urls` for general guidelines in composing
 #RL strings.  In particular, special characters, such as those often
 #art of passwords, must be URL encoded to be properly parsed.

 #dditional keyword arguments may then follow it which
 #stablish various options on the resulting :class:`_engine.Engine`
 #nd its underlying :class:`.Dialect` and :class:`_pool.Pool`
 #onstructs::

 #ngine = create_engine("mysql://scott:tiger@hostname/dbname",
 #ncoding='latin1', echo=True)

 #he string form of the URL is
 #`dialect[+driver]://user:password@host/dbname[?key=value..]``, where
 #`dialect`` is a database name such as ``mysql``, ``oracle``,
 #`postgresql``, etc., and ``driver`` the name of a DBAPI, such as
 #`psycopg2``, ``pyodbc``, ``cx_oracle``, etc.  Alternatively,
 #he URL can be an instance of :class:`~sqlalchemy.engine.url.URL`.

 #`**kwargs`` takes a wide variety of options which are routed
 #owards their appropriate components.  Arguments may be specific to
 #he :class:`_engine.Engine`, the underlying :class:`.Dialect`,
 #s well as the
 #class:`_pool.Pool`.  Specific dialects also accept keyword arguments that
 #re unique to that dialect.   Here, we describe the parameters
 #hat are common to most :func:`_sa.create_engine()` usage.

 #nce established, the newly resulting :class:`_engine.Engine` will
 #equest a connection from the underlying :class:`_pool.Pool` once
 #meth:`_engine.Engine.connect` is called, or a method which depends on it
 #uch as :meth:`_engine.Engine.execute` is invoked.   The
 #class:`_pool.Pool` in turn
 #ill establish the first actual DBAPI connection when this request
 #s received.   The :func:`_sa.create_engine` call itself does **not**
 #stablish any actual DBAPI connections directly.

 #. seealso::

 #doc:`/core/engines`

 #doc:`/dialects/index`

 #ref:`connections_toplevel`

 #param case_sensitive: if False, result column names
 #ill match in a case-insensitive fashion, that is,
 #`row['SomeColumn']``.

 #param connect_args: a dictionary of options which will be
 #assed directly to the DBAPI's ``connect()`` method as
 #dditional keyword arguments.  See the example
 #t :ref:`custom_dbapi_args`.

 #param convert_unicode=False: if set to True, causes
 #ll :class:`.String` datatypes to act as though the
 #paramref:`.String.convert_unicode` flag has been set to ``True``,
 #egardless of a setting of ``False`` on an individual :class:`.String`
 #ype.  This has the effect of causing all :class:`.String` -based
 #olumns to accommodate Python Unicode objects directly as though the
 #atatype were the :class:`.Unicode` type.

 #. deprecated:: 1.3

 #he :paramref:`_sa.create_engine.convert_unicode` parameter
 #s deprecated and will be removed in a future release.
 #ll modern DBAPIs now support Python Unicode directly and this
 #arameter is unnecessary.

 #param creator: a callable which returns a DBAPI connection.
 #his creation function will be passed to the underlying
 #onnection pool and will be used to create all new database
 #onnections. Usage of this function causes connection
 #arameters specified in the URL argument to be bypassed.

 #his hook is not as flexible as the newer
 #meth:`_events.DialectEvents.do_connect` hook which allows complete
 #ontrol over how a connection is made to the database, given the full
 #et of URL arguments and state beforehand.

 #. seealso::

 #meth:`_events.DialectEvents.do_connect` - event hook that allows
 #ull control over DBAPI connection mechanics.

 #ref:`custom_dbapi_args`

 #param echo=False: if True, the Engine will log all statements
 #s well as a ``repr()`` of their parameter lists to the default log
 #andler, which defaults to ``sys.stdout`` for output.   If set to the
 #tring ``"debug"``, result rows will be printed to the standard output
 #s well. The ``echo`` attribute of ``Engine`` can be modified at any
 #ime to turn logging on and off; direct control of logging is also
 #vailable using the standard Python ``logging`` module.

 #. seealso::

 #ref:`dbengine_logging` - further detail on how to configure
 #ogging.


 #param echo_pool=False: if True, the connection pool will log
 #nformational output such as when connections are invalidated
 #s well as when connections are recycled to the default log handler,
 #hich defaults to ``sys.stdout`` for output.   If set to the string
 #`"debug"``, the logging will include pool checkouts and checkins.
 #irect control of logging is also available using the standard Python
 #`logging`` module.

 #. seealso::

 #ref:`dbengine_logging` - further detail on how to configure
 #ogging.


 #param empty_in_strategy:   No longer used; SQLAlchemy now uses
 #empty set" behavior for IN in all cases.

 #param enable_from_linting: defaults to True.  Will emit a warning
 #f a given SELECT statement is found to have un-linked FROM elements
 #hich would cause a cartesian product.

 #. versionadded:: 1.4

 #. seealso::

 #ref:`change_4737`

 #param encoding: Defaults to ``utf-8``.  This is the string
 #ncoding used by SQLAlchemy for string encode/decode
 #perations which occur within SQLAlchemy, **outside of
 #he DBAPIs own encoding facilities.**

 #. note:: The ``encoding`` parameter deals only with in-Python
 #ncoding issues that were prevalent with many DBAPIs under  Python
 #.  Under Python 3 it is mostly unused.   For  DBAPIs that require
 #lient encoding configurations, such as those of MySQL and Oracle,
 #lease consult specific :ref:`dialect documentation
 #dialect_toplevel>` for details.

 #ll modern DBAPIs that work in Python 3 necessarily feature direct
 #upport for Python unicode strings.   Under Python 2, this was not
 #lways the case.  For those scenarios where the DBAPI is detected as
 #ot supporting a Python ``unicode`` object under Python 2, this
 #ncoding is used to determine the source/destination encoding.  It is
 #*not used** for those cases where the DBAPI handles unicode directly.

 #o properly configure a system to accommodate Python ``unicode``
 #bjects, the DBAPI should be configured to handle unicode to the
 #reatest degree as is appropriate - see the notes on unicode pertaining
 #o the specific target database in use at :ref:`dialect_toplevel`.

 #reas where string encoding may need to be accommodated
 #utside of the DBAPI, nearly always under **Python 2 only**,
 #nclude zero or more of:

 # the values passed to bound parameters, corresponding to
 #he :class:`.Unicode` type or the :class:`.String` type
 #hen ``convert_unicode`` is ``True``;
 # the values returned in result set columns corresponding
 #o the :class:`.Unicode` type or the :class:`.String`
 #ype when ``convert_unicode`` is ``True``;
 # the string SQL statement passed to the DBAPI's
 #`cursor.execute()`` method;
 # the string names of the keys in the bound parameter
 #ictionary passed to the DBAPI's ``cursor.execute()``
 #s well as ``cursor.setinputsizes()`` methods;
 # the string column names retrieved from the DBAPI's
 #`cursor.description`` attribute.

 #hen using Python 3, the DBAPI is required to support all of the above
 #alues as Python ``unicode`` objects, which in Python 3 are just known
 #s ``str``.  In Python 2, the DBAPI does not specify unicode behavior
 #t all, so SQLAlchemy must make decisions for each of the above values
 #n a per-DBAPI basis - implementations are completely inconsistent in
 #heir behavior.

 #param execution_options: Dictionary execution options which will
 #e applied to all connections.  See
 #meth:`~sqlalchemy.engine.Connection.execution_options`

 #param future: Use the 2.0 style :class:`_future.Engine` and
 #class:`_future.Connection` API.

 #. versionadded:: 1.4

 #. seealso::

 #ref:`migration_20_toplevel`

 #param hide_parameters: Boolean, when set to True, SQL statement parameters
 #ill not be displayed in INFO logging nor will they be formatted into
 #he string representation of :class:`.StatementError` objects.

 #. versionadded:: 1.3.8

 #. seealso::

 #ref:`dbengine_logging` - further detail on how to configure
 #ogging.

 #param implicit_returning=True: When ``True``, a RETURNING-
 #ompatible construct, if available, will be used to
 #etch newly generated primary key values when a single row
 #NSERT statement is emitted with no existing returning()
 #lause.  This applies to those backends which support RETURNING
 #r a compatible construct, including PostgreSQL, Firebird, Oracle,
 #icrosoft SQL Server.   Set this to ``False`` to disable
 #he automatic usage of RETURNING.

 #param isolation_level: this string parameter is interpreted by various
 #ialects in order to affect the transaction isolation level of the
 #atabase connection.   The parameter essentially accepts some subset of
 #hese string arguments: ``"SERIALIZABLE"``, ``"REPEATABLE READ"``,
 #`"READ COMMITTED"``, ``"READ UNCOMMITTED"`` and ``"AUTOCOMMIT"``.
 #ehavior here varies per backend, and
 #ndividual dialects should be consulted directly.

 #ote that the isolation level can also be set on a
 #er-:class:`_engine.Connection` basis as well, using the
 #paramref:`.Connection.execution_options.isolation_level`
 #eature.

 #. seealso::

 #attr:`_engine.Connection.default_isolation_level`
 # view default level

 #paramref:`.Connection.execution_options.isolation_level`
 # set per :class:`_engine.Connection` isolation level

 #ref:`SQLite Transaction Isolation <sqlite_isolation_level>`

 #ref:`PostgreSQL Transaction Isolation <postgresql_isolation_level>`

 #ref:`MySQL Transaction Isolation <mysql_isolation_level>`

 #ref:`session_transaction_isolation` - for the ORM

 #param json_deserializer: for dialects that support the
 #class:`_types.JSON`
 #atatype, this is a Python callable that will convert a JSON string
 #o a Python object.  By default, the Python ``json.loads`` function is
 #sed.

 #. versionchanged:: 1.3.7  The SQLite dialect renamed this from
 #`_json_deserializer``.

 #param json_serializer: for dialects that support the :class:`_types.JSON`
 #atatype, this is a Python callable that will render a given object
 #s JSON.   By default, the Python ``json.dumps`` function is used.

 #. versionchanged:: 1.3.7  The SQLite dialect renamed this from
 #`_json_serializer``.


 #param label_length=None: optional integer value which limits
 #he size of dynamically generated column labels to that many
 #haracters. If less than 6, labels are generated as
 #_(counter)". If ``None``, the value of
 #`dialect.max_identifier_length``, which may be affected via the
 #paramref:`_sa.create_engine.max_identifier_length` parameter,
 #s used instead.   The value of
 #paramref:`_sa.create_engine.label_length`
 #ay not be larger than that of
 #paramref:`_sa.create_engine.max_identfier_length`.

 #. seealso::

 #paramref:`_sa.create_engine.max_identifier_length`

 #param listeners: A list of one or more
 #class:`~sqlalchemy.interfaces.PoolListener` objects which will
 #eceive connection pool events.

 #param logging_name:  String identifier which will be used within
 #he "name" field of logging records generated within the
 #sqlalchemy.engine" logger. Defaults to a hexstring of the
 #bject's id.

 #. seealso::

 #ref:`dbengine_logging` - further detail on how to configure
 #ogging.

 #paramref:`_engine.Connection.execution_options.logging_token`



 #param max_identifier_length: integer; override the max_identifier_length
 #etermined by the dialect.  if ``None`` or zero, has no effect.  This
 #s the database's configured maximum number of characters that may be
 #sed in a SQL identifier such as a table name, column name, or label
 #ame. All dialects determine this value automatically, however in the
 #ase of a new database version for which this value has changed but
 #QLAlchemy's dialect has not been adjusted, the value may be passed
 #ere.

 #. versionadded:: 1.3.9

 #. seealso::

 #paramref:`_sa.create_engine.label_length`

 #param max_overflow=10: the number of connections to allow in
 #onnection pool "overflow", that is connections that can be
 #pened above and beyond the pool_size setting, which defaults
 #o five. this is only used with :class:`~sqlalchemy.pool.QueuePool`.

 #param module=None: reference to a Python module object (the module
 #tself, not its string name).  Specifies an alternate DBAPI module to
 #e used by the engine's dialect.  Each sub-dialect references a
 #pecific DBAPI which will be imported before first connect.  This
 #arameter causes the import to be bypassed, and the given module to
 #e used instead. Can be used for testing of DBAPIs as well as to
 #nject "mock" DBAPI implementations into the :class:`_engine.Engine`.

 #param paramstyle=None: The `paramstyle <https://legacy.python.org/dev/peps/pep-0249/#paramstyle>`_
 #o use when rendering bound parameters.  This style defaults to the
 #ne recommended by the DBAPI itself, which is retrieved from the
 #`.paramstyle`` attribute of the DBAPI.  However, most DBAPIs accept
 #ore than one paramstyle, and in particular it may be desirable
 #o change a "named" paramstyle into a "positional" one, or vice versa.
 #hen this attribute is passed, it should be one of the values
 #`"qmark"``, ``"numeric"``, ``"named"``, ``"format"`` or
 #`"pyformat"``, and should correspond to a parameter style known
 #o be supported by the DBAPI in use.

 #param pool=None: an already-constructed instance of
 #class:`~sqlalchemy.pool.Pool`, such as a
 #class:`~sqlalchemy.pool.QueuePool` instance. If non-None, this
 #ool will be used directly as the underlying connection pool
 #or the engine, bypassing whatever connection parameters are
 #resent in the URL argument. For information on constructing
 #onnection pools manually, see :ref:`pooling_toplevel`.

 #param poolclass=None: a :class:`~sqlalchemy.pool.Pool`
 #ubclass, which will be used to create a connection pool
 #nstance using the connection parameters given in the URL. Note
 #his differs from ``pool`` in that you don't actually
 #nstantiate the pool in this case, you just indicate what type
 #f pool to be used.

 #param pool_logging_name:  String identifier which will be used within
 #he "name" field of logging records generated within the
 #sqlalchemy.pool" logger. Defaults to a hexstring of the object's
 #d.


 #. seealso::

 #ref:`dbengine_logging` - further detail on how to configure
 #ogging.


 #param pool_pre_ping: boolean, if True will enable the connection pool
 #pre-ping" feature that tests connections for liveness upon
 #ach checkout.

 #. versionadded:: 1.2

 #. seealso::

 #ref:`pool_disconnects_pessimistic`

 #param pool_size=5: the number of connections to keep open
 #nside the connection pool. This used with
 #class:`~sqlalchemy.pool.QueuePool` as
 #ell as :class:`~sqlalchemy.pool.SingletonThreadPool`.  With
 #class:`~sqlalchemy.pool.QueuePool`, a ``pool_size`` setting
 #f 0 indicates no limit; to disable pooling, set ``poolclass`` to
 #class:`~sqlalchemy.pool.NullPool` instead.

 #param pool_recycle=-1: this setting causes the pool to recycle
 #onnections after the given number of seconds has passed. It
 #efaults to -1, or no timeout. For example, setting to 3600
 #eans connections will be recycled after one hour. Note that
 #ySQL in particular will disconnect automatically if no
 #ctivity is detected on a connection for eight hours (although
 #his is configurable with the MySQLDB connection itself and the
 #erver configuration as well).

 #. seealso::

 #ref:`pool_setting_recycle`

 #param pool_reset_on_return='rollback': set the
 #paramref:`_pool.Pool.reset_on_return` parameter of the underlying
 #class:`_pool.Pool` object, which can be set to the values
 #`"rollback"``, ``"commit"``, or ``None``.

 #. seealso::

 #paramref:`_pool.Pool.reset_on_return`

 #param pool_timeout=30: number of seconds to wait before giving
 #p on getting a connection from the pool. This is only used
 #ith :class:`~sqlalchemy.pool.QueuePool`. This can be a float but is
 #ubject to the limitations of Python time functions which may not be
 #eliable in the tens of milliseconds.

 #. note: don't use 30.0 above, it seems to break with the :param tag

 #param pool_use_lifo=False: use LIFO (last-in-first-out) when retrieving
 #onnections from :class:`.QueuePool` instead of FIFO
 #first-in-first-out). Using LIFO, a server-side timeout scheme can
 #educe the number of connections used during non- peak   periods of
 #se.   When planning for server-side timeouts, ensure that a recycle or
 #re-ping strategy is in use to gracefully   handle stale connections.

 #. versionadded:: 1.3

 #. seealso::

 #ref:`pool_use_lifo`

 #ref:`pool_disconnects`

 #param plugins: string list of plugin names to load.  See
 #class:`.CreateEnginePlugin` for background.

 #. versionadded:: 1.2.3

 #param query_cache_size: size of the cache used to cache the SQL string
 #orm of queries.  Set to zero to disable caching.

 #he cache is pruned of its least recently used items when its size reaches
 # * 1.5.  Defaults to 500, meaning the cache will always store at least
 #00 SQL statements when filled, and will grow up to 750 items at which
 #oint it is pruned back down to 500 by removing the 250 least recently
 #sed items.

 #aching is accomplished on a per-statement basis by generating a
 #ache key that represents the statement's structure, then generating
 #tring SQL for the current dialect only if that key is not present
 #n the cache.   All statements support caching, however some features
 #uch as an INSERT with a large set of parameters will intentionally
 #ypass the cache.   SQL logging will indicate statistics for each
 #tatement whether or not it were pull from the cache.

 #. note:: some ORM functions related to unit-of-work persistence as well
 #s some attribute loading strategies will make use of individual
 #er-mapper caches outside of the main cache.


 #. seealso::

 #ref:`sql_caching`

 #. versionadded:: 1.4

 #""  # noqa

 #f "strategy" in kwargs:
 #trat = kwargs.pop("strategy")
 #f strat == "mock":
 #eturn create_mock_engine(url, **kwargs)
 #lse:
 #aise exc.ArgumentError("unknown strategy: %r" % strat)

 #wargs.pop("empty_in_strategy", None)

    # create url.URL object
 # = _url.make_url(url)

 #, plugins, kwargs = u._instantiate_plugins(kwargs)

 #ntrypoint = u._get_entrypoint()
 #ialect_cls = entrypoint.get_dialect_cls(u)

 #f kwargs.pop("_coerce_config", False):

 #ef pop_kwarg(key, default=None):
 #alue = kwargs.pop(key, default)
 #f key in dialect_cls.engine_config_types:
 #alue = dialect_cls.engine_config_types[key](value)
 #eturn value

 #lse:
 #op_kwarg = kwargs.pop

 #ialect_args = {}
    # consume dialect arguments from kwargs
 #or k in util.get_cls_kwargs(dialect_cls):
 #f k in kwargs:
 #ialect_args[k] = pop_kwarg(k)

 #bapi = kwargs.pop("module", None)
 #f dbapi is None:
 #bapi_args = {}
 #or k in util.get_func_kwargs(dialect_cls.dbapi):
 #f k in kwargs:
 #bapi_args[k] = pop_kwarg(k)
 #bapi = dialect_cls.dbapi(**dbapi_args)

 #ialect_args["dbapi"] = dbapi

 #ialect_args.setdefault("compiler_linting", compiler.NO_LINTING)
 #nable_from_linting = kwargs.pop("enable_from_linting", True)
 #f enable_from_linting:
 #ialect_args["compiler_linting"] ^= compiler.COLLECT_CARTESIAN_PRODUCTS

 #or plugin in plugins:
 #lugin.handle_dialect_kwargs(dialect_cls, dialect_args)

    # create dialect
 #ialect = dialect_cls(**dialect_args)

    # assemble connection arguments
 #cargs, cparams) = dialect.create_connect_args(u)
 #params.update(pop_kwarg("connect_args", {}))
 #args = list(cargs)  # allow mutability

    # look for existing pool or create
 #ool = pop_kwarg("pool", None)
 #f pool is None:

 #ef connect(connection_record=None):
 #f dialect._has_events:
 #or fn in dialect.dispatch.do_connect:
 #onnection = fn(dialect, connection_record, cargs, cparams)
 #f connection is not None:
 #eturn connection
 #eturn dialect.connect(*cargs, **cparams)

 #reator = pop_kwarg("creator", connect)

 #oolclass = pop_kwarg("poolclass", None)
 #f poolclass is None:
 #oolclass = dialect.get_dialect_pool_class(u)
 #ool_args = {"dialect": dialect}

        # consume pool arguments from kwargs, translating a few of
        # the arguments
 #ranslate = {
 #logging_name": "pool_logging_name",
 #echo": "echo_pool",
 #timeout": "pool_timeout",
 #recycle": "pool_recycle",
 #events": "pool_events",
 #reset_on_return": "pool_reset_on_return",
 #pre_ping": "pool_pre_ping",
 #use_lifo": "pool_use_lifo",
 #
 #or k in util.get_cls_kwargs(poolclass):
 #k = translate.get(k, k)
 #f tk in kwargs:
 #ool_args[k] = pop_kwarg(tk)

 #or plugin in plugins:
 #lugin.handle_pool_kwargs(poolclass, pool_args)

 #ool = poolclass(creator, **pool_args)
 #lse:
 #f isinstance(pool, poollib.dbapi_proxy._DBProxy):
 #ool = pool.get_pool(*cargs, **cparams)

 #ool._dialect = dialect

    # create engine.
 #f pop_kwarg("future", False):
 #rom sqlalchemy import future

 #efault_engine_class = future.Engine
 #lse:
 #efault_engine_class = base.Engine

 #ngineclass = kwargs.pop("_future_engine_class", default_engine_class)

 #ngine_args = {}
 #or k in util.get_cls_kwargs(engineclass):
 #f k in kwargs:
 #ngine_args[k] = pop_kwarg(k)

    # internal flags used by the test suite for instrumenting / proxying
    # engines with mocks etc.
 #initialize = kwargs.pop("_initialize", True)
 #wrap_do_on_connect = kwargs.pop("_wrap_do_on_connect", None)

    # all kwargs should be consumed
 #f kwargs:
 #aise TypeError(
 #Invalid argument(s) %s sent to create_engine(), "
 #using configuration %s/%s/%s.  Please check that the "
 #keyword arguments are appropriate for this combination "
 #of components."
 # (
 #,".join("'%s'" % k for k in kwargs),
 #ialect.__class__.__name__,
 #ool.__class__.__name__,
 #ngineclass.__name__,
 #
 #

 #ngine = engineclass(pool, dialect, u, **engine_args)

 #f _initialize:
 #o_on_connect = dialect.on_connect_url(u)
 #f do_on_connect:
 #f _wrap_do_on_connect:
 #o_on_connect = _wrap_do_on_connect(do_on_connect)

 #ef on_connect(dbapi_connection, connection_record):
 #o_on_connect(dbapi_connection)

 #vent.listen(pool, "connect", on_connect)

 #ef first_connect(dbapi_connection, connection_record):
 # = base.Connection(
 #ngine,
 #onnection=dbapi_connection,
 #has_events=False,
                # reconnecting will be a reentrant condition, so if the
                # connection goes away, Connection is then closed
 #allow_revalidate=False,
 #
 #._execution_options = util.EMPTY_DICT

 #ry:
 #ialect.initialize(c)
 #inally:
                # note that "invalidated" and "closed" are mutually
                # exclusive in 1.4 Connection.
 #f not c.invalidated and not c.closed:
                    # transaction is rolled back otherwise, tested by
                    # test/dialect/postgresql/test_dialect.py
                    # ::MiscBackendTest::test_initial_transaction_state
 #ialect.do_rollback(c.connection)

        # previously, the "first_connect" event was used here, which was then
        # scaled back if the "on_connect" handler were present.  now,
        # since "on_connect" is virtually always present, just use
        # "connect" event with once_unless_exception in all cases so that
        # the connection event flow is consistent in all cases.
 #vent.listen(
 #ool, "connect", first_connect, _once_unless_exception=True
 #

 #ialect_cls.engine_created(engine)
 #f entrypoint is not dialect_cls:
 #ntrypoint.engine_created(engine)

 #or plugin in plugins:
 #lugin.engine_created(engine)

 #eturn engine


def engine_from_config(configuration, prefix="sqlalchemy.", **kwargs):
 #""Create a new Engine instance using a configuration dictionary.

 #he dictionary is typically produced from a config file.

 #he keys of interest to ``engine_from_config()`` should be prefixed, e.g.
 #`sqlalchemy.url``, ``sqlalchemy.echo``, etc.  The 'prefix' argument
 #ndicates the prefix to be searched for.  Each matching key (after the
 #refix is stripped) is treated as though it were the corresponding keyword
 #rgument to a :func:`_sa.create_engine` call.

 #he only required key is (assuming the default prefix) ``sqlalchemy.url``,
 #hich provides the :ref:`database URL <database_urls>`.

 # select set of keyword arguments will be "coerced" to their
 #xpected type based on string values.    The set of arguments
 #s extensible per-dialect using the ``engine_config_types`` accessor.

 #param configuration: A dictionary (typically produced from a config file,
 #ut this is not a requirement).  Items whose keys start with the value
 #f 'prefix' will have that prefix stripped, and will then be passed to
 #func:`_sa.create_engine`.

 #param prefix: Prefix to match and then strip from keys
 #n 'configuration'.

 #param kwargs: Each keyword argument to ``engine_from_config()`` itself
 #verrides the corresponding item taken from the 'configuration'
 #ictionary.  Keyword arguments should *not* be prefixed.

 #""

 #ptions = dict(
 #key[len(prefix) :], configuration[key])
 #or key in configuration
 #f key.startswith(prefix)
 #
 #ptions["_coerce_config"] = True
 #ptions.update(kwargs)
 #rl = options.pop("url")
 #eturn create_engine(url, **options)
