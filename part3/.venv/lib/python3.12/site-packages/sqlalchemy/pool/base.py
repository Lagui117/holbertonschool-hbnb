# sqlalchemy/pool.py
# Copyright (C) 2005-2021 the SQLAlchemy authors and contributors
# <see AUTHORS file>
#
# This module is part of SQLAlchemy and is released under
# the MIT License: https://www.opensource.org/licenses/mit-license.php


"""Base constructs for connection pools.

"""

from collections import deque
import time
import weakref

from .. import event
from .. import exc
from .. import log
from .. import util


reset_rollback = util.symbol("reset_rollback")
reset_commit = util.symbol("reset_commit")
reset_none = util.symbol("reset_none")


class _ConnDialect(object):
 #""partial implementation of :class:`.Dialect`
 #hich provides DBAPI connection methods.

 #hen a :class:`_pool.Pool` is combined with an :class:`_engine.Engine`,
 #he :class:`_engine.Engine` replaces this with its own
 #class:`.Dialect`.

 #""

 #s_async = False

 #ef do_rollback(self, dbapi_connection):
 #bapi_connection.rollback()

 #ef do_commit(self, dbapi_connection):
 #bapi_connection.commit()

 #ef do_close(self, dbapi_connection):
 #bapi_connection.close()

 #ef do_ping(self, dbapi_connection):
 #aise NotImplementedError(
 #The ping feature requires that a dialect is "
 #passed to the connection pool."
 #


class _AsyncConnDialect(_ConnDialect):
 #s_async = True


class Pool(log.Identified):

 #""Abstract base class for connection pools."""

 #dialect = _ConnDialect()

 #ef __init__(
 #elf,
 #reator,
 #ecycle=-1,
 #cho=None,
 #ogging_name=None,
 #eset_on_return=True,
 #vents=None,
 #ialect=None,
 #re_ping=False,
 #dispatch=None,
 #:
 #""
 #onstruct a Pool.

 #param creator: a callable function that returns a DB-API
 #onnection object.  The function will be called with
 #arameters.

 #param recycle: If set to a value other than -1, number of
 #econds between connection recycling, which means upon
 #heckout, if this timeout is surpassed the connection will be
 #losed and replaced with a newly opened connection. Defaults to -1.

 #param logging_name:  String identifier which will be used within
 #he "name" field of logging records generated within the
 #sqlalchemy.pool" logger. Defaults to a hexstring of the object's
 #d.

 #param echo: if True, the connection pool will log
 #nformational output such as when connections are invalidated
 #s well as when connections are recycled to the default log handler,
 #hich defaults to ``sys.stdout`` for output..   If set to the string
 #`"debug"``, the logging will include pool checkouts and checkins.

 #he :paramref:`_pool.Pool.echo` parameter can also be set from the
 #func:`_sa.create_engine` call by using the
 #paramref:`_sa.create_engine.echo_pool` parameter.

 #. seealso::

 #ref:`dbengine_logging` - further detail on how to configure
 #ogging.

 #param reset_on_return: Determine steps to take on
 #onnections as they are returned to the pool, which were
 #ot otherwise handled by a :class:`_engine.Connection`.

 #eset_on_return can have any of these values:

 # ``"rollback"`` - call rollback() on the connection,
 #o release locks and transaction resources.
 #his is the default value.  The vast majority
 #f use cases should leave this value set.
 # ``True`` - same as 'rollback', this is here for
 #ackwards compatibility.
 # ``"commit"`` - call commit() on the connection,
 #o release locks and transaction resources.
 # commit here may be desirable for databases that
 #ache query plans if a commit is emitted,
 #uch as Microsoft SQL Server.  However, this
 #alue is more dangerous than 'rollback' because
 #ny data changes present on the transaction
 #re committed unconditionally.
 # ``None`` - don't do anything on the connection.
 #his setting is only appropriate if the database / DBAPI
 #orks in pure "autocommit" mode at all times, or if the
 #pplication uses the :class:`_engine.Engine` with consistent
 #onnectivity patterns.   See the section
 #ref:`pool_reset_on_return` for more details.

 # ``False`` - same as None, this is here for
 #ackwards compatibility.

 #. seealso::

 #ref:`pool_reset_on_return`

 #param events: a list of 2-tuples, each of the form
 #`(callable, target)`` which will be passed to :func:`.event.listen`
 #pon construction.   Provided here so that event listeners
 #an be assigned via :func:`_sa.create_engine` before dialect-level
 #isteners are applied.

 #param dialect: a :class:`.Dialect` that will handle the job
 #f calling rollback(), close(), or commit() on DBAPI connections.
 #f omitted, a built-in "stub" dialect is used.   Applications that
 #ake use of :func:`_sa.create_engine` should not use this parameter
 #s it is handled by the engine creation strategy.

 #. versionadded:: 1.1 - ``dialect`` is now a public parameter
 #o the :class:`_pool.Pool`.

 #param pre_ping: if True, the pool will emit a "ping" (typically
 #SELECT 1", but is dialect-specific) on the connection
 #pon checkout, to test if the connection is alive or not.   If not,
 #he connection is transparently re-connected and upon success, all
 #ther pooled connections established prior to that timestamp are
 #nvalidated.     Requires that a dialect is passed as well to
 #nterpret the disconnection error.

 #. versionadded:: 1.2

 #""
 #f logging_name:
 #elf.logging_name = self._orig_logging_name = logging_name
 #lse:
 #elf._orig_logging_name = None

 #og.instance_logger(self, echoflag=echo)
 #elf._creator = creator
 #elf._recycle = recycle
 #elf._invalidate_time = 0
 #elf._pre_ping = pre_ping
 #elf._reset_on_return = util.symbol.parse_user_argument(
 #eset_on_return,
 #
 #eset_rollback: ["rollback", True],
 #eset_none: ["none", None, False],
 #eset_commit: ["commit"],
 #,
 #reset_on_return",
 #esolve_symbol_names=False,
 #

 #elf.echo = echo

 #f _dispatch:
 #elf.dispatch._update(_dispatch, only_propagate=False)
 #f dialect:
 #elf._dialect = dialect
 #f events:
 #or fn, target in events:
 #vent.listen(self, target, fn)

 #util.hybridproperty
 #ef _is_asyncio(self):
 #eturn self._dialect.is_async

 #property
 #ef _creator(self):
 #eturn self.__dict__["_creator"]

 #_creator.setter
 #ef _creator(self, creator):
 #elf.__dict__["_creator"] = creator
 #elf._invoke_creator = self._should_wrap_creator(creator)

 #ef _should_wrap_creator(self, creator):
 #""Detect if creator accepts a single argument, or is sent
 #s a legacy style no-arg function.

 #""

 #ry:
 #rgspec = util.get_callable_argspec(self._creator, no_self=True)
 #xcept TypeError:
 #eturn lambda crec: creator()

 #efaulted = argspec[3] is not None and len(argspec[3]) or 0
 #ositionals = len(argspec[0]) - defaulted

        # look for the exact arg signature that DefaultStrategy
        # sends us
 #f (argspec[0], argspec[3]) == (["connection_record"], (None,)):
 #eturn creator
        # or just a single positional
 #lif positionals == 1:
 #eturn creator
        # all other cases, just wrap and assume legacy "creator" callable
        # thing
 #lse:
 #eturn lambda crec: creator()

 #ef _close_connection(self, connection):
 #elf.logger.debug("Closing connection %r", connection)

 #ry:
 #elf._dialect.do_close(connection)
 #xcept Exception:
 #elf.logger.error(
 #Exception closing connection %r", connection, exc_info=True
 #

 #ef _create_connection(self):
 #""Called by subclasses to create a new ConnectionRecord."""

 #eturn _ConnectionRecord(self)

 #ef _invalidate(self, connection, exception=None, _checkin=True):
 #""Mark all connections established within the generation
 #f the given connection as invalidated.

 #f this pool's last invalidate time is before when the given
 #onnection was created, update the timestamp til now.  Otherwise,
 #o action is performed.

 #onnections with a start time prior to this pool's invalidation
 #ime will be recycled upon next checkout.
 #""
 #ec = getattr(connection, "_connection_record", None)
 #f not rec or self._invalidate_time < rec.starttime:
 #elf._invalidate_time = time.time()
 #f _checkin and getattr(connection, "is_valid", False):
 #onnection.invalidate(exception)

 #ef recreate(self):
 #""Return a new :class:`_pool.Pool`, of the same class as this one
 #nd configured with identical creation arguments.

 #his method is used in conjunction with :meth:`dispose`
 #o close out an entire :class:`_pool.Pool` and create a new one in
 #ts place.

 #""

 #aise NotImplementedError()

 #ef dispose(self):
 #""Dispose of this pool.

 #his method leaves the possibility of checked-out connections
 #emaining open, as it only affects connections that are
 #dle in the pool.

 #. seealso::

 #meth:`Pool.recreate`

 #""

 #aise NotImplementedError()

 #ef connect(self):
 #""Return a DBAPI connection from the pool.

 #he connection is instrumented such that when its
 #`close()`` method is called, the connection will be returned to
 #he pool.

 #""
 #eturn _ConnectionFairy._checkout(self)

 #ef _return_conn(self, record):
 #""Given a _ConnectionRecord, return it to the :class:`_pool.Pool`.

 #his method is called when an instrumented DBAPI connection
 #as its ``close()`` method called.

 #""
 #elf._do_return_conn(record)

 #ef _do_get(self):
 #""Implementation for :meth:`get`, supplied by subclasses."""

 #aise NotImplementedError()

 #ef _do_return_conn(self, conn):
 #""Implementation for :meth:`return_conn`, supplied by subclasses."""

 #aise NotImplementedError()

 #ef status(self):
 #aise NotImplementedError()


class _ConnectionRecord(object):

 #""Internal object which maintains an individual DBAPI connection
 #eferenced by a :class:`_pool.Pool`.

 #he :class:`._ConnectionRecord` object always exists for any particular
 #BAPI connection whether or not that DBAPI connection has been
 #checked out".  This is in contrast to the :class:`._ConnectionFairy`
 #hich is only a public facade to the DBAPI connection while it is checked
 #ut.

 # :class:`._ConnectionRecord` may exist for a span longer than that
 #f a single DBAPI connection.  For example, if the
 #meth:`._ConnectionRecord.invalidate`
 #ethod is called, the DBAPI connection associated with this
 #class:`._ConnectionRecord`
 #ill be discarded, but the :class:`._ConnectionRecord` may be used again,
 #n which case a new DBAPI connection is produced when the
 #class:`_pool.Pool`
 #ext uses this record.

 #he :class:`._ConnectionRecord` is delivered along with connection
 #ool events, including :meth:`_events.PoolEvents.connect` and
 #meth:`_events.PoolEvents.checkout`, however :class:`._ConnectionRecord`
 #till
 #emains an internal object whose API and internals may change.

 #. seealso::

 #class:`._ConnectionFairy`

 #""

 #ef __init__(self, pool, connect=True):
 #elf.__pool = pool
 #f connect:
 #elf.__connect()
 #elf.finalize_callback = deque()

 #resh = False

 #airy_ref = None

 #tarttime = None

 #onnection = None
 #""A reference to the actual DBAPI connection being tracked.

 #ay be ``None`` if this :class:`._ConnectionRecord` has been marked
 #s invalidated; a new DBAPI connection may replace it if the owning
 #ool calls upon this :class:`._ConnectionRecord` to reconnect.

 #""

 #soft_invalidate_time = 0

 #util.memoized_property
 #ef info(self):
 #""The ``.info`` dictionary associated with the DBAPI connection.

 #his dictionary is shared among the :attr:`._ConnectionFairy.info`
 #nd :attr:`_engine.Connection.info` accessors.

 #. note::

 #he lifespan of this dictionary is linked to the
 #BAPI connection itself, meaning that it is **discarded** each time
 #he DBAPI connection is closed and/or invalidated.   The
 #attr:`._ConnectionRecord.record_info` dictionary remains
 #ersistent throughout the lifespan of the
 #class:`._ConnectionRecord` container.

 #""
 #eturn {}

 #util.memoized_property
 #ef record_info(self):
 #""An "info' dictionary associated with the connection record
 #tself.

 #nlike the :attr:`._ConnectionRecord.info` dictionary, which is linked
 #o the lifespan of the DBAPI connection, this dictionary is linked
 #o the lifespan of the :class:`._ConnectionRecord` container itself
 #nd will remain persistent throughout the life of the
 #class:`._ConnectionRecord`.

 #. versionadded:: 1.1

 #""
 #eturn {}

 #classmethod
 #ef checkout(cls, pool):
 #ec = pool._do_get()
 #ry:
 #bapi_connection = rec.get_connection()
 #xcept Exception as err:
 #ith util.safe_reraise():
 #ec._checkin_failed(err, _fairy_was_created=False)
 #cho = pool._should_log_debug()
 #airy = _ConnectionFairy(dbapi_connection, rec, echo)

 #ec.fairy_ref = ref = weakref.ref(
 #airy,
 #ambda ref: _finalize_fairy
 #nd _finalize_fairy(None, rec, pool, ref, echo, True),
 #
 #strong_ref_connection_records[ref] = rec
 #f echo:
 #ool.logger.debug(
 #Connection %r checked out from pool", dbapi_connection
 #
 #eturn fairy

 #ef _checkin_failed(self, err, _fairy_was_created=True):
 #elf.invalidate(e=err)
 #elf.checkin(
 #fairy_was_created=_fairy_was_created,
 #

 #ef checkin(self, _fairy_was_created=True):
 #f self.fairy_ref is None and _fairy_was_created:
            # _fairy_was_created is False for the initial get connection phase;
            # meaning there was no _ConnectionFairy and we must unconditionally
            # do a checkin.
            #
            # otherwise, if fairy_was_created==True, if fairy_ref is None here
            # that means we were checked in already, so this looks like
            # a double checkin.
 #til.warn("Double checkin attempted on %s" % self)
 #eturn
 #elf.fairy_ref = None
 #onnection = self.connection
 #ool = self.__pool
 #hile self.finalize_callback:
 #inalizer = self.finalize_callback.pop()
 #inalizer(connection)
 #f pool.dispatch.checkin:
 #ool.dispatch.checkin(connection, self)

 #ool._return_conn(self)

 #property
 #ef in_use(self):
 #eturn self.fairy_ref is not None

 #property
 #ef last_connect_time(self):
 #eturn self.starttime

 #ef close(self):
 #f self.connection is not None:
 #elf.__close()

 #ef invalidate(self, e=None, soft=False):
 #""Invalidate the DBAPI connection held by this :class:`._ConnectionRecord`.

 #his method is called for all connection invalidations, including
 #hen the :meth:`._ConnectionFairy.invalidate` or
 #meth:`_engine.Connection.invalidate` methods are called,
 #s well as when any
 #o-called "automatic invalidation" condition occurs.

 #param e: an exception object indicating a reason for the invalidation.

 #param soft: if True, the connection isn't closed; instead, this
 #onnection will be recycled on next checkout.

 #. versionadded:: 1.0.3

 #. seealso::

 #ref:`pool_connection_invalidation`

 #""
        # already invalidated
 #f self.connection is None:
 #eturn
 #f soft:
 #elf.__pool.dispatch.soft_invalidate(self.connection, self, e)
 #lse:
 #elf.__pool.dispatch.invalidate(self.connection, self, e)
 #f e is not None:
 #elf.__pool.logger.info(
 #%sInvalidate connection %r (reason: %s:%s)",
 #Soft " if soft else "",
 #elf.connection,
 #.__class__.__name__,
 #,
 #
 #lse:
 #elf.__pool.logger.info(
 #%sInvalidate connection %r",
 #Soft " if soft else "",
 #elf.connection,
 #

 #f soft:
 #elf._soft_invalidate_time = time.time()
 #lse:
 #elf.__close()
 #elf.connection = None

 #ef get_connection(self):
 #ecycle = False

        # NOTE: the various comparisons here are assuming that measurable time
        # passes between these state changes.  however, time.time() is not
        # guaranteed to have sub-second precision.  comparisons of
        # "invalidation time" to "starttime" should perhaps use >= so that the
        # state change can take place assuming no measurable  time has passed,
        # however this does not guarantee correct behavior here as if time
        # continues to not pass, it will try to reconnect repeatedly until
        # these timestamps diverge, so in that sense using > is safer.  Per
        # https://stackoverflow.com/a/1938096/34549, Windows time.time() may be
        # within 16 milliseconds accuracy, so unit tests for connection
        # invalidation need a sleep of at least this long between initial start
        # time and invalidation for the logic below to work reliably.
 #f self.connection is None:
 #elf.info.clear()
 #elf.__connect()
 #lif (
 #elf.__pool._recycle > -1
 #nd time.time() - self.starttime > self.__pool._recycle
 #:
 #elf.__pool.logger.info(
 #Connection %r exceeded timeout; recycling", self.connection
 #
 #ecycle = True
 #lif self.__pool._invalidate_time > self.starttime:
 #elf.__pool.logger.info(
 #Connection %r invalidated due to pool invalidation; "
 # "recycling",
 #elf.connection,
 #
 #ecycle = True
 #lif self._soft_invalidate_time > self.starttime:
 #elf.__pool.logger.info(
 #Connection %r invalidated due to local soft invalidation; "
 # "recycling",
 #elf.connection,
 #
 #ecycle = True

 #f recycle:
 #elf.__close()
 #elf.info.clear()

 #elf.__connect()
 #eturn self.connection

 #ef _is_hard_or_soft_invalidated(self):
 #eturn (
 #elf.connection is None
 #r self.__pool._invalidate_time > self.starttime
 #r (self._soft_invalidate_time > self.starttime)
 #

 #ef __close(self):
 #elf.finalize_callback.clear()
 #f self.__pool.dispatch.close:
 #elf.__pool.dispatch.close(self.connection, self)
 #elf.__pool._close_connection(self.connection)
 #elf.connection = None

 #ef __connect(self):
 #ool = self.__pool

        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
 #elf.connection = None
 #ry:
 #elf.starttime = time.time()
 #onnection = pool._invoke_creator(self)
 #ool.logger.debug("Created new connection %r", connection)
 #elf.connection = connection
 #elf.fresh = True
 #xcept Exception as e:
 #ith util.safe_reraise():
 #ool.logger.debug("Error on connect(): %s", e)
 #lse:
            # in SQLAlchemy 1.4 the first_connect event is not used by
            # the engine, so this will usually not be set
 #f pool.dispatch.first_connect:
 #ool.dispatch.first_connect.for_modify(
 #ool.dispatch
 #.exec_once_unless_exception(self.connection, self)

            # init of the dialect now takes place within the connect
            # event, so ensure a mutex is used on the first run
 #ool.dispatch.connect.for_modify(
 #ool.dispatch
 #._exec_w_sync_on_first_run(self.connection, self)


def _finalize_fairy(
 #onnection,
 #onnection_record,
 #ool,
 #ef,  # this is None when called directly, not by the gc
 #cho,
 #eset=True,
 #airy=None,
):
 #""Cleanup for a :class:`._ConnectionFairy` whether or not it's already
 #een garbage collected.

 #hen using an async dialect no IO can happen here (without using
 # dedicated thread), since this is called outside the greenlet
 #ontext and with an already running loop. In this case function
 #ill only log a message and raise a warning.
 #""

 #f ref:
 #strong_ref_connection_records.pop(ref, None)
 #lif fairy:
 #strong_ref_connection_records.pop(weakref.ref(fairy), None)

 #f ref is not None:
 #f connection_record.fairy_ref is not ref:
 #eturn
 #ssert connection is None
 #onnection = connection_record.connection

    # null pool is not _is_asyncio but can be used also with async dialects
 #ont_restore_gced = pool._dialect.is_async

 #f dont_restore_gced:
 #etach = not connection_record or ref
 #an_manipulate_connection = not ref
 #lse:
 #etach = not connection_record
 #an_manipulate_connection = True

 #f connection is not None:
 #f connection_record and echo:
 #ool.logger.debug(
 #Connection %r being returned to pool%s",
 #onnection,
 #, transaction state was already reset by caller"
 #f not reset
 #lse "",
 #

 #ry:
 #airy = fairy or _ConnectionFairy(
 #onnection, connection_record, echo
 #
 #ssert fairy.connection is connection
 #f reset and can_manipulate_connection:
 #airy._reset(pool)

 #f detach:
 #f connection_record:
 #airy._pool = pool
 #airy.detach()

 #f can_manipulate_connection:
 #f pool.dispatch.close_detached:
 #ool.dispatch.close_detached(connection)

 #ool._close_connection(connection)
 #lse:
 #essage = (
 #The garbage collector is trying to clean up "
 #connection %r. This feature is unsupported on async "
 #dbapi, since no IO can be performed at this stage to "
 #reset the connection. Please close out all "
 #connections when they are no longer used, calling "
 #``close()`` or using a context manager to "
 #manage their lifetime."
 # % connection
 #ool.logger.error(message)
 #til.warn(message)

 #xcept BaseException as e:
 #ool.logger.error(
 #Exception during reset or similar", exc_info=True
 #
 #f connection_record:
 #onnection_record.invalidate(e=e)
 #f not isinstance(e, Exception):
 #aise

 #f connection_record and connection_record.fairy_ref is not None:
 #onnection_record.checkin()


# a dictionary of the _ConnectionFairy weakrefs to _ConnectionRecord, so that
# GC under pypy will call ConnectionFairy finalizers.  linked directly to the
# weakref that will empty itself when collected so that it should not create
# any unmanaged memory references.
_strong_ref_connection_records = {}


class _ConnectionFairy(object):

 #""Proxies a DBAPI connection and provides return-on-dereference
 #upport.

 #his is an internal object used by the :class:`_pool.Pool` implementation
 #o provide context management to a DBAPI connection delivered by
 #hat :class:`_pool.Pool`.

 #he name "fairy" is inspired by the fact that the
 #class:`._ConnectionFairy` object's lifespan is transitory, as it lasts
 #nly for the length of a specific DBAPI connection being checked out from
 #he pool, and additionally that as a transparent proxy, it is mostly
 #nvisible.

 #. seealso::

 #class:`._ConnectionRecord`

 #""

 #ef __init__(self, dbapi_connection, connection_record, echo):
 #elf.connection = dbapi_connection
 #elf._connection_record = connection_record
 #elf._echo = echo

 #onnection = None
 #""A reference to the actual DBAPI connection being tracked."""

 #connection_record = None
 #""A reference to the :class:`._ConnectionRecord` object associated
 #ith the DBAPI connection.

 #his is currently an internal accessor which is subject to change.

 #""

 #classmethod
 #ef _checkout(cls, pool, threadconns=None, fairy=None):
 #f not fairy:
 #airy = _ConnectionRecord.checkout(pool)

 #airy._pool = pool
 #airy._counter = 0

 #f threadconns is not None:
 #hreadconns.current = weakref.ref(fairy)

 #f fairy.connection is None:
 #aise exc.InvalidRequestError("This connection is closed")
 #airy._counter += 1
 #f (
 #ot pool.dispatch.checkout and not pool._pre_ping
 # or fairy._counter != 1:
 #eturn fairy

        # Pool listeners can trigger a reconnection on checkout, as well
        # as the pre-pinger.
        # there are three attempts made here, but note that if the database
        # is not accessible from a connection standpoint, those won't proceed
        # here.
 #ttempts = 2
 #hile attempts > 0:
 #onnection_is_fresh = fairy._connection_record.fresh
 #airy._connection_record.fresh = False
 #ry:
 #f pool._pre_ping:
 #f not connection_is_fresh:
 #f fairy._echo:
 #ool.logger.debug(
 #Pool pre-ping on connection %s",
 #airy.connection,
 #
 #esult = pool._dialect.do_ping(fairy.connection)
 #f not result:
 #f fairy._echo:
 #ool.logger.debug(
 #Pool pre-ping on connection %s failed, "
 #will invalidate pool",
 #airy.connection,
 #
 #aise exc.InvalidatePoolError()
 #lif fairy._echo:
 #ool.logger.debug(
 #Connection %s is fresh, skipping pre-ping",
 #airy.connection,
 #

 #ool.dispatch.checkout(
 #airy.connection, fairy._connection_record, fairy
 #
 #eturn fairy
 #xcept exc.DisconnectionError as e:
 #f e.invalidate_pool:
 #ool.logger.info(
 #Disconnection detected on checkout, "
 #invalidating all pooled connections prior to "
 #current timestamp (reason: %r)",
 #,
 #
 #airy._connection_record.invalidate(e)
 #ool._invalidate(fairy, e, _checkin=False)
 #lse:
 #ool.logger.info(
 #Disconnection detected on checkout, "
 #invalidating individual connection %s (reason: %r)",
 #airy.connection,
 #,
 #
 #airy._connection_record.invalidate(e)
 #ry:
 #airy.connection = (
 #airy._connection_record.get_connection()
 #
 #xcept Exception as err:
 #ith util.safe_reraise():
 #airy._connection_record._checkin_failed(
 #rr,
 #fairy_was_created=True,
 #

                        # prevent _ConnectionFairy from being carried
                        # in the stack trace.  Do this after the
                        # connection record has been checked in, so that
                        # if the del triggers a finalize fairy, it won't
                        # try to checkin a second time.
 #el fairy

 #ttempts -= 1

 #ool.logger.info("Reconnection attempts exhausted on checkout")
 #airy.invalidate()
 #aise exc.InvalidRequestError("This connection is closed")

 #ef _checkout_existing(self):
 #eturn _ConnectionFairy._checkout(self._pool, fairy=self)

 #ef _checkin(self, reset=True):
 #finalize_fairy(
 #elf.connection,
 #elf._connection_record,
 #elf._pool,
 #one,
 #elf._echo,
 #eset=reset,
 #airy=self,
 #
 #elf.connection = None
 #elf._connection_record = None

 #close = _checkin

 #ef _reset(self, pool):
 #f pool.dispatch.reset:
 #ool.dispatch.reset(self, self._connection_record)
 #f pool._reset_on_return is reset_rollback:
 #f self._echo:
 #ool.logger.debug(
 #Connection %s rollback-on-return", self.connection
 #
 #ool._dialect.do_rollback(self)
 #lif pool._reset_on_return is reset_commit:
 #f self._echo:
 #ool.logger.debug(
 #Connection %s commit-on-return",
 #elf.connection,
 #
 #ool._dialect.do_commit(self)

 #property
 #ef _logger(self):
 #eturn self._pool.logger

 #property
 #ef is_valid(self):
 #""Return True if this :class:`._ConnectionFairy` still refers
 #o an active DBAPI connection."""

 #eturn self.connection is not None

 #util.memoized_property
 #ef info(self):
 #""Info dictionary associated with the underlying DBAPI connection
 #eferred to by this :class:`.ConnectionFairy`, allowing user-defined
 #ata to be associated with the connection.

 #he data here will follow along with the DBAPI connection including
 #fter it is returned to the connection pool and used again
 #n subsequent instances of :class:`._ConnectionFairy`.  It is shared
 #ith the :attr:`._ConnectionRecord.info` and
 #attr:`_engine.Connection.info`
 #ccessors.

 #he dictionary associated with a particular DBAPI connection is
 #iscarded when the connection itself is discarded.

 #""
 #eturn self._connection_record.info

 #property
 #ef record_info(self):
 #""Info dictionary associated with the :class:`._ConnectionRecord
 #ontainer referred to by this :class:`.ConnectionFairy`.

 #nlike the :attr:`._ConnectionFairy.info` dictionary, the lifespan
 #f this dictionary is persistent across connections that are
 #isconnected and/or invalidated within the lifespan of a
 #class:`._ConnectionRecord`.

 #. versionadded:: 1.1

 #""
 #f self._connection_record:
 #eturn self._connection_record.record_info
 #lse:
 #eturn None

 #ef invalidate(self, e=None, soft=False):
 #""Mark this connection as invalidated.

 #his method can be called directly, and is also called as a result
 #f the :meth:`_engine.Connection.invalidate` method.   When invoked,
 #he DBAPI connection is immediately closed and discarded from
 #urther use by the pool.  The invalidation mechanism proceeds
 #ia the :meth:`._ConnectionRecord.invalidate` internal method.

 #param e: an exception object indicating a reason for the invalidation.

 #param soft: if True, the connection isn't closed; instead, this
 #onnection will be recycled on next checkout.

 #. versionadded:: 1.0.3

 #. seealso::

 #ref:`pool_connection_invalidation`

 #""

 #f self.connection is None:
 #til.warn("Can't invalidate an already-closed connection.")
 #eturn
 #f self._connection_record:
 #elf._connection_record.invalidate(e=e, soft=soft)
 #f not soft:
 #elf.connection = None
 #elf._checkin()

 #ef cursor(self, *args, **kwargs):
 #""Return a new DBAPI cursor for the underlying connection.

 #his method is a proxy for the ``connection.cursor()`` DBAPI
 #ethod.

 #""
 #eturn self.connection.cursor(*args, **kwargs)

 #ef __getattr__(self, key):
 #eturn getattr(self.connection, key)

 #ef detach(self):
 #""Separate this connection from its Pool.

 #his means that the connection will no longer be returned to the
 #ool when closed, and will instead be literally closed.  The
 #ontaining ConnectionRecord is separated from the DB-API connection,
 #nd will create a new connection when next used.

 #ote that any overall connection limiting constraints imposed by a
 #ool implementation may be violated after a detach, as the detached
 #onnection is removed from the pool's knowledge and control.
 #""

 #f self._connection_record is not None:
 #ec = self._connection_record
 #ec.fairy_ref = None
 #ec.connection = None
            # TODO: should this be _return_conn?
 #elf._pool._do_return_conn(self._connection_record)
 #elf.info = self.info.copy()
 #elf._connection_record = None

 #f self._pool.dispatch.detach:
 #elf._pool.dispatch.detach(self.connection, rec)

 #ef close(self):
 #elf._counter -= 1
 #f self._counter == 0:
 #elf._checkin()

 #ef _close_no_reset(self):
 #elf._counter -= 1
 #f self._counter == 0:
 #elf._checkin(reset=False)
