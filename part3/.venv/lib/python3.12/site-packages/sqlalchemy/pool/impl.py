# sqlalchemy/pool.py
# Copyright (C) 2005-2021 the SQLAlchemy authors and contributors
# <see AUTHORS file>
#
# This module is part of SQLAlchemy and is released under
# the MIT License: https://www.opensource.org/licenses/mit-license.php


"""Pool implementation classes.

"""

import traceback
import weakref

from .base import _AsyncConnDialect
from .base import _ConnectionFairy
from .base import _ConnectionRecord
from .base import Pool
from .. import exc
from .. import util
from ..util import chop_traceback
from ..util import queue as sqla_queue
from ..util import threading


class QueuePool(Pool):

 #""A :class:`_pool.Pool`
 #hat imposes a limit on the number of open connections.

 #class:`.QueuePool` is the default pooling implementation used for
 #ll :class:`_engine.Engine` objects, unless the SQLite dialect is in use.

 #""

 #is_asyncio = False
 #queue_class = sqla_queue.Queue

 #ef __init__(
 #elf,
 #reator,
 #ool_size=5,
 #ax_overflow=10,
 #imeout=30.0,
 #se_lifo=False,
 #*kw
 #:
 #"""
 #onstruct a QueuePool.

 #param creator: a callable function that returns a DB-API
 #onnection object, same as that of :paramref:`_pool.Pool.creator`.

 #param pool_size: The size of the pool to be maintained,
 #efaults to 5. This is the largest number of connections that
 #ill be kept persistently in the pool. Note that the pool
 #egins with no connections; once this number of connections
 #s requested, that number of connections will remain.
 #`pool_size`` can be set to 0 to indicate no size limit; to
 #isable pooling, use a :class:`~sqlalchemy.pool.NullPool`
 #nstead.

 #param max_overflow: The maximum overflow size of the
 #ool. When the number of checked-out connections reaches the
 #ize set in pool_size, additional connections will be
 #eturned up to this limit. When those additional connections
 #re returned to the pool, they are disconnected and
 #iscarded. It follows then that the total number of
 #imultaneous connections the pool will allow is pool_size +
 #max_overflow`, and the total number of "sleeping"
 #onnections the pool will allow is pool_size. `max_overflow`
 #an be set to -1 to indicate no overflow limit; no limit
 #ill be placed on the total number of concurrent
 #onnections. Defaults to 10.

 #param timeout: The number of seconds to wait before giving up
 #n returning a connection. Defaults to 30.0. This can be a float
 #ut is subject to the limitations of Python time functions which
 #ay not be reliable in the tens of milliseconds.

 #param use_lifo: use LIFO (last-in-first-out) when retrieving
 #onnections instead of FIFO (first-in-first-out). Using LIFO, a
 #erver-side timeout scheme can reduce the number of connections used
 #uring non-peak periods of use.   When planning for server-side
 #imeouts, ensure that a recycle or pre-ping strategy is in use to
 #racefully handle stale connections.

 #. versionadded:: 1.3

 #. seealso::

 #ref:`pool_use_lifo`

 #ref:`pool_disconnects`

 #param \**kw: Other keyword arguments including
 #paramref:`_pool.Pool.recycle`, :paramref:`_pool.Pool.echo`,
 #paramref:`_pool.Pool.reset_on_return` and others are passed to the
 #class:`_pool.Pool` constructor.

 #""
 #ool.__init__(self, creator, **kw)
 #elf._pool = self._queue_class(pool_size, use_lifo=use_lifo)
 #elf._overflow = 0 - pool_size
 #elf._max_overflow = max_overflow
 #elf._timeout = timeout
 #elf._overflow_lock = threading.Lock()

 #ef _do_return_conn(self, conn):
 #ry:
 #elf._pool.put(conn, False)
 #xcept sqla_queue.Full:
 #ry:
 #onn.close()
 #inally:
 #elf._dec_overflow()

 #ef _do_get(self):
 #se_overflow = self._max_overflow > -1

 #ry:
 #ait = use_overflow and self._overflow >= self._max_overflow
 #eturn self._pool.get(wait, self._timeout)
 #xcept sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
 #ass
 #f use_overflow and self._overflow >= self._max_overflow:
 #f not wait:
 #eturn self._do_get()
 #lse:
 #aise exc.TimeoutError(
 #QueuePool limit of size %d overflow %d reached, "
 #connection timed out, timeout %0.2f"
 # (self.size(), self.overflow(), self._timeout),
 #ode="3o7r",
 #

 #f self._inc_overflow():
 #ry:
 #eturn self._create_connection()
 #xcept:
 #ith util.safe_reraise():
 #elf._dec_overflow()
 #lse:
 #eturn self._do_get()

 #ef _inc_overflow(self):
 #f self._max_overflow == -1:
 #elf._overflow += 1
 #eturn True
 #ith self._overflow_lock:
 #f self._overflow < self._max_overflow:
 #elf._overflow += 1
 #eturn True
 #lse:
 #eturn False

 #ef _dec_overflow(self):
 #f self._max_overflow == -1:
 #elf._overflow -= 1
 #eturn True
 #ith self._overflow_lock:
 #elf._overflow -= 1
 #eturn True

 #ef recreate(self):
 #elf.logger.info("Pool recreating")
 #eturn self.__class__(
 #elf._creator,
 #ool_size=self._pool.maxsize,
 #ax_overflow=self._max_overflow,
 #re_ping=self._pre_ping,
 #se_lifo=self._pool.use_lifo,
 #imeout=self._timeout,
 #ecycle=self._recycle,
 #cho=self.echo,
 #ogging_name=self._orig_logging_name,
 #eset_on_return=self._reset_on_return,
 #dispatch=self.dispatch,
 #ialect=self._dialect,
 #

 #ef dispose(self):
 #hile True:
 #ry:
 #onn = self._pool.get(False)
 #onn.close()
 #xcept sqla_queue.Empty:
 #reak

 #elf._overflow = 0 - self.size()
 #elf.logger.info("Pool disposed. %s", self.status())

 #ef status(self):
 #eturn (
 #Pool size: %d  Connections in pool: %d "
 #Current Overflow: %d Current Checked out "
 #connections: %d"
 # (
 #elf.size(),
 #elf.checkedin(),
 #elf.overflow(),
 #elf.checkedout(),
 #
 #

 #ef size(self):
 #eturn self._pool.maxsize

 #ef timeout(self):
 #eturn self._timeout

 #ef checkedin(self):
 #eturn self._pool.qsize()

 #ef overflow(self):
 #eturn self._overflow

 #ef checkedout(self):
 #eturn self._pool.maxsize - self._pool.qsize() + self._overflow


class AsyncAdaptedQueuePool(QueuePool):
 #is_asyncio = True
 #queue_class = sqla_queue.AsyncAdaptedQueue
 #dialect = _AsyncConnDialect()


class FallbackAsyncAdaptedQueuePool(AsyncAdaptedQueuePool):
 #queue_class = sqla_queue.FallbackAsyncAdaptedQueue


class NullPool(Pool):

 #""A Pool which does not pool connections.

 #nstead it literally opens and closes the underlying DB-API connection
 #er each connection open/close.

 #econnect-related functions such as ``recycle`` and connection
 #nvalidation are not supported by this Pool implementation, since
 #o connections are held persistently.

 #""

 #ef status(self):
 #eturn "NullPool"

 #ef _do_return_conn(self, conn):
 #onn.close()

 #ef _do_get(self):
 #eturn self._create_connection()

 #ef recreate(self):
 #elf.logger.info("Pool recreating")

 #eturn self.__class__(
 #elf._creator,
 #ecycle=self._recycle,
 #cho=self.echo,
 #ogging_name=self._orig_logging_name,
 #eset_on_return=self._reset_on_return,
 #re_ping=self._pre_ping,
 #dispatch=self.dispatch,
 #ialect=self._dialect,
 #

 #ef dispose(self):
 #ass


class SingletonThreadPool(Pool):

 #""A Pool that maintains one connection per thread.

 #aintains one connection per each thread, never moving a connection to a
 #hread other than the one which it was created in.

 #. warning::  the :class:`.SingletonThreadPool` will call ``.close()``
 #n arbitrary connections that exist beyond the size setting of
 #`pool_size``, e.g. if more unique **thread identities**
 #han what ``pool_size`` states are used.   This cleanup is
 #on-deterministic and not sensitive to whether or not the connections
 #inked to those thread identities are currently in use.

 #class:`.SingletonThreadPool` may be improved in a future release,
 #owever in its current status it is generally used only for test
 #cenarios using a SQLite ``:memory:`` database and is not recommended
 #or production use.


 #ptions are the same as those of :class:`_pool.Pool`, as well as:

 #param pool_size: The number of threads in which to maintain connections
 #t once.  Defaults to five.

 #class:`.SingletonThreadPool` is used by the SQLite dialect
 #utomatically when a memory-based database is used.
 #ee :ref:`sqlite_toplevel`.

 #""

 #is_asyncio = False

 #ef __init__(self, creator, pool_size=5, **kw):
 #ool.__init__(self, creator, **kw)
 #elf._conn = threading.local()
 #elf._fairy = threading.local()
 #elf._all_conns = set()
 #elf.size = pool_size

 #ef recreate(self):
 #elf.logger.info("Pool recreating")
 #eturn self.__class__(
 #elf._creator,
 #ool_size=self.size,
 #ecycle=self._recycle,
 #cho=self.echo,
 #re_ping=self._pre_ping,
 #ogging_name=self._orig_logging_name,
 #eset_on_return=self._reset_on_return,
 #dispatch=self.dispatch,
 #ialect=self._dialect,
 #

 #ef dispose(self):
 #""Dispose of this pool."""

 #or conn in self._all_conns:
 #ry:
 #onn.close()
 #xcept Exception:
                # pysqlite won't even let you close a conn from a thread
                # that didn't create it
 #ass

 #elf._all_conns.clear()

 #ef _cleanup(self):
 #hile len(self._all_conns) >= self.size:
 # = self._all_conns.pop()
 #.close()

 #ef status(self):
 #eturn "SingletonThreadPool id:%d size: %d" % (
 #d(self),
 #en(self._all_conns),
 #

 #ef _do_return_conn(self, conn):
 #ass

 #ef _do_get(self):
 #ry:
 # = self._conn.current()
 #f c:
 #eturn c
 #xcept AttributeError:
 #ass
 # = self._create_connection()
 #elf._conn.current = weakref.ref(c)
 #f len(self._all_conns) >= self.size:
 #elf._cleanup()
 #elf._all_conns.add(c)
 #eturn c

 #ef connect(self):
        # vendored from Pool to include the now removed use_threadlocal
        # behavior
 #ry:
 #ec = self._fairy.current()
 #xcept AttributeError:
 #ass
 #lse:
 #f rec is not None:
 #eturn rec._checkout_existing()

 #eturn _ConnectionFairy._checkout(self, self._fairy)

 #ef _return_conn(self, record):
 #ry:
 #el self._fairy.current
 #xcept AttributeError:
 #ass
 #elf._do_return_conn(record)


class StaticPool(Pool):

 #""A Pool of exactly one connection, used for all requests.

 #econnect-related functions such as ``recycle`` and connection
 #nvalidation (which is also used to support auto-reconnect) are only
 #artially supported right now and may not yield good results.


 #""

 #util.memoized_property
 #ef connection(self):
 #eturn _ConnectionRecord(self)

 #ef status(self):
 #eturn "StaticPool"

 #ef dispose(self):
 #f (
 #connection" in self.__dict__
 #nd self.connection.connection is not None
 #:
 #elf.connection.close()
 #el self.__dict__["connection"]

 #ef recreate(self):
 #elf.logger.info("Pool recreating")
 #eturn self.__class__(
 #reator=self._creator,
 #ecycle=self._recycle,
 #eset_on_return=self._reset_on_return,
 #re_ping=self._pre_ping,
 #cho=self.echo,
 #ogging_name=self._orig_logging_name,
 #dispatch=self.dispatch,
 #ialect=self._dialect,
 #

 #ef _transfer_from(self, other_static_pool):
        # used by the test suite to make a new engine / pool without
        # losing the state of an existing SQLite :memory: connection
 #elf._invoke_creator = (
 #ambda crec: other_static_pool.connection.connection
 #

 #ef _create_connection(self):
 #aise NotImplementedError()

 #ef _do_return_conn(self, conn):
 #ass

 #ef _do_get(self):
 #ec = self.connection
 #f rec._is_hard_or_soft_invalidated():
 #el self.__dict__["connection"]
 #ec = self.connection

 #eturn rec


class AssertionPool(Pool):

 #""A :class:`_pool.Pool` that allows at most one checked out connection at
 #ny given time.

 #his will raise an exception if more than one connection is checked out
 #t a time.  Useful for debugging code that is using more connections
 #han desired.

 #""

 #ef __init__(self, *args, **kw):
 #elf._conn = None
 #elf._checked_out = False
 #elf._store_traceback = kw.pop("store_traceback", True)
 #elf._checkout_traceback = None
 #ool.__init__(self, *args, **kw)

 #ef status(self):
 #eturn "AssertionPool"

 #ef _do_return_conn(self, conn):
 #f not self._checked_out:
 #aise AssertionError("connection is not checked out")
 #elf._checked_out = False
 #ssert conn is self._conn

 #ef dispose(self):
 #elf._checked_out = False
 #f self._conn:
 #elf._conn.close()

 #ef recreate(self):
 #elf.logger.info("Pool recreating")
 #eturn self.__class__(
 #elf._creator,
 #cho=self.echo,
 #re_ping=self._pre_ping,
 #ecycle=self._recycle,
 #eset_on_return=self._reset_on_return,
 #ogging_name=self._orig_logging_name,
 #dispatch=self.dispatch,
 #ialect=self._dialect,
 #

 #ef _do_get(self):
 #f self._checked_out:
 #f self._checkout_traceback:
 #uffix = " at:\n%s" % "".join(
 #hop_traceback(self._checkout_traceback)
 #
 #lse:
 #uffix = ""
 #aise AssertionError("connection is already checked out" + suffix)

 #f not self._conn:
 #elf._conn = self._create_connection()

 #elf._checked_out = True
 #f self._store_traceback:
 #elf._checkout_traceback = traceback.format_stack()
 #eturn self._conn
