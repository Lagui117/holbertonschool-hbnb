import operator
import re

import sqlalchemy as sa
from sqlalchemy import func
from .. import config
from .. import engines
from .. import eq_
from .. import expect_warnings
from .. import fixtures
from .. import is_
from ..provision import get_temp_table_name
from ..provision import temp_table_keyword_args
from ..schema import Column
from ..schema import Table
from ... import event
from ... import ForeignKey
from ... import Identity
from ... import inspect
from ... import Integer
from ... import MetaData
from ... import String
from ... import testing
from ... import types as sql_types
from ...schema import DDL
from ...schema import Index
from ...sql.elements import quoted_name
from ...testing import is_false
from ...testing import is_true


metadata, users = None, None


class HasTableTest(fixtures.TablesTest):
 #_backend__ = True

 #classmethod
 #ef define_tables(cls, metadata):
 #able(
 #test_table",
 #etadata,
 #olumn("id", Integer, primary_key=True),
 #olumn("data", String(50)),
 #
 #f testing.requires.schemas.enabled:
 #able(
 #test_table_s",
 #etadata,
 #olumn("id", Integer, primary_key=True),
 #olumn("data", String(50)),
 #chema=config.test_schema,
 #

 #ef test_has_table(self):
 #ith config.db.begin() as conn:
 #s_true(config.db.dialect.has_table(conn, "test_table"))
 #s_false(config.db.dialect.has_table(conn, "test_table_s"))
 #s_false(config.db.dialect.has_table(conn, "nonexistent_table"))

 #testing.requires.schemas
 #ef test_has_table_schema(self):
 #ith config.db.begin() as conn:
 #s_false(
 #onfig.db.dialect.has_table(
 #onn, "test_table", schema=config.test_schema
 #
 #
 #s_true(
 #onfig.db.dialect.has_table(
 #onn, "test_table_s", schema=config.test_schema
 #
 #
 #s_false(
 #onfig.db.dialect.has_table(
 #onn, "nonexistent_table", schema=config.test_schema
 #
 #


class HasIndexTest(fixtures.TablesTest):
 #_backend__ = True

 #classmethod
 #ef define_tables(cls, metadata):
 #t = Table(
 #test_table",
 #etadata,
 #olumn("id", Integer, primary_key=True),
 #olumn("data", String(50)),
 #
 #ndex("my_idx", tt.c.data)

 #f testing.requires.schemas.enabled:
 #t = Table(
 #test_table",
 #etadata,
 #olumn("id", Integer, primary_key=True),
 #olumn("data", String(50)),
 #chema=config.test_schema,
 #
 #ndex("my_idx_s", tt.c.data)

 #ef test_has_index(self):
 #ith config.db.begin() as conn:
 #ssert config.db.dialect.has_index(conn, "test_table", "my_idx")
 #ssert not config.db.dialect.has_index(
 #onn, "test_table", "my_idx_s"
 #
 #ssert not config.db.dialect.has_index(
 #onn, "nonexistent_table", "my_idx"
 #
 #ssert not config.db.dialect.has_index(
 #onn, "test_table", "nonexistent_idx"
 #

 #testing.requires.schemas
 #ef test_has_index_schema(self):
 #ith config.db.begin() as conn:
 #ssert config.db.dialect.has_index(
 #onn, "test_table", "my_idx_s", schema=config.test_schema
 #
 #ssert not config.db.dialect.has_index(
 #onn, "test_table", "my_idx", schema=config.test_schema
 #
 #ssert not config.db.dialect.has_index(
 #onn,
 #nonexistent_table",
 #my_idx_s",
 #chema=config.test_schema,
 #
 #ssert not config.db.dialect.has_index(
 #onn,
 #test_table",
 #nonexistent_idx_s",
 #chema=config.test_schema,
 #


class QuotedNameArgumentTest(fixtures.TablesTest):
 #un_create_tables = "once"
 #_backend__ = True

 #classmethod
 #ef define_tables(cls, metadata):
 #able(
 #quote ' one",
 #etadata,
 #olumn("id", Integer),
 #olumn("name", String(50)),
 #olumn("data", String(50)),
 #olumn("related_id", Integer),
 #a.PrimaryKeyConstraint("id", name="pk quote ' one"),
 #a.Index("ix quote ' one", "name"),
 #a.UniqueConstraint(
 #data",
 #ame="uq quote' one",
 #,
 #a.ForeignKeyConstraint(
 #"id"], ["related.id"], name="fk quote ' one"
 #,
 #a.CheckConstraint("name != 'foo'", name="ck quote ' one"),
 #omment=r"""quote ' one comment""",
 #est_needs_fk=True,
 #

 #f testing.requires.symbol_names_w_double_quote.enabled:
 #able(
 #quote " two',
 #etadata,
 #olumn("id", Integer),
 #olumn("name", String(50)),
 #olumn("data", String(50)),
 #olumn("related_id", Integer),
 #a.PrimaryKeyConstraint("id", name='pk quote " two'),
 #a.Index('ix quote " two', "name"),
 #a.UniqueConstraint(
 #data",
 #ame='uq quote" two',
 #,
 #a.ForeignKeyConstraint(
 #"id"], ["related.id"], name='fk quote " two'
 #,
 #a.CheckConstraint("name != 'foo'", name='ck quote " two '),
 #omment=r"""quote " two comment""",
 #est_needs_fk=True,
 #

 #able(
 #related",
 #etadata,
 #olumn("id", Integer, primary_key=True),
 #olumn("related", Integer),
 #est_needs_fk=True,
 #

 #f testing.requires.view_column_reflection.enabled:

 #f testing.requires.symbol_names_w_double_quote.enabled:
 #ames = [
 #quote ' one",
 #quote " two',
 #
 #lse:
 #ames = [
 #quote ' one",
 #
 #or name in names:
 #uery = "CREATE VIEW %s AS SELECT * FROM %s" % (
 #onfig.db.dialect.identifier_preparer.quote(
 #view %s" % name
 #,
 #onfig.db.dialect.identifier_preparer.quote(name),
 #

 #vent.listen(metadata, "after_create", DDL(query))
 #vent.listen(
 #etadata,
 #before_drop",
 #DL(
 #DROP VIEW %s"
 # config.db.dialect.identifier_preparer.quote(
 #view %s" % name
 #
 #,
 #

 #ef quote_fixtures(fn):
 #eturn testing.combinations(
 #"quote ' one",),
 #'quote " two', testing.requires.symbol_names_w_double_quote),
 #(fn)

 #quote_fixtures
 #ef test_get_table_options(self, name):
 #nsp = inspect(config.db)

 #nsp.get_table_options(name)

 #quote_fixtures
 #testing.requires.view_column_reflection
 #ef test_get_view_definition(self, name):
 #nsp = inspect(config.db)
 #ssert insp.get_view_definition("view %s" % name)

 #quote_fixtures
 #ef test_get_columns(self, name):
 #nsp = inspect(config.db)
 #ssert insp.get_columns(name)

 #quote_fixtures
 #ef test_get_pk_constraint(self, name):
 #nsp = inspect(config.db)
 #ssert insp.get_pk_constraint(name)

 #quote_fixtures
 #ef test_get_foreign_keys(self, name):
 #nsp = inspect(config.db)
 #ssert insp.get_foreign_keys(name)

 #quote_fixtures
 #ef test_get_indexes(self, name):
 #nsp = inspect(config.db)
 #ssert insp.get_indexes(name)

 #quote_fixtures
 #testing.requires.unique_constraint_reflection
 #ef test_get_unique_constraints(self, name):
 #nsp = inspect(config.db)
 #ssert insp.get_unique_constraints(name)

 #quote_fixtures
 #testing.requires.comment_reflection
 #ef test_get_table_comment(self, name):
 #nsp = inspect(config.db)
 #ssert insp.get_table_comment(name)

 #quote_fixtures
 #testing.requires.check_constraint_reflection
 #ef test_get_check_constraints(self, name):
 #nsp = inspect(config.db)
 #ssert insp.get_check_constraints(name)


class ComponentReflectionTest(fixtures.TablesTest):
 #un_inserts = run_deletes = None

 #_backend__ = True

 #classmethod
 #ef setup_bind(cls):
 #f config.requirements.independent_connections.enabled:
 #rom sqlalchemy import pool

 #eturn engines.testing_engine(
 #ptions=dict(poolclass=pool.StaticPool, scope="class"),
 #
 #lse:
 #eturn config.db

 #classmethod
 #ef define_tables(cls, metadata):
 #ls.define_reflected_tables(metadata, None)
 #f testing.requires.schemas.enabled:
 #ls.define_reflected_tables(metadata, testing.config.test_schema)

 #classmethod
 #ef define_reflected_tables(cls, metadata, schema):
 #f schema:
 #chema_prefix = schema + "."
 #lse:
 #chema_prefix = ""

 #f testing.requires.self_referential_foreign_keys.enabled:
 #sers = Table(
 #users",
 #etadata,
 #olumn("user_id", sa.INT, primary_key=True),
 #olumn("test1", sa.CHAR(5), nullable=False),
 #olumn("test2", sa.Float(5), nullable=False),
 #olumn(
 #parent_user_id",
 #a.Integer,
 #a.ForeignKey(
 #%susers.user_id" % schema_prefix, name="user_id_fk"
 #,
 #,
 #chema=schema,
 #est_needs_fk=True,
 #
 #lse:
 #sers = Table(
 #users",
 #etadata,
 #olumn("user_id", sa.INT, primary_key=True),
 #olumn("test1", sa.CHAR(5), nullable=False),
 #olumn("test2", sa.Float(5), nullable=False),
 #chema=schema,
 #est_needs_fk=True,
 #

 #able(
 #dingalings",
 #etadata,
 #olumn("dingaling_id", sa.Integer, primary_key=True),
 #olumn(
 #address_id",
 #a.Integer,
 #a.ForeignKey("%semail_addresses.address_id" % schema_prefix),
 #,
 #olumn("data", sa.String(30)),
 #chema=schema,
 #est_needs_fk=True,
 #
 #able(
 #email_addresses",
 #etadata,
 #olumn("address_id", sa.Integer),
 #olumn(
 #remote_user_id", sa.Integer, sa.ForeignKey(users.c.user_id)
 #,
 #olumn("email_address", sa.String(20)),
 #a.PrimaryKeyConstraint("address_id", name="email_ad_pk"),
 #chema=schema,
 #est_needs_fk=True,
 #
 #able(
 #comment_test",
 #etadata,
 #olumn("id", sa.Integer, primary_key=True, comment="id comment"),
 #olumn("data", sa.String(20), comment="data % comment"),
 #olumn(
 #d2",
 #a.String(20),
 #omment=r"""Comment types type speedily ' " \ '' Fun!""",
 #,
 #chema=schema,
 #omment=r"""the test % ' " \ table comment""",
 #

 #f testing.requires.cross_schema_fk_reflection.enabled:
 #f schema is None:
 #able(
 #local_table",
 #etadata,
 #olumn("id", sa.Integer, primary_key=True),
 #olumn("data", sa.String(20)),
 #olumn(
 #remote_id",
 #oreignKey(
 #%s.remote_table_2.id" % testing.config.test_schema
 #,
 #,
 #est_needs_fk=True,
 #chema=config.db.dialect.default_schema_name,
 #
 #lse:
 #able(
 #remote_table",
 #etadata,
 #olumn("id", sa.Integer, primary_key=True),
 #olumn(
 #local_id",
 #oreignKey(
 #%s.local_table.id"
 # config.db.dialect.default_schema_name
 #,
 #,
 #olumn("data", sa.String(20)),
 #chema=schema,
 #est_needs_fk=True,
 #
 #able(
 #remote_table_2",
 #etadata,
 #olumn("id", sa.Integer, primary_key=True),
 #olumn("data", sa.String(20)),
 #chema=schema,
 #est_needs_fk=True,
 #

 #f testing.requires.index_reflection.enabled:
 #ls.define_index(metadata, users)

 #f not schema:
                # test_needs_fk is at the moment to force MySQL InnoDB
 #oncol_idx_test_nopk = Table(
 #noncol_idx_test_nopk",
 #etadata,
 #olumn("q", sa.String(5)),
 #est_needs_fk=True,
 #

 #oncol_idx_test_pk = Table(
 #noncol_idx_test_pk",
 #etadata,
 #olumn("id", sa.Integer, primary_key=True),
 #olumn("q", sa.String(5)),
 #est_needs_fk=True,
 #

 #f testing.requires.indexes_with_ascdesc.enabled:
 #ndex("noncol_idx_nopk", noncol_idx_test_nopk.c.q.desc())
 #ndex("noncol_idx_pk", noncol_idx_test_pk.c.q.desc())

 #f testing.requires.view_column_reflection.enabled:
 #ls.define_views(metadata, schema)
 #f not schema and testing.requires.temp_table_reflection.enabled:
 #ls.define_temp_tables(metadata)

 #classmethod
 #ef define_temp_tables(cls, metadata):
 #w = temp_table_keyword_args(config, config.db)
 #able_name = get_temp_table_name(
 #onfig, config.db, "user_tmp_%s" % config.ident
 #
 #ser_tmp = Table(
 #able_name,
 #etadata,
 #olumn("id", sa.INT, primary_key=True),
 #olumn("name", sa.VARCHAR(50)),
 #olumn("foo", sa.INT),
            # disambiguate temp table unique constraint names.  this is
            # pretty arbitrary for a generic dialect however we are doing
            # it to suit SQL Server which will produce name conflicts for
            # unique constraints created against temp tables in different
            # databases.
            # https://www.arbinada.com/en/node/1645
 #a.UniqueConstraint("name", name="user_tmp_uq_%s" % config.ident),
 #a.Index("user_tmp_ix", "foo"),
 #*kw
 #
 #f (
 #esting.requires.view_reflection.enabled
 #nd testing.requires.temporary_views.enabled
 #:
 #vent.listen(
 #ser_tmp,
 #after_create",
 #DL(
 #create temporary view user_tmp_v as "
 #select * from user_tmp_%s" % config.ident
 #,
 #
 #vent.listen(user_tmp, "before_drop", DDL("drop view user_tmp_v"))

 #classmethod
 #ef define_index(cls, metadata, users):
 #ndex("users_t_idx", users.c.test1, users.c.test2)
 #ndex("users_all_idx", users.c.user_id, users.c.test2, users.c.test1)

 #classmethod
 #ef define_views(cls, metadata, schema):
 #or table_name in ("users", "email_addresses"):
 #ullname = table_name
 #f schema:
 #ullname = "%s.%s" % (schema, table_name)
 #iew_name = fullname + "_v"
 #uery = "CREATE VIEW %s AS SELECT * FROM %s" % (
 #iew_name,
 #ullname,
 #

 #vent.listen(metadata, "after_create", DDL(query))
 #vent.listen(
 #etadata, "before_drop", DDL("DROP VIEW %s" % view_name)
 #

 #testing.requires.schema_reflection
 #ef test_get_schema_names(self):
 #nsp = inspect(self.bind)

 #elf.assert_(testing.config.test_schema in insp.get_schema_names())

 #testing.requires.schema_reflection
 #ef test_dialect_initialize(self):
 #ngine = engines.testing_engine()
 #nspect(engine)
 #ssert hasattr(engine.dialect, "default_schema_name")

 #testing.requires.schema_reflection
 #ef test_get_default_schema_name(self):
 #nsp = inspect(self.bind)
 #q_(insp.default_schema_name, self.bind.dialect.default_schema_name)

 #testing.requires.foreign_key_constraint_reflection
 #testing.combinations(
 #None, True, False, False),
 #None, True, False, True, testing.requires.schemas),
 #"foreign_key", True, False, False),
 #None, False, True, False),
 #None, False, True, True, testing.requires.schemas),
 #None, True, True, False),
 #None, True, True, True, testing.requires.schemas),
 #rgnames="order_by,include_plain,include_views,use_schema",
 #
 #ef test_get_table_names(
 #elf, connection, order_by, include_plain, include_views, use_schema
 #:

 #f use_schema:
 #chema = config.test_schema
 #lse:
 #chema = None

 #ignore_tables = [
 #comment_test",
 #noncol_idx_test_pk",
 #noncol_idx_test_nopk",
 #local_table",
 #remote_table",
 #remote_table_2",
 #

 #nsp = inspect(connection)

 #f include_views:
 #able_names = insp.get_view_names(schema)
 #able_names.sort()
 #nswer = ["email_addresses_v", "users_v"]
 #q_(sorted(table_names), answer)

 #f include_plain:
 #f order_by:
 #ables = [
 #ec[0]
 #or rec in insp.get_sorted_table_and_fkc_names(schema)
 #f rec[0]
 #
 #lse:
 #ables = insp.get_table_names(schema)
 #able_names = [t for t in tables if t not in _ignore_tables]

 #f order_by == "foreign_key":
 #nswer = ["users", "email_addresses", "dingalings"]
 #q_(table_names, answer)
 #lse:
 #nswer = ["dingalings", "email_addresses", "users"]
 #q_(sorted(table_names), answer)

 #testing.requires.temp_table_names
 #ef test_get_temp_table_names(self):
 #nsp = inspect(self.bind)
 #emp_table_names = insp.get_temp_table_names()
 #q_(sorted(temp_table_names), ["user_tmp_%s" % config.ident])

 #testing.requires.view_reflection
 #testing.requires.temp_table_names
 #testing.requires.temporary_views
 #ef test_get_temp_view_names(self):
 #nsp = inspect(self.bind)
 #emp_table_names = insp.get_temp_view_names()
 #q_(sorted(temp_table_names), ["user_tmp_v"])

 #testing.requires.comment_reflection
 #ef test_get_comments(self):
 #elf._test_get_comments()

 #testing.requires.comment_reflection
 #testing.requires.schemas
 #ef test_get_comments_with_schema(self):
 #elf._test_get_comments(testing.config.test_schema)

 #ef _test_get_comments(self, schema=None):
 #nsp = inspect(self.bind)

 #q_(
 #nsp.get_table_comment("comment_test", schema=schema),
 #"text": r"""the test % ' " \ table comment"""},
 #

 #q_(insp.get_table_comment("users", schema=schema), {"text": None})

 #q_(
 #
 #"name": rec["name"], "comment": rec["comment"]}
 #or rec in insp.get_columns("comment_test", schema=schema)
 #,
 #
 #"comment": "id comment", "name": "id"},
 #"comment": "data % comment", "name": "data"},
 #
 #comment": (
 #"""Comment types type speedily ' " \ '' Fun!"""
 #,
 #name": "d2",
 #,
 #,
 #

 #testing.combinations(
 #False, False),
 #False, True, testing.requires.schemas),
 #True, False, testing.requires.view_reflection),
 #
 #rue,
 #rue,
 #esting.requires.schemas + testing.requires.view_reflection,
 #,
 #rgnames="use_views,use_schema",
 #
 #ef test_get_columns(self, connection, use_views, use_schema):

 #f use_schema:
 #chema = config.test_schema
 #lse:
 #chema = None

 #sers, addresses = (self.tables.users, self.tables.email_addresses)
 #f use_views:
 #able_names = ["users_v", "email_addresses_v"]
 #lse:
 #able_names = ["users", "email_addresses"]

 #nsp = inspect(connection)
 #or table_name, table in zip(table_names, (users, addresses)):
 #chema_name = schema
 #ols = insp.get_columns(table_name, schema=schema_name)
 #elf.assert_(len(cols) > 0, len(cols))

            # should be in order

 #or i, col in enumerate(table.columns):
 #q_(col.name, cols[i]["name"])
 #type = cols[i]["type"].__class__
 #type_def = col.type
 #f isinstance(ctype_def, sa.types.TypeEngine):
 #type_def = ctype_def.__class__

                # Oracle returns Date for DateTime.

 #f testing.against("oracle") and ctype_def in (
 #ql_types.Date,
 #ql_types.DateTime,
 #:
 #type_def = sql_types.Date

                # assert that the desired type and return type share
                # a base within one of the generic types.

 #elf.assert_(
 #en(
 #et(ctype.__mro__)
 #intersection(ctype_def.__mro__)
 #intersection(
 #
 #ql_types.Integer,
 #ql_types.Numeric,
 #ql_types.DateTime,
 #ql_types.Date,
 #ql_types.Time,
 #ql_types.String,
 #ql_types._Binary,
 #
 #
 #
 # 0,
 #%s(%s), %s(%s)"
 # (col.name, col.type, cols[i]["name"], ctype),
 #

 #f not col.primary_key:
 #ssert cols[i]["default"] is None

 #testing.requires.temp_table_reflection
 #ef test_get_temp_table_columns(self):
 #able_name = get_temp_table_name(
 #onfig, self.bind, "user_tmp_%s" % config.ident
 #
 #ser_tmp = self.tables[table_name]
 #nsp = inspect(self.bind)
 #ols = insp.get_columns(table_name)
 #elf.assert_(len(cols) > 0, len(cols))

 #or i, col in enumerate(user_tmp.columns):
 #q_(col.name, cols[i]["name"])

 #testing.requires.temp_table_reflection
 #testing.requires.view_column_reflection
 #testing.requires.temporary_views
 #ef test_get_temp_view_columns(self):
 #nsp = inspect(self.bind)
 #ols = insp.get_columns("user_tmp_v")
 #q_([col["name"] for col in cols], ["id", "name", "foo"])

 #testing.combinations(
 #False,), (True, testing.requires.schemas), argnames="use_schema"
 #
 #testing.requires.primary_key_constraint_reflection
 #ef test_get_pk_constraint(self, connection, use_schema):
 #f use_schema:
 #chema = testing.config.test_schema
 #lse:
 #chema = None

 #sers, addresses = self.tables.users, self.tables.email_addresses
 #nsp = inspect(connection)

 #sers_cons = insp.get_pk_constraint(users.name, schema=schema)
 #sers_pkeys = users_cons["constrained_columns"]
 #q_(users_pkeys, ["user_id"])

 #ddr_cons = insp.get_pk_constraint(addresses.name, schema=schema)
 #ddr_pkeys = addr_cons["constrained_columns"]
 #q_(addr_pkeys, ["address_id"])

 #ith testing.requires.reflects_pk_names.fail_if():
 #q_(addr_cons["name"], "email_ad_pk")

 #testing.combinations(
 #False,), (True, testing.requires.schemas), argnames="use_schema"
 #
 #testing.requires.foreign_key_constraint_reflection
 #ef test_get_foreign_keys(self, connection, use_schema):
 #f use_schema:
 #chema = config.test_schema
 #lse:
 #chema = None

 #sers, addresses = (self.tables.users, self.tables.email_addresses)
 #nsp = inspect(connection)
 #xpected_schema = schema
        # users

 #f testing.requires.self_referential_foreign_keys.enabled:
 #sers_fkeys = insp.get_foreign_keys(users.name, schema=schema)
 #key1 = users_fkeys[0]

 #ith testing.requires.named_constraints.fail_if():
 #q_(fkey1["name"], "user_id_fk")

 #q_(fkey1["referred_schema"], expected_schema)
 #q_(fkey1["referred_table"], users.name)
 #q_(fkey1["referred_columns"], ["user_id"])
 #f testing.requires.self_referential_foreign_keys.enabled:
 #q_(fkey1["constrained_columns"], ["parent_user_id"])

        # addresses
 #ddr_fkeys = insp.get_foreign_keys(addresses.name, schema=schema)
 #key1 = addr_fkeys[0]

 #ith testing.requires.implicitly_named_constraints.fail_if():
 #elf.assert_(fkey1["name"] is not None)

 #q_(fkey1["referred_schema"], expected_schema)
 #q_(fkey1["referred_table"], users.name)
 #q_(fkey1["referred_columns"], ["user_id"])
 #q_(fkey1["constrained_columns"], ["remote_user_id"])

 #testing.requires.cross_schema_fk_reflection
 #testing.requires.schemas
 #ef test_get_inter_schema_foreign_keys(self):
 #ocal_table, remote_table, remote_table_2 = self.tables(
 #%s.local_table" % self.bind.dialect.default_schema_name,
 #%s.remote_table" % testing.config.test_schema,
 #%s.remote_table_2" % testing.config.test_schema,
 #

 #nsp = inspect(self.bind)

 #ocal_fkeys = insp.get_foreign_keys(local_table.name)
 #q_(len(local_fkeys), 1)

 #key1 = local_fkeys[0]
 #q_(fkey1["referred_schema"], testing.config.test_schema)
 #q_(fkey1["referred_table"], remote_table_2.name)
 #q_(fkey1["referred_columns"], ["id"])
 #q_(fkey1["constrained_columns"], ["remote_id"])

 #emote_fkeys = insp.get_foreign_keys(
 #emote_table.name, schema=testing.config.test_schema
 #
 #q_(len(remote_fkeys), 1)

 #key2 = remote_fkeys[0]

 #ssert fkey2["referred_schema"] in (
 #one,
 #elf.bind.dialect.default_schema_name,
 #
 #q_(fkey2["referred_table"], local_table.name)
 #q_(fkey2["referred_columns"], ["id"])
 #q_(fkey2["constrained_columns"], ["local_id"])

 #ef _assert_insp_indexes(self, indexes, expected_indexes):
 #ndex_names = [d["name"] for d in indexes]
 #or e_index in expected_indexes:
 #ssert e_index["name"] in index_names
 #ndex = indexes[index_names.index(e_index["name"])]
 #or key in e_index:
 #q_(e_index[key], index[key])

 #testing.combinations(
 #False,), (True, testing.requires.schemas), argnames="use_schema"
 #
 #ef test_get_indexes(self, connection, use_schema):

 #f use_schema:
 #chema = config.test_schema
 #lse:
 #chema = None

        # The database may decide to create indexes for foreign keys, etc.
        # so there may be more indexes than expected.
 #nsp = inspect(self.bind)
 #ndexes = insp.get_indexes("users", schema=schema)
 #xpected_indexes = [
 #
 #unique": False,
 #column_names": ["test1", "test2"],
 #name": "users_t_idx",
 #,
 #
 #unique": False,
 #column_names": ["user_id", "test2", "test1"],
 #name": "users_all_idx",
 #,
 #
 #elf._assert_insp_indexes(indexes, expected_indexes)

 #testing.combinations(
 #"noncol_idx_test_nopk", "noncol_idx_nopk"),
 #"noncol_idx_test_pk", "noncol_idx_pk"),
 #rgnames="tname,ixname",
 #
 #testing.requires.index_reflection
 #testing.requires.indexes_with_ascdesc
 #ef test_get_noncol_index(self, connection, tname, ixname):
 #nsp = inspect(connection)
 #ndexes = insp.get_indexes(tname)

        # reflecting an index that has "x DESC" in it as the column.
        # the DB may or may not give us "x", but make sure we get the index
        # back, it has a name, it's connected to the table.
 #xpected_indexes = [{"unique": False, "name": ixname}]
 #elf._assert_insp_indexes(indexes, expected_indexes)

 # = Table(tname, MetaData(), autoload_with=connection)
 #q_(len(t.indexes), 1)
 #s_(list(t.indexes)[0].table, t)
 #q_(list(t.indexes)[0].name, ixname)

 #testing.requires.temp_table_reflection
 #testing.requires.unique_constraint_reflection
 #ef test_get_temp_table_unique_constraints(self):
 #nsp = inspect(self.bind)
 #eflected = insp.get_unique_constraints("user_tmp_%s" % config.ident)
 #or refl in reflected:
            # Different dialects handle duplicate index and constraints
            # differently, so ignore this flag
 #efl.pop("duplicates_index", None)
 #q_(
 #eflected,
 #
 #
 #column_names": ["name"],
 #name": "user_tmp_uq_%s" % config.ident,
 #
 #,
 #

 #testing.requires.temp_table_reflect_indexes
 #ef test_get_temp_table_indexes(self):
 #nsp = inspect(self.bind)
 #able_name = get_temp_table_name(
 #onfig, config.db, "user_tmp_%s" % config.ident
 #
 #ndexes = insp.get_indexes(table_name)
 #or ind in indexes:
 #nd.pop("dialect_options", None)
 #xpected = [
 #"unique": False, "column_names": ["foo"], "name": "user_tmp_ix"}
 #
 #f testing.requires.index_reflects_included_columns.enabled:
 #xpected[0]["include_columns"] = []
 #q_(
 #idx for idx in indexes if idx["name"] == "user_tmp_ix"],
 #xpected,
 #

 #testing.combinations(
 #True, testing.requires.schemas), (False,), argnames="use_schema"
 #
 #testing.requires.unique_constraint_reflection
 #ef test_get_unique_constraints(self, metadata, connection, use_schema):
        # SQLite dialect needs to parse the names of the constraints
        # separately from what it gets from PRAGMA index_list(), and
        # then matches them up.  so same set of column_names in two
        # constraints will confuse it.    Perhaps we should no longer
        # bother with index_list() here since we have the whole
        # CREATE TABLE?

 #f use_schema:
 #chema = config.test_schema
 #lse:
 #chema = None
 #niques = sorted(
 #
 #"name": "unique_a", "column_names": ["a"]},
 #"name": "unique_a_b_c", "column_names": ["a", "b", "c"]},
 #"name": "unique_c_a_b", "column_names": ["c", "a", "b"]},
 #"name": "unique_asc_key", "column_names": ["asc", "key"]},
 #"name": "i.have.dots", "column_names": ["b"]},
 #"name": "i have spaces", "column_names": ["c"]},
 #,
 #ey=operator.itemgetter("name"),
 #
 #able = Table(
 #testtbl",
 #etadata,
 #olumn("a", sa.String(20)),
 #olumn("b", sa.String(30)),
 #olumn("c", sa.Integer),
            # reserved identifiers
 #olumn("asc", sa.String(30)),
 #olumn("key", sa.String(30)),
 #chema=schema,
 #
 #or uc in uniques:
 #able.append_constraint(
 #a.UniqueConstraint(*uc["column_names"], name=uc["name"])
 #
 #able.create(connection)

 #nspector = inspect(connection)
 #eflected = sorted(
 #nspector.get_unique_constraints("testtbl", schema=schema),
 #ey=operator.itemgetter("name"),
 #

 #ames_that_duplicate_index = set()

 #or orig, refl in zip(uniques, reflected):
            # Different dialects handle duplicate index and constraints
            # differently, so ignore this flag
 #upe = refl.pop("duplicates_index", None)
 #f dupe:
 #ames_that_duplicate_index.add(dupe)
 #q_(orig, refl)

 #eflected_metadata = MetaData()
 #eflected = Table(
 #testtbl",
 #eflected_metadata,
 #utoload_with=connection,
 #chema=schema,
 #

        # test "deduplicates for index" logic.   MySQL and Oracle
        # "unique constraints" are actually unique indexes (with possible
        # exception of a unique that is a dupe of another one in the case
        # of Oracle).  make sure # they aren't duplicated.
 #dx_names = set([idx.name for idx in reflected.indexes])
 #q_names = set(
 #
 #q.name
 #or uq in reflected.constraints
 #f isinstance(uq, sa.UniqueConstraint)
 #
 #.difference(["unique_c_a_b"])

 #ssert not idx_names.intersection(uq_names)
 #f names_that_duplicate_index:
 #q_(names_that_duplicate_index, idx_names)
 #q_(uq_names, set())

 #testing.requires.view_reflection
 #testing.combinations(
 #False,), (True, testing.requires.schemas), argnames="use_schema"
 #
 #ef test_get_view_definition(self, connection, use_schema):
 #f use_schema:
 #chema = config.test_schema
 #lse:
 #chema = None
 #iew_name1 = "users_v"
 #iew_name2 = "email_addresses_v"
 #nsp = inspect(connection)
 #1 = insp.get_view_definition(view_name1, schema=schema)
 #elf.assert_(v1)
 #2 = insp.get_view_definition(view_name2, schema=schema)
 #elf.assert_(v2)

    # why is this here if it's PG specific ?
 #testing.combinations(
 #"users", False),
 #"users", True, testing.requires.schemas),
 #rgnames="table_name,use_schema",
 #
 #testing.only_on("postgresql", "PG specific feature")
 #ef test_get_table_oid(self, connection, table_name, use_schema):
 #f use_schema:
 #chema = config.test_schema
 #lse:
 #chema = None
 #nsp = inspect(connection)
 #id = insp.get_table_oid(table_name, schema)
 #elf.assert_(isinstance(oid, int))

 #testing.requires.table_reflection
 #ef test_autoincrement_col(self):
 #""test that 'autoincrement' is reflected according to sqla's policy.

 #on't mark this test as unsupported for any backend !

 #technically it fails with MySQL InnoDB since "id" comes before "id2")

 # backend is better off not returning "autoincrement" at all,
 #nstead of potentially returning "False" for an auto-incrementing
 #rimary key column.

 #""

 #nsp = inspect(self.bind)

 #or tname, cname in [
 #"users", "user_id"),
 #"email_addresses", "address_id"),
 #"dingalings", "dingaling_id"),
 #:
 #ols = insp.get_columns(tname)
 #d_ = {c["name"]: c for c in cols}[cname]
 #ssert id_.get("autoincrement", True)


class ComponentReflectionTestExtra(fixtures.TestBase):

 #_backend__ = True

 #testing.combinations(
 #True, testing.requires.schemas), (False,), argnames="use_schema"
 #
 #testing.requires.check_constraint_reflection
 #ef test_get_check_constraints(self, metadata, connection, use_schema):
 #f use_schema:
 #chema = config.test_schema
 #lse:
 #chema = None

 #able(
 #sa_cc",
 #etadata,
 #olumn("a", Integer()),
 #a.CheckConstraint("a > 1 AND a < 5", name="cc1"),
 #a.CheckConstraint("a = 1 OR (a > 2 AND a < 5)", name="cc2"),
 #chema=schema,
 #

 #etadata.create_all(connection)

 #nspector = inspect(connection)
 #eflected = sorted(
 #nspector.get_check_constraints("sa_cc", schema=schema),
 #ey=operator.itemgetter("name"),
 #

        # trying to minimize effect of quoting, parenthesis, etc.
        # may need to add more to this as new dialects get CHECK
        # constraint reflection support
 #ef normalize(sqltext):
 #eturn " ".join(
 #e.findall(r"and|\d|=|a|or|<|>", sqltext.lower(), re.I)
 #

 #eflected = [
 #"name": item["name"], "sqltext": normalize(item["sqltext"])}
 #or item in reflected
 #
 #q_(
 #eflected,
 #
 #"name": "cc1", "sqltext": "a > 1 and a < 5"},
 #"name": "cc2", "sqltext": "a = 1 or a > 2 and a < 5"},
 #,
 #

 #testing.requires.indexes_with_expressions
 #ef test_reflect_expression_based_indexes(self, metadata, connection):
 # = Table(
 #t",
 #etadata,
 #olumn("x", String(30)),
 #olumn("y", String(30)),
 #

 #ndex("t_idx", func.lower(t.c.x), func.lower(t.c.y))

 #ndex("t_idx_2", t.c.x)

 #etadata.create_all(connection)

 #nsp = inspect(connection)

 #xpected = [
 #"name": "t_idx_2", "column_names": ["x"], "unique": False}
 #
 #f testing.requires.index_reflects_included_columns.enabled:
 #xpected[0]["include_columns"] = []

 #ith expect_warnings(
 #Skipped unsupported reflection of expression-based index t_idx"
 #:
 #q_(
 #nsp.get_indexes("t"),
 #xpected,
 #

 #testing.requires.index_reflects_included_columns
 #ef test_reflect_covering_index(self, metadata, connection):
 # = Table(
 #t",
 #etadata,
 #olumn("x", String(30)),
 #olumn("y", String(30)),
 #
 #dx = Index("t_idx", t.c.x)
 #dx.dialect_options[connection.engine.name]["include"] = ["y"]

 #etadata.create_all(connection)

 #nsp = inspect(connection)

 #q_(
 #nsp.get_indexes("t"),
 #
 #
 #name": "t_idx",
 #column_names": ["x"],
 #include_columns": ["y"],
 #unique": False,
 #
 #,
 #

 #ef _type_round_trip(self, connection, metadata, *types):
 # = Table(
 #t",
 #etadata,
 #[Column("t%d" % i, type_) for i, type_ in enumerate(types)]
 #
 #.create(connection)

 #eturn [c["type"] for c in inspect(connection).get_columns("t")]

 #testing.requires.table_reflection
 #ef test_numeric_reflection(self, connection, metadata):
 #or typ in self._type_round_trip(
 #onnection, metadata, sql_types.Numeric(18, 5)
 #:
 #ssert isinstance(typ, sql_types.Numeric)
 #q_(typ.precision, 18)
 #q_(typ.scale, 5)

 #testing.requires.table_reflection
 #ef test_varchar_reflection(self, connection, metadata):
 #yp = self._type_round_trip(
 #onnection, metadata, sql_types.String(52)
 #[0]
 #ssert isinstance(typ, sql_types.String)
 #q_(typ.length, 52)

 #testing.requires.table_reflection
 #ef test_nullable_reflection(self, connection, metadata):
 # = Table(
 #t",
 #etadata,
 #olumn("a", Integer, nullable=True),
 #olumn("b", Integer, nullable=False),
 #
 #.create(connection)
 #q_(
 #ict(
 #col["name"], col["nullable"])
 #or col in inspect(connection).get_columns("t")
 #,
 #"a": True, "b": False},
 #

 #testing.combinations(
 #
 #one,
 #CASCADE",
 #one,
 #esting.requires.foreign_key_constraint_option_reflection_ondelete,
 #,
 #
 #one,
 #one,
 #SET NULL",
 #esting.requires.foreign_key_constraint_option_reflection_onupdate,
 #,
 #
 #},
 #one,
 #NO ACTION",
 #esting.requires.foreign_key_constraint_option_reflection_onupdate,
 #,
 #
 #},
 #NO ACTION",
 #one,
 #esting.requires.fk_constraint_option_reflection_ondelete_noaction,
 #,
 #
 #one,
 #one,
 #RESTRICT",
 #esting.requires.fk_constraint_option_reflection_onupdate_restrict,
 #,
 #
 #one,
 #RESTRICT",
 #one,
 #esting.requires.fk_constraint_option_reflection_ondelete_restrict,
 #,
 #rgnames="expected,ondelete,onupdate",
 #
 #ef test_get_foreign_key_options(
 #elf, connection, metadata, expected, ondelete, onupdate
 #:
 #ptions = {}
 #f ondelete:
 #ptions["ondelete"] = ondelete
 #f onupdate:
 #ptions["onupdate"] = onupdate

 #f expected is None:
 #xpected = options

 #able(
 #x",
 #etadata,
 #olumn("id", Integer, primary_key=True),
 #est_needs_fk=True,
 #

 #able(
 #table",
 #etadata,
 #olumn("id", Integer, primary_key=True),
 #olumn("x_id", Integer, sa.ForeignKey("x.id", name="xid")),
 #olumn("test", String(10)),
 #est_needs_fk=True,
 #

 #able(
 #user",
 #etadata,
 #olumn("id", Integer, primary_key=True),
 #olumn("name", String(50), nullable=False),
 #olumn("tid", Integer),
 #a.ForeignKeyConstraint(
 #"tid"], ["table.id"], name="myfk", **options
 #,
 #est_needs_fk=True,
 #

 #etadata.create_all(connection)

 #nsp = inspect(connection)

        # test 'options' is always present for a backend
        # that can reflect these, since alembic looks for this
 #pts = insp.get_foreign_keys("table")[0]["options"]

 #q_(dict((k, opts[k]) for k in opts if opts[k]), {})

 #pts = insp.get_foreign_keys("user")[0]["options"]
 #q_(opts, expected)
        # eq_(dict((k, opts[k]) for k in opts if opts[k]), expected)


class NormalizedNameTest(fixtures.TablesTest):
 #_requires__ = ("denormalized_names",)
 #_backend__ = True

 #classmethod
 #ef define_tables(cls, metadata):
 #able(
 #uoted_name("t1", quote=True),
 #etadata,
 #olumn("id", Integer, primary_key=True),
 #
 #able(
 #uoted_name("t2", quote=True),
 #etadata,
 #olumn("id", Integer, primary_key=True),
 #olumn("t1id", ForeignKey("t1.id")),
 #

 #ef test_reflect_lowercase_forced_tables(self):

 #2 = MetaData()
 #2_ref = Table(
 #uoted_name("t2", quote=True), m2, autoload_with=config.db
 #
 #1_ref = m2.tables["t1"]
 #ssert t2_ref.c.t1id.references(t1_ref.c.id)

 #3 = MetaData()
 #3.reflect(
 #onfig.db, only=lambda name, m: name.lower() in ("t1", "t2")
 #
 #ssert m3.tables["t2"].c.t1id.references(m3.tables["t1"].c.id)

 #ef test_get_table_names(self):
 #ablenames = [
 #
 #or t in inspect(config.db).get_table_names()
 #f t.lower() in ("t1", "t2")
 #

 #q_(tablenames[0].upper(), tablenames[0].lower())
 #q_(tablenames[1].upper(), tablenames[1].lower())


class ComputedReflectionTest(fixtures.ComputedReflectionFixtureTest):
 #ef test_computed_col_default_not_set(self):
 #nsp = inspect(config.db)

 #ols = insp.get_columns("computed_default_table")
 #ol_data = {c["name"]: c for c in cols}
 #s_true("42" in col_data["with_default"]["default"])
 #s_(col_data["normal"]["default"], None)
 #s_(col_data["computed_col"]["default"], None)

 #ef test_get_column_returns_computed(self):
 #nsp = inspect(config.db)

 #ols = insp.get_columns("computed_default_table")
 #ata = {c["name"]: c for c in cols}
 #or key in ("id", "normal", "with_default"):
 #s_true("computed" not in data[key])
 #ompData = data["computed_col"]
 #s_true("computed" in compData)
 #s_true("sqltext" in compData["computed"])
 #q_(self.normalize(compData["computed"]["sqltext"]), "normal+42")
 #q_(
 #persisted" in compData["computed"],
 #esting.requires.computed_columns_reflect_persisted.enabled,
 #
 #f testing.requires.computed_columns_reflect_persisted.enabled:
 #q_(
 #ompData["computed"]["persisted"],
 #esting.requires.computed_columns_default_persisted.enabled,
 #

 #ef check_column(self, data, column, sqltext, persisted):
 #s_true("computed" in data[column])
 #ompData = data[column]["computed"]
 #q_(self.normalize(compData["sqltext"]), sqltext)
 #f testing.requires.computed_columns_reflect_persisted.enabled:
 #s_true("persisted" in compData)
 #s_(compData["persisted"], persisted)

 #ef test_get_column_returns_persisted(self):
 #nsp = inspect(config.db)

 #ols = insp.get_columns("computed_column_table")
 #ata = {c["name"]: c for c in cols}

 #elf.check_column(
 #ata,
 #computed_no_flag",
 #normal+42",
 #esting.requires.computed_columns_default_persisted.enabled,
 #
 #f testing.requires.computed_columns_virtual.enabled:
 #elf.check_column(
 #ata,
 #computed_virtual",
 #normal+2",
 #alse,
 #
 #f testing.requires.computed_columns_stored.enabled:
 #elf.check_column(
 #ata,
 #computed_stored",
 #normal-42",
 #rue,
 #

 #testing.requires.schemas
 #ef test_get_column_returns_persisted_with_schema(self):
 #nsp = inspect(config.db)

 #ols = insp.get_columns(
 #computed_column_table", schema=config.test_schema
 #
 #ata = {c["name"]: c for c in cols}

 #elf.check_column(
 #ata,
 #computed_no_flag",
 #normal/42",
 #esting.requires.computed_columns_default_persisted.enabled,
 #
 #f testing.requires.computed_columns_virtual.enabled:
 #elf.check_column(
 #ata,
 #computed_virtual",
 #normal/2",
 #alse,
 #
 #f testing.requires.computed_columns_stored.enabled:
 #elf.check_column(
 #ata,
 #computed_stored",
 #normal*42",
 #rue,
 #


class IdentityReflectionTest(fixtures.TablesTest):
 #un_inserts = run_deletes = None

 #_backend__ = True
 #_requires__ = ("identity_columns", "table_reflection")

 #classmethod
 #ef define_tables(cls, metadata):
 #able(
 #t1",
 #etadata,
 #olumn("normal", Integer),
 #olumn("id1", Integer, Identity()),
 #
 #able(
 #t2",
 #etadata,
 #olumn(
 #id2",
 #nteger,
 #dentity(
 #lways=True,
 #tart=2,
 #ncrement=3,
 #invalue=-2,
 #axvalue=42,
 #ycle=True,
 #ache=4,
 #,
 #,
 #
 #f testing.requires.schemas.enabled:
 #able(
 #t1",
 #etadata,
 #olumn("normal", Integer),
 #olumn("id1", Integer, Identity(always=True, start=20)),
 #chema=config.test_schema,
 #

 #ef check(self, value, exp, approx):
 #f testing.requires.identity_columns_standard.enabled:
 #ommon_keys = (
 #always",
 #start",
 #increment",
 #minvalue",
 #maxvalue",
 #cycle",
 #cache",
 #
 #or k in list(value):
 #f k not in common_keys:
 #alue.pop(k)
 #f approx:
 #q_(len(value), len(exp))
 #or k in value:
 #f k == "minvalue":
 #s_true(value[k] <= exp[k])
 #lif k in {"maxvalue", "cache"}:
 #s_true(value[k] >= exp[k])
 #lse:
 #q_(value[k], exp[k], k)
 #lse:
 #q_(value, exp)
 #lse:
 #q_(value["start"], exp["start"])
 #q_(value["increment"], exp["increment"])

 #ef test_reflect_identity(self):
 #nsp = inspect(config.db)

 #ols = insp.get_columns("t1") + insp.get_columns("t2")
 #or col in cols:
 #f col["name"] == "normal":
 #s_false("identity" in col)
 #lif col["name"] == "id1":
 #s_true(col["autoincrement"] in (True, "auto"))
 #q_(col["default"], None)
 #s_true("identity" in col)
 #elf.check(
 #ol["identity"],
 #ict(
 #lways=False,
 #tart=1,
 #ncrement=1,
 #invalue=1,
 #axvalue=2147483647,
 #ycle=False,
 #ache=1,
 #,
 #pprox=True,
 #
 #lif col["name"] == "id2":
 #s_true(col["autoincrement"] in (True, "auto"))
 #q_(col["default"], None)
 #s_true("identity" in col)
 #elf.check(
 #ol["identity"],
 #ict(
 #lways=True,
 #tart=2,
 #ncrement=3,
 #invalue=-2,
 #axvalue=42,
 #ycle=True,
 #ache=4,
 #,
 #pprox=False,
 #

 #testing.requires.schemas
 #ef test_reflect_identity_schema(self):
 #nsp = inspect(config.db)

 #ols = insp.get_columns("t1", schema=config.test_schema)
 #or col in cols:
 #f col["name"] == "normal":
 #s_false("identity" in col)
 #lif col["name"] == "id1":
 #s_true(col["autoincrement"] in (True, "auto"))
 #q_(col["default"], None)
 #s_true("identity" in col)
 #elf.check(
 #ol["identity"],
 #ict(
 #lways=True,
 #tart=20,
 #ncrement=1,
 #invalue=1,
 #axvalue=2147483647,
 #ycle=False,
 #ache=1,
 #,
 #pprox=True,
 #


class CompositeKeyReflectionTest(fixtures.TablesTest):
 #_backend__ = True

 #classmethod
 #ef define_tables(cls, metadata):
 #b1 = Table(
 #tb1",
 #etadata,
 #olumn("id", Integer),
 #olumn("attr", Integer),
 #olumn("name", sql_types.VARCHAR(20)),
 #a.PrimaryKeyConstraint("name", "id", "attr", name="pk_tb1"),
 #chema=None,
 #est_needs_fk=True,
 #
 #able(
 #tb2",
 #etadata,
 #olumn("id", Integer, primary_key=True),
 #olumn("pid", Integer),
 #olumn("pattr", Integer),
 #olumn("pname", sql_types.VARCHAR(20)),
 #a.ForeignKeyConstraint(
 #"pname", "pid", "pattr"],
 #tb1.c.name, tb1.c.id, tb1.c.attr],
 #ame="fk_tb1_name_id_attr",
 #,
 #chema=None,
 #est_needs_fk=True,
 #

 #testing.requires.primary_key_constraint_reflection
 #ef test_pk_column_order(self):
        # test for issue #5661
 #nsp = inspect(self.bind)
 #rimary_key = insp.get_pk_constraint(self.tables.tb1.name)
 #q_(primary_key.get("constrained_columns"), ["name", "id", "attr"])

 #testing.requires.foreign_key_constraint_reflection
 #ef test_fk_column_order(self):
        # test for issue #5661
 #nsp = inspect(self.bind)
 #oreign_keys = insp.get_foreign_keys(self.tables.tb2.name)
 #q_(len(foreign_keys), 1)
 #key1 = foreign_keys[0]
 #q_(fkey1.get("referred_columns"), ["name", "id", "attr"])
 #q_(fkey1.get("constrained_columns"), ["pname", "pid", "pattr"])


__all__ = (
 #ComponentReflectionTest",
 #ComponentReflectionTestExtra",
 #QuotedNameArgumentTest",
 #HasTableTest",
 #HasIndexTest",
 #NormalizedNameTest",
 #ComputedReflectionTest",
 #IdentityReflectionTest",
 #CompositeKeyReflectionTest",
)
