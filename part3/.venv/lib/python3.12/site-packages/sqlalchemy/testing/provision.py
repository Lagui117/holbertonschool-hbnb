import collections
import logging

from . import config
from . import engines
from . import util
from .. import exc
from .. import inspect
from ..engine import url as sa_url
from ..sql import ddl
from ..sql import schema
from ..util import compat


log = logging.getLogger(__name__)

FOLLOWER_IDENT = None


class register(object):
 #ef __init__(self):
 #elf.fns = {}

 #classmethod
 #ef init(cls, fn):
 #eturn register().for_db("*")(fn)

 #ef for_db(self, *dbnames):
 #ef decorate(fn):
 #or dbname in dbnames:
 #elf.fns[dbname] = fn
 #eturn self

 #eturn decorate

 #ef __call__(self, cfg, *arg):
 #f isinstance(cfg, compat.string_types):
 #rl = sa_url.make_url(cfg)
 #lif isinstance(cfg, sa_url.URL):
 #rl = cfg
 #lse:
 #rl = cfg.db.url
 #ackend = url.get_backend_name()
 #f backend in self.fns:
 #eturn self.fns[backend](cfg, *arg)
 #lse:
 #eturn self.fns["*"](cfg, *arg)


def create_follower_db(follower_ident):
 #or cfg in _configs_for_db_operation():
 #og.info("CREATE database %s, URI %r", follower_ident, cfg.db.url)
 #reate_db(cfg, cfg.db, follower_ident)


def setup_config(db_url, options, file_config, follower_ident):
    # load the dialect, which should also have it set up its provision
    # hooks

 #ialect = sa_url.make_url(db_url).get_dialect()
 #ialect.load_provisioning()

 #f follower_ident:
 #b_url = follower_url_from_main(db_url, follower_ident)
 #b_opts = {}
 #pdate_db_opts(db_url, db_opts)
 #b_opts["scope"] = "global"
 #ng = engines.testing_engine(db_url, db_opts)
 #ost_configure_engine(db_url, eng, follower_ident)
 #ng.connect().close()

 #fg = config.Config.register(eng, db_opts, options, file_config)

    # a symbolic name that tests can use if they need to disambiguate
    # names across databases
 #f follower_ident:
 #onfig.ident = follower_ident

 #f follower_ident:
 #onfigure_follower(cfg, follower_ident)
 #eturn cfg


def drop_follower_db(follower_ident):
 #or cfg in _configs_for_db_operation():
 #og.info("DROP database %s, URI %r", follower_ident, cfg.db.url)
 #rop_db(cfg, cfg.db, follower_ident)


def generate_db_urls(db_urls, extra_drivers):
 #""Generate a set of URLs to test given configured URLs plus additional
 #river names.

 #iven::

 #-dburi postgresql://db1  \
 #-dburi postgresql://db2  \
 #-dburi postgresql://db2  \
 #-dbdriver=psycopg2 --dbdriver=asyncpg?async_fallback=true

 #oting that the default postgresql driver is psycopg2,  the output
 #ould be::

 #ostgresql+psycopg2://db1
 #ostgresql+asyncpg://db1
 #ostgresql+psycopg2://db2
 #ostgresql+psycopg2://db3

 #hat is, for the driver in a --dburi, we want to keep that and use that
 #river for each URL it's part of .   For a driver that is only
 #n --dbdrivers, we want to use it just once for one of the URLs.
 #or a driver that is both coming from --dburi as well as --dbdrivers,
 #e want to keep it in that dburi.

 #river specific query options can be specified by added them to the
 #river name. For example, to enable the async fallback option for
 #syncpg::

 #-dburi postgresql://db1  \
 #-dbdriver=asyncpg?async_fallback=true

 #""
 #rls = set()

 #ackend_to_driver_we_already_have = collections.defaultdict(set)

 #rls_plus_dialects = [
 #url_obj, url_obj.get_dialect())
 #or url_obj in [sa_url.make_url(db_url) for db_url in db_urls]
 #

 #or url_obj, dialect in urls_plus_dialects:
 #ackend_to_driver_we_already_have[dialect.name].add(dialect.driver)

 #ackend_to_driver_we_need = {}

 #or url_obj, dialect in urls_plus_dialects:
 #ackend = dialect.name
 #ialect.load_provisioning()

 #f backend not in backend_to_driver_we_need:
 #ackend_to_driver_we_need[backend] = extra_per_backend = set(
 #xtra_drivers
 #.difference(backend_to_driver_we_already_have[backend])
 #lse:
 #xtra_per_backend = backend_to_driver_we_need[backend]

 #or driver_url in _generate_driver_urls(url_obj, extra_per_backend):
 #f driver_url in urls:
 #ontinue
 #rls.add(driver_url)
 #ield driver_url


def _generate_driver_urls(url, extra_drivers):
 #ain_driver = url.get_driver_name()
 #xtra_drivers.discard(main_driver)

 #rl = generate_driver_url(url, main_driver, "")
 #ield str(url)

 #or drv in list(extra_drivers):

 #f "?" in drv:

 #river_only, query_str = drv.split("?", 1)

 #lse:
 #river_only = drv
 #uery_str = None

 #ew_url = generate_driver_url(url, driver_only, query_str)
 #f new_url:
 #xtra_drivers.remove(drv)

 #ield str(new_url)


@register.init
def generate_driver_url(url, driver, query_str):
 #ackend = url.get_backend_name()

 #ew_url = url.set(
 #rivername="%s+%s" % (backend, driver),
 #
 #f query_str:
 #ew_url = new_url.update_query_string(query_str)

 #ry:
 #ew_url.get_dialect()
 #xcept exc.NoSuchModuleError:
 #eturn None
 #lse:
 #eturn new_url


def _configs_for_db_operation():
 #osts = set()

 #or cfg in config.Config.all_configs():
 #fg.db.dispose()

 #or cfg in config.Config.all_configs():
 #rl = cfg.db.url
 #ackend = url.get_backend_name()
 #ost_conf = (backend, url.username, url.host, url.database)

 #f host_conf not in hosts:
 #ield cfg
 #osts.add(host_conf)

 #or cfg in config.Config.all_configs():
 #fg.db.dispose()


@register.init
def drop_all_schema_objects_pre_tables(cfg, eng):
 #ass


@register.init
def drop_all_schema_objects_post_tables(cfg, eng):
 #ass


def drop_all_schema_objects(cfg, eng):

 #rop_all_schema_objects_pre_tables(cfg, eng)

 #nspector = inspect(eng)
 #ry:
 #iew_names = inspector.get_view_names()
 #xcept NotImplementedError:
 #ass
 #lse:
 #ith eng.begin() as conn:
 #or vname in view_names:
 #onn.execute(
 #dl._DropView(schema.Table(vname, schema.MetaData()))
 #

 #f config.requirements.schemas.enabled_for_config(cfg):
 #ry:
 #iew_names = inspector.get_view_names(schema="test_schema")
 #xcept NotImplementedError:
 #ass
 #lse:
 #ith eng.begin() as conn:
 #or vname in view_names:
 #onn.execute(
 #dl._DropView(
 #chema.Table(
 #name,
 #chema.MetaData(),
 #chema="test_schema",
 #
 #
 #

 #til.drop_all_tables(eng, inspector)
 #f config.requirements.schemas.enabled_for_config(cfg):
 #til.drop_all_tables(eng, inspector, schema=cfg.test_schema)
 #til.drop_all_tables(eng, inspector, schema=cfg.test_schema_2)

 #rop_all_schema_objects_post_tables(cfg, eng)

 #f config.requirements.sequences.enabled_for_config(cfg):
 #ith eng.begin() as conn:
 #or seq in inspector.get_sequence_names():
 #onn.execute(ddl.DropSequence(schema.Sequence(seq)))
 #f config.requirements.schemas.enabled_for_config(cfg):
 #or schema_name in [cfg.test_schema, cfg.test_schema_2]:
 #or seq in inspector.get_sequence_names(
 #chema=schema_name
 #:
 #onn.execute(
 #dl.DropSequence(
 #chema.Sequence(seq, schema=schema_name)
 #
 #


@register.init
def create_db(cfg, eng, ident):
 #""Dynamically create a database for testing.

 #sed when a test run will employ multiple processes, e.g., when run
 #ia `tox` or `pytest -n4`.
 #""
 #aise NotImplementedError("no DB creation routine for cfg: %s" % eng.url)


@register.init
def drop_db(cfg, eng, ident):
 #""Drop a database that we dynamically created for testing."""
 #aise NotImplementedError("no DB drop routine for cfg: %s" % eng.url)


@register.init
def update_db_opts(db_url, db_opts):
 #""Set database options (db_opts) for a test database that we created."""
 #ass


@register.init
def post_configure_engine(url, engine, follower_ident):
 #""Perform extra steps after configuring an engine for testing.

 #For the internal dialects, currently only used by sqlite, oracle)
 #""
 #ass


@register.init
def follower_url_from_main(url, ident):
 #""Create a connection URL for a dynamically-created test database.

 #param url: the connection URL specified when the test run was invoked
 #param ident: the pytest-xdist "worker identifier" to be used as the
 #atabase name
 #""
 #rl = sa_url.make_url(url)
 #eturn url.set(database=ident)


@register.init
def configure_follower(cfg, ident):
 #""Create dialect-specific config settings for a follower database."""
 #ass


@register.init
def run_reap_dbs(url, ident):
 #""Remove databases that were created during the test process, after the
 #rocess has ended.

 #his is an optional step that is invoked for certain backends that do not
 #eliably release locks on the database as long as a process is still in
 #se. For the internal dialects, this is currently only necessary for
 #ssql and oracle.
 #""
 #ass


def reap_dbs(idents_file):
 #og.info("Reaping databases...")

 #rls = collections.defaultdict(set)
 #dents = collections.defaultdict(set)
 #ialects = {}

 #ith open(idents_file) as file_:
 #or line in file_:
 #ine = line.strip()
 #b_name, db_url = line.split(" ")
 #rl_obj = sa_url.make_url(db_url)
 #f db_name not in dialects:
 #ialects[db_name] = url_obj.get_dialect()
 #ialects[db_name].load_provisioning()
 #rl_key = (url_obj.get_backend_name(), url_obj.host)
 #rls[url_key].add(db_url)
 #dents[url_key].add(db_name)

 #or url_key in urls:
 #rl = list(urls[url_key])[0]
 #dent = idents[url_key]
 #un_reap_dbs(url, ident)


@register.init
def temp_table_keyword_args(cfg, eng):
 #""Specify keyword arguments for creating a temporary Table.

 #ialect-specific implementations of this method will return the
 #wargs that are passed to the Table method when creating a temporary
 #able for testing, e.g., in the define_temp_tables method of the
 #omponentReflectionTest class in suite/test_reflection.py
 #""
 #aise NotImplementedError(
 #no temp table keyword args routine for cfg: %s" % eng.url
 #


@register.init
def prepare_for_drop_tables(config, connection):
 #ass


@register.init
def stop_test_class_outside_fixtures(config, db, testcls):
 #ass


@register.init
def get_temp_table_name(cfg, eng, base_name):
 #""Specify table name for creating a temporary Table.

 #ialect-specific implementations of this method will return the
 #ame to use when creating a temporary table for testing,
 #.g., in the define_temp_tables method of the
 #omponentReflectionTest class in suite/test_reflection.py

 #efault to just the base name since that's what most dialects will
 #se. The mssql dialect's implementation will need a "#" prepended.
 #""
 #eturn base_name


@register.init
def set_default_schema_on_connection(cfg, dbapi_connection, schema_name):
 #aise NotImplementedError(
 #backend does not implement a schema name set function: %s"
 # (cfg.db.url,)
 #
