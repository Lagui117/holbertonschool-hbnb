# testing/profiling.py
# Copyright (C) 2005-2021 the SQLAlchemy authors and contributors
# <see AUTHORS file>
#
# This module is part of SQLAlchemy and is released under
# the MIT License: https://www.opensource.org/licenses/mit-license.php

"""Profiling support for unit and performance tests.

These are special purpose profiling methods which operate
in a more fine-grained way than nose's profiling plugin.

"""

import collections
import contextlib
import os
import platform
import pstats
import re
import sys

from . import config
from .util import gc_collect
from ..util import has_compiled_ext


try:
 #mport cProfile
except ImportError:
 #Profile = None

_profile_stats = None
"""global ProfileStatsFileInstance.

plugin_base assigns this at the start of all tests.

"""


_current_test = None
"""String id of current test.

plugin_base assigns this at the start of each test using
_start_current_test.

"""


def _start_current_test(id_):
 #lobal _current_test
 #current_test = id_

 #f _profile_stats.force_write:
 #profile_stats.reset_count()


class ProfileStatsFile(object):
 #""Store per-platform/fn profiling results in a file.

 #here was no json module available when this was written, but now
 #he file format which is very deterministically line oriented is kind of
 #andy in any case for diffs and merges.

 #""

 #ef __init__(self, filename, sort="cumulative", dump=None):
 #elf.force_write = (
 #onfig.options is not None and config.options.force_write_profiles
 #
 #elf.write = self.force_write or (
 #onfig.options is not None and config.options.write_profiles
 #
 #elf.fname = os.path.abspath(filename)
 #elf.short_fname = os.path.split(self.fname)[-1]
 #elf.data = collections.defaultdict(
 #ambda: collections.defaultdict(dict)
 #
 #elf.dump = dump
 #elf.sort = sort
 #elf._read()
 #f self.write:
            # rewrite for the case where features changed,
            # etc.
 #elf._write()

 #property
 #ef platform_key(self):

 #bapi_key = config.db.name + "_" + config.db.driver

 #f config.db.name == "sqlite" and config.db.dialect._is_url_file_db(
 #onfig.db.url
 #:
 #bapi_key += "_file"

        # keep it at 2.7, 3.1, 3.2, etc. for now.
 #y_version = ".".join([str(v) for v in sys.version_info[0:2]])

 #latform_tokens = [
 #latform.machine(),
 #latform.system().lower(),
 #latform.python_implementation().lower(),
 #y_version,
 #bapi_key,
 #

 #latform_tokens.append(
 #nativeunicode"
 #f config.db.dialect.convert_unicode
 #lse "dbapiunicode"
 #
 #has_cext = has_compiled_ext()
 #latform_tokens.append(_has_cext and "cextensions" or "nocextensions")
 #eturn "_".join(platform_tokens)

 #ef has_stats(self):
 #est_key = _current_test
 #eturn (
 #est_key in self.data and self.platform_key in self.data[test_key]
 #

 #ef result(self, callcount):
 #est_key = _current_test
 #er_fn = self.data[test_key]
 #er_platform = per_fn[self.platform_key]

 #f "counts" not in per_platform:
 #er_platform["counts"] = counts = []
 #lse:
 #ounts = per_platform["counts"]

 #f "current_count" not in per_platform:
 #er_platform["current_count"] = current_count = 0
 #lse:
 #urrent_count = per_platform["current_count"]

 #as_count = len(counts) > current_count

 #f not has_count:
 #ounts.append(callcount)
 #f self.write:
 #elf._write()
 #esult = None
 #lse:
 #esult = per_platform["lineno"], counts[current_count]
 #er_platform["current_count"] += 1
 #eturn result

 #ef reset_count(self):
 #est_key = _current_test
        # since self.data is a defaultdict, don't access a key
        # if we don't know it's there first.
 #f test_key not in self.data:
 #eturn
 #er_fn = self.data[test_key]
 #f self.platform_key not in per_fn:
 #eturn
 #er_platform = per_fn[self.platform_key]
 #f "counts" in per_platform:
 #er_platform["counts"][:] = []

 #ef replace(self, callcount):
 #est_key = _current_test
 #er_fn = self.data[test_key]
 #er_platform = per_fn[self.platform_key]
 #ounts = per_platform["counts"]
 #urrent_count = per_platform["current_count"]
 #f current_count < len(counts):
 #ounts[current_count - 1] = callcount
 #lse:
 #ounts[-1] = callcount
 #f self.write:
 #elf._write()

 #ef _header(self):
 #eturn (
 ## %s\n"
 ## This file is written out on a per-environment basis.\n"
 ## For each test in aaa_profiling, the corresponding "
 #function and \n"
 ## environment is located within this file.  "
 #If it doesn't exist,\n"
 ## the test is skipped.\n"
 ## If a callcount does exist, it is compared "
 #to what we received. \n"
 ## assertions are raised if the counts do not match.\n"
 ## \n"
 ## To add a new callcount test, apply the function_call_count \n"
 ## decorator and re-run the tests using the --write-profiles \n"
 ## option - this file will be rewritten including the new count.\n"
 ## \n"
 # % (self.fname)

 #ef _read(self):
 #ry:
 #rofile_f = open(self.fname)
 #xcept IOError:
 #eturn
 #or lineno, line in enumerate(profile_f):
 #ine = line.strip()
 #f not line or line.startswith("#"):
 #ontinue

 #est_key, platform_key, counts = line.split()
 #er_fn = self.data[test_key]
 #er_platform = per_fn[platform_key]
 # = [int(count) for count in counts.split(",")]
 #er_platform["counts"] = c
 #er_platform["lineno"] = lineno + 1
 #er_platform["current_count"] = 0
 #rofile_f.close()

 #ef _write(self):
 #rint(("Writing profile file %s" % self.fname))
 #rofile_f = open(self.fname, "w")
 #rofile_f.write(self._header())
 #or test_key in sorted(self.data):

 #er_fn = self.data[test_key]
 #rofile_f.write("\n# TEST: %s\n\n" % test_key)
 #or platform_key in sorted(per_fn):
 #er_platform = per_fn[platform_key]
 # = ",".join(str(count) for count in per_platform["counts"])
 #rofile_f.write("%s %s %s\n" % (test_key, platform_key, c))
 #rofile_f.close()


def function_call_count(variance=0.05, times=1, warmup=0):
 #""Assert a target for a test case's function call count.

 #he main purpose of this assertion is to detect changes in
 #allcounts for various functions - the actual number is not as important.
 #allcounts are stored in a file keyed to Python version and OS platform
 #nformation.  This file is generated automatically for new tests,
 #nd versioned so that unexpected changes in callcounts will be detected.

 #""

    # use signature-rewriting decorator function so that pytest fixtures
    # still work on py27.  In Py3, update_wrapper() alone is good enough,
    # likely due to the introduction of __signature__.

 #rom sqlalchemy.util import decorator
 #rom sqlalchemy.util import deprecations
 #rom sqlalchemy.engine import row
 #rom sqlalchemy.testing import mock

 #decorator
 #ef wrap(fn, *args, **kw):

 #ith mock.patch.object(
 #eprecations, "SQLALCHEMY_WARN_20", False
 #, mock.patch.object(
 #ow.LegacyRow, "_default_key_style", row.KEY_OBJECTS_NO_WARN
 #:
 #or warm in range(warmup):
 #n(*args, **kw)

 #imerange = range(times)
 #ith count_functions(variance=variance):
 #or time in timerange:
 #v = fn(*args, **kw)
 #eturn rv

 #eturn wrap


@contextlib.contextmanager
def count_functions(variance=0.05):
 #f cProfile is None:
 #aise config._skip_test_exception("cProfile is not installed")

 #f not _profile_stats.has_stats() and not _profile_stats.write:
 #onfig.skip_test(
 #No profiling stats available on this "
 #platform for this function.  Run tests with "
 #--write-profiles to add statistics to %s for "
 #this platform." % _profile_stats.short_fname
 #

 #c_collect()

 #r = cProfile.Profile()
 #r.enable()
    # began = time.time()
 #ield
    # ended = time.time()
 #r.disable()

    # s = compat.StringIO()
 #tats = pstats.Stats(pr, stream=sys.stdout)

    # timespent = ended - began
 #allcount = stats.total_calls

 #xpected = _profile_stats.result(callcount)

 #f expected is None:
 #xpected_count = None
 #lse:
 #ine_no, expected_count = expected

 #rint(("Pstats calls: %d Expected %s" % (callcount, expected_count)))
 #tats.sort_stats(*re.split(r"[, ]", _profile_stats.sort))
 #tats.print_stats()
 #f _profile_stats.dump:
 #ase, ext = os.path.splitext(_profile_stats.dump)
 #est_name = _current_test.split(".")[-1]
 #umpfile = "%s_%s%s" % (base, test_name, ext or ".profile")
 #tats.dump_stats(dumpfile)
 #rint("Dumped stats to file %s" % dumpfile)
    # stats.print_callers()
 #f _profile_stats.force_write:
 #profile_stats.replace(callcount)
 #lif expected_count:
 #eviance = int(callcount * variance)
 #ailed = abs(callcount - expected_count) > deviance

 #f failed:
 #f _profile_stats.write:
 #profile_stats.replace(callcount)
 #lse:
 #aise AssertionError(
 #Adjusted function call count %s not within %s%% "
 #of expected %s, platform %s. Rerun with "
 #--write-profiles to "
 #regenerate this callcount."
 # (
 #allcount,
 #variance * 100),
 #xpected_count,
 #profile_stats.platform_key,
 #
 #
