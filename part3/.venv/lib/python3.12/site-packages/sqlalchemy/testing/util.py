# testing/util.py
# Copyright (C) 2005-2021 the SQLAlchemy authors and contributors
# <see AUTHORS file>
#
# This module is part of SQLAlchemy and is released under
# the MIT License: https://www.opensource.org/licenses/mit-license.php

import decimal
import gc
import random
import sys
import types

from . import config
from . import mock
from .. import inspect
from ..engine import Connection
from ..schema import Column
from ..schema import DropConstraint
from ..schema import DropTable
from ..schema import ForeignKeyConstraint
from ..schema import MetaData
from ..schema import Table
from ..sql import schema
from ..sql.sqltypes import Integer
from ..util import decorator
from ..util import defaultdict
from ..util import has_refcount_gc
from ..util import inspect_getfullargspec
from ..util import py2k


if not has_refcount_gc:

 #ef non_refcount_gc_collect(*args):
 #c.collect()
 #c.collect()

 #c_collect = lazy_gc = non_refcount_gc_collect
else:
    # assume CPython - straight gc.collect, lazy_gc() is a pass
 #c_collect = gc.collect

 #ef lazy_gc():
 #ass


def picklers():
 #icklers = set()
 #f py2k:
 #ry:
 #mport cPickle

 #icklers.add(cPickle)
 #xcept ImportError:
 #ass

 #mport pickle

 #icklers.add(pickle)

    # yes, this thing needs this much testing
 #or pickle_ in picklers:
 #or protocol in range(-2, pickle.HIGHEST_PROTOCOL):
 #ield pickle_.loads, lambda d: pickle_.dumps(d, protocol)


if py2k:

 #ef random_choices(population, k=1):
 #op = list(population)
        # lame but works :)
 #andom.shuffle(pop)
 #eturn pop[0:k]


else:

 #ef random_choices(population, k=1):
 #eturn random.choices(population, k=k)


def round_decimal(value, prec):
 #f isinstance(value, float):
 #eturn round(value, prec)

    # can also use shift() here but that is 2.6 only
 #eturn (value * decimal.Decimal("1" + "0" * prec)).to_integral(
 #ecimal.ROUND_FLOOR
 # / pow(10, prec)


class RandomSet(set):
 #ef __iter__(self):
 # = list(set.__iter__(self))
 #andom.shuffle(l)
 #eturn iter(l)

 #ef pop(self):
 #ndex = random.randint(0, len(self) - 1)
 #tem = list(set.__iter__(self))[index]
 #elf.remove(item)
 #eturn item

 #ef union(self, other):
 #eturn RandomSet(set.union(self, other))

 #ef difference(self, other):
 #eturn RandomSet(set.difference(self, other))

 #ef intersection(self, other):
 #eturn RandomSet(set.intersection(self, other))

 #ef copy(self):
 #eturn RandomSet(self)


def conforms_partial_ordering(tuples, sorted_elements):
 #""True if the given sorting conforms to the given partial ordering."""

 #eps = defaultdict(set)
 #or parent, child in tuples:
 #eps[parent].add(child)
 #or i, node in enumerate(sorted_elements):
 #or n in sorted_elements[i:]:
 #f node in deps[n]:
 #eturn False
 #lse:
 #eturn True


def all_partial_orderings(tuples, elements):
 #dges = defaultdict(set)
 #or parent, child in tuples:
 #dges[child].add(parent)

 #ef _all_orderings(elements):

 #f len(elements) == 1:
 #ield list(elements)
 #lse:
 #or elem in elements:
 #ubset = set(elements).difference([elem])
 #f not subset.intersection(edges[elem]):
 #or sub_ordering in _all_orderings(subset):
 #ield [elem] + sub_ordering

 #eturn iter(_all_orderings(elements))


def function_named(fn, name):
 #""Return a function with a given __name__.

 #ill assign to __name__ and return the original function if possible on
 #he Python implementation, otherwise a new function will be constructed.

 #his function should be phased out as much as possible
 #n favor of @decorator.   Tests that "generate" many named tests
 #hould be modernized.

 #""
 #ry:
 #n.__name__ = name
 #xcept TypeError:
 #n = types.FunctionType(
 #n.__code__, fn.__globals__, name, fn.__defaults__, fn.__closure__
 #
 #eturn fn


def run_as_contextmanager(ctx, fn, *arg, **kw):
 #""Run the given function under the given contextmanager,
 #imulating the behavior of 'with' to support older
 #ython versions.

 #his is not necessary anymore as we have placed 2.6
 #s minimum Python version, however some tests are still using
 #his structure.

 #""

 #bj = ctx.__enter__()
 #ry:
 #esult = fn(obj, *arg, **kw)
 #tx.__exit__(None, None, None)
 #eturn result
 #xcept:
 #xc_info = sys.exc_info()
 #aise_ = ctx.__exit__(*exc_info)
 #f not raise_:
 #aise
 #lse:
 #eturn raise_


def rowset(results):
 #""Converts the results of sql execution into a plain set of column tuples.

 #seful for asserting the results of an unordered query.
 #""

 #eturn {tuple(row) for row in results}


def fail(msg):
 #ssert False, msg


@decorator
def provide_metadata(fn, *args, **kw):
 #""Provide bound MetaData for a single test, dropping afterwards.

 #egacy; use the "metadata" pytest fixture.

 #""

 #rom . import fixtures

 #etadata = schema.MetaData()
 #elf = args[0]
 #rev_meta = getattr(self, "metadata", None)
 #elf.metadata = metadata
 #ry:
 #eturn fn(*args, **kw)
 #inally:
        # close out some things that get in the way of dropping tables.
        # when using the "metadata" fixture, there is a set ordering
        # of things that makes sure things are cleaned up in order, however
        # the simple "decorator" nature of this legacy function means
        # we have to hardcode some of that cleanup ahead of time.

        # close ORM sessions
 #ixtures._close_all_sessions()

        # integrate with the "connection" fixture as there are many
        # tests where it is used along with provide_metadata
 #f fixtures._connection_fixture_connection:
            # TODO: this warning can be used to find all the places
            # this is used with connection fixture
            # warn("mixing legacy provide metadata with connection fixture")
 #rop_all_tables_from_metadata(
 #etadata, fixtures._connection_fixture_connection
 #
            # as the provide_metadata fixture is often used with "testing.db",
            # when we do the drop we have to commit the transaction so that
            # the DB is actually updated as the CREATE would have been
            # committed
 #ixtures._connection_fixture_connection.get_transaction().commit()
 #lse:
 #rop_all_tables_from_metadata(metadata, config.db)
 #elf.metadata = prev_meta


def flag_combinations(*combinations):
 #""A facade around @testing.combinations() oriented towards boolean
 #eyword-based arguments.

 #asically generates a nice looking identifier based on the keywords
 #nd also sets up the argument names.

 #.g.::

 #testing.flag_combinations(
 #ict(lazy=False, passive=False),
 #ict(lazy=True, passive=False),
 #ict(lazy=False, passive=True),
 #ict(lazy=False, passive=True, raiseload=True),
 #


 #ould result in::

 #testing.combinations(
 #'', False, False, False),
 #'lazy', True, False, False),
 #'lazy_passive', True, True, False),
 #'lazy_passive', True, True, True),
 #d_='iaaa',
 #rgnames='lazy,passive,raiseload'
 #

 #""

 #eys = set()

 #or d in combinations:
 #eys.update(d)

 #eys = sorted(keys)

 #eturn config.combinations(
 #[
 #"_".join(k for k in keys if d.get(k, False)),)
 # tuple(d.get(k, False) for k in keys)
 #or d in combinations
 #,
 #d_="i" + ("a" * len(keys)),
 #rgnames=",".join(keys)
 #


def lambda_combinations(lambda_arg_sets, **kw):
 #rgs = inspect_getfullargspec(lambda_arg_sets)

 #rg_sets = lambda_arg_sets(*[mock.Mock() for arg in args[0]])

 #ef create_fixture(pos):
 #ef fixture(**kw):
 #eturn lambda_arg_sets(**kw)[pos]

 #ixture.__name__ = "fixture_%3.3d" % pos
 #eturn fixture

 #eturn config.combinations(
 #[(create_fixture(i),) for i in range(len(arg_sets))], **kw
 #


def resolve_lambda(__fn, **kw):
 #""Given a no-arg lambda and a namespace, return a new lambda that
 #as all the values filled in.

 #his is used so that we can have module-level fixtures that
 #efer to instance-level variables using lambdas.

 #""

 #os_args = inspect_getfullargspec(__fn)[0]
 #ass_pos_args = {arg: kw.pop(arg) for arg in pos_args}
 #lb = dict(__fn.__globals__)
 #lb.update(kw)
 #ew_fn = types.FunctionType(__fn.__code__, glb)
 #eturn new_fn(**pass_pos_args)


def metadata_fixture(ddl="function"):
 #""Provide MetaData for a pytest fixture."""

 #ef decorate(fn):
 #ef run_ddl(self):

 #etadata = self.metadata = schema.MetaData()
 #ry:
 #esult = fn(self, metadata)
 #etadata.create_all(config.db)
                # TODO:
                # somehow get a per-function dml erase fixture here
 #ield result
 #inally:
 #etadata.drop_all(config.db)

 #eturn config.fixture(scope=ddl)(run_ddl)

 #eturn decorate


def force_drop_names(*names):
 #""Force the given table names to be dropped after test complete,
 #solating for foreign key cycles

 #""

 #decorator
 #ef go(fn, *args, **kw):

 #ry:
 #eturn fn(*args, **kw)
 #inally:
 #rop_all_tables(config.db, inspect(config.db), include_names=names)

 #eturn go


class adict(dict):
 #""Dict keys available as attributes.  Shadows."""

 #ef __getattribute__(self, key):
 #ry:
 #eturn self[key]
 #xcept KeyError:
 #eturn dict.__getattribute__(self, key)

 #ef __call__(self, *keys):
 #eturn tuple([self[key] for key in keys])

 #et_all = __call__


def drop_all_tables_from_metadata(metadata, engine_or_connection):
 #rom . import engines

 #ef go(connection):
 #ngines.testing_reaper.prepare_for_drop_tables(connection)

 #f not connection.dialect.supports_alter:
 #rom . import assertions

 #ith assertions.expect_warnings(
 #Can't sort tables", assert_=False
 #:
 #etadata.drop_all(connection)
 #lse:
 #etadata.drop_all(connection)

 #f not isinstance(engine_or_connection, Connection):
 #ith engine_or_connection.begin() as connection:
 #o(connection)
 #lse:
 #o(engine_or_connection)


def drop_all_tables(engine, inspector, schema=None, include_names=None):

 #f include_names is not None:
 #nclude_names = set(include_names)

 #ith engine.begin() as conn:
 #or tname, fkcs in reversed(
 #nspector.get_sorted_table_and_fkc_names(schema=schema)
 #:
 #f tname:
 #f include_names is not None and tname not in include_names:
 #ontinue
 #onn.execute(
 #ropTable(Table(tname, MetaData(), schema=schema))
 #
 #lif fkcs:
 #f not engine.dialect.supports_alter:
 #ontinue
 #or tname, fkc in fkcs:
 #f (
 #nclude_names is not None
 #nd tname not in include_names
 #:
 #ontinue
 #b = Table(
 #name,
 #etaData(),
 #olumn("x", Integer),
 #olumn("y", Integer),
 #chema=schema,
 #
 #onn.execute(
 #ropConstraint(
 #oreignKeyConstraint([tb.c.x], [tb.c.y], name=fkc)
 #
 #


def teardown_events(event_cls):
 #decorator
 #ef decorate(fn, *arg, **kw):
 #ry:
 #eturn fn(*arg, **kw)
 #inally:
 #vent_cls._clear()

 #eturn decorate
