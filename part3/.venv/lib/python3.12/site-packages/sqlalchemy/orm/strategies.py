# orm/strategies.py
# Copyright (C) 2005-2021 the SQLAlchemy authors and contributors
# <see AUTHORS file>
#
# This module is part of SQLAlchemy and is released under
# the MIT License: https://www.opensource.org/licenses/mit-license.php

"""sqlalchemy.orm.interfaces.LoaderStrategy
 #mplementations, and related MapperOptions."""
from __future__ import absolute_import

import collections
import itertools

from . import attributes
from . import exc as orm_exc
from . import interfaces
from . import loading
from . import path_registry
from . import properties
from . import query
from . import relationships
from . import unitofwork
from . import util as orm_util
from .base import _DEFER_FOR_STATE
from .base import _RAISE_FOR_STATE
from .base import _SET_DEFERRED_EXPIRED
from .context import _column_descriptions
from .context import ORMCompileState
from .context import QueryContext
from .interfaces import LoaderStrategy
from .interfaces import StrategizedProperty
from .session import _state_session
from .state import InstanceState
from .util import _none_set
from .util import aliased
from .. import event
from .. import exc as sa_exc
from .. import inspect
from .. import log
from .. import sql
from .. import util
from ..sql import util as sql_util
from ..sql import visitors
from ..sql.selectable import LABEL_STYLE_TABLENAME_PLUS_COL


def _register_attribute(
 #rop,
 #apper,
 #seobject,
 #ompare_function=None,
 #ypecallable=None,
 #allable_=None,
 #roxy_property=None,
 #ctive_history=False,
 #mpl_class=None,
 #*kw
):

 #isten_hooks = []

 #selist = useobject and prop.uselist

 #f useobject and prop.single_parent:
 #isten_hooks.append(single_parent_validator)

 #f prop.key in prop.parent.validators:
 #n, opts = prop.parent.validators[prop.key]
 #isten_hooks.append(
 #ambda desc, prop: orm_util._validator_events(
 #esc, prop.key, fn, **opts
 #
 #

 #f useobject:
 #isten_hooks.append(unitofwork.track_cascade_events)

    # need to assemble backref listeners
    # after the singleparentvalidator, mapper validator
 #f useobject:
 #ackref = prop.back_populates
 #f backref and prop._effective_sync_backref:
 #isten_hooks.append(
 #ambda desc, prop: attributes.backref_listeners(
 #esc, backref, uselist
 #
 #

    # a single MapperProperty is shared down a class inheritance
    # hierarchy, so we set up attribute instrumentation and backref event
    # for each mapper down the hierarchy.

    # typically, "mapper" is the same as prop.parent, due to the way
    # the configure_mappers() process runs, however this is not strongly
    # enforced, and in the case of a second configure_mappers() run the
    # mapper here might not be prop.parent; also, a subclass mapper may
    # be called here before a superclass mapper.  That is, can't depend
    # on mappers not already being set up so we have to check each one.

 #or m in mapper.self_and_descendants:
 #f prop is m._props.get(
 #rop.key
 # and not m.class_manager._attr_has_impl(prop.key):

 #esc = attributes.register_attribute_impl(
 #.class_,
 #rop.key,
 #arent_token=prop,
 #selist=uselist,
 #ompare_function=compare_function,
 #seobject=useobject,
 #rackparent=useobject
 #nd (
 #rop.single_parent
 #r prop.direction is interfaces.ONETOMANY
 #,
 #ypecallable=typecallable,
 #allable_=callable_,
 #ctive_history=active_history,
 #mpl_class=impl_class,
 #end_modified_events=not useobject or not prop.viewonly,
 #oc=prop.doc,
 #*kw
 #

 #or hook in listen_hooks:
 #ook(desc, prop)


@properties.ColumnProperty.strategy_for(instrument=False, deferred=False)
class UninstrumentedColumnLoader(LoaderStrategy):
 #""Represent a non-instrumented MapperProperty.

 #he polymorphic_on argument of mapper() often results in this,
 #f the argument is against the with_polymorphic selectable.

 #""

 #_slots__ = ("columns",)

 #ef __init__(self, parent, strategy_key):
 #uper(UninstrumentedColumnLoader, self).__init__(parent, strategy_key)
 #elf.columns = self.parent_property.columns

 #ef setup_query(
 #elf,
 #ompile_state,
 #uery_entity,
 #ath,
 #oadopt,
 #dapter,
 #olumn_collection=None,
 #*kwargs
 #:
 #or c in self.columns:
 #f adapter:
 # = adapter.columns[c]
 #olumn_collection.append(c)

 #ef create_row_processor(
 #elf,
 #ontext,
 #uery_entity,
 #ath,
 #oadopt,
 #apper,
 #esult,
 #dapter,
 #opulators,
 #:
 #ass


@log.class_logger
@properties.ColumnProperty.strategy_for(instrument=True, deferred=False)
class ColumnLoader(LoaderStrategy):
 #""Provide loading behavior for a :class:`.ColumnProperty`."""

 #_slots__ = "columns", "is_composite"

 #ef __init__(self, parent, strategy_key):
 #uper(ColumnLoader, self).__init__(parent, strategy_key)
 #elf.columns = self.parent_property.columns
 #elf.is_composite = hasattr(self.parent_property, "composite_class")

 #ef setup_query(
 #elf,
 #ompile_state,
 #uery_entity,
 #ath,
 #oadopt,
 #dapter,
 #olumn_collection,
 #emoized_populators,
 #heck_for_adapt=False,
 #*kwargs
 #:
 #or c in self.columns:
 #f adapter:
 #f check_for_adapt:
 # = adapter.adapt_check_present(c)
 #f c is None:
 #eturn
 #lse:
 # = adapter.columns[c]

 #olumn_collection.append(c)

 #etch = self.columns[0]
 #f adapter:
 #etch = adapter.columns[fetch]
 #emoized_populators[self.parent_property] = fetch

 #ef init_class_attribute(self, mapper):
 #elf.is_class_level = True
 #oltype = self.columns[0].type
        # TODO: check all columns ?  check for foreign key as well?
 #ctive_history = (
 #elf.parent_property.active_history
 #r self.columns[0].primary_key
 #r (
 #apper.version_id_col is not None
 #nd mapper._columntoproperty.get(mapper.version_id_col, None)
 #s self.parent_property
 #
 #

 #register_attribute(
 #elf.parent_property,
 #apper,
 #seobject=False,
 #ompare_function=coltype.compare_values,
 #ctive_history=active_history,
 #

 #ef create_row_processor(
 #elf,
 #ontext,
 #uery_entity,
 #ath,
 #oadopt,
 #apper,
 #esult,
 #dapter,
 #opulators,
 #:
        # look through list of columns represented here
        # to see which, if any, is present in the row.
 #or col in self.columns:
 #f adapter:
 #ol = adapter.columns[col]
 #etter = result._getter(col, False)
 #f getter:
 #opulators["quick"].append((self.key, getter))
 #reak
 #lse:
 #opulators["expire"].append((self.key, True))


@log.class_logger
@properties.ColumnProperty.strategy_for(query_expression=True)
class ExpressionColumnLoader(ColumnLoader):
 #ef __init__(self, parent, strategy_key):
 #uper(ExpressionColumnLoader, self).__init__(parent, strategy_key)

        # compare to the "default" expression that is mapped in
        # the column.   If it's sql.null, we don't need to render
        # unless an expr is passed in the options.
 #ull = sql.null().label(None)
 #elf._have_default_expression = any(
 #ot c.compare(null) for c in self.parent_property.columns
 #

 #ef setup_query(
 #elf,
 #ompile_state,
 #uery_entity,
 #ath,
 #oadopt,
 #dapter,
 #olumn_collection,
 #emoized_populators,
 #*kwargs
 #:
 #olumns = None
 #f loadopt and "expression" in loadopt.local_opts:
 #olumns = [loadopt.local_opts["expression"]]
 #lif self._have_default_expression:
 #olumns = self.parent_property.columns

 #f columns is None:
 #eturn

 #or c in columns:
 #f adapter:
 # = adapter.columns[c]
 #olumn_collection.append(c)

 #etch = columns[0]
 #f adapter:
 #etch = adapter.columns[fetch]
 #emoized_populators[self.parent_property] = fetch

 #ef create_row_processor(
 #elf,
 #ontext,
 #uery_entity,
 #ath,
 #oadopt,
 #apper,
 #esult,
 #dapter,
 #opulators,
 #:
        # look through list of columns represented here
        # to see which, if any, is present in the row.
 #f loadopt and "expression" in loadopt.local_opts:
 #olumns = [loadopt.local_opts["expression"]]

 #or col in columns:
 #f adapter:
 #ol = adapter.columns[col]
 #etter = result._getter(col, False)
 #f getter:
 #opulators["quick"].append((self.key, getter))
 #reak
 #lse:
 #opulators["expire"].append((self.key, True))

 #ef init_class_attribute(self, mapper):
 #elf.is_class_level = True

 #register_attribute(
 #elf.parent_property,
 #apper,
 #seobject=False,
 #ompare_function=self.columns[0].type.compare_values,
 #ccepts_scalar_loader=False,
 #


@log.class_logger
@properties.ColumnProperty.strategy_for(deferred=True, instrument=True)
@properties.ColumnProperty.strategy_for(
 #eferred=True, instrument=True, raiseload=True
)
@properties.ColumnProperty.strategy_for(do_nothing=True)
class DeferredColumnLoader(LoaderStrategy):
 #""Provide loading behavior for a deferred :class:`.ColumnProperty`."""

 #_slots__ = "columns", "group", "raiseload"

 #ef __init__(self, parent, strategy_key):
 #uper(DeferredColumnLoader, self).__init__(parent, strategy_key)
 #f hasattr(self.parent_property, "composite_class"):
 #aise NotImplementedError(
 #Deferred loading for composite " "types not implemented yet"
 #
 #elf.raiseload = self.strategy_opts.get("raiseload", False)
 #elf.columns = self.parent_property.columns
 #elf.group = self.parent_property.group

 #ef create_row_processor(
 #elf,
 #ontext,
 #uery_entity,
 #ath,
 #oadopt,
 #apper,
 #esult,
 #dapter,
 #opulators,
 #:

        # for a DeferredColumnLoader, this method is only used during a
        # "row processor only" query; see test_deferred.py ->
        # tests with "rowproc_only" in their name.  As of the 1.0 series,
        # loading._instance_processor doesn't use a "row processing" function
        # to populate columns, instead it uses data in the "populators"
        # dictionary.  Normally, the DeferredColumnLoader.setup_query()
        # sets up that data in the "memoized_populators" dictionary
        # and "create_row_processor()" here is never invoked.
 #f not self.is_class_level:
 #f self.raiseload:
 #et_deferred_for_local_state = (
 #elf.parent_property._raise_column_loader
 #
 #lse:
 #et_deferred_for_local_state = (
 #elf.parent_property._deferred_column_loader
 #
 #opulators["new"].append((self.key, set_deferred_for_local_state))
 #lse:
 #opulators["expire"].append((self.key, False))

 #ef init_class_attribute(self, mapper):
 #elf.is_class_level = True

 #register_attribute(
 #elf.parent_property,
 #apper,
 #seobject=False,
 #ompare_function=self.columns[0].type.compare_values,
 #allable_=self._load_for_state,
 #oad_on_unexpire=False,
 #

 #ef setup_query(
 #elf,
 #ompile_state,
 #uery_entity,
 #ath,
 #oadopt,
 #dapter,
 #olumn_collection,
 #emoized_populators,
 #nly_load_props=None,
 #*kw
 #:

 #f (
 #
 #ompile_state.compile_options._render_for_subquery
 #nd self.parent_property._renders_in_subqueries
 #
 #r (
 #oadopt
 #nd "undefer_pks" in loadopt.local_opts
 #nd set(self.columns).intersection(
 #elf.parent._should_undefer_in_wildcard
 #
 #
 #r (
 #oadopt
 #nd self.group
 #nd loadopt.local_opts.get(
 #undefer_group_%s" % self.group, False
 #
 #
 #r (only_load_props and self.key in only_load_props)
 #:
 #elf.parent_property._get_strategy(
 #("deferred", False), ("instrument", True))
 #.setup_query(
 #ompile_state,
 #uery_entity,
 #ath,
 #oadopt,
 #dapter,
 #olumn_collection,
 #emoized_populators,
 #*kw
 #
 #lif self.is_class_level:
 #emoized_populators[self.parent_property] = _SET_DEFERRED_EXPIRED
 #lif not self.raiseload:
 #emoized_populators[self.parent_property] = _DEFER_FOR_STATE
 #lse:
 #emoized_populators[self.parent_property] = _RAISE_FOR_STATE

 #ef _load_for_state(self, state, passive):
 #f not state.key:
 #eturn attributes.ATTR_EMPTY

 #f not passive & attributes.SQL_OK:
 #eturn attributes.PASSIVE_NO_RESULT

 #ocalparent = state.manager.mapper

 #f self.group:
 #oload = [
 #.key
 #or p in localparent.iterate_properties
 #f isinstance(p, StrategizedProperty)
 #nd isinstance(p.strategy, DeferredColumnLoader)
 #nd p.group == self.group
 #
 #lse:
 #oload = [self.key]

        # narrow the keys down to just those which have no history
 #roup = [k for k in toload if k in state.unmodified]

 #ession = _state_session(state)
 #f session is None:
 #aise orm_exc.DetachedInstanceError(
 #Parent instance %s is not bound to a Session; "
 #deferred load operation of attribute '%s' cannot proceed"
 # (orm_util.state_str(state), self.key)
 #

 #f self.raiseload:
 #elf._invoke_raise_load(state, passive, "raise")

 #f (
 #oading.load_on_ident(
 #ession,
 #ql.select(localparent).set_label_style(
 #ABEL_STYLE_TABLENAME_PLUS_COL
 #,
 #tate.key,
 #nly_load_props=group,
 #efresh_state=state,
 #
 #s None
 #:
 #aise orm_exc.ObjectDeletedError(state)

 #eturn attributes.ATTR_WAS_SET

 #ef _invoke_raise_load(self, state, passive, lazy):
 #aise sa_exc.InvalidRequestError(
 #'%s' is not available due to raiseload=True" % (self,)
 #


class LoadDeferredColumns(object):
 #""serializable loader object used by DeferredColumnLoader"""

 #ef __init__(self, key, raiseload=False):
 #elf.key = key
 #elf.raiseload = raiseload

 #ef __call__(self, state, passive=attributes.PASSIVE_OFF):
 #ey = self.key

 #ocalparent = state.manager.mapper
 #rop = localparent._props[key]
 #f self.raiseload:
 #trategy_key = (
 #"deferred", True),
 #"instrument", True),
 #"raiseload", True),
 #
 #lse:
 #trategy_key = (("deferred", True), ("instrument", True))
 #trategy = prop._get_strategy(strategy_key)
 #eturn strategy._load_for_state(state, passive)


class AbstractRelationshipLoader(LoaderStrategy):
 #""LoaderStratgies which deal with related objects."""

 #_slots__ = "mapper", "target", "uselist", "entity"

 #ef __init__(self, parent, strategy_key):
 #uper(AbstractRelationshipLoader, self).__init__(parent, strategy_key)
 #elf.mapper = self.parent_property.mapper
 #elf.entity = self.parent_property.entity
 #elf.target = self.parent_property.target
 #elf.uselist = self.parent_property.uselist


@log.class_logger
@relationships.RelationshipProperty.strategy_for(do_nothing=True)
class DoNothingLoader(LoaderStrategy):
 #""Relationship loader that makes no change to the object's state.

 #ompared to NoLoader, this loader does not initialize the
 #ollection/attribute to empty/none; the usual default LazyLoader will
 #ake effect.

 #""


@log.class_logger
@relationships.RelationshipProperty.strategy_for(lazy="noload")
@relationships.RelationshipProperty.strategy_for(lazy=None)
class NoLoader(AbstractRelationshipLoader):
 #""Provide loading behavior for a :class:`.RelationshipProperty`
 #ith "lazy=None".

 #""

 #_slots__ = ()

 #ef init_class_attribute(self, mapper):
 #elf.is_class_level = True

 #register_attribute(
 #elf.parent_property,
 #apper,
 #seobject=True,
 #ypecallable=self.parent_property.collection_class,
 #

 #ef create_row_processor(
 #elf,
 #ontext,
 #uery_entity,
 #ath,
 #oadopt,
 #apper,
 #esult,
 #dapter,
 #opulators,
 #:
 #ef invoke_no_load(state, dict_, row):
 #f self.uselist:
 #ttributes.init_state_collection(state, dict_, self.key)
 #lse:
 #ict_[self.key] = None

 #opulators["new"].append((self.key, invoke_no_load))


@log.class_logger
@relationships.RelationshipProperty.strategy_for(lazy=True)
@relationships.RelationshipProperty.strategy_for(lazy="select")
@relationships.RelationshipProperty.strategy_for(lazy="raise")
@relationships.RelationshipProperty.strategy_for(lazy="raise_on_sql")
@relationships.RelationshipProperty.strategy_for(lazy="baked_select")
class LazyLoader(AbstractRelationshipLoader, util.MemoizedSlots):
 #""Provide loading behavior for a :class:`.RelationshipProperty`
 #ith "lazy=True", that is loads when first accessed.

 #""

 #_slots__ = (
 #_lazywhere",
 #_rev_lazywhere",
 #_lazyload_reverse_option",
 #_order_by",
 #use_get",
 #is_aliased_class",
 #_bind_to_col",
 #_equated_columns",
 #_rev_bind_to_col",
 #_rev_equated_columns",
 #_simple_lazy_clause",
 #_raise_always",
 #_raise_on_sql",
 #_lambda_cache",
 #

 #ef __init__(self, parent, strategy_key):
 #uper(LazyLoader, self).__init__(parent, strategy_key)
 #elf._raise_always = self.strategy_opts["lazy"] == "raise"
 #elf._raise_on_sql = self.strategy_opts["lazy"] == "raise_on_sql"

 #elf.is_aliased_class = inspect(self.entity).is_aliased_class

 #oin_condition = self.parent_property._join_condition
 #
 #elf._lazywhere,
 #elf._bind_to_col,
 #elf._equated_columns,
 # = join_condition.create_lazy_clause()

 #
 #elf._rev_lazywhere,
 #elf._rev_bind_to_col,
 #elf._rev_equated_columns,
 # = join_condition.create_lazy_clause(reverse_direction=True)

 #f self.parent_property.order_by:
 #elf._order_by = [
 #ql_util._deep_annotate(elem, {"_orm_adapt": True})
 #or elem in util.to_list(self.parent_property.order_by)
 #
 #lse:
 #elf._order_by = None

 #elf.logger.info("%s lazy loading clause %s", self, self._lazywhere)

        # determine if our "lazywhere" clause is the same as the mapper's
        # get() clause.  then we can just use mapper.get()
        #
        # TODO: the "not self.uselist" can be taken out entirely; a m2o
        # load that populates for a list (very unusual, but is possible with
        # the API) can still set for "None" and the attribute system will
        # populate as an empty list.
 #elf.use_get = (
 #ot self.is_aliased_class
 #nd not self.uselist
 #nd self.entity._get_clause[0].compare(
 #elf._lazywhere,
 #se_proxies=True,
 #ompare_keys=False,
 #quivalents=self.mapper._equivalent_columns,
 #
 #

 #f self.use_get:
 #or col in list(self._equated_columns):
 #f col in self.mapper._equivalent_columns:
 #or c in self.mapper._equivalent_columns[col]:
 #elf._equated_columns[c] = self._equated_columns[col]

 #elf.logger.info(
 #%s will use Session.get() to " "optimize instance loads", self
 #

 #ef init_class_attribute(self, mapper):
 #elf.is_class_level = True

 #legacy_inactive_history_style = (
 #elf.parent_property._legacy_inactive_history_style
 #

 #f self.parent_property.active_history:
 #ctive_history = True
 #deferred_history = False

 #lif (
 #elf.parent_property.direction is not interfaces.MANYTOONE
 #r not self.use_get
 #:
 #f _legacy_inactive_history_style:
 #ctive_history = True
 #deferred_history = False
 #lse:
 #ctive_history = False
 #deferred_history = True
 #lse:
 #ctive_history = _deferred_history = False

 #register_attribute(
 #elf.parent_property,
 #apper,
 #seobject=True,
 #allable_=self._load_for_state,
 #ypecallable=self.parent_property.collection_class,
 #ctive_history=active_history,
 #deferred_history=_deferred_history,
 #

 #ef _memoized_attr__simple_lazy_clause(self):

 #azywhere = sql_util._deep_annotate(
 #elf._lazywhere, {"_orm_adapt": True}
 #

 #riterion, bind_to_col = (lazywhere, self._bind_to_col)

 #arams = []

 #ef visit_bindparam(bindparam):
 #indparam.unique = False

 #isitors.traverse(criterion, {}, {"bindparam": visit_bindparam})

 #ef visit_bindparam(bindparam):
 #f bindparam._identifying_key in bind_to_col:
 #arams.append(
 #
 #indparam.key,
 #ind_to_col[bindparam._identifying_key],
 #one,
 #
 #
 #lif bindparam.callable is None:
 #arams.append((bindparam.key, None, bindparam.value))

 #riterion = visitors.cloned_traverse(
 #riterion, {}, {"bindparam": visit_bindparam}
 #

 #eturn criterion, params

 #ef _generate_lazy_clause(self, state, passive):
 #riterion, param_keys = self._simple_lazy_clause

 #f state is None:
 #eturn sql_util.adapt_criterion_to_null(
 #riterion, [key for key, ident, value in param_keys]
 #

 #apper = self.parent_property.parent

 # = state.obj()  # strong ref
 #ict_ = attributes.instance_dict(o)

 #f passive & attributes.INIT_OK:
 #assive ^= attributes.INIT_OK

 #arams = {}
 #or key, ident, value in param_keys:
 #f ident is not None:
 #f passive and passive & attributes.LOAD_AGAINST_COMMITTED:
 #alue = mapper._get_committed_state_attr_by_column(
 #tate, dict_, ident, passive
 #
 #lse:
 #alue = mapper._get_state_attr_by_column(
 #tate, dict_, ident, passive
 #

 #arams[key] = value

 #eturn criterion, params

 #ef _invoke_raise_load(self, state, passive, lazy):
 #aise sa_exc.InvalidRequestError(
 #'%s' is not available due to lazy='%s'" % (self, lazy)
 #

 #ef _load_for_state(self, state, passive, loadopt=None, extra_criteria=()):

 #f not state.key and (
 #
 #ot self.parent_property.load_on_pending
 #nd not state._load_pending
 #
 #r not state.session_id
 #:
 #eturn attributes.ATTR_EMPTY

 #ending = not state.key
 #rimary_key_identity = None

 #se_get = self.use_get and (not loadopt or not loadopt._extra_criteria)

 #f (not passive & attributes.SQL_OK and not use_get) or (
 #ot passive & attributes.NON_PERSISTENT_OK and pending
 #:
 #eturn attributes.PASSIVE_NO_RESULT

 #f (
            # we were given lazy="raise"
 #elf._raise_always
            # the no_raise history-related flag was not passed
 #nd not passive & attributes.NO_RAISE
 #nd (
                # if we are use_get and related_object_ok is disabled,
                # which means we are at most looking in the identity map
                # for history purposes or otherwise returning
                # PASSIVE_NO_RESULT, don't raise.  This is also a
                # history-related flag
 #ot use_get
 #r passive & attributes.RELATED_OBJECT_OK
 #
 #:

 #elf._invoke_raise_load(state, passive, "raise")

 #ession = _state_session(state)
 #f not session:
 #f passive & attributes.NO_RAISE:
 #eturn attributes.PASSIVE_NO_RESULT

 #aise orm_exc.DetachedInstanceError(
 #Parent instance %s is not bound to a Session; "
 #lazy load operation of attribute '%s' cannot proceed"
 # (orm_util.state_str(state), self.key)
 #

        # if we have a simple primary key load, check the
        # identity map without generating a Query at all
 #f use_get:
 #rimary_key_identity = self._get_ident_for_use_get(
 #ession, state, passive
 #
 #f attributes.PASSIVE_NO_RESULT in primary_key_identity:
 #eturn attributes.PASSIVE_NO_RESULT
 #lif attributes.NEVER_SET in primary_key_identity:
 #eturn attributes.NEVER_SET

 #f _none_set.issuperset(primary_key_identity):
 #eturn None

 #f (
 #elf.key in state.dict
 #nd not passive & attributes.DEFERRED_HISTORY_LOAD
 #:
 #eturn attributes.ATTR_WAS_SET

            # look for this identity in the identity map.  Delegate to the
            # Query class in use, as it may have special rules for how it
            # does this, including how it decides what the correct
            # identity_token would be for this identity.

 #nstance = session._identity_lookup(
 #elf.entity,
 #rimary_key_identity,
 #assive=passive,
 #azy_loaded_from=state,
 #

 #f instance is not None:
 #f instance is attributes.PASSIVE_CLASS_MISMATCH:
 #eturn None
 #lse:
 #eturn instance
 #lif (
 #ot passive & attributes.SQL_OK
 #r not passive & attributes.RELATED_OBJECT_OK
 #:
 #eturn attributes.PASSIVE_NO_RESULT

 #eturn self._emit_lazyload(
 #ession,
 #tate,
 #rimary_key_identity,
 #assive,
 #oadopt,
 #xtra_criteria,
 #

 #ef _get_ident_for_use_get(self, session, state, passive):
 #nstance_mapper = state.manager.mapper

 #f passive & attributes.LOAD_AGAINST_COMMITTED:
 #et_attr = instance_mapper._get_committed_state_attr_by_column
 #lse:
 #et_attr = instance_mapper._get_state_attr_by_column

 #ict_ = state.dict

 #eturn [
 #et_attr(state, dict_, self._equated_columns[pk], passive=passive)
 #or pk in self.mapper.primary_key
 #

 #ef _memoized_attr__lambda_cache(self):
        # cache is per lazy loader, and is used for caching of
        # sqlalchemy.sql.lambdas.AnalyzedCode and
        # sqlalchemy.sql.lambdas.AnalyzedFunction objects which are generated
        # from the StatementLambda used.
 #eturn util.LRUCache(30)

 #util.preload_module("sqlalchemy.orm.strategy_options")
 #ef _emit_lazyload(
 #elf,
 #ession,
 #tate,
 #rimary_key_identity,
 #assive,
 #oadopt,
 #xtra_criteria,
 #:
 #trategy_options = util.preloaded.orm_strategy_options

 #tmt = sql.lambda_stmt(
 #ambda: sql.select(self.entity)
 #set_label_style(LABEL_STYLE_TABLENAME_PLUS_COL)
 #_set_compile_options(ORMCompileState.default_compile_options),
 #lobal_track_bound_values=False,
 #ambda_cache=self._lambda_cache,
 #rack_on=(self,),
 #

 #f not self.parent_property.bake_queries:
 #tmt = stmt.spoil()

 #oad_options = QueryContext.default_load_options

 #oad_options += {
 #_invoke_all_eagers": False,
 #_lazy_loaded_from": state,
 #

 #f self.parent_property.secondary is not None:
 #tmt = stmt.add_criteria(
 #ambda stmt: stmt.select_from(
 #elf.mapper, self.parent_property.secondary
 #,
 #rack_on=[self.parent_property],
 #

 #ending = not state.key

        # don't autoflush on pending
 #f pending or passive & attributes.NO_AUTOFLUSH:
 #tmt += lambda stmt: stmt.execution_options(autoflush=False)

 #se_get = self.use_get

 #f state.load_options or (loadopt and loadopt._extra_criteria):
 #ffective_path = state.load_path[self.parent_property]

 #pts = list(state.load_options)

 #f loadopt and loadopt._extra_criteria:
 #se_get = False
 #pts += (
 #rm_util.LoaderCriteriaOption(self.entity, extra_criteria),
 #

 #tmt += lambda stmt: stmt.options(*opts)
 #lse:
            # this path is used if there are not already any options
            # in the query, but an event may want to add them
 #ffective_path = state.mapper._path_registry[self.parent_property]

 #tmt += lambda stmt: stmt._update_compile_options(
 #"_current_path": effective_path}
 #

 #f use_get:
 #f self._raise_on_sql and not passive & attributes.NO_RAISE:
 #elf._invoke_raise_load(state, passive, "raise_on_sql")

 #eturn loading.load_on_pk_identity(
 #ession, stmt, primary_key_identity, load_options=load_options
 #

 #f self._order_by:
 #tmt = stmt.add_criteria(
 #ambda stmt: stmt.order_by(*self._order_by), track_on=[self]
 #

 #ef _lazyload_reverse(compile_context):
 #or rev in self.parent_property._reverse_property:
                # reverse props that are MANYTOONE are loading *this*
                # object from get(), so don't need to eager out to those.
 #f (
 #ev.direction is interfaces.MANYTOONE
 #nd rev._use_get
 #nd not isinstance(rev.strategy, LazyLoader)
 #:
 #trategy_options.Load.for_existing_path(
 #ompile_context.compile_options._current_path[
 #ev.parent
 #
 #.lazyload(rev).process_compile_state(compile_context)

 #tmt = stmt.add_criteria(
 #ambda stmt: stmt._add_context_option(
 #lazyload_reverse, self.parent_property
 #,
 #rack_on=[self],
 #

 #azy_clause, params = self._generate_lazy_clause(state, passive)

 #xecution_options = {
 #_sa_orm_load_options": load_options,
 #

 #f (
 #elf.key in state.dict
 #nd not passive & attributes.DEFERRED_HISTORY_LOAD
 #:
 #eturn attributes.ATTR_WAS_SET

 #f pending:
 #f util.has_intersection(orm_util._none_set, params.values()):
 #eturn None

 #lif util.has_intersection(orm_util._never_set, params.values()):
 #eturn None

 #f self._raise_on_sql and not passive & attributes.NO_RAISE:
 #elf._invoke_raise_load(state, passive, "raise_on_sql")

 #tmt = stmt.add_criteria(
 #ambda stmt: stmt.where(lazy_clause), enable_tracking=False
 #

 #esult = session.execute(
 #tmt, params, execution_options=execution_options
 #

 #esult = result.unique().scalars().all()

 #f self.uselist:
 #eturn result
 #lse:
 # = len(result)
 #f l:
 #f l > 1:
 #til.warn(
 #Multiple rows returned with "
 #uselist=False for lazily-loaded attribute '%s' "
 # self.parent_property
 #

 #eturn result[0]
 #lse:
 #eturn None

 #ef create_row_processor(
 #elf,
 #ontext,
 #uery_entity,
 #ath,
 #oadopt,
 #apper,
 #esult,
 #dapter,
 #opulators,
 #:
 #ey = self.key

 #f not self.is_class_level or (loadopt and loadopt._extra_criteria):
            # we are not the primary manager for this attribute
            # on this class - set up a
            # per-instance lazyloader, which will override the
            # class-level behavior.
            # this currently only happens when using a
            # "lazyload" option on a "no load"
            # attribute - "eager" attributes always have a
            # class-level lazyloader installed.
 #et_lazy_callable = (
 #nstanceState._instance_level_callable_processor
 #(
 #apper.class_manager,
 #oadLazyAttribute(
 #ey,
 #elf,
 #oadopt,
 #oadopt._generate_extra_criteria(context)
 #f loadopt._extra_criteria
 #lse None,
 #,
 #ey,
 #

 #opulators["new"].append((self.key, set_lazy_callable))
 #lif context.populate_existing or mapper.always_refresh:

 #ef reset_for_lazy_callable(state, dict_, row):
                # we are the primary manager for this attribute on
                # this class - reset its
                # per-instance attribute state, so that the class-level
                # lazy loader is
                # executed when next referenced on this instance.
                # this is needed in
                # populate_existing() types of scenarios to reset
                # any existing state.
 #tate._reset(dict_, key)

 #opulators["new"].append((self.key, reset_for_lazy_callable))


class LoadLazyAttribute(object):
 #""semi-serializable loader object used by LazyLoader

 #istorically, this object would be carried along with instances that
 #eeded to run lazyloaders, so it had to be serializable to support
 #ached instances.

 #his is no longer a general requirement, and the case where this object
 #s used is exactly the case where we can't really serialize easily,
 #hich is when extra criteria in the loader option is present.

 #e can't reliably serialize that as it refers to mapped entities and
 #liasedClass objects that are local to the current process, which would
 #eed to be matched up on deserialize e.g. the sqlalchemy.ext.serializer
 #pproach.

 #""

 #ef __init__(self, key, initiating_strategy, loadopt, extra_criteria):
 #elf.key = key
 #elf.strategy_key = initiating_strategy.strategy_key
 #elf.loadopt = loadopt
 #elf.extra_criteria = extra_criteria

 #ef __getstate__(self):
 #f self.extra_criteria is not None:
 #til.warn(
 #Can't reliably serialize a lazyload() option that "
 #contains additional criteria; please use eager loading "
 #for this case"
 #
 #eturn {
 #key": self.key,
 #strategy_key": self.strategy_key,
 #loadopt": self.loadopt,
 #extra_criteria": (),
 #

 #ef __call__(self, state, passive=attributes.PASSIVE_OFF):
 #ey = self.key
 #nstance_mapper = state.manager.mapper
 #rop = instance_mapper._props[key]
 #trategy = prop._strategies[self.strategy_key]

 #eturn strategy._load_for_state(
 #tate,
 #assive,
 #oadopt=self.loadopt,
 #xtra_criteria=self.extra_criteria,
 #


class PostLoader(AbstractRelationshipLoader):
 #""A relationship loader that emits a second SELECT statement."""

 #ef _check_recursive_postload(self, context, path, join_depth=None):
 #ffective_path = (
 #ontext.compile_state.current_path or orm_util.PathRegistry.root
 # + path

 #f loading.PostLoad.path_exists(
 #ontext, effective_path, self.parent_property
 #:
 #eturn True

 #ath_w_prop = path[self.parent_property]
 #ffective_path_w_prop = effective_path[self.parent_property]

 #f not path_w_prop.contains(context.attributes, "loader"):
 #f join_depth:
 #f effective_path_w_prop.length / 2 > join_depth:
 #eturn True
 #lif effective_path_w_prop.contains_mapper(self.mapper):
 #eturn True

 #eturn False

 #ef _immediateload_create_row_processor(
 #elf,
 #ontext,
 #uery_entity,
 #ath,
 #oadopt,
 #apper,
 #esult,
 #dapter,
 #opulators,
 #:
 #eturn self.parent_property._get_strategy(
 #("lazy", "immediate"),)
 #.create_row_processor(
 #ontext,
 #uery_entity,
 #ath,
 #oadopt,
 #apper,
 #esult,
 #dapter,
 #opulators,
 #


@relationships.RelationshipProperty.strategy_for(lazy="immediate")
class ImmediateLoader(PostLoader):
 #_slots__ = ()

 #ef init_class_attribute(self, mapper):
 #elf.parent_property._get_strategy(
 #("lazy", "select"),)
 #.init_class_attribute(mapper)

 #ef create_row_processor(
 #elf,
 #ontext,
 #uery_entity,
 #ath,
 #oadopt,
 #apper,
 #esult,
 #dapter,
 #opulators,
 #:
 #ef load_immediate(state, dict_, row):
 #tate.get_impl(self.key).get(state, dict_, flags)

 #f self._check_recursive_postload(context, path):
            # this will not emit SQL and will only emit for a many-to-one
            # "use get" load.   the "_RELATED" part means it may return
            # instance even if its expired, since this is a mutually-recursive
            # load operation.
 #lags = attributes.PASSIVE_NO_FETCH_RELATED | attributes.NO_RAISE
 #lse:
 #lags = attributes.PASSIVE_OFF | attributes.NO_RAISE

 #opulators["delayed"].append((self.key, load_immediate))


@log.class_logger
@relationships.RelationshipProperty.strategy_for(lazy="subquery")
class SubqueryLoader(PostLoader):
 #_slots__ = ("join_depth",)

 #ef __init__(self, parent, strategy_key):
 #uper(SubqueryLoader, self).__init__(parent, strategy_key)
 #elf.join_depth = self.parent_property.join_depth

 #ef init_class_attribute(self, mapper):
 #elf.parent_property._get_strategy(
 #("lazy", "select"),)
 #.init_class_attribute(mapper)

 #ef _get_leftmost(
 #elf,
 #rig_query_entity_index,
 #ubq_path,
 #urrent_compile_state,
 #s_root,
 #:
 #iven_subq_path = subq_path
 #ubq_path = subq_path.path
 #ubq_mapper = orm_util._class_to_mapper(subq_path[0])

        # determine attributes of the leftmost mapper
 #f (
 #elf.parent.isa(subq_mapper)
 #nd self.parent_property is subq_path[1]
 #:
 #eftmost_mapper, leftmost_prop = self.parent, self.parent_property
 #lse:
 #eftmost_mapper, leftmost_prop = subq_mapper, subq_path[1]

 #f is_root:
            # the subq_path is also coming from cached state, so when we start
            # building up this path, it has to also be converted to be in terms
            # of the current state. this is for the specific case of the entity
            # is an AliasedClass against a subquery that's not otherwise going
            # to adapt
 #ew_subq_path = current_compile_state._entities[
 #rig_query_entity_index
 #.entity_zero._path_registry[leftmost_prop]
 #dditional = len(subq_path) - len(new_subq_path)
 #f additional:
 #ew_subq_path += path_registry.PathRegistry.coerce(
 #ubq_path[-additional:]
 #
 #lse:
 #ew_subq_path = given_subq_path

 #eftmost_cols = leftmost_prop.local_columns

 #eftmost_attr = [
 #etattr(
 #ew_subq_path.path[0].entity,
 #eftmost_mapper._columntoproperty[c].key,
 #
 #or c in leftmost_cols
 #

 #eturn leftmost_mapper, leftmost_attr, leftmost_prop, new_subq_path

 #ef _generate_from_original_query(
 #elf,
 #rig_compile_state,
 #rig_query,
 #eftmost_mapper,
 #eftmost_attr,
 #eftmost_relationship,
 #rig_entity,
 #:
        # reformat the original query
        # to look only for significant columns
 # = orig_query._clone().correlate(None)

        # LEGACY: make a Query back from the select() !!
        # This suits at least two legacy cases:
        # 1. applications which expect before_compile() to be called
        #    below when we run .subquery() on this query (Keystone)
        # 2. applications which are doing subqueryload with complex
        #    from_self() queries, as query.subquery() / .statement
        #    has to do the full compile context for multiply-nested
        #    from_self() (Neutron) - see test_subqload_from_self
        #    for demo.
 #2 = query.Query.__new__(query.Query)
 #2.__dict__.update(q.__dict__)
 # = q2

        # set the query's "FROM" list explicitly to what the
        # FROM list would be in any case, as we will be limiting
        # the columns in the SELECT list which may no longer include
        # all entities mentioned in things like WHERE, JOIN, etc.
 #f not q._from_obj:
 #._enable_assertions = False
 #.select_from.non_generative(
 #,
 #{
 #nt["entity"]
 #or ent in _column_descriptions(
 #rig_query, compile_state=orig_compile_state
 #
 #f ent["entity"] is not None
 #
 #

        # select from the identity columns of the outer (specifically, these
        # are the 'local_cols' of the property).  This will remove other
        # columns from the query that might suggest the right entity which is
        # why we do set select_from above.   The attributes we have are
        # coerced and adapted using the original query's adapter, which is
        # needed only for the case of adapting a subclass column to
        # that of a polymorphic selectable, e.g. we have
        # Engineer.primary_language and the entity is Person.  All other
        # adaptations, e.g. from_self, select_entity_from(), will occur
        # within the new query when it compiles, as the compile_state we are
        # using here is only a partial one.  If the subqueryload is from a
        # with_polymorphic() or other aliased() object, left_attr will already
        # be the correct attributes so no adaptation is needed.
 #arget_cols = orig_compile_state._adapt_col_list(
 #
 #ql.coercions.expect(sql.roles.ColumnsClauseRole, o)
 #or o in leftmost_attr
 #,
 #rig_compile_state._get_current_adapter(),
 #
 #._raw_columns = target_cols

 #istinct_target_key = leftmost_relationship.distinct_target_key

 #f distinct_target_key is True:
 #._distinct = True
 #lif distinct_target_key is None:
            # if target_cols refer to a non-primary key or only
            # part of a composite primary key, set the q as distinct
 #or t in set(c.table for c in target_cols):
 #f not set(target_cols).issuperset(t.primary_key):
 #._distinct = True
 #reak

        # don't need ORDER BY if no limit/offset
 #f not q._has_row_limiting_clause:
 #._order_by_clauses = ()

 #f q._distinct is True and q._order_by_clauses:
            # the logic to automatically add the order by columns to the query
            # when distinct is True is deprecated in the query
 #o_add = sql_util.expand_column_list_from_order_by(
 #arget_cols, q._order_by_clauses
 #
 #f to_add:
 #._set_entities(target_cols + to_add)

        # the original query now becomes a subquery
        # which we'll join onto.
        # LEGACY: as "q" is a Query, the before_compile() event is invoked
        # here.
 #mbed_q = q.set_label_style(LABEL_STYLE_TABLENAME_PLUS_COL).subquery()
 #eft_alias = orm_util.AliasedClass(
 #eftmost_mapper, embed_q, use_mapper_path=True
 #
 #eturn left_alias

 #ef _prep_for_joins(self, left_alias, subq_path):
        # figure out what's being joined.  a.k.a. the fun part
 #o_join = []
 #airs = list(subq_path.pairs())

 #or i, (mapper, prop) in enumerate(pairs):
 #f i > 0:
                # look at the previous mapper in the chain -
                # if it is as or more specific than this prop's
                # mapper, use that instead.
                # note we have an assumption here that
                # the non-first element is always going to be a mapper,
                # not an AliasedClass

 #rev_mapper = pairs[i - 1][1].mapper
 #o_append = prev_mapper if prev_mapper.isa(mapper) else mapper
 #lse:
 #o_append = mapper

 #o_join.append((to_append, prop.key))

        # determine the immediate parent class we are joining from,
        # which needs to be aliased.

 #f len(to_join) < 2:
            # in the case of a one level eager load, this is the
            # leftmost "left_alias".
 #arent_alias = left_alias
 #lse:
 #nfo = inspect(to_join[-1][0])
 #f info.is_aliased_class:
 #arent_alias = info.entity
 #lse:
                # alias a plain mapper as we may be
                # joining multiple times
 #arent_alias = orm_util.AliasedClass(
 #nfo.entity, use_mapper_path=True
 #

 #ocal_cols = self.parent_property.local_columns

 #ocal_attr = [
 #etattr(parent_alias, self.parent._columntoproperty[c].key)
 #or c in local_cols
 #
 #eturn to_join, local_attr, parent_alias

 #ef _apply_joins(
 #elf, q, to_join, left_alias, parent_alias, effective_entity
 #:

 #tj = len(to_join)
 #f ltj == 1:
 #o_join = [
 #etattr(left_alias, to_join[0][1]).of_type(effective_entity)
 #
 #lif ltj == 2:
 #o_join = [
 #etattr(left_alias, to_join[0][1]).of_type(parent_alias),
 #etattr(parent_alias, to_join[-1][1]).of_type(
 #ffective_entity
 #,
 #
 #lif ltj > 2:
 #iddle = [
 #
 #rm_util.AliasedClass(item[0])
 #f not inspect(item[0]).is_aliased_class
 #lse item[0].entity,
 #tem[1],
 #
 #or item in to_join[1:-1]
 #
 #nner = []

 #hile middle:
 #tem = middle.pop(0)
 #ttr = getattr(item[0], item[1])
 #f middle:
 #ttr = attr.of_type(middle[0][0])
 #lse:
 #ttr = attr.of_type(parent_alias)

 #nner.append(attr)

 #o_join = (
 #getattr(left_alias, to_join[0][1]).of_type(inner[0].parent)]
 # inner
 # [
 #etattr(parent_alias, to_join[-1][1]).of_type(
 #ffective_entity
 #
 #
 #

 #or attr in to_join:
 # = q.join(attr)

 #eturn q

 #ef _setup_options(
 #elf,
 #ontext,
 #,
 #ubq_path,
 #ewritten_path,
 #rig_query,
 #ffective_entity,
 #oadopt,
 #:
 #pts = orig_query._with_options

 #f loadopt and loadopt._extra_criteria:

 #pts += (
 #rm_util.LoaderCriteriaOption(
 #elf.entity,
 #oadopt._generate_extra_criteria(context),
 #,
 #

        # propagate loader options etc. to the new query.
        # these will fire relative to subq_path.
 # = q._with_current_path(rewritten_path)
 # = q.options(*opts)

 #eturn q

 #ef _setup_outermost_orderby(self, q):
 #f self.parent_property.order_by:

 #ef _setup_outermost_orderby(compile_context):
 #ompile_context.eager_order_by += tuple(
 #til.to_list(self.parent_property.order_by)
 #

 # = q._add_context_option(
 #setup_outermost_orderby, self.parent_property
 #

 #eturn q

 #lass _SubqCollections(object):
 #""Given a :class:`_query.Query` used to emit the "subquery load",
 #rovide a load interface that executes the query at the
 #irst moment a value is needed.

 #""

 #_slots__ = (
 #session",
 #execution_options",
 #load_options",
 #params",
 #subq",
 #_data",
 #

 #ef __init__(self, context, subq):
            # avoid creating a cycle by storing context
            # even though that's preferable
 #elf.session = context.session
 #elf.execution_options = context.execution_options
 #elf.load_options = context.load_options
 #elf.params = context.params or {}
 #elf.subq = subq
 #elf._data = None

 #ef get(self, key, default):
 #f self._data is None:
 #elf._load()
 #eturn self._data.get(key, default)

 #ef _load(self):
 #elf._data = collections.defaultdict(list)

 # = self.subq
 #ssert q.session is None

 # = q.with_session(self.session)

 #f self.load_options._populate_existing:
 # = q.populate_existing()
            # to work with baked query, the parameters may have been
            # updated since this query was created, so take these into account

 #ows = list(q.params(self.params))
 #or k, v in itertools.groupby(rows, lambda x: x[1:]):
 #elf._data[k].extend(vv[0] for vv in v)

 #ef loader(self, state, dict_, row):
 #f self._data is None:
 #elf._load()

 #ef _setup_query_from_rowproc(
 #elf,
 #ontext,
 #uery_entity,
 #ath,
 #ntity,
 #oadopt,
 #dapter,
 #:
 #ompile_state = context.compile_state
 #f (
 #ot compile_state.compile_options._enable_eagerloads
 #r compile_state.compile_options._for_refresh_state
 #:
 #eturn

 #rig_query_entity_index = compile_state._entities.index(query_entity)
 #ontext.loaders_require_buffering = True

 #ath = path[self.parent_property]

        # build up a path indicating the path from the leftmost
        # entity to the thing we're subquery loading.
 #ith_poly_entity = path.get(
 #ompile_state.attributes, "path_with_polymorphic", None
 #
 #f with_poly_entity is not None:
 #ffective_entity = with_poly_entity
 #lse:
 #ffective_entity = self.entity

 #ubq_path, rewritten_path = context.query._execution_options.get(
 #"subquery_paths", None),
 #orm_util.PathRegistry.root, orm_util.PathRegistry.root),
 #
 #s_root = subq_path is orm_util.PathRegistry.root
 #ubq_path = subq_path + path
 #ewritten_path = rewritten_path + path

        # if not via query option, check for
        # a cycle
        # TODO: why is this here???  this is now handled
        # by the _check_recursive_postload call
 #f not path.contains(compile_state.attributes, "loader"):
 #f self.join_depth:
 #f (
 #
 #ompile_state.current_path.length
 #f compile_state.current_path
 #lse 0
 #
 # path.length
 # / 2 > self.join_depth:
 #eturn
 #lif subq_path.contains_mapper(self.mapper):
 #eturn

        # use the current query being invoked, not the compile state
        # one.  this is so that we get the current parameters.  however,
        # it means we can't use the existing compile state, we have to make
        # a new one.    other approaches include possibly using the
        # compiled query but swapping the params, seems only marginally
        # less time spent but more complicated
 #rig_query = context.query._execution_options.get(
 #"orig_query", SubqueryLoader), context.query
 #

        # make a new compile_state for the query that's probably cached, but
        # we're sort of undoing a bit of that caching :(
 #ompile_state_cls = ORMCompileState._get_plugin_class_for_plugin(
 #rig_query, "orm"
 #

 #f orig_query._is_lambda_element:
 #f context.load_options._lazy_loaded_from is None:
 #til.warn(
 #subqueryloader for "%s" must invoke lambda callable '
 #at %r in "
 #order to produce a new query, decreasing the efficiency "
 #of caching for this statement.  Consider using "
 #selectinload() for more effective full-lambda caching"
 # (self, orig_query)
 #
 #rig_query = orig_query._resolved

        # this is the more "quick" version, however it's not clear how
        # much of this we need.    in particular I can't get a test to
        # fail if the "set_base_alias" is missing and not sure why that is.
 #rig_compile_state = compile_state_cls._create_entities_collection(
 #rig_query, legacy=False
 #

 #
 #eftmost_mapper,
 #eftmost_attr,
 #eftmost_relationship,
 #ewritten_path,
 # = self._get_leftmost(
 #rig_query_entity_index,
 #ewritten_path,
 #rig_compile_state,
 #s_root,
 #

        # generate a new Query from the original, then
        # produce a subquery from it.
 #eft_alias = self._generate_from_original_query(
 #rig_compile_state,
 #rig_query,
 #eftmost_mapper,
 #eftmost_attr,
 #eftmost_relationship,
 #ntity,
 #

        # generate another Query that will join the
        # left alias to the target relationships.
        # basically doing a longhand
        # "from_self()".  (from_self() itself not quite industrial
        # strength enough for all contingencies...but very close)

 # = query.Query(effective_entity)

 #._execution_options = q._execution_options.union(
 #
 #"orig_query", SubqueryLoader): orig_query,
 #"subquery_paths", None): (subq_path, rewritten_path),
 #
 #

 # = q._set_enable_single_crit(False)
 #o_join, local_attr, parent_alias = self._prep_for_joins(
 #eft_alias, subq_path
 #

 # = q.add_columns(*local_attr)
 # = self._apply_joins(
 #, to_join, left_alias, parent_alias, effective_entity
 #

 # = self._setup_options(
 #ontext,
 #,
 #ubq_path,
 #ewritten_path,
 #rig_query,
 #ffective_entity,
 #oadopt,
 #
 # = self._setup_outermost_orderby(q)

 #eturn q

 #ef create_row_processor(
 #elf,
 #ontext,
 #uery_entity,
 #ath,
 #oadopt,
 #apper,
 #esult,
 #dapter,
 #opulators,
 #:

 #f context.refresh_state:
 #eturn self._immediateload_create_row_processor(
 #ontext,
 #uery_entity,
 #ath,
 #oadopt,
 #apper,
 #esult,
 #dapter,
 #opulators,
 #
        # the subqueryloader does a similar check in setup_query() unlike
        # the other post loaders, however we have this here for consistency
 #lif self._check_recursive_postload(context, path, self.join_depth):
 #eturn

 #f not self.parent.class_manager[self.key].impl.supports_population:
 #aise sa_exc.InvalidRequestError(
 #'%s' does not support object "
 #population - eager loading cannot be applied." % self
 #

        # a little dance here as the "path" is still something that only
        # semi-tracks the exact series of things we are loading, still not
        # telling us about with_polymorphic() and stuff like that when it's at
        # the root..  the initial MapperEntity is more accurate for this case.
 #f len(path) == 1:
 #f not orm_util._entity_isa(query_entity.entity_zero, self.parent):
 #eturn
 #lif not orm_util._entity_isa(path[-1], self.parent):
 #eturn

 #ubq = self._setup_query_from_rowproc(
 #ontext,
 #uery_entity,
 #ath,
 #ath[-1],
 #oadopt,
 #dapter,
 #

 #f subq is None:
 #eturn

 #ssert subq.session is None

 #ath = path[self.parent_property]

 #ocal_cols = self.parent_property.local_columns

        # cache the loaded collections in the context
        # so that inheriting mappers don't re-load when they
        # call upon create_row_processor again
 #ollections = path.get(context.attributes, "collections")
 #f collections is None:
 #ollections = self._SubqCollections(context, subq)
 #ath.set(context.attributes, "collections", collections)

 #f adapter:
 #ocal_cols = [adapter.columns[c] for c in local_cols]

 #f self.uselist:
 #elf._create_collection_loader(
 #ontext, result, collections, local_cols, populators
 #
 #lse:
 #elf._create_scalar_loader(
 #ontext, result, collections, local_cols, populators
 #

 #ef _create_collection_loader(
 #elf, context, result, collections, local_cols, populators
 #:
 #uple_getter = result._tuple_getter(local_cols)

 #ef load_collection_from_subq(state, dict_, row):
 #ollection = collections.get(tuple_getter(row), ())
 #tate.get_impl(self.key).set_committed_value(
 #tate, dict_, collection
 #

 #ef load_collection_from_subq_existing_row(state, dict_, row):
 #f self.key not in dict_:
 #oad_collection_from_subq(state, dict_, row)

 #opulators["new"].append((self.key, load_collection_from_subq))
 #opulators["existing"].append(
 #self.key, load_collection_from_subq_existing_row)
 #

 #f context.invoke_all_eagers:
 #opulators["eager"].append((self.key, collections.loader))

 #ef _create_scalar_loader(
 #elf, context, result, collections, local_cols, populators
 #:
 #uple_getter = result._tuple_getter(local_cols)

 #ef load_scalar_from_subq(state, dict_, row):
 #ollection = collections.get(tuple_getter(row), (None,))
 #f len(collection) > 1:
 #til.warn(
 #Multiple rows returned with "
 #uselist=False for eagerly-loaded attribute '%s' " % self
 #

 #calar = collection[0]
 #tate.get_impl(self.key).set_committed_value(state, dict_, scalar)

 #ef load_scalar_from_subq_existing_row(state, dict_, row):
 #f self.key not in dict_:
 #oad_scalar_from_subq(state, dict_, row)

 #opulators["new"].append((self.key, load_scalar_from_subq))
 #opulators["existing"].append(
 #self.key, load_scalar_from_subq_existing_row)
 #
 #f context.invoke_all_eagers:
 #opulators["eager"].append((self.key, collections.loader))


@log.class_logger
@relationships.RelationshipProperty.strategy_for(lazy="joined")
@relationships.RelationshipProperty.strategy_for(lazy=False)
class JoinedLoader(AbstractRelationshipLoader):
 #""Provide loading behavior for a :class:`.RelationshipProperty`
 #sing joined eager loading.

 #""

 #_slots__ = "join_depth", "_aliased_class_pool"

 #ef __init__(self, parent, strategy_key):
 #uper(JoinedLoader, self).__init__(parent, strategy_key)
 #elf.join_depth = self.parent_property.join_depth
 #elf._aliased_class_pool = []

 #ef init_class_attribute(self, mapper):
 #elf.parent_property._get_strategy(
 #("lazy", "select"),)
 #.init_class_attribute(mapper)

 #ef setup_query(
 #elf,
 #ompile_state,
 #uery_entity,
 #ath,
 #oadopt,
 #dapter,
 #olumn_collection=None,
 #arentmapper=None,
 #hained_from_outerjoin=False,
 #*kwargs
 #:
 #""Add a left outer join to the statement that's being constructed."""

 #f not compile_state.compile_options._enable_eagerloads:
 #eturn
 #lif self.uselist:
 #ompile_state.multi_row_eager_loaders = True

 #ath = path[self.parent_property]

 #ith_polymorphic = None

 #ser_defined_adapter = (
 #elf._init_user_defined_eager_proc(
 #oadopt, compile_state, compile_state.attributes
 #
 #f loadopt
 #lse False
 #

 #f user_defined_adapter is not False:
 #
 #lauses,
 #dapter,
 #dd_to_collection,
 # = self._setup_query_on_user_defined_adapter(
 #ompile_state,
 #uery_entity,
 #ath,
 #dapter,
 #ser_defined_adapter,
 #
 #lse:
            # if not via query option, check for
            # a cycle
 #f not path.contains(compile_state.attributes, "loader"):
 #f self.join_depth:
 #f path.length / 2 > self.join_depth:
 #eturn
 #lif path.contains_mapper(self.mapper):
 #eturn

 #
 #lauses,
 #dapter,
 #dd_to_collection,
 #hained_from_outerjoin,
 # = self._generate_row_adapter(
 #ompile_state,
 #uery_entity,
 #ath,
 #oadopt,
 #dapter,
 #olumn_collection,
 #arentmapper,
 #hained_from_outerjoin,
 #

 #ith_poly_entity = path.get(
 #ompile_state.attributes, "path_with_polymorphic", None
 #
 #f with_poly_entity is not None:
 #ith_polymorphic = inspect(
 #ith_poly_entity
 #.with_polymorphic_mappers
 #lse:
 #ith_polymorphic = None

 #ath = path[self.entity]

 #oading._setup_entity_query(
 #ompile_state,
 #elf.mapper,
 #uery_entity,
 #ath,
 #lauses,
 #dd_to_collection,
 #ith_polymorphic=with_polymorphic,
 #arentmapper=self.mapper,
 #hained_from_outerjoin=chained_from_outerjoin,
 #

 #f with_poly_entity is not None and None in set(
 #ompile_state.secondary_columns
 #:
 #aise sa_exc.InvalidRequestError(
 #Detected unaliased columns when generating joined "
 #load.  Make sure to use aliased=True or flat=True "
 #when using joined loading with with_polymorphic()."
 #

 #ef _init_user_defined_eager_proc(
 #elf, loadopt, compile_state, target_attributes
 #:

        # check if the opt applies at all
 #f "eager_from_alias" not in loadopt.local_opts:
            # nope
 #eturn False

 #ath = loadopt.path.parent

        # the option applies.  check if the "user_defined_eager_row_processor"
        # has been built up.
 #dapter = path.get(
 #ompile_state.attributes, "user_defined_eager_row_processor", False
 #
 #f adapter is not False:
            # just return it
 #eturn adapter

        # otherwise figure it out.
 #lias = loadopt.local_opts["eager_from_alias"]
 #oot_mapper, prop = path[-2:]

 #f alias is not None:
 #f isinstance(alias, str):
 #lias = prop.target.alias(alias)
 #dapter = sql_util.ColumnAdapter(
 #lias, equivalents=prop.mapper._equivalent_columns
 #
 #lse:
 #f path.contains(
 #ompile_state.attributes, "path_with_polymorphic"
 #:
 #ith_poly_entity = path.get(
 #ompile_state.attributes, "path_with_polymorphic"
 #
 #dapter = orm_util.ORMAdapter(
 #ith_poly_entity,
 #quivalents=prop.mapper._equivalent_columns,
 #
 #lse:
 #dapter = compile_state._polymorphic_adapters.get(
 #rop.mapper, None
 #
 #ath.set(
 #arget_attributes,
 #user_defined_eager_row_processor",
 #dapter,
 #

 #eturn adapter

 #ef _setup_query_on_user_defined_adapter(
 #elf, context, entity, path, adapter, user_defined_adapter
 #:

        # apply some more wrapping to the "user defined adapter"
        # if we are setting up the query for SQL render.
 #dapter = entity._get_entity_clauses(context)

 #f adapter and user_defined_adapter:
 #ser_defined_adapter = user_defined_adapter.wrap(adapter)
 #ath.set(
 #ontext.attributes,
 #user_defined_eager_row_processor",
 #ser_defined_adapter,
 #
 #lif adapter:
 #ser_defined_adapter = adapter
 #ath.set(
 #ontext.attributes,
 #user_defined_eager_row_processor",
 #ser_defined_adapter,
 #

 #dd_to_collection = context.primary_columns
 #eturn user_defined_adapter, adapter, add_to_collection

 #ef _gen_pooled_aliased_class(self, context):
        # keep a local pool of AliasedClass objects that get re-used.
        # we need one unique AliasedClass per query per appearance of our
        # entity in the query.

 #f inspect(self.entity).is_aliased_class:
 #lt_selectable = inspect(self.entity).selectable
 #lse:
 #lt_selectable = None

 #ey = ("joinedloader_ac", self)
 #f key not in context.attributes:
 #ontext.attributes[key] = idx = 0
 #lse:
 #ontext.attributes[key] = idx = context.attributes[key] + 1

 #f idx >= len(self._aliased_class_pool):
 #o_adapt = orm_util.AliasedClass(
 #elf.mapper,
 #lias=alt_selectable._anonymous_fromclause(flat=True)
 #f alt_selectable is not None
 #lse None,
 #lat=True,
 #se_mapper_path=True,
 #

            # load up the .columns collection on the Alias() before
            # the object becomes shared among threads.  this prevents
            # races for column identities.
 #nspect(to_adapt).selectable.c
 #elf._aliased_class_pool.append(to_adapt)

 #eturn self._aliased_class_pool[idx]

 #ef _generate_row_adapter(
 #elf,
 #ompile_state,
 #ntity,
 #ath,
 #oadopt,
 #dapter,
 #olumn_collection,
 #arentmapper,
 #hained_from_outerjoin,
 #:
 #ith_poly_entity = path.get(
 #ompile_state.attributes, "path_with_polymorphic", None
 #
 #f with_poly_entity:
 #o_adapt = with_poly_entity
 #lse:
 #o_adapt = self._gen_pooled_aliased_class(compile_state)

 #lauses = inspect(to_adapt)._memo(
 #"joinedloader_ormadapter", self),
 #rm_util.ORMAdapter,
 #o_adapt,
 #quivalents=self.mapper._equivalent_columns,
 #dapt_required=True,
 #llow_label_resolve=False,
 #nonymize_labels=True,
 #

 #ssert clauses.aliased_class is not None

 #nnerjoin = (
 #oadopt.local_opts.get("innerjoin", self.parent_property.innerjoin)
 #f loadopt is not None
 #lse self.parent_property.innerjoin
 #

 #f not innerjoin:
            # if this is an outer join, all non-nested eager joins from
            # this path must also be outer joins
 #hained_from_outerjoin = True

 #ompile_state.create_eager_joins.append(
 #
 #elf._create_eager_join,
 #ntity,
 #ath,
 #dapter,
 #arentmapper,
 #lauses,
 #nnerjoin,
 #hained_from_outerjoin,
 #oadopt._extra_criteria if loadopt else (),
 #
 #

 #dd_to_collection = compile_state.secondary_columns
 #ath.set(compile_state.attributes, "eager_row_processor", clauses)

 #eturn clauses, adapter, add_to_collection, chained_from_outerjoin

 #ef _create_eager_join(
 #elf,
 #ompile_state,
 #uery_entity,
 #ath,
 #dapter,
 #arentmapper,
 #lauses,
 #nnerjoin,
 #hained_from_outerjoin,
 #xtra_criteria,
 #:
 #f parentmapper is None:
 #ocalparent = query_entity.mapper
 #lse:
 #ocalparent = parentmapper

        # whether or not the Query will wrap the selectable in a subquery,
        # and then attach eager load joins to that (i.e., in the case of
        # LIMIT/OFFSET etc.)
 #hould_nest_selectable = (
 #ompile_state.multi_row_eager_loaders
 #nd compile_state._should_nest_selectable
 #

 #uery_entity_key = None

 #f (
 #uery_entity not in compile_state.eager_joins
 #nd not should_nest_selectable
 #nd compile_state.from_clauses
 #:

 #ndexes = sql_util.find_left_clause_that_matches_given(
 #ompile_state.from_clauses, query_entity.selectable
 #

 #f len(indexes) > 1:
                # for the eager load case, I can't reproduce this right
                # now.   For query.join() I can.
 #aise sa_exc.InvalidRequestError(
 #Can't identify which query entity in which to joined "
 #eager load from.   Please use an exact match when "
 #specifying the join path."
 #

 #f indexes:
 #lause = compile_state.from_clauses[indexes[0]]
                # join to an existing FROM clause on the query.
                # key it to its list index in the eager_joins dict.
                # Query._compile_context will adapt as needed and
                # append to the FROM clause of the select().
 #uery_entity_key, default_towrap = indexes[0], clause

 #f query_entity_key is None:
 #uery_entity_key, default_towrap = (
 #uery_entity,
 #uery_entity.selectable,
 #

 #owrap = compile_state.eager_joins.setdefault(
 #uery_entity_key, default_towrap
 #

 #f adapter:
 #f getattr(adapter, "aliased_class", None):
                # joining from an adapted entity.  The adapted entity
                # might be a "with_polymorphic", so resolve that to our
                # specific mapper's entity before looking for our attribute
                # name on it.
 #fm = inspect(adapter.aliased_class)._entity_for_mapper(
 #ocalparent
 #f localparent.isa(self.parent)
 #lse self.parent
 #

                # look for our attribute on the adapted entity, else fall back
                # to our straight property
 #nclause = getattr(efm.entity, self.key, self.parent_property)
 #lse:
 #nclause = getattr(
 #rm_util.AliasedClass(
 #elf.parent, adapter.selectable, use_mapper_path=True
 #,
 #elf.key,
 #elf.parent_property,
 #

 #lse:
 #nclause = self.parent_property

 #ssert clauses.aliased_class is not None

 #ttach_on_outside = (
 #ot chained_from_outerjoin
 #r not innerjoin
 #r innerjoin == "unnested"
 #r query_entity.entity_zero.represents_outer_join
 #

 #xtra_join_criteria = extra_criteria
 #dditional_entity_criteria = compile_state.global_attributes.get(
 #"additional_entity_criteria", self.mapper), ()
 #
 #f additional_entity_criteria:
 #xtra_join_criteria += tuple(
 #e._resolve_where_criteria(self.mapper)
 #or ae in additional_entity_criteria
 #f ae.propagate_to_loaders
 #

 #f attach_on_outside:
            # this is the "classic" eager join case.
 #agerjoin = orm_util._ORMJoin(
 #owrap,
 #lauses.aliased_class,
 #nclause,
 #souter=not innerjoin
 #r query_entity.entity_zero.represents_outer_join
 #r (chained_from_outerjoin and isinstance(towrap, sql.Join)),
 #left_memo=self.parent,
 #right_memo=self.mapper,
 #extra_criteria=extra_join_criteria,
 #
 #lse:
            # all other cases are innerjoin=='nested' approach
 #agerjoin = self._splice_nested_inner_join(
 #ath, towrap, clauses, onclause, extra_join_criteria
 #

 #ompile_state.eager_joins[query_entity_key] = eagerjoin

        # send a hint to the Query as to where it may "splice" this join
 #agerjoin.stop_on = query_entity.selectable

 #f not parentmapper:
            # for parentclause that is the non-eager end of the join,
            # ensure all the parent cols in the primaryjoin are actually
            # in the
            # columns clause (i.e. are not deferred), so that aliasing applied
            # by the Query propagates those columns outward.
            # This has the effect
            # of "undefering" those columns.
 #or col in sql_util._find_columns(
 #elf.parent_property.primaryjoin
 #:
 #f localparent.persist_selectable.c.contains_column(col):
 #f adapter:
 #ol = adapter.columns[col]
 #ompile_state.primary_columns.append(col)

 #f self.parent_property.order_by:
 #ompile_state.eager_order_by += tuple(
 #eagerjoin._target_adapter.copy_and_process)(
 #til.to_list(self.parent_property.order_by)
 #
 #

 #ef _splice_nested_inner_join(
 #elf, path, join_obj, clauses, onclause, extra_criteria, splicing=False
 #:

 #f splicing is False:
            # first call is always handed a join object
            # from the outside
 #ssert isinstance(join_obj, orm_util._ORMJoin)
 #lif isinstance(join_obj, sql.selectable.FromGrouping):
 #eturn self._splice_nested_inner_join(
 #ath,
 #oin_obj.element,
 #lauses,
 #nclause,
 #xtra_criteria,
 #plicing,
 #
 #lif not isinstance(join_obj, orm_util._ORMJoin):
 #f path[-2] is splicing:
 #eturn orm_util._ORMJoin(
 #oin_obj,
 #lauses.aliased_class,
 #nclause,
 #souter=False,
 #left_memo=splicing,
 #right_memo=path[-1].mapper,
 #extra_criteria=extra_criteria,
 #
 #lse:
                # only here if splicing == True
 #eturn None

 #arget_join = self._splice_nested_inner_join(
 #ath,
 #oin_obj.right,
 #lauses,
 #nclause,
 #xtra_criteria,
 #oin_obj._right_memo,
 #
 #f target_join is None:
 #ight_splice = False
 #arget_join = self._splice_nested_inner_join(
 #ath,
 #oin_obj.left,
 #lauses,
 #nclause,
 #xtra_criteria,
 #oin_obj._left_memo,
 #
 #f target_join is None:
                # should only return None when recursively called,
                # e.g. splicing==True
 #ssert (
 #plicing is not False
 #, "assertion failed attempting to produce joined eager loads"
 #eturn None
 #lse:
 #ight_splice = True

 #f right_splice:
            # for a right splice, attempt to flatten out
            # a JOIN b JOIN c JOIN .. to avoid needless
            # parenthesis nesting
 #f not join_obj.isouter and not target_join.isouter:
 #agerjoin = join_obj._splice_into_center(target_join)
 #lse:
 #agerjoin = orm_util._ORMJoin(
 #oin_obj.left,
 #arget_join,
 #oin_obj.onclause,
 #souter=join_obj.isouter,
 #left_memo=join_obj._left_memo,
 #
 #lse:
 #agerjoin = orm_util._ORMJoin(
 #arget_join,
 #oin_obj.right,
 #oin_obj.onclause,
 #souter=join_obj.isouter,
 #right_memo=join_obj._right_memo,
 #

 #agerjoin._target_adapter = target_join._target_adapter
 #eturn eagerjoin

 #ef _create_eager_adapter(self, context, result, adapter, path, loadopt):
 #ompile_state = context.compile_state

 #ser_defined_adapter = (
 #elf._init_user_defined_eager_proc(
 #oadopt, compile_state, context.attributes
 #
 #f loadopt
 #lse False
 #

 #f user_defined_adapter is not False:
 #ecorator = user_defined_adapter
            # user defined eagerloads are part of the "primary"
            # portion of the load.
            # the adapters applied to the Query should be honored.
 #f compile_state.compound_eager_adapter and decorator:
 #ecorator = decorator.wrap(
 #ompile_state.compound_eager_adapter
 #
 #lif compile_state.compound_eager_adapter:
 #ecorator = compile_state.compound_eager_adapter
 #lse:
 #ecorator = path.get(
 #ompile_state.attributes, "eager_row_processor"
 #
 #f decorator is None:
 #eturn False

 #f self.mapper._result_has_identity_key(result, decorator):
 #eturn decorator
 #lse:
            # no identity key - don't return a row
            # processor, will cause a degrade to lazy
 #eturn False

 #ef create_row_processor(
 #elf,
 #ontext,
 #uery_entity,
 #ath,
 #oadopt,
 #apper,
 #esult,
 #dapter,
 #opulators,
 #:
 #f not self.parent.class_manager[self.key].impl.supports_population:
 #aise sa_exc.InvalidRequestError(
 #'%s' does not support object "
 #population - eager loading cannot be applied." % self
 #

 #f self.uselist:
 #ontext.loaders_require_uniquing = True

 #ur_path = path[self.parent_property]

 #ager_adapter = self._create_eager_adapter(
 #ontext, result, adapter, our_path, loadopt
 #

 #f eager_adapter is not False:
 #ey = self.key

 #instance = loading._instance_processor(
 #uery_entity,
 #elf.mapper,
 #ontext,
 #esult,
 #ur_path[self.entity],
 #ager_adapter,
 #

 #f not self.uselist:
 #elf._create_scalar_loader(context, key, _instance, populators)
 #lse:
 #elf._create_collection_loader(
 #ontext, key, _instance, populators
 #
 #lse:
 #elf.parent_property._get_strategy(
 #("lazy", "select"),)
 #.create_row_processor(
 #ontext,
 #uery_entity,
 #ath,
 #oadopt,
 #apper,
 #esult,
 #dapter,
 #opulators,
 #

 #ef _create_collection_loader(self, context, key, _instance, populators):
 #ef load_collection_from_joined_new_row(state, dict_, row):
            # note this must unconditionally clear out any existing collection.
            # an existing collection would be present only in the case of
            # populate_existing().
 #ollection = attributes.init_state_collection(state, dict_, key)
 #esult_list = util.UniqueAppender(
 #ollection, "append_without_event"
 #
 #ontext.attributes[(state, key)] = result_list
 #nst = _instance(row)
 #f inst is not None:
 #esult_list.append(inst)

 #ef load_collection_from_joined_existing_row(state, dict_, row):
 #f (state, key) in context.attributes:
 #esult_list = context.attributes[(state, key)]
 #lse:
                # appender_key can be absent from context.attributes
                # with isnew=False when self-referential eager loading
                # is used; the same instance may be present in two
                # distinct sets of result columns
 #ollection = attributes.init_state_collection(
 #tate, dict_, key
 #
 #esult_list = util.UniqueAppender(
 #ollection, "append_without_event"
 #
 #ontext.attributes[(state, key)] = result_list
 #nst = _instance(row)
 #f inst is not None:
 #esult_list.append(inst)

 #ef load_collection_from_joined_exec(state, dict_, row):
 #instance(row)

 #opulators["new"].append(
 #self.key, load_collection_from_joined_new_row)
 #
 #opulators["existing"].append(
 #self.key, load_collection_from_joined_existing_row)
 #
 #f context.invoke_all_eagers:
 #opulators["eager"].append(
 #self.key, load_collection_from_joined_exec)
 #

 #ef _create_scalar_loader(self, context, key, _instance, populators):
 #ef load_scalar_from_joined_new_row(state, dict_, row):
            # set a scalar object instance directly on the parent
            # object, bypassing InstrumentedAttribute event handlers.
 #ict_[key] = _instance(row)

 #ef load_scalar_from_joined_existing_row(state, dict_, row):
            # call _instance on the row, even though the object has
            # been created, so that we further descend into properties
 #xisting = _instance(row)

            # conflicting value already loaded, this shouldn't happen
 #f key in dict_:
 #f existing is not dict_[key]:
 #til.warn(
 #Multiple rows returned with "
 #uselist=False for eagerly-loaded attribute '%s' "
 # self
 #
 #lse:
                # this case is when one row has multiple loads of the
                # same entity (e.g. via aliasing), one has an attribute
                # that the other doesn't.
 #ict_[key] = existing

 #ef load_scalar_from_joined_exec(state, dict_, row):
 #instance(row)

 #opulators["new"].append((self.key, load_scalar_from_joined_new_row))
 #opulators["existing"].append(
 #self.key, load_scalar_from_joined_existing_row)
 #
 #f context.invoke_all_eagers:
 #opulators["eager"].append(
 #self.key, load_scalar_from_joined_exec)
 #


@log.class_logger
@relationships.RelationshipProperty.strategy_for(lazy="selectin")
class SelectInLoader(PostLoader, util.MemoizedSlots):
 #_slots__ = (
 #join_depth",
 #omit_join",
 #_parent_alias",
 #_query_info",
 #_fallback_query_info",
 #_lambda_cache",
 #

 #uery_info = collections.namedtuple(
 #queryinfo",
 #
 #load_only_child",
 #load_with_join",
 #in_expr",
 #pk_cols",
 #zero_idx",
 #child_lookup_cols",
 #,
 #

 #chunksize = 500

 #ef __init__(self, parent, strategy_key):
 #uper(SelectInLoader, self).__init__(parent, strategy_key)
 #elf.join_depth = self.parent_property.join_depth
 #s_m2o = self.parent_property.direction is interfaces.MANYTOONE

 #f self.parent_property.omit_join is not None:
 #elf.omit_join = self.parent_property.omit_join
 #lse:
 #azyloader = self.parent_property._get_strategy(
 #("lazy", "select"),)
 #
 #f is_m2o:
 #elf.omit_join = lazyloader.use_get
 #lse:
 #elf.omit_join = self.parent._get_clause[0].compare(
 #azyloader._rev_lazywhere,
 #se_proxies=True,
 #ompare_keys=False,
 #quivalents=self.parent._equivalent_columns,
 #

 #f self.omit_join:
 #f is_m2o:
 #elf._query_info = self._init_for_omit_join_m2o()
 #elf._fallback_query_info = self._init_for_join()
 #lse:
 #elf._query_info = self._init_for_omit_join()
 #lse:
 #elf._query_info = self._init_for_join()

 #ef _init_for_omit_join(self):
 #k_to_fk = dict(
 #elf.parent_property._join_condition.local_remote_pairs
 #
 #k_to_fk.update(
 #equiv, pk_to_fk[k])
 #or k in list(pk_to_fk)
 #or equiv in self.parent._equivalent_columns.get(k, ())
 #

 #k_cols = fk_cols = [
 #k_to_fk[col] for col in self.parent.primary_key if col in pk_to_fk
 #
 #f len(fk_cols) > 1:
 #n_expr = sql.tuple_(*fk_cols)
 #ero_idx = False
 #lse:
 #n_expr = fk_cols[0]
 #ero_idx = True

 #eturn self.query_info(False, False, in_expr, pk_cols, zero_idx, None)

 #ef _init_for_omit_join_m2o(self):
 #k_cols = self.mapper.primary_key
 #f len(pk_cols) > 1:
 #n_expr = sql.tuple_(*pk_cols)
 #ero_idx = False
 #lse:
 #n_expr = pk_cols[0]
 #ero_idx = True

 #azyloader = self.parent_property._get_strategy((("lazy", "select"),))
 #ookup_cols = [lazyloader._equated_columns[pk] for pk in pk_cols]

 #eturn self.query_info(
 #rue, False, in_expr, pk_cols, zero_idx, lookup_cols
 #

 #ef _init_for_join(self):
 #elf._parent_alias = aliased(self.parent.class_)
 #a_insp = inspect(self._parent_alias)
 #k_cols = [
 #a_insp._adapt_element(col) for col in self.parent.primary_key
 #
 #f len(pk_cols) > 1:
 #n_expr = sql.tuple_(*pk_cols)
 #ero_idx = False
 #lse:
 #n_expr = pk_cols[0]
 #ero_idx = True
 #eturn self.query_info(False, True, in_expr, pk_cols, zero_idx, None)

 #ef init_class_attribute(self, mapper):
 #elf.parent_property._get_strategy(
 #("lazy", "select"),)
 #.init_class_attribute(mapper)

 #ef _memoized_attr__lambda_cache(self):
        # cache is per lazy loader, and is used for caching of
        # sqlalchemy.sql.lambdas.AnalyzedCode and
        # sqlalchemy.sql.lambdas.AnalyzedFunction objects which are generated
        # from the StatementLambda used.
 #eturn util.LRUCache(30)

 #ef create_row_processor(
 #elf,
 #ontext,
 #uery_entity,
 #ath,
 #oadopt,
 #apper,
 #esult,
 #dapter,
 #opulators,
 #:

 #f context.refresh_state:
 #eturn self._immediateload_create_row_processor(
 #ontext,
 #uery_entity,
 #ath,
 #oadopt,
 #apper,
 #esult,
 #dapter,
 #opulators,
 #
 #lif self._check_recursive_postload(context, path, self.join_depth):
 #eturn

 #f not self.parent.class_manager[self.key].impl.supports_population:
 #aise sa_exc.InvalidRequestError(
 #'%s' does not support object "
 #population - eager loading cannot be applied." % self
 #

        # a little dance here as the "path" is still something that only
        # semi-tracks the exact series of things we are loading, still not
        # telling us about with_polymorphic() and stuff like that when it's at
        # the root..  the initial MapperEntity is more accurate for this case.
 #f len(path) == 1:
 #f not orm_util._entity_isa(query_entity.entity_zero, self.parent):
 #eturn
 #lif not orm_util._entity_isa(path[-1], self.parent):
 #eturn

 #electin_path = (
 #ontext.compile_state.current_path or orm_util.PathRegistry.root
 # + path

 #ath_w_prop = path[self.parent_property]

        # build up a path indicating the path from the leftmost
        # entity to the thing we're subquery loading.
 #ith_poly_entity = path_w_prop.get(
 #ontext.attributes, "path_with_polymorphic", None
 #
 #f with_poly_entity is not None:
 #ffective_entity = inspect(with_poly_entity)
 #lse:
 #ffective_entity = self.entity

 #oading.PostLoad.callable_for_path(
 #ontext,
 #electin_path,
 #elf.parent,
 #elf.parent_property,
 #elf._load_for_path,
 #ffective_entity,
 #oadopt,
 #

 #ef _load_for_path(
 #elf, context, path, states, load_only, effective_entity, loadopt
 #:
 #f load_only and self.key not in load_only:
 #eturn

 #uery_info = self._query_info

 #f query_info.load_only_child:
 #ur_states = collections.defaultdict(list)
 #one_states = []

 #apper = self.parent

 #or state, overwrite in states:
 #tate_dict = state.dict
 #elated_ident = tuple(
 #apper._get_state_attr_by_column(
 #tate,
 #tate_dict,
 #k,
 #assive=attributes.PASSIVE_NO_FETCH,
 #
 #or lk in query_info.child_lookup_cols
 #
                # if the loaded parent objects do not have the foreign key
                # to the related item loaded, then degrade into the joined
                # version of selectinload
 #f attributes.PASSIVE_NO_RESULT in related_ident:
 #uery_info = self._fallback_query_info
 #reak

                # organize states into lists keyed to particular foreign
                # key values.
 #f None not in related_ident:
 #ur_states[related_ident].append(
 #state, state_dict, overwrite)
 #
 #lse:
                    # For FK values that have None, add them to a
                    # separate collection that will be populated separately
 #one_states.append((state, state_dict, overwrite))

        # note the above conditional may have changed query_info
 #f not query_info.load_only_child:
 #ur_states = [
 #state.key[1], state, state.dict, overwrite)
 #or state, overwrite in states
 #

 #k_cols = query_info.pk_cols
 #n_expr = query_info.in_expr

 #f not query_info.load_with_join:
            # in "omit join" mode, the primary key column and the
            # "in" expression are in terms of the related entity.  So
            # if the related entity is polymorphic or otherwise aliased,
            # we need to adapt our "pk_cols" and "in_expr" to that
            # entity.   in non-"omit join" mode, these are against the
            # parent entity and do not need adaption.
 #f effective_entity.is_aliased_class:
 #k_cols = [
 #ffective_entity._adapt_element(col) for col in pk_cols
 #
 #n_expr = effective_entity._adapt_element(in_expr)

 # = sql.lambda_stmt(
 #ambda: sql.select(
 #rm_util.Bundle("pk", *pk_cols), effective_entity
 #
 #set_label_style(LABEL_STYLE_TABLENAME_PLUS_COL)
 #_set_compile_options(ORMCompileState.default_compile_options)
 #_set_propagate_attrs(
 #
 #compile_state_plugin": "orm",
 #plugin_subject": effective_entity,
 #
 #,
 #ambda_cache=self._lambda_cache,
 #lobal_track_bound_values=False,
 #rack_on=(self, effective_entity) + (tuple(pk_cols),),
 #

 #f not self.parent_property.bake_queries:
 # = q.spoil()

 #f not query_info.load_with_join:
            # the Bundle we have in the "omit_join" case is against raw, non
            # annotated columns, so to ensure the Query knows its primary
            # entity, we add it explicitly.  If we made the Bundle against
            # annotated columns, we hit a performance issue in this specific
            # case, which is detailed in issue #4347.
 # = q.add_criteria(lambda q: q.select_from(effective_entity))
 #lse:
            # in the non-omit_join case, the Bundle is against the annotated/
            # mapped column of the parent entity, but the #4347 issue does not
            # occur in this case.
 # = q.add_criteria(
 #ambda q: q.select_from(self._parent_alias).join(
 #etattr(
 #elf._parent_alias, self.parent_property.key
 #.of_type(effective_entity)
 #,
 #rack_on=[self],
 #

 # = q.add_criteria(
 #ambda q: q.filter(in_expr.in_(sql.bindparam("primary_keys")))
 #
        # a test which exercises what these comments talk about is
        # test_selectin_relations.py -> test_twolevel_selectin_w_polymorphic
        #
        # effective_entity above is given to us in terms of the cached
        # statement, namely this one:
 #rig_query = context.compile_state.select_statement

        # the actual statement that was requested is this one:
        #  context_query = context.query
        #
        # that's not the cached one, however.  So while it is of the identical
        # structure, if it has entities like AliasedInsp, which we get from
        # aliased() or with_polymorphic(), the AliasedInsp will likely be a
        # different object identity each time, and will not match up
        # hashing-wise to the corresponding AliasedInsp that's in the
        # cached query, meaning it won't match on paths and loader lookups
        # and loaders like this one will be skipped if it is used in options.
        #
        # Now we want to transfer loader options from the parent query to the
        # "selectinload" query we're about to run.   Which query do we transfer
        # the options from?  We use the cached query, because the options in
        # that query will be in terms of the effective entity we were just
        # handed.
        #
        # But now the selectinload query we are running is *also*
        # cached.  What if it's cached and running from some previous iteration
        # of that AliasedInsp?  Well in that case it will also use the previous
        # iteration of the loader options.   If the query expires and
        # gets generated again, it will be handed the current effective_entity
        # and the current _with_options, again in terms of whatever
        # compile_state.select_statement happens to be right now, so the
        # query will still be internally consistent and loader callables
        # will be correctly invoked.

 #ffective_path = path[self.parent_property]

 #ptions = orig_query._with_options

 #f loadopt and loadopt._extra_criteria:
 #ptions += (
 #rm_util.LoaderCriteriaOption(
 #ffective_entity,
 #oadopt._generate_extra_criteria(context),
 #,
 #

 # = q.add_criteria(
 #ambda q: q.options(*options)._update_compile_options(
 #"_current_path": effective_path}
 #
 #

 #f context.populate_existing:
 # = q.add_criteria(
 #ambda q: q.execution_options(populate_existing=True)
 #

 #f self.parent_property.order_by:
 #f not query_info.load_with_join:
 #ager_order_by = self.parent_property.order_by
 #f effective_entity.is_aliased_class:
 #ager_order_by = [
 #ffective_entity._adapt_element(elem)
 #or elem in eager_order_by
 #
 # = q.add_criteria(lambda q: q.order_by(*eager_order_by))
 #lse:

 #ef _setup_outermost_orderby(compile_context):
 #ompile_context.eager_order_by += tuple(
 #til.to_list(self.parent_property.order_by)
 #

 # = q.add_criteria(
 #ambda q: q._add_context_option(
 #setup_outermost_orderby, self.parent_property
 #,
 #rack_on=[self],
 #

 #f query_info.load_only_child:
 #elf._load_via_child(
 #ur_states, none_states, query_info, q, context
 #
 #lse:
 #elf._load_via_parent(our_states, query_info, q, context)

 #ef _load_via_child(self, our_states, none_states, query_info, q, context):
 #selist = self.uselist

        # this sort is really for the benefit of the unit tests
 #ur_keys = sorted(our_states)
 #hile our_keys:
 #hunk = our_keys[0 : self._chunksize]
 #ur_keys = our_keys[self._chunksize :]
 #ata = {
 #: v
 #or k, v in context.session.execute(
 #,
 #arams={
 #primary_keys": [
 #ey[0] if query_info.zero_idx else key
 #or key in chunk
 #
 #,
 #.unique()
 #

 #or key in chunk:
                # for a real foreign key and no concurrent changes to the
                # DB while running this method, "key" is always present in
                # data.  However, for primaryjoins without real foreign keys
                # a non-None primaryjoin condition may still refer to no
                # related object.
 #elated_obj = data.get(key, None)
 #or state, dict_, overwrite in our_states[key]:
 #f not overwrite and self.key in dict_:
 #ontinue

 #tate.get_impl(self.key).set_committed_value(
 #tate,
 #ict_,
 #elated_obj if not uselist else [related_obj],
 #
        # populate none states with empty value / collection
 #or state, dict_, overwrite in none_states:
 #f not overwrite and self.key in dict_:
 #ontinue

            # note it's OK if this is a uselist=True attribute, the empty
            # collection will be populated
 #tate.get_impl(self.key).set_committed_value(state, dict_, None)

 #ef _load_via_parent(self, our_states, query_info, q, context):
 #selist = self.uselist
 #empty_result = () if uselist else None

 #hile our_states:
 #hunk = our_states[0 : self._chunksize]
 #ur_states = our_states[self._chunksize :]

 #rimary_keys = [
 #ey[0] if query_info.zero_idx else key
 #or key, state, state_dict, overwrite in chunk
 #

 #ata = collections.defaultdict(list)
 #or k, v in itertools.groupby(
 #ontext.session.execute(
 #, params={"primary_keys": primary_keys}
 #.unique(),
 #ambda x: x[0],
 #:
 #ata[k].extend(vv[1] for vv in v)

 #or key, state, state_dict, overwrite in chunk:

 #f not overwrite and self.key in state_dict:
 #ontinue

 #ollection = data.get(key, _empty_result)

 #f not uselist and collection:
 #f len(collection) > 1:
 #til.warn(
 #Multiple rows returned with "
 #uselist=False for eagerly-loaded "
 #attribute '%s' " % self
 #
 #tate.get_impl(self.key).set_committed_value(
 #tate, state_dict, collection[0]
 #
 #lse:
                    # note that empty tuple set on uselist=False sets the
                    # value to None
 #tate.get_impl(self.key).set_committed_value(
 #tate, state_dict, collection
 #


def single_parent_validator(desc, prop):
 #ef _do_check(state, value, oldvalue, initiator):
 #f value is not None and initiator.key == prop.key:
 #asparent = initiator.hasparent(attributes.instance_state(value))
 #f hasparent and oldvalue is not value:
 #aise sa_exc.InvalidRequestError(
 #Instance %s is already associated with an instance "
 #of %s via its %s attribute, and is only allowed a "
 #single parent."
 # (orm_util.instance_str(value), state.class_, prop),
 #ode="bbf1",
 #
 #eturn value

 #ef append(state, value, initiator):
 #eturn _do_check(state, value, None, initiator)

 #ef set_(state, value, oldvalue, initiator):
 #eturn _do_check(state, value, oldvalue, initiator)

 #vent.listen(
 #esc, "append", append, raw=True, retval=True, active_history=True
 #
 #vent.listen(desc, "set", set_, raw=True, retval=True, active_history=True)
