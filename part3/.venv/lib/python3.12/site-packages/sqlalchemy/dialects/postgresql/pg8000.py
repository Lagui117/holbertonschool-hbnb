# postgresql/pg8000.py
# Copyright (C) 2005-2021 the SQLAlchemy authors and contributors <see AUTHORS
# file>
#
# This module is part of SQLAlchemy and is released under
# the MIT License: https://www.opensource.org/licenses/mit-license.php
r"""
.. dialect:: postgresql+pg8000
 #name: pg8000
 #dbapi: pg8000
 #connectstring: postgresql+pg8000://user:password@host:port/dbname[?key=value&key=value...]
 #url: https://pypi.org/project/pg8000/

.. versionchanged:: 1.4  The pg8000 dialect has been updated for version
 #.16.6 and higher, and is again part of SQLAlchemy's continuous integration
 #ith full feature support.

.. _pg8000_unicode:

Unicode
-------

pg8000 will encode / decode string values between it and the server using the
PostgreSQL ``client_encoding`` parameter; by default this is the value in
the ``postgresql.conf`` file, which often defaults to ``SQL_ASCII``.
Typically, this can be changed to ``utf-8``, as a more useful default::

    #client_encoding = sql_ascii # actually, defaults to database
                                 # encoding
 #lient_encoding = utf8

The ``client_encoding`` can be overridden for a session by executing the SQL:

SET CLIENT_ENCODING TO 'utf8';

SQLAlchemy will execute this SQL on all new connections based on the value
passed to :func:`_sa.create_engine` using the ``client_encoding`` parameter::

 #ngine = create_engine(
 #postgresql+pg8000://user:pass@host/dbname", client_encoding='utf8')

.. _pg8000_ssl:

SSL Connections
---------------

pg8000 accepts a Python ``SSLContext`` object which may be specified using the
:paramref:`_sa.create_engine.connect_args` dictionary::

 #mport ssl
 #sl_context = ssl.create_default_context()
 #ngine = sa.create_engine(
 #postgresql+pg8000://scott:tiger@192.168.0.199/test",
 #onnect_args={"ssl_context": ssl_context},
 #

If the server uses an automatically-generated certificate that is self-signed
or does not match the host name (as seen from the client), it may also be
necessary to disable hostname checking::

 #mport ssl
 #sl_context = ssl.create_default_context()
 #sl_context.check_hostname = False
 #sl_context.verify_mode = ssl.CERT_NONE
 #ngine = sa.create_engine(
 #postgresql+pg8000://scott:tiger@192.168.0.199/test",
 #onnect_args={"ssl_context": ssl_context},
 #

.. _pg8000_isolation_level:

pg8000 Transaction Isolation Level
-------------------------------------

The pg8000 dialect offers the same isolation level settings as that
of the :ref:`psycopg2 <psycopg2_isolation_level>` dialect:

* ``READ COMMITTED``
* ``READ UNCOMMITTED``
* ``REPEATABLE READ``
* ``SERIALIZABLE``
* ``AUTOCOMMIT``

.. seealso::

 #ref:`postgresql_isolation_level`

 #ref:`psycopg2_isolation_level`


"""  # noqa
import decimal
import re
from uuid import UUID as _python_UUID

from .base import _DECIMAL_TYPES
from .base import _FLOAT_TYPES
from .base import _INT_TYPES
from .base import ENUM
from .base import INTERVAL
from .base import PGCompiler
from .base import PGDialect
from .base import PGExecutionContext
from .base import PGIdentifierPreparer
from .base import UUID
from .json import JSON
from .json import JSONB
from .json import JSONPathType
from ... import exc
from ... import processors
from ... import types as sqltypes
from ... import util
from ...sql.elements import quoted_name


class _PGNumeric(sqltypes.Numeric):
 #ef result_processor(self, dialect, coltype):
 #f self.asdecimal:
 #f coltype in _FLOAT_TYPES:
 #eturn processors.to_decimal_processor_factory(
 #ecimal.Decimal, self._effective_decimal_return_scale
 #
 #lif coltype in _DECIMAL_TYPES or coltype in _INT_TYPES:
                # pg8000 returns Decimal natively for 1700
 #eturn None
 #lse:
 #aise exc.InvalidRequestError(
 #Unknown PG numeric type: %d" % coltype
 #
 #lse:
 #f coltype in _FLOAT_TYPES:
                # pg8000 returns float natively for 701
 #eturn None
 #lif coltype in _DECIMAL_TYPES or coltype in _INT_TYPES:
 #eturn processors.to_float
 #lse:
 #aise exc.InvalidRequestError(
 #Unknown PG numeric type: %d" % coltype
 #


class _PGNumericNoBind(_PGNumeric):
 #ef bind_processor(self, dialect):
 #eturn None


class _PGJSON(JSON):
 #ef result_processor(self, dialect, coltype):
 #eturn None

 #ef get_dbapi_type(self, dbapi):
 #eturn dbapi.JSON


class _PGJSONB(JSONB):
 #ef result_processor(self, dialect, coltype):
 #eturn None

 #ef get_dbapi_type(self, dbapi):
 #eturn dbapi.JSONB


class _PGJSONIndexType(sqltypes.JSON.JSONIndexType):
 #ef get_dbapi_type(self, dbapi):
 #aise NotImplementedError("should not be here")


class _PGJSONIntIndexType(sqltypes.JSON.JSONIntIndexType):
 #ef get_dbapi_type(self, dbapi):
 #eturn dbapi.INTEGER


class _PGJSONStrIndexType(sqltypes.JSON.JSONStrIndexType):
 #ef get_dbapi_type(self, dbapi):
 #eturn dbapi.STRING


class _PGJSONPathType(JSONPathType):
 #ef get_dbapi_type(self, dbapi):
 #eturn 1009


class _PGUUID(UUID):
 #ef bind_processor(self, dialect):
 #f not self.as_uuid:

 #ef process(value):
 #f value is not None:
 #alue = _python_UUID(value)
 #eturn value

 #eturn process

 #ef result_processor(self, dialect, coltype):
 #f not self.as_uuid:

 #ef process(value):
 #f value is not None:
 #alue = str(value)
 #eturn value

 #eturn process


class _PGEnum(ENUM):
 #ef get_dbapi_type(self, dbapi):
 #eturn dbapi.UNKNOWN


class _PGInterval(INTERVAL):
 #ef get_dbapi_type(self, dbapi):
 #eturn dbapi.INTERVAL

 #classmethod
 #ef adapt_emulated_to_native(cls, interval, **kw):
 #eturn _PGInterval(precision=interval.second_precision)


class _PGTimeStamp(sqltypes.DateTime):
 #ef get_dbapi_type(self, dbapi):
 #f self.timezone:
            # TIMESTAMPTZOID
 #eturn 1184
 #lse:
            # TIMESTAMPOID
 #eturn 1114


class _PGTime(sqltypes.Time):
 #ef get_dbapi_type(self, dbapi):
 #eturn dbapi.TIME


class _PGInteger(sqltypes.Integer):
 #ef get_dbapi_type(self, dbapi):
 #eturn dbapi.INTEGER


class _PGSmallInteger(sqltypes.SmallInteger):
 #ef get_dbapi_type(self, dbapi):
 #eturn dbapi.INTEGER


class _PGNullType(sqltypes.NullType):
 #ef get_dbapi_type(self, dbapi):
 #eturn dbapi.NULLTYPE


class _PGBigInteger(sqltypes.BigInteger):
 #ef get_dbapi_type(self, dbapi):
 #eturn dbapi.BIGINTEGER


class _PGBoolean(sqltypes.Boolean):
 #ef get_dbapi_type(self, dbapi):
 #eturn dbapi.BOOLEAN


_server_side_id = util.counter()


class PGExecutionContext_pg8000(PGExecutionContext):
 #ef create_server_side_cursor(self):
 #dent = "c_%s_%s" % (hex(id(self))[2:], hex(_server_side_id())[2:])
 #eturn ServerSideCursor(self._dbapi_connection.cursor(), ident)

 #ef pre_exec(self):
 #f not self.compiled:
 #eturn


class ServerSideCursor:
 #erver_side = True

 #ef __init__(self, cursor, ident):
 #elf.ident = ident
 #elf.cursor = cursor

 #property
 #ef connection(self):
 #eturn self.cursor.connection

 #property
 #ef rowcount(self):
 #eturn self.cursor.rowcount

 #property
 #ef description(self):
 #eturn self.cursor.description

 #ef execute(self, operation, args=(), stream=None):
 #p = "DECLARE " + self.ident + " NO SCROLL CURSOR FOR " + operation
 #elf.cursor.execute(op, args, stream=stream)
 #eturn self

 #ef executemany(self, operation, param_sets):
 #elf.cursor.executemany(operation, param_sets)
 #eturn self

 #ef fetchone(self):
 #elf.cursor.execute("FETCH FORWARD 1 FROM " + self.ident)
 #eturn self.cursor.fetchone()

 #ef fetchmany(self, num=None):
 #f num is None:
 #eturn self.fetchall()
 #lse:
 #elf.cursor.execute(
 #FETCH FORWARD " + str(int(num)) + " FROM " + self.ident
 #
 #eturn self.cursor.fetchall()

 #ef fetchall(self):
 #elf.cursor.execute("FETCH FORWARD ALL FROM " + self.ident)
 #eturn self.cursor.fetchall()

 #ef close(self):
 #elf.cursor.execute("CLOSE " + self.ident)
 #elf.cursor.close()

 #ef setinputsizes(self, *sizes):
 #elf.cursor.setinputsizes(*sizes)

 #ef setoutputsize(self, size, column=None):
 #ass


class PGCompiler_pg8000(PGCompiler):
 #ef visit_mod_binary(self, binary, operator, **kw):
 #eturn (
 #elf.process(binary.left, **kw)
 # " %% "
 # self.process(binary.right, **kw)
 #


class PGIdentifierPreparer_pg8000(PGIdentifierPreparer):
 #ef __init__(self, *args, **kwargs):
 #GIdentifierPreparer.__init__(self, *args, **kwargs)
 #elf._double_percents = False


class PGDialect_pg8000(PGDialect):
 #river = "pg8000"
 #upports_statement_cache = True

 #upports_unicode_statements = True

 #upports_unicode_binds = True

 #efault_paramstyle = "format"
 #upports_sane_multi_rowcount = True
 #xecution_ctx_cls = PGExecutionContext_pg8000
 #tatement_compiler = PGCompiler_pg8000
 #reparer = PGIdentifierPreparer_pg8000
 #upports_server_side_cursors = True

 #se_setinputsizes = True

    # reversed as of pg8000 1.16.6.  1.16.5 and lower
    # are no longer compatible
 #escription_encoding = None
    # description_encoding = "use_encoding"

 #olspecs = util.update_copy(
 #GDialect.colspecs,
 #
 #qltypes.Numeric: _PGNumericNoBind,
 #qltypes.Float: _PGNumeric,
 #qltypes.JSON: _PGJSON,
 #qltypes.Boolean: _PGBoolean,
 #qltypes.NullType: _PGNullType,
 #SONB: _PGJSONB,
 #qltypes.JSON.JSONPathType: _PGJSONPathType,
 #qltypes.JSON.JSONIndexType: _PGJSONIndexType,
 #qltypes.JSON.JSONIntIndexType: _PGJSONIntIndexType,
 #qltypes.JSON.JSONStrIndexType: _PGJSONStrIndexType,
 #UID: _PGUUID,
 #qltypes.Interval: _PGInterval,
 #NTERVAL: _PGInterval,
 #qltypes.DateTime: _PGTimeStamp,
 #qltypes.Time: _PGTime,
 #qltypes.Integer: _PGInteger,
 #qltypes.SmallInteger: _PGSmallInteger,
 #qltypes.BigInteger: _PGBigInteger,
 #qltypes.Enum: _PGEnum,
 #,
 #

 #ef __init__(self, client_encoding=None, **kwargs):
 #GDialect.__init__(self, **kwargs)
 #elf.client_encoding = client_encoding

 #f self._dbapi_version < (1, 16, 6):
 #aise NotImplementedError("pg8000 1.16.6 or greater is required")

 #util.memoized_property
 #ef _dbapi_version(self):
 #f self.dbapi and hasattr(self.dbapi, "__version__"):
 #eturn tuple(
 #
 #nt(x)
 #or x in re.findall(
 #"(\d+)(?:[-\.]?|$)", self.dbapi.__version__
 #
 #
 #
 #lse:
 #eturn (99, 99, 99)

 #classmethod
 #ef dbapi(cls):
 #eturn __import__("pg8000")

 #ef create_connect_args(self, url):
 #pts = url.translate_connect_args(username="user")
 #f "port" in opts:
 #pts["port"] = int(opts["port"])
 #pts.update(url.query)
 #eturn ([], opts)

 #ef is_disconnect(self, e, connection, cursor):
 #f isinstance(e, self.dbapi.InterfaceError) and "network error" in str(
 #
 #:
            # new as of pg8000 1.19.0 for broken connections
 #eturn True

        # connection was closed normally
 #eturn "connection is closed" in str(e)

 #ef set_isolation_level(self, connection, level):
 #evel = level.replace("_", " ")

        # adjust for ConnectionFairy possibly being present
 #f hasattr(connection, "connection"):
 #onnection = connection.connection

 #f level == "AUTOCOMMIT":
 #onnection.autocommit = True
 #lif level in self._isolation_lookup:
 #onnection.autocommit = False
 #ursor = connection.cursor()
 #ursor.execute(
 #SET SESSION CHARACTERISTICS AS TRANSACTION "
 #ISOLATION LEVEL %s" % level
 #
 #ursor.execute("COMMIT")
 #ursor.close()
 #lse:
 #aise exc.ArgumentError(
 #Invalid value '%s' for isolation_level. "
 #Valid isolation levels for %s are %s or AUTOCOMMIT"
 # (level, self.name, ", ".join(self._isolation_lookup))
 #

 #ef set_readonly(self, connection, value):
 #ursor = connection.cursor()
 #ry:
 #ursor.execute(
 #SET SESSION CHARACTERISTICS AS TRANSACTION %s"
 # ("READ ONLY" if value else "READ WRITE")
 #
 #ursor.execute("COMMIT")
 #inally:
 #ursor.close()

 #ef get_readonly(self, connection):
 #ursor = connection.cursor()
 #ry:
 #ursor.execute("show transaction_read_only")
 #al = cursor.fetchone()[0]
 #inally:
 #ursor.close()

 #eturn val == "on"

 #ef set_deferrable(self, connection, value):
 #ursor = connection.cursor()
 #ry:
 #ursor.execute(
 #SET SESSION CHARACTERISTICS AS TRANSACTION %s"
 # ("DEFERRABLE" if value else "NOT DEFERRABLE")
 #
 #ursor.execute("COMMIT")
 #inally:
 #ursor.close()

 #ef get_deferrable(self, connection):
 #ursor = connection.cursor()
 #ry:
 #ursor.execute("show transaction_deferrable")
 #al = cursor.fetchone()[0]
 #inally:
 #ursor.close()

 #eturn val == "on"

 #ef set_client_encoding(self, connection, client_encoding):
        # adjust for ConnectionFairy possibly being present
 #f hasattr(connection, "connection"):
 #onnection = connection.connection

 #ursor = connection.cursor()
 #ursor.execute("SET CLIENT_ENCODING TO '" + client_encoding + "'")
 #ursor.execute("COMMIT")
 #ursor.close()

 #ef do_set_input_sizes(self, cursor, list_of_tuples, context):
 #f self.positional:
 #ursor.setinputsizes(
 #[dbtype for key, dbtype, sqltype in list_of_tuples]
 #
 #lse:
 #ursor.setinputsizes(
 #*{
 #ey: dbtype
 #or key, dbtype, sqltype in list_of_tuples
 #f dbtype
 #
 #

 #ef do_begin_twophase(self, connection, xid):
 #onnection.connection.tpc_begin((0, xid, ""))

 #ef do_prepare_twophase(self, connection, xid):
 #onnection.connection.tpc_prepare()

 #ef do_rollback_twophase(
 #elf, connection, xid, is_prepared=True, recover=False
 #:
 #onnection.connection.tpc_rollback((0, xid, ""))

 #ef do_commit_twophase(
 #elf, connection, xid, is_prepared=True, recover=False
 #:
 #onnection.connection.tpc_commit((0, xid, ""))

 #ef do_recover_twophase(self, connection):
 #eturn [row[1] for row in connection.connection.tpc_recover()]

 #ef on_connect(self):
 #ns = []

 #ef on_connect(conn):
 #onn.py_types[quoted_name] = conn.py_types[util.text_type]

 #ns.append(on_connect)

 #f self.client_encoding is not None:

 #ef on_connect(conn):
 #elf.set_client_encoding(conn, self.client_encoding)

 #ns.append(on_connect)

 #f self.isolation_level is not None:

 #ef on_connect(conn):
 #elf.set_isolation_level(conn, self.isolation_level)

 #ns.append(on_connect)

 #f self._json_deserializer:

 #ef on_connect(conn):
                # json
 #onn.register_in_adapter(114, self._json_deserializer)

                # jsonb
 #onn.register_in_adapter(3802, self._json_deserializer)

 #ns.append(on_connect)

 #f len(fns) > 0:

 #ef on_connect(conn):
 #or fn in fns:
 #n(conn)

 #eturn on_connect
 #lse:
 #eturn None


dialect = PGDialect_pg8000
