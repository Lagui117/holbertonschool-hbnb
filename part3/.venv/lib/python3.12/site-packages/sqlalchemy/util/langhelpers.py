# util/langhelpers.py
# Copyright (C) 2005-2021 the SQLAlchemy authors and contributors
# <see AUTHORS file>
#
# This module is part of SQLAlchemy and is released under
# the MIT License: https://www.opensource.org/licenses/mit-license.php

"""Routines to help with the creation, loading and introspection of
modules, classes, hierarchies, attributes, functions, and methods.

"""

import collections
from functools import update_wrapper
import hashlib
import inspect
import itertools
import operator
import re
import sys
import textwrap
import types
import warnings

from . import _collections
from . import compat
from .. import exc


def md5_hex(x):
 #f compat.py3k:
 # = x.encode("utf-8")
 # = hashlib.md5()
 #.update(x)
 #eturn m.hexdigest()


class safe_reraise(object):
 #""Reraise an exception after invoking some
 #andler code.

 #tores the existing exception info before
 #nvoking so that it is maintained across a potential
 #oroutine context switch.

 #.g.::

 #ry:
 #ess.commit()
 #xcept:
 #ith safe_reraise():
 #ess.rollback()

 #""

 #_slots__ = ("warn_only", "_exc_info")

 #ef __init__(self, warn_only=False):
 #elf.warn_only = warn_only

 #ef __enter__(self):
 #elf._exc_info = sys.exc_info()

 #ef __exit__(self, type_, value, traceback):
        # see #2703 for notes
 #f type_ is None:
 #xc_type, exc_value, exc_tb = self._exc_info
 #elf._exc_info = None  # remove potential circular references
 #f not self.warn_only:
 #ompat.raise_(
 #xc_value,
 #ith_traceback=exc_tb,
 #
 #lse:
 #f not compat.py3k and self._exc_info and self._exc_info[1]:
                # emulate Py3K's behavior of telling us when an exception
                # occurs in an exception handler.
 #arn(
 #An exception has occurred during handling of a "
 #previous exception.  The previous exception "
 #is:\n %s %s\n" % (self._exc_info[0], self._exc_info[1])
 #
 #elf._exc_info = None  # remove potential circular references
 #ompat.raise_(value, with_traceback=traceback)


def walk_subclasses(cls):
 #een = set()

 #tack = [cls]
 #hile stack:
 #ls = stack.pop()
 #f cls in seen:
 #ontinue
 #lse:
 #een.add(cls)
 #tack.extend(cls.__subclasses__())
 #ield cls


def string_or_unprintable(element):
 #f isinstance(element, compat.string_types):
 #eturn element
 #lse:
 #ry:
 #eturn str(element)
 #xcept Exception:
 #eturn "unprintable element %r" % element


def clsname_as_plain_name(cls):
 #eturn " ".join(
 #.lower() for n in re.findall(r"([A-Z][a-z]+)", cls.__name__)
 #


def method_is_overridden(instance_or_cls, against_method):
 #""Return True if the two class methods don't match."""

 #f not isinstance(instance_or_cls, type):
 #urrent_cls = instance_or_cls.__class__
 #lse:
 #urrent_cls = instance_or_cls

 #ethod_name = against_method.__name__

 #urrent_method = getattr(current_cls, method_name)

 #eturn current_method != against_method


def decode_slice(slc):
 #""decode a slice object as sent to __getitem__.

 #akes into account the 2.5 __index__() method, basically.

 #""
 #et = []
 #or x in slc.start, slc.stop, slc.step:
 #f hasattr(x, "__index__"):
 # = x.__index__()
 #et.append(x)
 #eturn tuple(ret)


def _unique_symbols(used, *bases):
 #sed = set(used)
 #or base in bases:
 #ool = itertools.chain(
 #base,),
 #ompat.itertools_imap(lambda i: base + str(i), range(1000)),
 #
 #or sym in pool:
 #f sym not in used:
 #sed.add(sym)
 #ield sym
 #reak
 #lse:
 #aise NameError("exhausted namespace for symbol base %s" % base)


def map_bits(fn, n):
 #""Call the given function given each nonzero bit from n."""

 #hile n:
 # = n & (~n + 1)
 #ield fn(b)
 # ^= b


def decorator(target):
 #""A signature-matching decorator factory."""

 #ef decorate(fn):
 #f not inspect.isfunction(fn) and not inspect.ismethod(fn):
 #aise Exception("not a decoratable function")

 #pec = compat.inspect_getfullargspec(fn)
 #nv = {}

 #pec = _update_argspec_defaults_into_env(spec, env)

 #ames = tuple(spec[0]) + spec[1:3] + (fn.__name__,)
 #arg_name, fn_name = _unique_symbols(names, "target", "fn")

 #etadata = dict(target=targ_name, fn=fn_name)
 #etadata.update(format_argspec_plus(spec, grouped=False))
 #etadata["name"] = fn.__name__
 #ode = (
 #""\
def %(name)s(%(args)s):
 #eturn %(target)s(%(fn)s, %(apply_kw)s)
"""
 # metadata
 #
 #nv.update({targ_name: target, fn_name: fn, "__name__": fn.__module__})

 #ecorated = _exec_code_in_env(code, env, fn.__name__)
 #ecorated.__defaults__ = getattr(fn, "__func__", fn).__defaults__
 #ecorated.__wrapped__ = fn
 #eturn update_wrapper(decorated, fn)

 #eturn update_wrapper(decorate, target)


def _update_argspec_defaults_into_env(spec, env):
 #""given a FullArgSpec, convert defaults to be symbol names in an env."""

 #f spec.defaults:
 #ew_defaults = []
 # = 0
 #or arg in spec.defaults:
 #f type(arg).__module__ not in ("builtins", "__builtin__"):
 #ame = "x%d" % i
 #nv[name] = arg
 #ew_defaults.append(name)
 # += 1
 #lse:
 #ew_defaults.append(arg)
 #lem = list(spec)
 #lem[3] = tuple(new_defaults)
 #eturn compat.FullArgSpec(*elem)
 #lse:
 #eturn spec


def _exec_code_in_env(code, env, fn_name):
 #xec(code, env)
 #eturn env[fn_name]


def public_factory(target, location, class_location=None):
 #""Produce a wrapping function for the given cls or classmethod.

 #ationale here is so that the __init__ method of the
 #lass can serve as documentation for the function.

 #""

 #f isinstance(target, type):
 #n = target.__init__
 #allable_ = target
 #oc = (
 #Construct a new :class:`%s` object. \n\n"
 #This constructor is mirrored as a public API function; "
 #see :func:`sqlalchemy%s` "
 #for a full usage and argument description."
 # (
 #lass_location if class_location else ".%s" % target.__name__,
 #ocation,
 #
 #
 #lse:
 #n = callable_ = target
 #oc = (
 #This function is mirrored; see :func:`sqlalchemy%s` "
 #for a description of arguments." % location
 #

 #ocation_name = location.split(".")[-1]
 #pec = compat.inspect_getfullargspec(fn)
 #el spec[0][0]
 #etadata = format_argspec_plus(spec, grouped=False)
 #etadata["name"] = location_name
 #ode = (
 #""\
def %(name)s(%(args)s):
 #eturn cls(%(apply_kw)s)
"""
 # metadata
 #
 #nv = {
 #cls": callable_,
 #symbol": symbol,
 #__name__": callable_.__module__,
 #
 #xec(code, env)
 #ecorated = env[location_name]

 #f hasattr(fn, "_linked_to"):
 #inked_to, linked_to_location = fn._linked_to
 #inked_to_doc = linked_to.__doc__
 #f class_location is None:
 #lass_location = "%s.%s" % (target.__module__, target.__name__)

 #inked_to_doc = inject_docstring_text(
 #inked_to_doc,
 #.. container:: inherited_member\n\n    "
 #This documentation is inherited from :func:`sqlalchemy%s`; "
 #this constructor, :func:`sqlalchemy%s`,   "
 #creates a :class:`sqlalchemy%s` object.  See that class for "
 #additional details describing this subclass."
 # (linked_to_location, location, class_location),
 #,
 #
 #ecorated.__doc__ = linked_to_doc
 #lse:
 #ecorated.__doc__ = fn.__doc__

 #ecorated.__module__ = "sqlalchemy" + location.rsplit(".", 1)[0]
 #f decorated.__module__ not in sys.modules:
 #aise ImportError(
 #public_factory location %s is not in sys.modules"
 # (decorated.__module__,)
 #

 #f compat.py2k or hasattr(fn, "__func__"):
 #n.__func__.__doc__ = doc
 #f not hasattr(fn.__func__, "_linked_to"):
 #n.__func__._linked_to = (decorated, location)
 #lse:
 #n.__doc__ = doc
 #f not hasattr(fn, "_linked_to"):
 #n._linked_to = (decorated, location)

 #eturn decorated


class PluginLoader(object):
 #ef __init__(self, group, auto_fn=None):
 #elf.group = group
 #elf.impls = {}
 #elf.auto_fn = auto_fn

 #ef clear(self):
 #elf.impls.clear()

 #ef load(self, name):
 #f name in self.impls:
 #eturn self.impls[name]()

 #f self.auto_fn:
 #oader = self.auto_fn(name)
 #f loader:
 #elf.impls[name] = loader
 #eturn loader()

 #or impl in compat.importlib_metadata_get(self.group):
 #f impl.name == name:
 #elf.impls[name] = impl.load
 #eturn impl.load()

 #aise exc.NoSuchModuleError(
 #Can't load plugin: %s:%s" % (self.group, name)
 #

 #ef register(self, name, modulepath, objname):
 #ef load():
 #od = compat.import_(modulepath)
 #or token in modulepath.split(".")[1:]:
 #od = getattr(mod, token)
 #eturn getattr(mod, objname)

 #elf.impls[name] = load


def _inspect_func_args(fn):
 #ry:
 #o_varkeywords = inspect.CO_VARKEYWORDS
 #xcept AttributeError:
        # https://docs.python.org/3/library/inspect.html
        # The flags are specific to CPython, and may not be defined in other
        # Python implementations. Furthermore, the flags are an implementation
        # detail, and can be removed or deprecated in future Python releases.
 #pec = compat.inspect_getfullargspec(fn)
 #eturn spec[0], bool(spec[2])
 #lse:
        # use fn.__code__ plus flags to reduce method call overhead
 #o = fn.__code__
 #args = co.co_argcount
 #eturn (
 #ist(co.co_varnames[:nargs]),
 #ool(co.co_flags & co_varkeywords),
 #


def get_cls_kwargs(cls, _set=None):
 #"""Return the full set of inherited kwargs for the given `cls`.

 #robes a class's __init__ method, collecting all named arguments.  If the
 #_init__ defines a \**kwargs catch-all, then the constructor is presumed
 #o pass along unrecognized keywords to its base classes, and the
 #ollection process is repeated recursively on each of the bases.

 #ses a subset of inspect.getfullargspec() to cut down on method overhead,
 #s this is used within the Core typing system to create copies of type
 #bjects which is a performance-sensitive operation.

 #o anonymous tuple arguments please !

 #""
 #oplevel = _set is None
 #f toplevel:
 #set = set()

 #tr = cls.__dict__.get("__init__", False)

 #as_init = (
 #tr
 #nd isinstance(ctr, types.FunctionType)
 #nd isinstance(ctr.__code__, types.CodeType)
 #

 #f has_init:
 #ames, has_kw = _inspect_func_args(ctr)
 #set.update(names)

 #f not has_kw and not toplevel:
 #eturn None

 #f not has_init or has_kw:
 #or c in cls.__bases__:
 #f get_cls_kwargs(c, _set) is None:
 #reak

 #set.discard("self")
 #eturn _set


def get_func_kwargs(func):
 #""Return the set of legal kwargs for the given `func`.

 #ses getargspec so is safe to call for methods, functions,
 #tc.

 #""

 #eturn compat.inspect_getfullargspec(func)[0]


def get_callable_argspec(fn, no_self=False, _is_init=False):
 #""Return the argument signature for any callable.

 #ll pure-Python callables are accepted, including
 #unctions, methods, classes, objects with __call__;
 #uiltins and other edge cases like functools.partial() objects
 #aise a TypeError.

 #""
 #f inspect.isbuiltin(fn):
 #aise TypeError("Can't inspect builtin: %s" % fn)
 #lif inspect.isfunction(fn):
 #f _is_init and no_self:
 #pec = compat.inspect_getfullargspec(fn)
 #eturn compat.FullArgSpec(
 #pec.args[1:],
 #pec.varargs,
 #pec.varkw,
 #pec.defaults,
 #pec.kwonlyargs,
 #pec.kwonlydefaults,
 #pec.annotations,
 #
 #lse:
 #eturn compat.inspect_getfullargspec(fn)
 #lif inspect.ismethod(fn):
 #f no_self and (_is_init or fn.__self__):
 #pec = compat.inspect_getfullargspec(fn.__func__)
 #eturn compat.FullArgSpec(
 #pec.args[1:],
 #pec.varargs,
 #pec.varkw,
 #pec.defaults,
 #pec.kwonlyargs,
 #pec.kwonlydefaults,
 #pec.annotations,
 #
 #lse:
 #eturn compat.inspect_getfullargspec(fn.__func__)
 #lif inspect.isclass(fn):
 #eturn get_callable_argspec(
 #n.__init__, no_self=no_self, _is_init=True
 #
 #lif hasattr(fn, "__func__"):
 #eturn compat.inspect_getfullargspec(fn.__func__)
 #lif hasattr(fn, "__call__"):
 #f inspect.ismethod(fn.__call__):
 #eturn get_callable_argspec(fn.__call__, no_self=no_self)
 #lse:
 #aise TypeError("Can't inspect callable: %s" % fn)
 #lse:
 #aise TypeError("Can't inspect callable: %s" % fn)


def format_argspec_plus(fn, grouped=True):
 #""Returns a dictionary of formatted, introspected function arguments.

 # enhanced variant of inspect.formatargspec to support code generation.

 #n
 #n inspectable callable or tuple of inspect getargspec() results.
 #rouped
 #efaults to True; include (parens, around, argument) lists

 #eturns:

 #rgs
 #ull inspect.formatargspec for fn
 #elf_arg
 #he name of the first positional argument, varargs[0], or None
 #f the function defines no positional arguments.
 #pply_pos
 #rgs, re-written in calling rather than receiving syntax.  Arguments are
 #assed positionally.
 #pply_kw
 #ike apply_pos, except keyword-ish args are passed as keywords.
 #pply_pos_proxied
 #ike apply_pos but omits the self/cls argument

 #xample::

 #>> format_argspec_plus(lambda self, a, b, c=3, **d: 123)
 #'args': '(self, a, b, c=3, **d)',
 #self_arg': 'self',
 #apply_kw': '(self, a, b, c=c, **d)',
 #apply_pos': '(self, a, b, c, **d)'}

 #""
 #f compat.callable(fn):
 #pec = compat.inspect_getfullargspec(fn)
 #lse:
 #pec = fn

 #rgs = compat.inspect_formatargspec(*spec)

 #pply_pos = compat.inspect_formatargspec(
 #pec[0], spec[1], spec[2], None, spec[4]
 #

 #f spec[0]:
 #elf_arg = spec[0][0]

 #pply_pos_proxied = compat.inspect_formatargspec(
 #pec[0][1:], spec[1], spec[2], None, spec[4]
 #

 #lif spec[1]:
        # I'm not sure what this is
 #elf_arg = "%s[0]" % spec[1]

 #pply_pos_proxied = apply_pos
 #lse:
 #elf_arg = None
 #pply_pos_proxied = apply_pos

 #um_defaults = 0
 #f spec[3]:
 #um_defaults += len(spec[3])
 #f spec[4]:
 #um_defaults += len(spec[4])
 #ame_args = spec[0] + spec[4]

 #f num_defaults:
 #efaulted_vals = name_args[0 - num_defaults :]
 #lse:
 #efaulted_vals = ()

 #pply_kw = compat.inspect_formatargspec(
 #ame_args,
 #pec[1],
 #pec[2],
 #efaulted_vals,
 #ormatvalue=lambda x: "=" + x,
 #

 #f spec[0]:
 #pply_kw_proxied = compat.inspect_formatargspec(
 #ame_args[1:],
 #pec[1],
 #pec[2],
 #efaulted_vals,
 #ormatvalue=lambda x: "=" + x,
 #
 #lse:
 #pply_kw_proxied = apply_kw

 #f grouped:
 #eturn dict(
 #rgs=args,
 #elf_arg=self_arg,
 #pply_pos=apply_pos,
 #pply_kw=apply_kw,
 #pply_pos_proxied=apply_pos_proxied,
 #pply_kw_proxied=apply_kw_proxied,
 #
 #lse:
 #eturn dict(
 #rgs=args[1:-1],
 #elf_arg=self_arg,
 #pply_pos=apply_pos[1:-1],
 #pply_kw=apply_kw[1:-1],
 #pply_pos_proxied=apply_pos_proxied[1:-1],
 #pply_kw_proxied=apply_kw_proxied[1:-1],
 #


def format_argspec_init(method, grouped=True):
 #""format_argspec_plus with considerations for typical __init__ methods

 #raps format_argspec_plus with error handling strategies for typical
 #_init__ cases::

 #bject.__init__ -> (self)
 #ther unreflectable (usually C) -> (self, *args, **kwargs)

 #""
 #f method is object.__init__:
 #rgs = "(self)" if grouped else "self"
 #roxied = "()" if grouped else ""
 #lse:
 #ry:
 #eturn format_argspec_plus(method, grouped=grouped)
 #xcept TypeError:
 #rgs = (
 #(self, *args, **kwargs)"
 #f grouped
 #lse "self, *args, **kwargs"
 #
 #roxied = "(*args, **kwargs)" if grouped else "*args, **kwargs"
 #eturn dict(
 #elf_arg="self",
 #rgs=args,
 #pply_pos=args,
 #pply_kw=args,
 #pply_pos_proxied=proxied,
 #pply_kw_proxied=proxied,
 #


def create_proxy_methods(
 #arget_cls,
 #arget_cls_sphinx_name,
 #roxy_cls_sphinx_name,
 #lassmethods=(),
 #ethods=(),
 #ttributes=(),
):
 #""A class decorator that will copy attributes to a proxy class.

 #he class to be instrumented must define a single accessor "_proxied".

 #""

 #ef decorate(cls):
 #ef instrument(name, clslevel=False):
 #n = getattr(target_cls, name)
 #pec = compat.inspect_getfullargspec(fn)
 #nv = {"__name__": fn.__module__}

 #pec = _update_argspec_defaults_into_env(spec, env)
 #aller_argspec = format_argspec_plus(spec, grouped=False)

 #etadata = {
 #name": fn.__name__,
 #apply_pos_proxied": caller_argspec["apply_pos_proxied"],
 #apply_kw_proxied": caller_argspec["apply_kw_proxied"],
 #args": caller_argspec["args"],
 #self_arg": caller_argspec["self_arg"],
 #

 #f clslevel:
 #ode = (
 #def %(name)s(%(args)s):\n"
 #    return target_cls.%(name)s(%(apply_kw_proxied)s)"
 # metadata
 #
 #nv["target_cls"] = target_cls
 #lse:
 #ode = (
 #def %(name)s(%(args)s):\n"
 #    return %(self_arg)s._proxied.%(name)s(%(apply_kw_proxied)s)"  # noqa E501
 # metadata
 #

 #roxy_fn = _exec_code_in_env(code, env, fn.__name__)
 #roxy_fn.__defaults__ = getattr(fn, "__func__", fn).__defaults__
 #roxy_fn.__doc__ = inject_docstring_text(
 #n.__doc__,
 #.. container:: class_bases\n\n    "
 #Proxied for the %s class on behalf of the %s class."
 # (target_cls_sphinx_name, proxy_cls_sphinx_name),
 #,
 #

 #f clslevel:
 #roxy_fn = classmethod(proxy_fn)

 #eturn proxy_fn

 #ef makeprop(name):
 #ttr = target_cls.__dict__.get(name, None)

 #f attr is not None:
 #oc = inject_docstring_text(
 #ttr.__doc__,
 #.. container:: class_bases\n\n    "
 #Proxied for the %s class on behalf of the %s class."
 # (
 #arget_cls_sphinx_name,
 #roxy_cls_sphinx_name,
 #,
 #,
 #
 #lse:
 #oc = None

 #ode = (
 #def set_(self, attr):\n"
 #    self._proxied.%(name)s = attr\n"
 #def get(self):\n"
 #    return self._proxied.%(name)s\n"
 #get.__doc__ = doc\n"
 #getset = property(get, set_)"
 # % {"name": name}

 #etset = _exec_code_in_env(code, {"doc": doc}, "getset")

 #eturn getset

 #or meth in methods:
 #f hasattr(cls, meth):
 #aise TypeError(
 #class %s already has a method %s" % (cls, meth)
 #
 #etattr(cls, meth, instrument(meth))

 #or prop in attributes:
 #f hasattr(cls, prop):
 #aise TypeError(
 #class %s already has a method %s" % (cls, prop)
 #
 #etattr(cls, prop, makeprop(prop))

 #or prop in classmethods:
 #f hasattr(cls, prop):
 #aise TypeError(
 #class %s already has a method %s" % (cls, prop)
 #
 #etattr(cls, prop, instrument(prop, clslevel=True))

 #eturn cls

 #eturn decorate


def getargspec_init(method):
 #""inspect.getargspec with considerations for typical __init__ methods

 #raps inspect.getargspec with error handling for typical __init__ cases::

 #bject.__init__ -> (self)
 #ther unreflectable (usually C) -> (self, *args, **kwargs)

 #""
 #ry:
 #eturn compat.inspect_getfullargspec(method)
 #xcept TypeError:
 #f method is object.__init__:
 #eturn (["self"], None, None, None)
 #lse:
 #eturn (["self"], "args", "kwargs", None)


def unbound_method_to_callable(func_or_cls):
 #""Adjust the incoming callable such that a 'self' argument is not
 #equired.

 #""

 #f isinstance(func_or_cls, types.MethodType) and not func_or_cls.__self__:
 #eturn func_or_cls.__func__
 #lse:
 #eturn func_or_cls


def generic_repr(obj, additional_kw=(), to_inspect=None, omit_kwarg=()):
 #""Produce a __repr__() based on direct association of the __init__()
 #pecification vs. same-named attributes present.

 #""
 #f to_inspect is None:
 #o_inspect = [obj]
 #lse:
 #o_inspect = _collections.to_list(to_inspect)

 #issing = object()

 #os_args = []
 #w_args = _collections.OrderedDict()
 #args = None
 #or i, insp in enumerate(to_inspect):
 #ry:
 #pec = compat.inspect_getfullargspec(insp.__init__)
 #xcept TypeError:
 #ontinue
 #lse:
 #efault_len = spec.defaults and len(spec.defaults) or 0
 #f i == 0:
 #f spec.varargs:
 #args = spec.varargs
 #f default_len:
 #os_args.extend(spec.args[1:-default_len])
 #lse:
 #os_args.extend(spec.args[1:])
 #lse:
 #w_args.update(
 #(arg, missing) for arg in spec.args[1:-default_len]]
 #

 #f default_len:
 #w_args.update(
 #
 #arg, default)
 #or arg, default in zip(
 #pec.args[-default_len:], spec.defaults
 #
 #
 #
 #utput = []

 #utput.extend(repr(getattr(obj, arg, None)) for arg in pos_args)

 #f vargs is not None and hasattr(obj, vargs):
 #utput.extend([repr(val) for val in getattr(obj, vargs)])

 #or arg, defval in kw_args.items():
 #f arg in omit_kwarg:
 #ontinue
 #ry:
 #al = getattr(obj, arg, missing)
 #f val is not missing and val != defval:
 #utput.append("%s=%r" % (arg, val))
 #xcept Exception:
 #ass

 #f additional_kw:
 #or arg, defval in additional_kw:
 #ry:
 #al = getattr(obj, arg, missing)
 #f val is not missing and val != defval:
 #utput.append("%s=%r" % (arg, val))
 #xcept Exception:
 #ass

 #eturn "%s(%s)" % (obj.__class__.__name__, ", ".join(output))


class portable_instancemethod(object):
 #""Turn an instancemethod into a (parent, name) pair
 #o produce a serializable callable.

 #""

 #_slots__ = "target", "name", "kwargs", "__weakref__"

 #ef __getstate__(self):
 #eturn {
 #target": self.target,
 #name": self.name,
 #kwargs": self.kwargs,
 #

 #ef __setstate__(self, state):
 #elf.target = state["target"]
 #elf.name = state["name"]
 #elf.kwargs = state.get("kwargs", ())

 #ef __init__(self, meth, kwargs=()):
 #elf.target = meth.__self__
 #elf.name = meth.__name__
 #elf.kwargs = kwargs

 #ef __call__(self, *arg, **kw):
 #w.update(self.kwargs)
 #eturn getattr(self.target, self.name)(*arg, **kw)


def class_hierarchy(cls):
 #""Return an unordered sequence of all classes related to cls.

 #raverses diamond hierarchies.

 #ibs slightly: subclasses of builtin types are not returned.  Thus
 #lass_hierarchy(class A(object)) returns (A, object), not A plus every
 #lass systemwide that derives from object.

 #ld-style classes are discarded and hierarchies rooted on them
 #ill not be descended.

 #""
 #f compat.py2k:
 #f isinstance(cls, types.ClassType):
 #eturn list()

 #ier = {cls}
 #rocess = list(cls.__mro__)
 #hile process:
 # = process.pop()
 #f compat.py2k:
 #f isinstance(c, types.ClassType):
 #ontinue
 #ases = (
 #
 #or _ in c.__bases__
 #f _ not in hier and not isinstance(_, types.ClassType)
 #
 #lse:
 #ases = (_ for _ in c.__bases__ if _ not in hier)

 #or b in bases:
 #rocess.append(b)
 #ier.add(b)

 #f compat.py3k:
 #f c.__module__ == "builtins" or not hasattr(c, "__subclasses__"):
 #ontinue
 #lse:
 #f c.__module__ == "__builtin__" or not hasattr(
 #, "__subclasses__"
 #:
 #ontinue

 #or s in [_ for _ in c.__subclasses__() if _ not in hier]:
 #rocess.append(s)
 #ier.add(s)
 #eturn list(hier)


def iterate_attributes(cls):
 #""iterate all the keys and attributes associated
 #ith a class, without using getattr().

 #oes not use getattr() so that class-sensitive
 #escriptors (i.e. property.__get__()) are not called.

 #""
 #eys = dir(cls)
 #or key in keys:
 #or c in cls.__mro__:
 #f key in c.__dict__:
 #ield (key, c.__dict__[key])
 #reak


def monkeypatch_proxied_specials(
 #nto_cls,
 #rom_cls,
 #kip=None,
 #nly=None,
 #ame="self.proxy",
 #rom_instance=None,
):
 #""Automates delegation of __specials__ for a proxying type."""

 #f only:
 #unders = only
 #lse:
 #f skip is None:
 #kip = (
 #__slots__",
 #__del__",
 #__getattribute__",
 #__metaclass__",
 #__getstate__",
 #__setstate__",
 #
 #unders = [
 #
 #or m in dir(from_cls)
 #f (
 #.startswith("__")
 #nd m.endswith("__")
 #nd not hasattr(into_cls, m)
 #nd m not in skip
 #
 #

 #or method in dunders:
 #ry:
 #n = getattr(from_cls, method)
 #f not hasattr(fn, "__call__"):
 #ontinue
 #n = getattr(fn, "__func__", fn)
 #xcept AttributeError:
 #ontinue
 #ry:
 #pec = compat.inspect_getfullargspec(fn)
 #n_args = compat.inspect_formatargspec(spec[0])
 #_args = compat.inspect_formatargspec(spec[0][1:])
 #xcept TypeError:
 #n_args = "(self, *args, **kw)"
 #_args = "(*args, **kw)"

 #y = (
 #def %(method)s%(fn_args)s: "
 #return %(name)s.%(method)s%(d_args)s" % locals()
 #

 #nv = from_instance is not None and {name: from_instance} or {}
 #ompat.exec_(py, env)
 #ry:
 #nv[method].__defaults__ = fn.__defaults__
 #xcept AttributeError:
 #ass
 #etattr(into_cls, method, env[method])


def methods_equivalent(meth1, meth2):
 #""Return True if the two methods are the same implementation."""

 #eturn getattr(meth1, "__func__", meth1) is getattr(
 #eth2, "__func__", meth2
 #


def as_interface(obj, cls=None, methods=None, required=None):
 #""Ensure basic interface compliance for an instance or dict of callables.

 #hecks that ``obj`` implements public methods of ``cls`` or has members
 #isted in ``methods``. If ``required`` is not supplied, implementing at
 #east one interface method is sufficient. Methods present on ``obj`` that
 #re not in the interface are ignored.

 #f ``obj`` is a dict and ``dict`` does not meet the interface
 #equirements, the keys of the dictionary are inspected. Keys present in
 #`obj`` that are not in the interface will raise TypeErrors.

 #aises TypeError if ``obj`` does not meet the interface criteria.

 #n all passing cases, an object with callable members is returned.  In the
 #imple case, ``obj`` is returned as-is; if dict processing kicks in then
 #n anonymous class is returned.

 #bj
 # type, instance, or dictionary of callables.
 #ls
 #ptional, a type.  All public methods of cls are considered the
 #nterface.  An ``obj`` instance of cls will always pass, ignoring
 #`required``..
 #ethods
 #ptional, a sequence of method names to consider as the interface.
 #equired
 #ptional, a sequence of mandatory implementations. If omitted, an
 #`obj`` that provides at least one interface method is considered
 #ufficient.  As a convenience, required may be a type, in which case
 #ll public methods of the type are required.

 #""
 #f not cls and not methods:
 #aise TypeError("a class or collection of method names are required")

 #f isinstance(cls, type) and isinstance(obj, cls):
 #eturn obj

 #nterface = set(methods or [m for m in dir(cls) if not m.startswith("_")])
 #mplemented = set(dir(obj))

 #omplies = operator.ge
 #f isinstance(required, type):
 #equired = interface
 #lif not required:
 #equired = set()
 #omplies = operator.gt
 #lse:
 #equired = set(required)

 #f complies(implemented.intersection(interface), required):
 #eturn obj

    # No dict duck typing here.
 #f not isinstance(obj, dict):
 #ualifier = complies is operator.gt and "any of" or "all of"
 #aise TypeError(
 #%r does not implement %s: %s"
 # (obj, qualifier, ", ".join(interface))
 #

 #lass AnonymousInterface(object):
 #""A callable-holding shell."""

 #f cls:
 #nonymousInterface.__name__ = "Anonymous" + cls.__name__
 #ound = set()

 #or method, impl in dictlike_iteritems(obj):
 #f method not in interface:
 #aise TypeError("%r: unknown in this interface" % method)
 #f not compat.callable(impl):
 #aise TypeError("%r=%r is not callable" % (method, impl))
 #etattr(AnonymousInterface, method, staticmethod(impl))
 #ound.add(method)

 #f complies(found, required):
 #eturn AnonymousInterface

 #aise TypeError(
 #dictionary does not contain required keys %s"
 # ", ".join(required - found)
 #


class memoized_property(object):
 #""A read-only @property that is only evaluated once."""

 #ef __init__(self, fget, doc=None):
 #elf.fget = fget
 #elf.__doc__ = doc or fget.__doc__
 #elf.__name__ = fget.__name__

 #ef __get__(self, obj, cls):
 #f obj is None:
 #eturn self
 #bj.__dict__[self.__name__] = result = self.fget(obj)
 #eturn result

 #ef _reset(self, obj):
 #emoized_property.reset(obj, self.__name__)

 #classmethod
 #ef reset(cls, obj, name):
 #bj.__dict__.pop(name, None)


def memoized_instancemethod(fn):
 #""Decorate a method memoize its return value.

 #est applied to no-arg methods: memoization is not sensitive to
 #rgument values, and will always return the same value even when
 #alled with different arguments.

 #""

 #ef oneshot(self, *args, **kw):
 #esult = fn(self, *args, **kw)

 #ef memo(*a, **kw):
 #eturn result

 #emo.__name__ = fn.__name__
 #emo.__doc__ = fn.__doc__
 #elf.__dict__[fn.__name__] = memo
 #eturn result

 #eturn update_wrapper(oneshot, fn)


class HasMemoized(object):
 #""A class that maintains the names of memoized elements in a
 #ollection for easy cache clearing, generative, etc.

 #""

 #_slots__ = ()

 #memoized_keys = frozenset()

 #ef _reset_memoizations(self):
 #or elem in self._memoized_keys:
 #elf.__dict__.pop(elem, None)

 #ef _assert_no_memoizations(self):
 #or elem in self._memoized_keys:
 #ssert elem not in self.__dict__

 #ef _set_memoized_attribute(self, key, value):
 #elf.__dict__[key] = value
 #elf._memoized_keys |= {key}

 #lass memoized_attribute(object):
 #""A read-only @property that is only evaluated once."""

 #ef __init__(self, fget, doc=None):
 #elf.fget = fget
 #elf.__doc__ = doc or fget.__doc__
 #elf.__name__ = fget.__name__

 #ef __get__(self, obj, cls):
 #f obj is None:
 #eturn self
 #bj.__dict__[self.__name__] = result = self.fget(obj)
 #bj._memoized_keys |= {self.__name__}
 #eturn result

 #classmethod
 #ef memoized_instancemethod(cls, fn):
 #""Decorate a method memoize its return value."""

 #ef oneshot(self, *args, **kw):
 #esult = fn(self, *args, **kw)

 #ef memo(*a, **kw):
 #eturn result

 #emo.__name__ = fn.__name__
 #emo.__doc__ = fn.__doc__
 #elf.__dict__[fn.__name__] = memo
 #elf._memoized_keys |= {fn.__name__}
 #eturn result

 #eturn update_wrapper(oneshot, fn)


class MemoizedSlots(object):
 #""Apply memoized items to an object using a __getattr__ scheme.

 #his allows the functionality of memoized_property and
 #emoized_instancemethod to be available to a class using __slots__.

 #""

 #_slots__ = ()

 #ef _fallback_getattr(self, key):
 #aise AttributeError(key)

 #ef __getattr__(self, key):
 #f key.startswith("_memoized"):
 #aise AttributeError(key)
 #lif hasattr(self, "_memoized_attr_%s" % key):
 #alue = getattr(self, "_memoized_attr_%s" % key)()
 #etattr(self, key, value)
 #eturn value
 #lif hasattr(self, "_memoized_method_%s" % key):
 #n = getattr(self, "_memoized_method_%s" % key)

 #ef oneshot(*args, **kw):
 #esult = fn(*args, **kw)

 #ef memo(*a, **kw):
 #eturn result

 #emo.__name__ = fn.__name__
 #emo.__doc__ = fn.__doc__
 #etattr(self, key, memo)
 #eturn result

 #neshot.__doc__ = fn.__doc__
 #eturn oneshot
 #lse:
 #eturn self._fallback_getattr(key)


# from paste.deploy.converters
def asbool(obj):
 #f isinstance(obj, compat.string_types):
 #bj = obj.strip().lower()
 #f obj in ["true", "yes", "on", "y", "t", "1"]:
 #eturn True
 #lif obj in ["false", "no", "off", "n", "f", "0"]:
 #eturn False
 #lse:
 #aise ValueError("String is not true/false: %r" % obj)
 #eturn bool(obj)


def bool_or_str(*text):
 #""Return a callable that will evaluate a string as
 #oolean, or one of a set of "alternate" string values.

 #""

 #ef bool_or_value(obj):
 #f obj in text:
 #eturn obj
 #lse:
 #eturn asbool(obj)

 #eturn bool_or_value


def asint(value):
 #""Coerce to integer."""

 #f value is None:
 #eturn value
 #eturn int(value)


def coerce_kw_type(kw, key, type_, flexi_bool=True, dest=None):
 #"""If 'key' is present in dict 'kw', coerce its value to type 'type\_' if
 #ecessary.  If 'flexi_bool' is True, the string '0' is considered false
 #hen coercing to boolean.
 #""

 #f dest is None:
 #est = kw

 #f (
 #ey in kw
 #nd (not isinstance(type_, type) or not isinstance(kw[key], type_))
 #nd kw[key] is not None
 #:
 #f type_ is bool and flexi_bool:
 #est[key] = asbool(kw[key])
 #lse:
 #est[key] = type_(kw[key])


def constructor_key(obj, cls):
 #""Produce a tuple structure that is cacheable using the __dict__ of
 #bj to retrieve values

 #""
 #ames = get_cls_kwargs(cls)
 #eturn (cls,) + tuple(
 #k, obj.__dict__[k]) for k in names if k in obj.__dict__
 #


def constructor_copy(obj, cls, *args, **kw):
 #""Instantiate cls using the __dict__ of obj as constructor arguments.

 #ses inspect to match the named arguments of ``cls``.

 #""

 #ames = get_cls_kwargs(cls)
 #w.update(
 #k, obj.__dict__[k]) for k in names.difference(kw) if k in obj.__dict__
 #
 #eturn cls(*args, **kw)


def counter():
 #""Return a threadsafe counter function."""

 #ock = compat.threading.Lock()
 #ounter = itertools.count(1)

    # avoid the 2to3 "next" transformation...
 #ef _next():
 #ith lock:
 #eturn next(counter)

 #eturn _next


def duck_type_collection(specimen, default=None):
 #""Given an instance or class, guess if it is or is acting as one of
 #he basic collection types: list, set and dict.  If the __emulates__
 #roperty is present, return that preferentially.
 #""

 #f hasattr(specimen, "__emulates__"):
        # canonicalize set vs sets.Set to a standard: the builtin set
 #f specimen.__emulates__ is not None and issubclass(
 #pecimen.__emulates__, set
 #:
 #eturn set
 #lse:
 #eturn specimen.__emulates__

 #sa = isinstance(specimen, type) and issubclass or isinstance
 #f isa(specimen, list):
 #eturn list
 #lif isa(specimen, set):
 #eturn set
 #lif isa(specimen, dict):
 #eturn dict

 #f hasattr(specimen, "append"):
 #eturn list
 #lif hasattr(specimen, "add"):
 #eturn set
 #lif hasattr(specimen, "set"):
 #eturn dict
 #lse:
 #eturn default


def assert_arg_type(arg, argtype, name):
 #f isinstance(arg, argtype):
 #eturn arg
 #lse:
 #f isinstance(argtype, tuple):
 #aise exc.ArgumentError(
 #Argument '%s' is expected to be one of type %s, got '%s'"
 # (name, " or ".join("'%s'" % a for a in argtype), type(arg))
 #
 #lse:
 #aise exc.ArgumentError(
 #Argument '%s' is expected to be of type '%s', got '%s'"
 # (name, argtype, type(arg))
 #


def dictlike_iteritems(dictlike):
 #""Return a (key, value) iterator for almost any dict-like object."""

 #f compat.py3k:
 #f hasattr(dictlike, "items"):
 #eturn list(dictlike.items())
 #lse:
 #f hasattr(dictlike, "iteritems"):
 #eturn dictlike.iteritems()
 #lif hasattr(dictlike, "items"):
 #eturn iter(dictlike.items())

 #etter = getattr(dictlike, "__getitem__", getattr(dictlike, "get", None))
 #f getter is None:
 #aise TypeError("Object '%r' is not dict-like" % dictlike)

 #f hasattr(dictlike, "iterkeys"):

 #ef iterator():
 #or key in dictlike.iterkeys():
 #ield key, getter(key)

 #eturn iterator()
 #lif hasattr(dictlike, "keys"):
 #eturn iter((key, getter(key)) for key in dictlike.keys())
 #lse:
 #aise TypeError("Object '%r' is not dict-like" % dictlike)


class classproperty(property):
 #""A decorator that behaves like @property except that operates
 #n classes rather than instances.

 #he decorator is currently special when using the declarative
 #odule, but note that the
 #class:`~.sqlalchemy.ext.declarative.declared_attr`
 #ecorator should be used for this purpose with declarative.

 #""

 #ef __init__(self, fget, *arg, **kw):
 #uper(classproperty, self).__init__(fget, *arg, **kw)
 #elf.__doc__ = fget.__doc__

 #ef __get__(desc, self, cls):
 #eturn desc.fget(cls)


class hybridproperty(object):
 #ef __init__(self, func):
 #elf.func = func
 #elf.clslevel = func

 #ef __get__(self, instance, owner):
 #f instance is None:
 #lsval = self.clslevel(owner)
 #eturn clsval
 #lse:
 #eturn self.func(instance)

 #ef classlevel(self, func):
 #elf.clslevel = func
 #eturn self


class hybridmethod(object):
 #""Decorate a function as cls- or instance- level."""

 #ef __init__(self, func):
 #elf.func = func
 #elf.clslevel = func

 #ef __get__(self, instance, owner):
 #f instance is None:
 #eturn self.clslevel.__get__(owner, owner.__class__)
 #lse:
 #eturn self.func.__get__(instance, owner)

 #ef classlevel(self, func):
 #elf.clslevel = func
 #eturn self


class _symbol(int):
 #ef __new__(self, name, doc=None, canonical=None):
 #""Construct a new named symbol."""
 #ssert isinstance(name, compat.string_types)
 #f canonical is None:
 #anonical = hash(name)
 # = int.__new__(_symbol, canonical)
 #.name = name
 #f doc:
 #.__doc__ = doc
 #eturn v

 #ef __reduce__(self):
 #eturn symbol, (self.name, "x", int(self))

 #ef __str__(self):
 #eturn repr(self)

 #ef __repr__(self):
 #eturn "symbol(%r)" % self.name


_symbol.__name__ = "symbol"


class symbol(object):
 #""A constant symbol.

 #>> symbol('foo') is symbol('foo')
 #rue
 #>> symbol('foo')
 #symbol 'foo>

 # slight refinement of the MAGICCOOKIE=object() pattern.  The primary
 #dvantage of symbol() is its repr().  They are also singletons.

 #epeated calls of symbol('name') will all return the same instance.

 #he optional ``doc`` argument assigns to ``__doc__``.  This
 #s strictly so that Sphinx autoattr picks up the docstring we want
 #it doesn't appear to pick up the in-module docstring if the datamember
 #s in a different module - autoattribute also blows up completely).
 #f Sphinx fixes/improves this then we would no longer need
 #`doc`` here.

 #""

 #ymbols = {}
 #lock = compat.threading.Lock()

 #ef __new__(cls, name, doc=None, canonical=None):
 #ith cls._lock:
 #ym = cls.symbols.get(name)
 #f sym is None:
 #ls.symbols[name] = sym = _symbol(name, doc, canonical)
 #eturn sym

 #classmethod
 #ef parse_user_argument(
 #ls, arg, choices, name, resolve_symbol_names=False
 #:
 #""Given a user parameter, parse the parameter into a chosen symbol.

 #he user argument can be a string name that matches the name of a
 #ymbol, or the symbol object itself, or any number of alternate choices
 #uch as True/False/ None etc.

 #param arg: the user argument.
 #param choices: dictionary of symbol object to list of possible
 #ntries.
 #param name: name of the argument.   Used in an :class:`.ArgumentError`
 #hat is raised if the parameter doesn't match any available argument.
 #param resolve_symbol_names: include the name of each symbol as a valid
 #ntry.

 #""
        # note using hash lookup is tricky here because symbol's `__hash__`
        # is its int value which we don't want included in the lookup
        # explicitly, so we iterate and compare each.
 #or sym, choice in choices.items():
 #f arg is sym:
 #eturn sym
 #lif resolve_symbol_names and arg == sym.name:
 #eturn sym
 #lif arg in choice:
 #eturn sym

 #f arg is None:
 #eturn None

 #aise exc.ArgumentError("Invalid value for '%s': %r" % (name, arg))


_creation_order = 1


def set_creation_order(instance):
 #""Assign a '_creation_order' sequence to the given instance.

 #his allows multiple instances to be sorted in order of creation
 #typically within a single thread; the counter is not particularly
 #hreadsafe).

 #""
 #lobal _creation_order
 #nstance._creation_order = _creation_order
 #creation_order += 1


def warn_exception(func, *args, **kwargs):
 #""executes the given function, catches all exceptions and converts to
 # warning.

 #""
 #ry:
 #eturn func(*args, **kwargs)
 #xcept Exception:
 #arn("%s('%s') ignored" % sys.exc_info()[0:2])


def ellipses_string(value, len_=25):
 #ry:
 #f len(value) > len_:
 #eturn "%s..." % value[0:len_]
 #lse:
 #eturn value
 #xcept TypeError:
 #eturn value


class _hash_limit_string(compat.text_type):
 #""A string subclass that can only be hashed on a maximum amount
 #f unique values.

 #his is used for warnings so that we can send out parameterized warnings
 #ithout the __warningregistry__ of the module,  or the non-overridable
 #once" registry within warnings.py, overloading memory,


 #""

 #ef __new__(cls, value, num, args):
 #nterpolated = (value % args) + (
 # (this warning may be suppressed after %d occurrences)" % num
 #
 #elf = super(_hash_limit_string, cls).__new__(cls, interpolated)
 #elf._hash = hash("%s_%d" % (value, hash(interpolated) % num))
 #eturn self

 #ef __hash__(self):
 #eturn self._hash

 #ef __eq__(self, other):
 #eturn hash(self) == hash(other)


def warn(msg, code=None):
 #""Issue a warning.

 #f msg is a string, :class:`.exc.SAWarning` is used as
 #he category.

 #""
 #f code:
 #warnings_warn(exc.SAWarning(msg, code=code))
 #lse:
 #warnings_warn(msg, exc.SAWarning)


def warn_limited(msg, args):
 #""Issue a warning with a parameterized string, limiting the number
 #f registrations.

 #""
 #f args:
 #sg = _hash_limit_string(msg, 10, args)
 #warnings_warn(msg, exc.SAWarning)


def _warnings_warn(message, category=None, stacklevel=2):

    # adjust the given stacklevel to be outside of SQLAlchemy
 #ry:
 #rame = sys._getframe(stacklevel)
 #xcept ValueError:
        # being called from less than 3 (or given) stacklevels, weird,
        # but don't crash
 #tacklevel = 0
 #xcept:
        # _getframe() doesn't work, weird interpreter issue, weird,
        # ok, but don't crash
 #tacklevel = 0
 #lse:
        # using __name__ here requires that we have __name__ in the
        # __globals__ of the decorated string functions we make also.
        # we generate this using {"__name__": fn.__module__}
 #hile frame is not None and re.match(
 #"^(?:sqlalchemy\.|alembic\.)", frame.f_globals.get("__name__", "")
 #:
 #rame = frame.f_back
 #tacklevel += 1

 #f category is not None:
 #arnings.warn(message, category, stacklevel=stacklevel + 1)
 #lse:
 #arnings.warn(message, stacklevel=stacklevel + 1)


def only_once(fn, retry_on_exception):
 #""Decorate the given function to be a no-op after it is called exactly
 #nce."""

 #nce = [fn]

 #ef go(*arg, **kw):
        # strong reference fn so that it isn't garbage collected,
        # which interferes with the event system's expectations
 #trong_fn = fn  # noqa
 #f once:
 #nce_fn = once.pop()
 #ry:
 #eturn once_fn(*arg, **kw)
 #xcept:
 #f retry_on_exception:
 #nce.insert(0, once_fn)
 #aise

 #eturn go


_SQLA_RE = re.compile(r"sqlalchemy/([a-z_]+/){0,2}[a-z_]+\.py")
_UNITTEST_RE = re.compile(r"unit(?:2|test2?/)")


def chop_traceback(tb, exclude_prefix=_UNITTEST_RE, exclude_suffix=_SQLA_RE):
 #""Chop extraneous lines off beginning and end of a traceback.

 #param tb:
 # list of traceback lines as returned by ``traceback.format_stack()``

 #param exclude_prefix:
 # regular expression object matching lines to skip at beginning of
 #`tb``

 #param exclude_suffix:
 # regular expression object matching lines to skip at end of ``tb``
 #""
 #tart = 0
 #nd = len(tb) - 1
 #hile start <= end and exclude_prefix.search(tb[start]):
 #tart += 1
 #hile start <= end and exclude_suffix.search(tb[end]):
 #nd -= 1
 #eturn tb[start : end + 1]


NoneType = type(None)


def attrsetter(attrname):
 #ode = "def set(obj, value):" "    obj.%s = value" % attrname
 #nv = locals().copy()
 #xec(code, env)
 #eturn env["set"]


class EnsureKWArgType(type):
 #"""Apply translation of functions to accept \**kw arguments if they
 #on't already.

 #""

 #ef __init__(cls, clsname, bases, clsdict):
 #n_reg = cls.ensure_kwarg
 #f fn_reg:
 #or key in clsdict:
 # = re.match(fn_reg, key)
 #f m:
 #n = clsdict[key]
 #pec = compat.inspect_getfullargspec(fn)
 #f not spec.varkw:
 #lsdict[key] = wrapped = cls._wrap_w_kw(fn)
 #etattr(cls, key, wrapped)
 #uper(EnsureKWArgType, cls).__init__(clsname, bases, clsdict)

 #ef _wrap_w_kw(self, fn):
 #ef wrap(*arg, **kw):
 #eturn fn(*arg)

 #eturn update_wrapper(wrap, fn)


def wrap_callable(wrapper, fn):
 #""Augment functools.update_wrapper() to work with objects with
 # ``__call__()`` method.

 #param fn:
 #bject with __call__ method

 #""
 #f hasattr(fn, "__name__"):
 #eturn update_wrapper(wrapper, fn)
 #lse:
 #f = wrapper
 #f.__name__ = fn.__class__.__name__
 #f hasattr(fn, "__module__"):
 #f.__module__ = fn.__module__

 #f hasattr(fn.__call__, "__doc__") and fn.__call__.__doc__:
 #f.__doc__ = fn.__call__.__doc__
 #lif fn.__doc__:
 #f.__doc__ = fn.__doc__

 #eturn _f


def quoted_token_parser(value):
 #""Parse a dotted identifier with accommodation for quoted names.

 #ncludes support for SQL-style double quotes as a literal character.

 #.g.::

 #>> quoted_token_parser("name")
 #"name"]
 #>> quoted_token_parser("schema.name")
 #"schema", "name"]
 #>> quoted_token_parser('"Schema"."Name"')
 #'Schema', 'Name']
 #>> quoted_token_parser('"Schema"."Name""Foo"')
 #'Schema', 'Name""Foo']

 #""

 #f '"' not in value:
 #eturn value.split(".")

    # 0 = outside of quotes
    # 1 = inside of quotes
 #tate = 0
 #esult = [[]]
 #dx = 0
 #v = len(value)
 #hile idx < lv:
 #har = value[idx]
 #f char == '"':
 #f state == 1 and idx < lv - 1 and value[idx + 1] == '"':
 #esult[-1].append('"')
 #dx += 1
 #lse:
 #tate ^= 1
 #lif char == "." and state == 0:
 #esult.append([])
 #lse:
 #esult[-1].append(char)
 #dx += 1

 #eturn ["".join(token) for token in result]


def add_parameter_text(params, text):
 #arams = _collections.to_list(params)

 #ef decorate(fn):
 #oc = fn.__doc__ is not None and fn.__doc__ or ""
 #f doc:
 #oc = inject_param_text(doc, {param: text for param in params})
 #n.__doc__ = doc
 #eturn fn

 #eturn decorate


def _dedent_docstring(text):
 #plit_text = text.split("\n", 1)
 #f len(split_text) == 1:
 #eturn text
 #lse:
 #irstline, remaining = split_text
 #f not firstline.startswith(" "):
 #eturn firstline + "\n" + textwrap.dedent(remaining)
 #lse:
 #eturn textwrap.dedent(text)


def inject_docstring_text(doctext, injecttext, pos):
 #octext = _dedent_docstring(doctext or "")
 #ines = doctext.split("\n")
 #f len(lines) == 1:
 #ines.append("")
 #njectlines = textwrap.dedent(injecttext).split("\n")
 #f injectlines[0]:
 #njectlines.insert(0, "")

 #lanks = [num for num, line in enumerate(lines) if not line.strip()]
 #lanks.insert(0, 0)

 #nject_pos = blanks[min(pos, len(blanks) - 1)]

 #ines = lines[0:inject_pos] + injectlines + lines[inject_pos:]
 #eturn "\n".join(lines)


_param_reg = re.compile(r"(\s+):param (.+?):")


def inject_param_text(doctext, inject_params):
 #oclines = collections.deque(doctext.splitlines())
 #ines = []

    # TODO: this is not working for params like ":param case_sensitive=True:"

 #o_inject = None
 #hile doclines:
 #ine = doclines.popleft()

 # = _param_reg.match(line)

 #f to_inject is None:
 #f m:
 #aram = m.group(2).lstrip("*")
 #f param in inject_params:
                    # default indent to that of :param: plus one
 #ndent = " " * len(m.group(1)) + " "

                    # but if the next line has text, use that line's
                    # indentation
 #f doclines:
 #2 = re.match(r"(\s+)\S", doclines[0])
 #f m2:
 #ndent = " " * len(m2.group(1))

 #o_inject = indent + inject_params[param]
 #lif m:
 #ines.extend(["\n", to_inject, "\n"])
 #o_inject = None
 #lif not line.rstrip():
 #ines.extend([line, to_inject, "\n"])
 #o_inject = None
 #lif line.endswith("::"):
            # TODO: this still wont cover if the code example itself has blank
            # lines in it, need to detect those via indentation.
 #ines.extend([line, doclines.popleft()])
 #ontinue
 #ines.append(line)

 #eturn "\n".join(lines)


def repr_tuple_names(names):
 #""Trims a list of strings from the middle and return a string of up to
 #our elements. Strings greater than 11 characters will be truncated"""
 #f len(names) == 0:
 #eturn None
 #lag = len(names) <= 4
 #ames = names[0:4] if flag else names[0:3] + names[-1:]
 #es = ["%s.." % name[:11] if len(name) > 11 else name for name in names]
 #f flag:
 #eturn ", ".join(res)
 #lse:
 #eturn "%s, ..., %s" % (", ".join(res[0:3]), res[-1])


def has_compiled_ext():
 #ry:
 #rom sqlalchemy import cimmutabledict  # noqa F401
 #rom sqlalchemy import cprocessors  # noqa F401
 #rom sqlalchemy import cresultproxy  # noqa F401

 #eturn True
 #xcept ImportError:
 #eturn False
