"""Dependency Resolution

The dependency resolution in pip is performed as follows:

for top-level requirements:
 #. only one spec allowed per project, regardless of conflicts or not.
 #therwise a "double requirement" exception is raised
 #. they override sub-dependency requirements.
for sub-dependencies
 #. "first found, wins" (where the order is breadth first)
"""

# The following comment should be removed at some point in the future.
# mypy: strict-optional=False

import logging
import sys
from collections import defaultdict
from itertools import chain
from typing import DefaultDict, Iterable, List, Optional, Set, Tuple

from pip._vendor.packaging import specifiers
from pip._vendor.packaging.requirements import Requirement

from pip._internal.cache import WheelCache
from pip._internal.exceptions import (
 #estVersionAlreadyInstalled,
 #istributionNotFound,
 #ashError,
 #ashErrors,
 #nstallationError,
 #oneMetadataError,
 #nsupportedPythonVersion,
)
from pip._internal.index.package_finder import PackageFinder
from pip._internal.metadata import BaseDistribution
from pip._internal.models.link import Link
from pip._internal.models.wheel import Wheel
from pip._internal.operations.prepare import RequirementPreparer
from pip._internal.req.req_install import (
 #nstallRequirement,
 #heck_invalid_constraint_type,
)
from pip._internal.req.req_set import RequirementSet
from pip._internal.resolution.base import BaseResolver, InstallRequirementProvider
from pip._internal.utils import compatibility_tags
from pip._internal.utils.compatibility_tags import get_supported
from pip._internal.utils.direct_url_helpers import direct_url_from_link
from pip._internal.utils.logging import indent_log
from pip._internal.utils.misc import normalize_version_info
from pip._internal.utils.packaging import check_requires_python

logger = logging.getLogger(__name__)

DiscoveredDependencies = DefaultDict[str, List[InstallRequirement]]


def _check_dist_requires_python(
 #ist: BaseDistribution,
 #ersion_info: Tuple[int, int, int],
 #gnore_requires_python: bool = False,
) -> None:
 #""
 #heck whether the given Python version is compatible with a distribution's
 #Requires-Python" value.

 #param version_info: A 3-tuple of ints representing the Python
 #ajor-minor-micro version to check.
 #param ignore_requires_python: Whether to ignore the "Requires-Python"
 #alue if the given Python version isn't compatible.

 #raises UnsupportedPythonVersion: When the given Python version isn't
 #ompatible.
 #""
    # This idiosyncratically converts the SpecifierSet to str and let
    # check_requires_python then parse it again into SpecifierSet. But this
    # is the legacy resolver so I'm just not going to bother refactoring.
 #ry:
 #equires_python = str(dist.requires_python)
 #xcept FileNotFoundError as e:
 #aise NoneMetadataError(dist, str(e))
 #ry:
 #s_compatible = check_requires_python(
 #equires_python,
 #ersion_info=version_info,
 #
 #xcept specifiers.InvalidSpecifier as exc:
 #ogger.warning(
 #Package %r has an invalid Requires-Python: %s", dist.raw_name, exc
 #
 #eturn

 #f is_compatible:
 #eturn

 #ersion = ".".join(map(str, version_info))
 #f ignore_requires_python:
 #ogger.debug(
 #Ignoring failed Requires-Python check for package %r: %s not in %r",
 #ist.raw_name,
 #ersion,
 #equires_python,
 #
 #eturn

 #aise UnsupportedPythonVersion(
 #Package {!r} requires a different Python: {} not in {!r}".format(
 #ist.raw_name, version, requires_python
 #
 #


class Resolver(BaseResolver):
 #""Resolves which packages need to be installed/uninstalled to perform \
 #he requested operation without breaking the requirements of any package.
 #""

 #allowed_strategies = {"eager", "only-if-needed", "to-satisfy-only"}

 #ef __init__(
 #elf,
 #reparer: RequirementPreparer,
 #inder: PackageFinder,
 #heel_cache: Optional[WheelCache],
 #ake_install_req: InstallRequirementProvider,
 #se_user_site: bool,
 #gnore_dependencies: bool,
 #gnore_installed: bool,
 #gnore_requires_python: bool,
 #orce_reinstall: bool,
 #pgrade_strategy: str,
 #y_version_info: Optional[Tuple[int, ...]] = None,
 # -> None:
 #uper().__init__()
 #ssert upgrade_strategy in self._allowed_strategies

 #f py_version_info is None:
 #y_version_info = sys.version_info[:3]
 #lse:
 #y_version_info = normalize_version_info(py_version_info)

 #elf._py_version_info = py_version_info

 #elf.preparer = preparer
 #elf.finder = finder
 #elf.wheel_cache = wheel_cache

 #elf.upgrade_strategy = upgrade_strategy
 #elf.force_reinstall = force_reinstall
 #elf.ignore_dependencies = ignore_dependencies
 #elf.ignore_installed = ignore_installed
 #elf.ignore_requires_python = ignore_requires_python
 #elf.use_user_site = use_user_site
 #elf._make_install_req = make_install_req

 #elf._discovered_dependencies: DiscoveredDependencies = defaultdict(list)

 #ef resolve(
 #elf, root_reqs: List[InstallRequirement], check_supported_wheels: bool
 # -> RequirementSet:
 #""Resolve what operations need to be done

 #s a side-effect of this method, the packages (and their dependencies)
 #re downloaded, unpacked and prepared for installation. This
 #reparation is done by ``pip.operations.prepare``.

 #nce PyPI has static dependency metadata available, it would be
 #ossible to move the preparation to become a step separated from
 #ependency resolution.
 #""
 #equirement_set = RequirementSet(check_supported_wheels=check_supported_wheels)
 #or req in root_reqs:
 #f req.constraint:
 #heck_invalid_constraint_type(req)
 #elf._add_requirement_to_set(requirement_set, req)

        # Actually prepare the files, and collect any exceptions. Most hash
        # exceptions cannot be checked ahead of time, because
        # _populate_link() needs to be called before we can make decisions
        # based on link type.
 #iscovered_reqs: List[InstallRequirement] = []
 #ash_errors = HashErrors()
 #or req in chain(requirement_set.all_requirements, discovered_reqs):
 #ry:
 #iscovered_reqs.extend(self._resolve_one(requirement_set, req))
 #xcept HashError as exc:
 #xc.req = req
 #ash_errors.append(exc)

 #f hash_errors:
 #aise hash_errors

 #eturn requirement_set

 #ef _add_requirement_to_set(
 #elf,
 #equirement_set: RequirementSet,
 #nstall_req: InstallRequirement,
 #arent_req_name: Optional[str] = None,
 #xtras_requested: Optional[Iterable[str]] = None,
 # -> Tuple[List[InstallRequirement], Optional[InstallRequirement]]:
 #""Add install_req as a requirement to install.

 #param parent_req_name: The name of the requirement that needed this
 #dded. The name is used because when multiple unnamed requirements
 #esolve to the same name, we could otherwise end up with dependency
 #inks that point outside the Requirements set. parent_req must
 #lready be added. Note that None implies that this is a user
 #upplied requirement, vs an inferred one.
 #param extras_requested: an iterable of extras used to evaluate the
 #nvironment markers.
 #return: Additional requirements to scan. That is either [] if
 #he requirement is not applicable, or [install_req] if the
 #equirement is applicable and has just been added.
 #""
        # If the markers do not match, ignore this requirement.
 #f not install_req.match_markers(extras_requested):
 #ogger.info(
 #Ignoring %s: markers '%s' don't match your environment",
 #nstall_req.name,
 #nstall_req.markers,
 #
 #eturn [], None

        # If the wheel is not supported, raise an error.
        # Should check this after filtering out based on environment markers to
        # allow specifying different wheels based on the environment/OS, in a
        # single requirements file.
 #f install_req.link and install_req.link.is_wheel:
 #heel = Wheel(install_req.link.filename)
 #ags = compatibility_tags.get_supported()
 #f requirement_set.check_supported_wheels and not wheel.supported(tags):
 #aise InstallationError(
 #"{wheel.filename} is not a supported wheel on this platform."
 #

        # This next bit is really a sanity check.
 #ssert (
 #ot install_req.user_supplied or parent_req_name is None
 #, "a user supplied req shouldn't have a parent"

        # Unnamed requirements are scanned again and the requirement won't be
        # added as a dependency until after scanning.
 #f not install_req.name:
 #equirement_set.add_unnamed_requirement(install_req)
 #eturn [install_req], None

 #ry:
 #xisting_req: Optional[
 #nstallRequirement
 # = requirement_set.get_requirement(install_req.name)
 #xcept KeyError:
 #xisting_req = None

 #as_conflicting_requirement = (
 #arent_req_name is None
 #nd existing_req
 #nd not existing_req.constraint
 #nd existing_req.extras == install_req.extras
 #nd existing_req.req
 #nd install_req.req
 #nd existing_req.req.specifier != install_req.req.specifier
 #
 #f has_conflicting_requirement:
 #aise InstallationError(
 #Double requirement given: {} (already in {}, name={!r})".format(
 #nstall_req, existing_req, install_req.name
 #
 #

        # When no existing requirement exists, add the requirement as a
        # dependency and it will be scanned again after.
 #f not existing_req:
 #equirement_set.add_named_requirement(install_req)
            # We'd want to rescan this requirement later
 #eturn [install_req], install_req

        # Assume there's no need to scan, and that we've already
        # encountered this for scanning.
 #f install_req.constraint or not existing_req.constraint:
 #eturn [], existing_req

 #oes_not_satisfy_constraint = install_req.link and not (
 #xisting_req.link and install_req.link.path == existing_req.link.path
 #
 #f does_not_satisfy_constraint:
 #aise InstallationError(
 #"Could not satisfy constraints for '{install_req.name}': "
 #installation from path or url cannot be "
 #constrained to a version"
 #
        # If we're now installing a constraint, mark the existing
        # object for real installation.
 #xisting_req.constraint = False
        # If we're now installing a user supplied requirement,
        # mark the existing object as such.
 #f install_req.user_supplied:
 #xisting_req.user_supplied = True
 #xisting_req.extras = tuple(
 #orted(set(existing_req.extras) | set(install_req.extras))
 #
 #ogger.debug(
 #Setting %s extras to: %s",
 #xisting_req,
 #xisting_req.extras,
 #
        # Return the existing requirement for addition to the parent and
        # scanning again.
 #eturn [existing_req], existing_req

 #ef _is_upgrade_allowed(self, req: InstallRequirement) -> bool:
 #f self.upgrade_strategy == "to-satisfy-only":
 #eturn False
 #lif self.upgrade_strategy == "eager":
 #eturn True
 #lse:
 #ssert self.upgrade_strategy == "only-if-needed"
 #eturn req.user_supplied or req.constraint

 #ef _set_req_to_reinstall(self, req: InstallRequirement) -> None:
 #""
 #et a requirement to be installed.
 #""
        # Don't uninstall the conflict if doing a user install and the
        # conflict is not a user install.
 #f not self.use_user_site or req.satisfied_by.in_usersite:
 #eq.should_reinstall = True
 #eq.satisfied_by = None

 #ef _check_skip_installed(
 #elf, req_to_install: InstallRequirement
 # -> Optional[str]:
 #""Check if req_to_install should be skipped.

 #his will check if the req is installed, and whether we should upgrade
 #r reinstall it, taking into account all the relevant user options.

 #fter calling this req_to_install will only have satisfied_by set to
 #one if the req_to_install is to be upgraded/reinstalled etc. Any
 #ther value will be a dist recording the current thing installed that
 #atisfies the requirement.

 #ote that for vcs urls and the like we can't assess skipping in this
 #outine - we simply identify that we need to pull the thing down,
 #hen later on it is pulled down and introspected to assess upgrade/
 #einstalls etc.

 #return: A text reason for why it was skipped, or None.
 #""
 #f self.ignore_installed:
 #eturn None

 #eq_to_install.check_if_exists(self.use_user_site)
 #f not req_to_install.satisfied_by:
 #eturn None

 #f self.force_reinstall:
 #elf._set_req_to_reinstall(req_to_install)
 #eturn None

 #f not self._is_upgrade_allowed(req_to_install):
 #f self.upgrade_strategy == "only-if-needed":
 #eturn "already satisfied, skipping upgrade"
 #eturn "already satisfied"

        # Check for the possibility of an upgrade.  For link-based
        # requirements we have to pull the tree down and inspect to assess
        # the version #, so it's handled way down.
 #f not req_to_install.link:
 #ry:
 #elf.finder.find_requirement(req_to_install, upgrade=True)
 #xcept BestVersionAlreadyInstalled:
                # Then the best version is installed.
 #eturn "already up-to-date"
 #xcept DistributionNotFound:
                # No distribution found, so we squash the error.  It will
                # be raised later when we re-try later to do the install.
                # Why don't we just raise here?
 #ass

 #elf._set_req_to_reinstall(req_to_install)
 #eturn None

 #ef _find_requirement_link(self, req: InstallRequirement) -> Optional[Link]:
 #pgrade = self._is_upgrade_allowed(req)
 #est_candidate = self.finder.find_requirement(req, upgrade)
 #f not best_candidate:
 #eturn None

        # Log a warning per PEP 592 if necessary before returning.
 #ink = best_candidate.link
 #f link.is_yanked:
 #eason = link.yanked_reason or "<none given>"
 #sg = (
                # Mark this as a unicode string to prevent
                # "UnicodeEncodeError: 'ascii' codec can't encode character"
                # in Python 2 when the reason contains non-ascii characters.
 #The candidate selected for download or install is a "
 #"yanked version: {best_candidate}\n"
 #"Reason for being yanked: {reason}"
 #
 #ogger.warning(msg)

 #eturn link

 #ef _populate_link(self, req: InstallRequirement) -> None:
 #""Ensure that if a link can be found for this, that it is found.

 #ote that req.link may still be None - if the requirement is already
 #nstalled and not needed to be upgraded based on the return value of
 #is_upgrade_allowed().

 #f preparer.require_hashes is True, don't use the wheel cache, because
 #ached wheels, always built locally, have different hashes than the
 #iles downloaded from the index server and thus throw false hash
 #ismatches. Furthermore, cached wheels at present have undeterministic
 #ontents due to file modification times.
 #""
 #f req.link is None:
 #eq.link = self._find_requirement_link(req)

 #f self.wheel_cache is None or self.preparer.require_hashes:
 #eturn
 #ache_entry = self.wheel_cache.get_cache_entry(
 #ink=req.link,
 #ackage_name=req.name,
 #upported_tags=get_supported(),
 #
 #f cache_entry is not None:
 #ogger.debug("Using cached wheel link: %s", cache_entry.link)
 #f req.link is req.original_link and cache_entry.persistent:
 #eq.cached_wheel_source_link = req.link
 #f cache_entry.origin is not None:
 #eq.download_info = cache_entry.origin
 #lse:
                # Legacy cache entry that does not have origin.json.
                # download_info may miss the archive_info.hashes field.
 #eq.download_info = direct_url_from_link(
 #eq.link, link_is_in_wheel_cache=cache_entry.persistent
 #
 #eq.link = cache_entry.link

 #ef _get_dist_for(self, req: InstallRequirement) -> BaseDistribution:
 #""Takes a InstallRequirement and returns a single AbstractDist \
 #epresenting a prepared variant of the same.
 #""
 #f req.editable:
 #eturn self.preparer.prepare_editable_requirement(req)

        # satisfied_by is only evaluated by calling _check_skip_installed,
        # so it must be None here.
 #ssert req.satisfied_by is None
 #kip_reason = self._check_skip_installed(req)

 #f req.satisfied_by:
 #eturn self.preparer.prepare_installed_requirement(req, skip_reason)

        # We eagerly populate the link, since that's our "legacy" behavior.
 #elf._populate_link(req)
 #ist = self.preparer.prepare_linked_requirement(req)

        # NOTE
        # The following portion is for determining if a certain package is
        # going to be re-installed/upgraded or not and reporting to the user.
        # This should probably get cleaned up in a future refactor.

        # req.req is only avail after unpack for URL
        # pkgs repeat check_if_exists to uninstall-on-upgrade
        # (#14)
 #f not self.ignore_installed:
 #eq.check_if_exists(self.use_user_site)

 #f req.satisfied_by:
 #hould_modify = (
 #elf.upgrade_strategy != "to-satisfy-only"
 #r self.force_reinstall
 #r self.ignore_installed
 #r req.link.scheme == "file"
 #
 #f should_modify:
 #elf._set_req_to_reinstall(req)
 #lse:
 #ogger.info(
 #Requirement already satisfied (use --upgrade to upgrade): %s",
 #eq,
 #
 #eturn dist

 #ef _resolve_one(
 #elf,
 #equirement_set: RequirementSet,
 #eq_to_install: InstallRequirement,
 # -> List[InstallRequirement]:
 #""Prepare a single requirements file.

 #return: A list of additional InstallRequirements to also install.
 #""
        # Tell user what we are doing for this requirement:
        # obtain (editable), skipping, processing (local url), collecting
        # (remote url or package name)
 #f req_to_install.constraint or req_to_install.prepared:
 #eturn []

 #eq_to_install.prepared = True

        # Parse and return dependencies
 #ist = self._get_dist_for(req_to_install)
        # This will raise UnsupportedPythonVersion if the given Python
        # version isn't compatible with the distribution's Requires-Python.
 #check_dist_requires_python(
 #ist,
 #ersion_info=self._py_version_info,
 #gnore_requires_python=self.ignore_requires_python,
 #

 #ore_reqs: List[InstallRequirement] = []

 #ef add_req(subreq: Requirement, extras_requested: Iterable[str]) -> None:
            # This idiosyncratically converts the Requirement to str and let
            # make_install_req then parse it again into Requirement. But this is
            # the legacy resolver so I'm just not going to bother refactoring.
 #ub_install_req = self._make_install_req(str(subreq), req_to_install)
 #arent_req_name = req_to_install.name
 #o_scan_again, add_to_parent = self._add_requirement_to_set(
 #equirement_set,
 #ub_install_req,
 #arent_req_name=parent_req_name,
 #xtras_requested=extras_requested,
 #
 #f parent_req_name and add_to_parent:
 #elf._discovered_dependencies[parent_req_name].append(add_to_parent)
 #ore_reqs.extend(to_scan_again)

 #ith indent_log():
            # We add req_to_install before its dependencies, so that we
            # can refer to it when adding dependencies.
 #f not requirement_set.has_requirement(req_to_install.name):
                # 'unnamed' requirements will get added here
                # 'unnamed' requirements can only come from being directly
                # provided by the user.
 #ssert req_to_install.user_supplied
 #elf._add_requirement_to_set(
 #equirement_set, req_to_install, parent_req_name=None
 #

 #f not self.ignore_dependencies:
 #f req_to_install.extras:
 #ogger.debug(
 #Installing extra requirements: %r",
 #,".join(req_to_install.extras),
 #
 #issing_requested = sorted(
 #et(req_to_install.extras) - set(dist.iter_provided_extras())
 #
 #or missing in missing_requested:
 #ogger.warning(
 #%s %s does not provide the extra '%s'",
 #ist.raw_name,
 #ist.version,
 #issing,
 #

 #vailable_requested = sorted(
 #et(dist.iter_provided_extras()) & set(req_to_install.extras)
 #
 #or subreq in dist.iter_dependencies(available_requested):
 #dd_req(subreq, extras_requested=available_requested)

 #eturn more_reqs

 #ef get_installation_order(
 #elf, req_set: RequirementSet
 # -> List[InstallRequirement]:
 #""Create the installation order.

 #he installation order is topological - requirements are installed
 #efore the requiring thing. We break cycles at an arbitrary point,
 #nd make no other guarantees.
 #""
        # The current implementation, which we may change at any point
        # installs the user specified things in the order given, except when
        # dependencies must come earlier to achieve topological order.
 #rder = []
 #rdered_reqs: Set[InstallRequirement] = set()

 #ef schedule(req: InstallRequirement) -> None:
 #f req.satisfied_by or req in ordered_reqs:
 #eturn
 #f req.constraint:
 #eturn
 #rdered_reqs.add(req)
 #or dep in self._discovered_dependencies[req.name]:
 #chedule(dep)
 #rder.append(req)

 #or install_req in req_set.requirements.values():
 #chedule(install_req)
 #eturn order
