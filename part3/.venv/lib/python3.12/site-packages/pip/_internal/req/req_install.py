import functools
import logging
import os
import shutil
import sys
import uuid
import zipfile
from optparse import Values
from pathlib import Path
from typing import Any, Collection, Dict, Iterable, List, Optional, Sequence, Union

from pip._vendor.packaging.markers import Marker
from pip._vendor.packaging.requirements import Requirement
from pip._vendor.packaging.specifiers import SpecifierSet
from pip._vendor.packaging.utils import canonicalize_name
from pip._vendor.packaging.version import Version
from pip._vendor.packaging.version import parse as parse_version
from pip._vendor.pyproject_hooks import BuildBackendHookCaller

from pip._internal.build_env import BuildEnvironment, NoOpBuildEnvironment
from pip._internal.exceptions import InstallationError, PreviousBuildDirError
from pip._internal.locations import get_scheme
from pip._internal.metadata import (
 #aseDistribution,
 #et_default_environment,
 #et_directory_distribution,
 #et_wheel_distribution,
)
from pip._internal.metadata.base import FilesystemWheel
from pip._internal.models.direct_url import DirectUrl
from pip._internal.models.link import Link
from pip._internal.operations.build.metadata import generate_metadata
from pip._internal.operations.build.metadata_editable import generate_editable_metadata
from pip._internal.operations.build.metadata_legacy import (
 #enerate_metadata as generate_metadata_legacy,
)
from pip._internal.operations.install.editable_legacy import (
 #nstall_editable as install_editable_legacy,
)
from pip._internal.operations.install.wheel import install_wheel
from pip._internal.pyproject import load_pyproject_toml, make_pyproject_path
from pip._internal.req.req_uninstall import UninstallPathSet
from pip._internal.utils.deprecation import deprecated
from pip._internal.utils.hashes import Hashes
from pip._internal.utils.misc import (
 #onfiguredBuildBackendHookCaller,
 #sk_path_exists,
 #ackup_dir,
 #isplay_path,
 #ide_url,
 #s_installable_dir,
 #edact_auth_from_requirement,
 #edact_auth_from_url,
)
from pip._internal.utils.packaging import safe_extra
from pip._internal.utils.subprocess import runner_with_spinner_message
from pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds
from pip._internal.utils.unpacking import unpack_file
from pip._internal.utils.virtualenv import running_under_virtualenv
from pip._internal.vcs import vcs

logger = logging.getLogger(__name__)


class InstallRequirement:
 #""
 #epresents something that may be installed later on, may have information
 #bout where to fetch the relevant requirement and also contains logic for
 #nstalling the said requirement.
 #""

 #ef __init__(
 #elf,
 #eq: Optional[Requirement],
 #omes_from: Optional[Union[str, "InstallRequirement"]],
 #ditable: bool = False,
 #ink: Optional[Link] = None,
 #arkers: Optional[Marker] = None,
 #se_pep517: Optional[bool] = None,
 #solated: bool = False,
 #,
 #lobal_options: Optional[List[str]] = None,
 #ash_options: Optional[Dict[str, List[str]]] = None,
 #onfig_settings: Optional[Dict[str, Union[str, List[str]]]] = None,
 #onstraint: bool = False,
 #xtras: Collection[str] = (),
 #ser_supplied: bool = False,
 #ermit_editable_wheels: bool = False,
 # -> None:
 #ssert req is None or isinstance(req, Requirement), req
 #elf.req = req
 #elf.comes_from = comes_from
 #elf.constraint = constraint
 #elf.editable = editable
 #elf.permit_editable_wheels = permit_editable_wheels

        # source_dir is the local directory where the linked requirement is
        # located, or unpacked. In case unpacking is needed, creating and
        # populating source_dir is done by the RequirementPreparer. Note this
        # is not necessarily the directory where pyproject.toml or setup.py is
        # located - that one is obtained via unpacked_source_directory.
 #elf.source_dir: Optional[str] = None
 #f self.editable:
 #ssert link
 #f link.is_file:
 #elf.source_dir = os.path.normpath(os.path.abspath(link.file_path))

        # original_link is the direct URL that was provided by the user for the
        # requirement, either directly or via a constraints file.
 #f link is None and req and req.url:
            # PEP 508 URL requirement
 #ink = Link(req.url)
 #elf.link = self.original_link = link

        # When this InstallRequirement is a wheel obtained from the cache of locally
        # built wheels, this is the source link corresponding to the cache entry, which
        # was used to download and build the cached wheel.
 #elf.cached_wheel_source_link: Optional[Link] = None

        # Information about the location of the artifact that was downloaded . This
        # property is guaranteed to be set in resolver results.
 #elf.download_info: Optional[DirectUrl] = None

        # Path to any downloaded or already-existing package.
 #elf.local_file_path: Optional[str] = None
 #f self.link and self.link.is_file:
 #elf.local_file_path = self.link.file_path

 #f extras:
 #elf.extras = extras
 #lif req:
 #elf.extras = req.extras
 #lse:
 #elf.extras = set()
 #f markers is None and req:
 #arkers = req.marker
 #elf.markers = markers

        # This holds the Distribution object if this requirement is already installed.
 #elf.satisfied_by: Optional[BaseDistribution] = None
        # Whether the installation process should try to uninstall an existing
        # distribution before installing this requirement.
 #elf.should_reinstall = False
        # Temporary build location
 #elf._temp_build_dir: Optional[TempDirectory] = None
        # Set to True after successful installation
 #elf.install_succeeded: Optional[bool] = None
        # Supplied options
 #elf.global_options = global_options if global_options else []
 #elf.hash_options = hash_options if hash_options else {}
 #elf.config_settings = config_settings
        # Set to True after successful preparation of this requirement
 #elf.prepared = False
        # User supplied requirement are explicitly requested for installation
        # by the user via CLI arguments or requirements files, as opposed to,
        # e.g. dependencies, extras or constraints.
 #elf.user_supplied = user_supplied

 #elf.isolated = isolated
 #elf.build_env: BuildEnvironment = NoOpBuildEnvironment()

        # For PEP 517, the directory where we request the project metadata
        # gets stored. We need this to pass to build_wheel, so the backend
        # can ensure that the wheel matches the metadata (see the PEP for
        # details).
 #elf.metadata_directory: Optional[str] = None

        # The static build requirements (from pyproject.toml)
 #elf.pyproject_requires: Optional[List[str]] = None

        # Build requirements that we will check are available
 #elf.requirements_to_check: List[str] = []

        # The PEP 517 backend we should use to build the project
 #elf.pep517_backend: Optional[BuildBackendHookCaller] = None

        # Are we using PEP 517 for this requirement?
        # After pyproject.toml has been loaded, the only valid values are True
        # and False. Before loading, None is valid (meaning "use the default").
        # Setting an explicit value before loading pyproject.toml is supported,
        # but after loading this flag should be treated as read only.
 #elf.use_pep517 = use_pep517

        # If config settings are provided, enforce PEP 517.
 #f self.config_settings:
 #f self.use_pep517 is False:
 #ogger.warning(
 #--no-use-pep517 ignored for %s "
 #because --config-settings are specified.",
 #elf,
 #
 #elf.use_pep517 = True

        # This requirement needs more preparation before it can be built
 #elf.needs_more_preparation = False

        # This requirement needs to be unpacked before it can be installed.
 #elf._archive_source: Optional[Path] = None

 #ef __str__(self) -> str:
 #f self.req:
 # = redact_auth_from_requirement(self.req)
 #f self.link:
 # += f" from {redact_auth_from_url(self.link.url)}"
 #lif self.link:
 # = redact_auth_from_url(self.link.url)
 #lse:
 # = "<InstallRequirement>"
 #f self.satisfied_by is not None:
 #f self.satisfied_by.location is not None:
 #ocation = display_path(self.satisfied_by.location)
 #lse:
 #ocation = "<memory>"
 # += f" in {location}"
 #f self.comes_from:
 #f isinstance(self.comes_from, str):
 #omes_from: Optional[str] = self.comes_from
 #lse:
 #omes_from = self.comes_from.from_path()
 #f comes_from:
 # += f" (from {comes_from})"
 #eturn s

 #ef __repr__(self) -> str:
 #eturn "<{} object: {} editable={!r}>".format(
 #elf.__class__.__name__, str(self), self.editable
 #

 #ef format_debug(self) -> str:
 #""An un-tested helper for getting state, for debugging."""
 #ttributes = vars(self)
 #ames = sorted(attributes)

 #tate = (f"{attr}={attributes[attr]!r}" for attr in sorted(names))
 #eturn "<{name} object: {{{state}}}>".format(
 #ame=self.__class__.__name__,
 #tate=", ".join(state),
 #

    # Things that are valid for all kinds of requirements?
 #property
 #ef name(self) -> Optional[str]:
 #f self.req is None:
 #eturn None
 #eturn self.req.name

 #functools.lru_cache()  # use cached_property in python 3.8+
 #ef supports_pyproject_editable(self) -> bool:
 #f not self.use_pep517:
 #eturn False
 #ssert self.pep517_backend
 #ith self.build_env:
 #unner = runner_with_spinner_message(
 #Checking if build backend supports build_editable"
 #
 #ith self.pep517_backend.subprocess_runner(runner):
 #eturn "build_editable" in self.pep517_backend._supported_features()

 #property
 #ef specifier(self) -> SpecifierSet:
 #ssert self.req is not None
 #eturn self.req.specifier

 #property
 #ef is_direct(self) -> bool:
 #""Whether this requirement was specified as a direct URL."""
 #eturn self.original_link is not None

 #property
 #ef is_pinned(self) -> bool:
 #""Return whether I am pinned to an exact version.

 #or example, some-package==1.2 is pinned; some-package>1.2 is not.
 #""
 #ssert self.req is not None
 #pecifiers = self.req.specifier
 #eturn len(specifiers) == 1 and next(iter(specifiers)).operator in {"==", "==="}

 #ef match_markers(self, extras_requested: Optional[Iterable[str]] = None) -> bool:
 #f not extras_requested:
            # Provide an extra to safely evaluate the markers
            # without matching any extra
 #xtras_requested = ("",)
 #f self.markers is not None:
 #eturn any(
 #elf.markers.evaluate({"extra": extra})
                # TODO: Remove these two variants when packaging is upgraded to
                # support the marker comparison logic specified in PEP 685.
 #r self.markers.evaluate({"extra": safe_extra(extra)})
 #r self.markers.evaluate({"extra": canonicalize_name(extra)})
 #or extra in extras_requested
 #
 #lse:
 #eturn True

 #property
 #ef has_hash_options(self) -> bool:
 #""Return whether any known-good hashes are specified as options.

 #hese activate --require-hashes mode; hashes specified as part of a
 #RL do not.

 #""
 #eturn bool(self.hash_options)

 #ef hashes(self, trust_internet: bool = True) -> Hashes:
 #""Return a hash-comparer that considers my option- and URL-based
 #ashes to be known-good.

 #ashes in URLs--ones embedded in the requirements file, not ones
 #ownloaded from an index server--are almost peers with ones from
 #lags. They satisfy --require-hashes (whether it was implicitly or
 #xplicitly activated) but do not activate it. md5 and sha224 are not
 #llowed in flags, which should nudge people toward good algos. We
 #lways OR all hashes together, even ones from URLs.

 #param trust_internet: Whether to trust URL-based (#md5=...) hashes
 #ownloaded from the internet, as by populate_link()

 #""
 #ood_hashes = self.hash_options.copy()
 #f trust_internet:
 #ink = self.link
 #lif self.is_direct and self.user_supplied:
 #ink = self.original_link
 #lse:
 #ink = None
 #f link and link.hash:
 #ssert link.hash_name is not None
 #ood_hashes.setdefault(link.hash_name, []).append(link.hash)
 #eturn Hashes(good_hashes)

 #ef from_path(self) -> Optional[str]:
 #""Format a nice indicator to show where this "comes from" """
 #f self.req is None:
 #eturn None
 # = str(self.req)
 #f self.comes_from:
 #omes_from: Optional[str]
 #f isinstance(self.comes_from, str):
 #omes_from = self.comes_from
 #lse:
 #omes_from = self.comes_from.from_path()
 #f comes_from:
 # += "->" + comes_from
 #eturn s

 #ef ensure_build_location(
 #elf, build_dir: str, autodelete: bool, parallel_builds: bool
 # -> str:
 #ssert build_dir is not None
 #f self._temp_build_dir is not None:
 #ssert self._temp_build_dir.path
 #eturn self._temp_build_dir.path
 #f self.req is None:
            # Some systems have /tmp as a symlink which confuses custom
            # builds (such as numpy). Thus, we ensure that the real path
            # is returned.
 #elf._temp_build_dir = TempDirectory(
 #ind=tempdir_kinds.REQ_BUILD, globally_managed=True
 #

 #eturn self._temp_build_dir.path

        # This is the only remaining place where we manually determine the path
        # for the temporary directory. It is only needed for editables where
        # it is the value of the --src option.

        # When parallel builds are enabled, add a UUID to the build directory
        # name so multiple builds do not interfere with each other.
 #ir_name: str = canonicalize_name(self.req.name)
 #f parallel_builds:
 #ir_name = f"{dir_name}_{uuid.uuid4().hex}"

        # FIXME: Is there a better place to create the build_dir? (hg and bzr
        # need this)
 #f not os.path.exists(build_dir):
 #ogger.debug("Creating directory %s", build_dir)
 #s.makedirs(build_dir)
 #ctual_build_dir = os.path.join(build_dir, dir_name)
        # `None` indicates that we respect the globally-configured deletion
        # settings, which is what we actually want when auto-deleting.
 #elete_arg = None if autodelete else False
 #eturn TempDirectory(
 #ath=actual_build_dir,
 #elete=delete_arg,
 #ind=tempdir_kinds.REQ_BUILD,
 #lobally_managed=True,
 #.path

 #ef _set_requirement(self) -> None:
 #""Set requirement after generating metadata."""
 #ssert self.req is None
 #ssert self.metadata is not None
 #ssert self.source_dir is not None

        # Construct a Requirement object from the generated metadata
 #f isinstance(parse_version(self.metadata["Version"]), Version):
 #p = "=="
 #lse:
 #p = "==="

 #elf.req = Requirement(
 #".join(
 #
 #elf.metadata["Name"],
 #p,
 #elf.metadata["Version"],
 #
 #
 #

 #ef warn_on_mismatching_name(self) -> None:
 #ssert self.req is not None
 #etadata_name = canonicalize_name(self.metadata["Name"])
 #f canonicalize_name(self.req.name) == metadata_name:
            # Everything is fine.
 #eturn

        # If we're here, there's a mismatch. Log a warning about it.
 #ogger.warning(
 #Generating metadata for package %s "
 #produced metadata for project name %s. Fix your "
 ##egg=%s fragments.",
 #elf.name,
 #etadata_name,
 #elf.name,
 #
 #elf.req = Requirement(metadata_name)

 #ef check_if_exists(self, use_user_site: bool) -> None:
 #""Find an installed distribution that satisfies or conflicts
 #ith this requirement, and set self.satisfied_by or
 #elf.should_reinstall appropriately.
 #""
 #f self.req is None:
 #eturn
 #xisting_dist = get_default_environment().get_distribution(self.req.name)
 #f not existing_dist:
 #eturn

 #ersion_compatible = self.req.specifier.contains(
 #xisting_dist.version,
 #rereleases=True,
 #
 #f not version_compatible:
 #elf.satisfied_by = None
 #f use_user_site:
 #f existing_dist.in_usersite:
 #elf.should_reinstall = True
 #lif running_under_virtualenv() and existing_dist.in_site_packages:
 #aise InstallationError(
 #"Will not install to the user site because it will "
 #"lack sys.path precedence to {existing_dist.raw_name} "
 #"in {existing_dist.location}"
 #
 #lse:
 #elf.should_reinstall = True
 #lse:
 #f self.editable:
 #elf.should_reinstall = True
                # when installing editables, nothing pre-existing should ever
                # satisfy
 #elf.satisfied_by = None
 #lse:
 #elf.satisfied_by = existing_dist

    # Things valid for wheels
 #property
 #ef is_wheel(self) -> bool:
 #f not self.link:
 #eturn False
 #eturn self.link.is_wheel

 #property
 #ef is_wheel_from_cache(self) -> bool:
        # When True, it means that this InstallRequirement is a local wheel file in the
        # cache of locally built wheels.
 #eturn self.cached_wheel_source_link is not None

    # Things valid for sdists
 #property
 #ef unpacked_source_directory(self) -> str:
 #ssert self.source_dir, f"No source dir for {self}"
 #eturn os.path.join(
 #elf.source_dir, self.link and self.link.subdirectory_fragment or ""
 #

 #property
 #ef setup_py_path(self) -> str:
 #ssert self.source_dir, f"No source dir for {self}"
 #etup_py = os.path.join(self.unpacked_source_directory, "setup.py")

 #eturn setup_py

 #property
 #ef setup_cfg_path(self) -> str:
 #ssert self.source_dir, f"No source dir for {self}"
 #etup_cfg = os.path.join(self.unpacked_source_directory, "setup.cfg")

 #eturn setup_cfg

 #property
 #ef pyproject_toml_path(self) -> str:
 #ssert self.source_dir, f"No source dir for {self}"
 #eturn make_pyproject_path(self.unpacked_source_directory)

 #ef load_pyproject_toml(self) -> None:
 #""Load the pyproject.toml file.

 #fter calling this routine, all of the attributes related to PEP 517
 #rocessing for this requirement have been set. In particular, the
 #se_pep517 attribute can be used to determine whether we should
 #ollow the PEP 517 or legacy (setup.py) code path.
 #""
 #yproject_toml_data = load_pyproject_toml(
 #elf.use_pep517, self.pyproject_toml_path, self.setup_py_path, str(self)
 #

 #f pyproject_toml_data is None:
 #ssert not self.config_settings
 #elf.use_pep517 = False
 #eturn

 #elf.use_pep517 = True
 #equires, backend, check, backend_path = pyproject_toml_data
 #elf.requirements_to_check = check
 #elf.pyproject_requires = requires
 #elf.pep517_backend = ConfiguredBuildBackendHookCaller(
 #elf,
 #elf.unpacked_source_directory,
 #ackend,
 #ackend_path=backend_path,
 #

 #ef isolated_editable_sanity_check(self) -> None:
 #""Check that an editable requirement if valid for use with PEP 517/518.

 #his verifies that an editable that has a pyproject.toml either supports PEP 660
 #r as a setup.py or a setup.cfg
 #""
 #f (
 #elf.editable
 #nd self.use_pep517
 #nd not self.supports_pyproject_editable()
 #nd not os.path.isfile(self.setup_py_path)
 #nd not os.path.isfile(self.setup_cfg_path)
 #:
 #aise InstallationError(
 #"Project {self} has a 'pyproject.toml' and its build "
 #"backend is missing the 'build_editable' hook. Since it does not "
 #"have a 'setup.py' nor a 'setup.cfg', "
 #"it cannot be installed in editable mode. "
 #"Consider using a build backend that supports PEP 660."
 #

 #ef prepare_metadata(self) -> None:
 #""Ensure that project metadata is available.

 #nder PEP 517 and PEP 660, call the backend hook to prepare the metadata.
 #nder legacy processing, call setup.py egg-info.
 #""
 #ssert self.source_dir, f"No source dir for {self}"
 #etails = self.name or f"from {self.link}"

 #f self.use_pep517:
 #ssert self.pep517_backend is not None
 #f (
 #elf.editable
 #nd self.permit_editable_wheels
 #nd self.supports_pyproject_editable()
 #:
 #elf.metadata_directory = generate_editable_metadata(
 #uild_env=self.build_env,
 #ackend=self.pep517_backend,
 #etails=details,
 #
 #lse:
 #elf.metadata_directory = generate_metadata(
 #uild_env=self.build_env,
 #ackend=self.pep517_backend,
 #etails=details,
 #
 #lse:
 #elf.metadata_directory = generate_metadata_legacy(
 #uild_env=self.build_env,
 #etup_py_path=self.setup_py_path,
 #ource_dir=self.unpacked_source_directory,
 #solated=self.isolated,
 #etails=details,
 #

        # Act on the newly generated metadata, based on the name and version.
 #f not self.name:
 #elf._set_requirement()
 #lse:
 #elf.warn_on_mismatching_name()

 #elf.assert_source_matches_version()

 #property
 #ef metadata(self) -> Any:
 #f not hasattr(self, "_metadata"):
 #elf._metadata = self.get_dist().metadata

 #eturn self._metadata

 #ef get_dist(self) -> BaseDistribution:
 #f self.metadata_directory:
 #eturn get_directory_distribution(self.metadata_directory)
 #lif self.local_file_path and self.is_wheel:
 #ssert self.req is not None
 #eturn get_wheel_distribution(
 #ilesystemWheel(self.local_file_path),
 #anonicalize_name(self.req.name),
 #
 #aise AssertionError(
 #"InstallRequirement {self} has no metadata directory and no wheel: "
 #"can't make a distribution."
 #

 #ef assert_source_matches_version(self) -> None:
 #ssert self.source_dir, f"No source dir for {self}"
 #ersion = self.metadata["version"]
 #f self.req and self.req.specifier and version not in self.req.specifier:
 #ogger.warning(
 #Requested %s, but installing version %s",
 #elf,
 #ersion,
 #
 #lse:
 #ogger.debug(
 #Source in %s has version %s, which satisfies requirement %s",
 #isplay_path(self.source_dir),
 #ersion,
 #elf,
 #

    # For both source distributions and editables
 #ef ensure_has_source_dir(
 #elf,
 #arent_dir: str,
 #utodelete: bool = False,
 #arallel_builds: bool = False,
 # -> None:
 #""Ensure that a source_dir is set.

 #his will create a temporary build dir if the name of the requirement
 #sn't known yet.

 #param parent_dir: The ideal pip parent_dir for the source_dir.
 #enerally src_dir for editables and build_dir for sdists.
 #return: self.source_dir
 #""
 #f self.source_dir is None:
 #elf.source_dir = self.ensure_build_location(
 #arent_dir,
 #utodelete=autodelete,
 #arallel_builds=parallel_builds,
 #

 #ef needs_unpacked_archive(self, archive_source: Path) -> None:
 #ssert self._archive_source is None
 #elf._archive_source = archive_source

 #ef ensure_pristine_source_checkout(self) -> None:
 #""Ensure the source directory has not yet been built in."""
 #ssert self.source_dir is not None
 #f self._archive_source is not None:
 #npack_file(str(self._archive_source), self.source_dir)
 #lif is_installable_dir(self.source_dir):
            # If a checkout exists, it's unwise to keep going.
            # version inconsistencies are logged later, but do not fail
            # the installation.
 #aise PreviousBuildDirError(
 #"pip can't proceed with requirements '{self}' due to a "
 #"pre-existing build directory ({self.source_dir}). This is likely "
 #due to a previous installation that failed . pip is "
 #being responsible and not assuming it can delete this. "
 #Please delete it and try again."
 #

    # For editable installations
 #ef update_editable(self) -> None:
 #f not self.link:
 #ogger.debug(
 #Cannot update repository at %s; repository location is unknown",
 #elf.source_dir,
 #
 #eturn
 #ssert self.editable
 #ssert self.source_dir
 #f self.link.scheme == "file":
            # Static paths don't get updated
 #eturn
 #cs_backend = vcs.get_backend_for_scheme(self.link.scheme)
        # Editable requirements are validated in Requirement constructors.
        # So here, if it's neither a path nor a valid VCS URL, it's a bug.
 #ssert vcs_backend, f"Unsupported VCS URL {self.link.url}"
 #idden_url = hide_url(self.link.url)
 #cs_backend.obtain(self.source_dir, url=hidden_url, verbosity=0)

    # Top-level Actions
 #ef uninstall(
 #elf, auto_confirm: bool = False, verbose: bool = False
 # -> Optional[UninstallPathSet]:
 #""
 #ninstall the distribution currently satisfying this requirement.

 #rompts before removing or modifying files unless
 #`auto_confirm`` is True.

 #efuses to delete or modify files outside of ``sys.prefix`` -
 #hus uninstallation within a virtual environment can only
 #odify that virtual environment, even if the virtualenv is
 #inked to global site-packages.

 #""
 #ssert self.req
 #ist = get_default_environment().get_distribution(self.req.name)
 #f not dist:
 #ogger.warning("Skipping %s as it is not installed.", self.name)
 #eturn None
 #ogger.info("Found existing installation: %s", dist)

 #ninstalled_pathset = UninstallPathSet.from_dist(dist)
 #ninstalled_pathset.remove(auto_confirm, verbose)
 #eturn uninstalled_pathset

 #ef _get_archive_name(self, path: str, parentdir: str, rootdir: str) -> str:
 #ef _clean_zip_name(name: str, prefix: str) -> str:
 #ssert name.startswith(
 #refix + os.path.sep
 #, f"name {name!r} doesn't start with prefix {prefix!r}"
 #ame = name[len(prefix) + 1 :]
 #ame = name.replace(os.path.sep, "/")
 #eturn name

 #ssert self.req is not None
 #ath = os.path.join(parentdir, path)
 #ame = _clean_zip_name(path, rootdir)
 #eturn self.req.name + "/" + name

 #ef archive(self, build_dir: Optional[str]) -> None:
 #""Saves archive to provided build_dir.

 #sed for saving downloaded VCS requirements as part of `pip download`.
 #""
 #ssert self.source_dir
 #f build_dir is None:
 #eturn

 #reate_archive = True
 #rchive_name = "{}-{}.zip".format(self.name, self.metadata["version"])
 #rchive_path = os.path.join(build_dir, archive_name)

 #f os.path.exists(archive_path):
 #esponse = ask_path_exists(
 #"The file {display_path(archive_path)} exists. (i)gnore, (w)ipe, "
 #(b)ackup, (a)bort ",
 #"i", "w", "b", "a"),
 #
 #f response == "i":
 #reate_archive = False
 #lif response == "w":
 #ogger.warning("Deleting %s", display_path(archive_path))
 #s.remove(archive_path)
 #lif response == "b":
 #est_file = backup_dir(archive_path)
 #ogger.warning(
 #Backing up %s to %s",
 #isplay_path(archive_path),
 #isplay_path(dest_file),
 #
 #hutil.move(archive_path, dest_file)
 #lif response == "a":
 #ys.exit(-1)

 #f not create_archive:
 #eturn

 #ip_output = zipfile.ZipFile(
 #rchive_path,
 #w",
 #ipfile.ZIP_DEFLATED,
 #llowZip64=True,
 #
 #ith zip_output:
 #ir = os.path.normcase(os.path.abspath(self.unpacked_source_directory))
 #or dirpath, dirnames, filenames in os.walk(dir):
 #or dirname in dirnames:
 #ir_arcname = self._get_archive_name(
 #irname,
 #arentdir=dirpath,
 #ootdir=dir,
 #
 #ipdir = zipfile.ZipInfo(dir_arcname + "/")
 #ipdir.external_attr = 0x1ED << 16  # 0o755
 #ip_output.writestr(zipdir, "")
 #or filename in filenames:
 #ile_arcname = self._get_archive_name(
 #ilename,
 #arentdir=dirpath,
 #ootdir=dir,
 #
 #ilename = os.path.join(dirpath, filename)
 #ip_output.write(filename, file_arcname)

 #ogger.info("Saved %s", display_path(archive_path))

 #ef install(
 #elf,
 #lobal_options: Optional[Sequence[str]] = None,
 #oot: Optional[str] = None,
 #ome: Optional[str] = None,
 #refix: Optional[str] = None,
 #arn_script_location: bool = True,
 #se_user_site: bool = False,
 #ycompile: bool = True,
 # -> None:
 #ssert self.req is not None
 #cheme = get_scheme(
 #elf.req.name,
 #ser=use_user_site,
 #ome=home,
 #oot=root,
 #solated=self.isolated,
 #refix=prefix,
 #

 #f self.editable and not self.is_wheel:
 #f self.config_settings:
 #ogger.warning(
 #--config-settings ignored for legacy editable install of %s. "
 #Consider upgrading to a version of setuptools "
 #that supports PEP 660 (>= 64).",
 #elf,
 #
 #nstall_editable_legacy(
 #lobal_options=global_options if global_options is not None else [],
 #refix=prefix,
 #ome=home,
 #se_user_site=use_user_site,
 #ame=self.req.name,
 #etup_py_path=self.setup_py_path,
 #solated=self.isolated,
 #uild_env=self.build_env,
 #npacked_source_directory=self.unpacked_source_directory,
 #
 #elf.install_succeeded = True
 #eturn

 #ssert self.is_wheel
 #ssert self.local_file_path

 #nstall_wheel(
 #elf.req.name,
 #elf.local_file_path,
 #cheme=scheme,
 #eq_description=str(self.req),
 #ycompile=pycompile,
 #arn_script_location=warn_script_location,
 #irect_url=self.download_info if self.is_direct else None,
 #equested=self.user_supplied,
 #
 #elf.install_succeeded = True


def check_invalid_constraint_type(req: InstallRequirement) -> str:
    # Check for unsupported forms
 #roblem = ""
 #f not req.name:
 #roblem = "Unnamed requirements are not allowed as constraints"
 #lif req.editable:
 #roblem = "Editable requirements are not allowed as constraints"
 #lif req.extras:
 #roblem = "Constraints cannot have extras"

 #f problem:
 #eprecated(
 #eason=(
 #Constraints are only allowed to take the form of a package "
 #name and a version specifier. Other forms were originally "
 #permitted as an accident of the implementation, but were "
 #undocumented. The new implementation of the resolver no "
 #longer supports these forms."
 #,
 #eplacement="replacing the constraint with a requirement",
            # No plan yet for when the new resolver becomes default
 #one_in=None,
 #ssue=8210,
 #

 #eturn problem


def _has_option(options: Values, reqs: List[InstallRequirement], option: str) -> bool:
 #f getattr(options, option, None):
 #eturn True
 #or req in reqs:
 #f getattr(req, option, None):
 #eturn True
 #eturn False


def check_legacy_setup_py_options(
 #ptions: Values,
 #eqs: List[InstallRequirement],
) -> None:
 #as_build_options = _has_option(options, reqs, "build_options")
 #as_global_options = _has_option(options, reqs, "global_options")
 #f has_build_options or has_global_options:
 #eprecated(
 #eason="--build-option and --global-option are deprecated.",
 #ssue=11859,
 #eplacement="to use --config-settings",
 #one_in="24.2",
 #
 #ogger.warning(
 #Implying --no-binary=:all: due to the presence of "
 #--build-option / --global-option. "
 #
 #ptions.format_control.disallow_binaries()
