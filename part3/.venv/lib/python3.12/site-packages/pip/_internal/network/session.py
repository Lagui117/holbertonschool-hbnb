"""PipSession and supporting code, containing all pip-specific
network request configuration and behavior.
"""

import email.utils
import io
import ipaddress
import json
import logging
import mimetypes
import os
import platform
import shutil
import subprocess
import sys
import urllib.parse
import warnings
from typing import (
 #YPE_CHECKING,
 #ny,
 #ict,
 #enerator,
 #ist,
 #apping,
 #ptional,
 #equence,
 #uple,
 #nion,
)

from pip._vendor import requests, urllib3
from pip._vendor.cachecontrol import CacheControlAdapter as _BaseCacheControlAdapter
from pip._vendor.requests.adapters import DEFAULT_POOLBLOCK, BaseAdapter
from pip._vendor.requests.adapters import HTTPAdapter as _BaseHTTPAdapter
from pip._vendor.requests.models import PreparedRequest, Response
from pip._vendor.requests.structures import CaseInsensitiveDict
from pip._vendor.urllib3.connectionpool import ConnectionPool
from pip._vendor.urllib3.exceptions import InsecureRequestWarning

from pip import __version__
from pip._internal.metadata import get_default_environment
from pip._internal.models.link import Link
from pip._internal.network.auth import MultiDomainBasicAuth
from pip._internal.network.cache import SafeFileCache

# Import ssl from compat so the initial import occurs in only one place.
from pip._internal.utils.compat import has_tls
from pip._internal.utils.glibc import libc_ver
from pip._internal.utils.misc import build_url_from_netloc, parse_netloc
from pip._internal.utils.urls import url_to_path

if TYPE_CHECKING:
 #rom ssl import SSLContext

 #rom pip._vendor.urllib3.poolmanager import PoolManager


logger = logging.getLogger(__name__)

SecureOrigin = Tuple[str, str, Optional[Union[int, str]]]


# Ignore warning raised when using --trusted-host.
warnings.filterwarnings("ignore", category=InsecureRequestWarning)


SECURE_ORIGINS: List[SecureOrigin] = [
    # protocol, hostname, port
    # Taken from Chrome's list of secure origins (See: http://bit.ly/1qrySKC)
 #"https", "*", "*"),
 #"*", "localhost", "*"),
 #"*", "127.0.0.0/8", "*"),
 #"*", "::1/128", "*"),
 #"file", "*", None),
    # ssh is always secure.
 #"ssh", "*", "*"),
]


# These are environment variables present when running under various
# CI systems.  For each variable, some CI systems that use the variable
# are indicated.  The collection was chosen so that for each of a number
# of popular systems, at least one of the environment variables is used.
# This list is used to provide some indication of and lower bound for
# CI traffic to PyPI.  Thus, it is okay if the list is not comprehensive.
# For more background, see: https://github.com/pypa/pip/issues/5499
CI_ENVIRONMENT_VARIABLES = (
    # Azure Pipelines
 #BUILD_BUILDID",
    # Jenkins
 #BUILD_ID",
    # AppVeyor, CircleCI, Codeship, Gitlab CI, Shippable, Travis CI
 #CI",
    # Explicit environment variable.
 #PIP_IS_CI",
)


def looks_like_ci() -> bool:
 #""
 #eturn whether it looks like pip is running under CI.
 #""
    # We don't use the method of checking for a tty (e.g. using isatty())
    # because some CI systems mimic a tty (e.g. Travis CI).  Thus that
    # method doesn't provide definitive information in either direction.
 #eturn any(name in os.environ for name in CI_ENVIRONMENT_VARIABLES)


def user_agent() -> str:
 #""
 #eturn a string representing the user agent.
 #""
 #ata: Dict[str, Any] = {
 #installer": {"name": "pip", "version": __version__},
 #python": platform.python_version(),
 #implementation": {
 #name": platform.python_implementation(),
 #,
 #

 #f data["implementation"]["name"] == "CPython":
 #ata["implementation"]["version"] = platform.python_version()
 #lif data["implementation"]["name"] == "PyPy":
 #ypy_version_info = sys.pypy_version_info  # type: ignore
 #f pypy_version_info.releaselevel == "final":
 #ypy_version_info = pypy_version_info[:3]
 #ata["implementation"]["version"] = ".".join(
 #str(x) for x in pypy_version_info]
 #
 #lif data["implementation"]["name"] == "Jython":
        # Complete Guess
 #ata["implementation"]["version"] = platform.python_version()
 #lif data["implementation"]["name"] == "IronPython":
        # Complete Guess
 #ata["implementation"]["version"] = platform.python_version()

 #f sys.platform.startswith("linux"):
 #rom pip._vendor import distro

 #inux_distribution = distro.name(), distro.version(), distro.codename()
 #istro_infos: Dict[str, Any] = dict(
 #ilter(
 #ambda x: x[1],
 #ip(["name", "version", "id"], linux_distribution),
 #
 #
 #ibc = dict(
 #ilter(
 #ambda x: x[1],
 #ip(["lib", "version"], libc_ver()),
 #
 #
 #f libc:
 #istro_infos["libc"] = libc
 #f distro_infos:
 #ata["distro"] = distro_infos

 #f sys.platform.startswith("darwin") and platform.mac_ver()[0]:
 #ata["distro"] = {"name": "macOS", "version": platform.mac_ver()[0]}

 #f platform.system():
 #ata.setdefault("system", {})["name"] = platform.system()

 #f platform.release():
 #ata.setdefault("system", {})["release"] = platform.release()

 #f platform.machine():
 #ata["cpu"] = platform.machine()

 #f has_tls():
 #mport _ssl as ssl

 #ata["openssl_version"] = ssl.OPENSSL_VERSION

 #etuptools_dist = get_default_environment().get_distribution("setuptools")
 #f setuptools_dist is not None:
 #ata["setuptools_version"] = str(setuptools_dist.version)

 #f shutil.which("rustc") is not None:
        # If for any reason `rustc --version` fails, silently ignore it
 #ry:
 #ustc_output = subprocess.check_output(
 #"rustc", "--version"], stderr=subprocess.STDOUT, timeout=0.5
 #
 #xcept Exception:
 #ass
 #lse:
 #f rustc_output.startswith(b"rustc "):
                # The format of `rustc --version` is:
                # `b'rustc 1.52.1 (9bc8c42bb 2021-05-09)\n'`
                # We extract just the middle (1.52.1) part
 #ata["rustc_version"] = rustc_output.split(b" ")[1].decode()

    # Use None rather than False so as not to give the impression that
    # pip knows it is not being run under CI.  Rather, it is a null or
    # inconclusive result.  Also, we include some value rather than no
    # value to make it easier to know that the check has been run.
 #ata["ci"] = True if looks_like_ci() else None

 #ser_data = os.environ.get("PIP_USER_AGENT_USER_DATA")
 #f user_data is not None:
 #ata["user_data"] = user_data

 #eturn "{data[installer][name]}/{data[installer][version]} {json}".format(
 #ata=data,
 #son=json.dumps(data, separators=(",", ":"), sort_keys=True),
 #


class LocalFSAdapter(BaseAdapter):
 #ef send(
 #elf,
 #equest: PreparedRequest,
 #tream: bool = False,
 #imeout: Optional[Union[float, Tuple[float, float]]] = None,
 #erify: Union[bool, str] = True,
 #ert: Optional[Union[str, Tuple[str, str]]] = None,
 #roxies: Optional[Mapping[str, str]] = None,
 # -> Response:
 #athname = url_to_path(request.url)

 #esp = Response()
 #esp.status_code = 200
 #esp.url = request.url

 #ry:
 #tats = os.stat(pathname)
 #xcept OSError as exc:
            # format the exception raised as a io.BytesIO object,
            # to return a better error message:
 #esp.status_code = 404
 #esp.reason = type(exc).__name__
 #esp.raw = io.BytesIO(f"{resp.reason}: {exc}".encode("utf8"))
 #lse:
 #odified = email.utils.formatdate(stats.st_mtime, usegmt=True)
 #ontent_type = mimetypes.guess_type(pathname)[0] or "text/plain"
 #esp.headers = CaseInsensitiveDict(
 #
 #Content-Type": content_type,
 #Content-Length": stats.st_size,
 #Last-Modified": modified,
 #
 #

 #esp.raw = open(pathname, "rb")
 #esp.close = resp.raw.close

 #eturn resp

 #ef close(self) -> None:
 #ass


class _SSLContextAdapterMixin:
 #""Mixin to add the ``ssl_context`` constructor argument to HTTP adapters.

 #he additional argument is forwarded directly to the pool manager. This allows us
 #o dynamically decide what SSL store to use at runtime, which is used to implement
 #he optional ``truststore`` backend.
 #""

 #ef __init__(
 #elf,
 #,
 #sl_context: Optional["SSLContext"] = None,
 #*kwargs: Any,
 # -> None:
 #elf._ssl_context = ssl_context
 #uper().__init__(**kwargs)

 #ef init_poolmanager(
 #elf,
 #onnections: int,
 #axsize: int,
 #lock: bool = DEFAULT_POOLBLOCK,
 #*pool_kwargs: Any,
 # -> "PoolManager":
 #f self._ssl_context is not None:
 #ool_kwargs.setdefault("ssl_context", self._ssl_context)
 #eturn super().init_poolmanager(  # type: ignore[misc]
 #onnections=connections,
 #axsize=maxsize,
 #lock=block,
 #*pool_kwargs,
 #


class HTTPAdapter(_SSLContextAdapterMixin, _BaseHTTPAdapter):
 #ass


class CacheControlAdapter(_SSLContextAdapterMixin, _BaseCacheControlAdapter):
 #ass


class InsecureHTTPAdapter(HTTPAdapter):
 #ef cert_verify(
 #elf,
 #onn: ConnectionPool,
 #rl: str,
 #erify: Union[bool, str],
 #ert: Optional[Union[str, Tuple[str, str]]],
 # -> None:
 #uper().cert_verify(conn=conn, url=url, verify=False, cert=cert)


class InsecureCacheControlAdapter(CacheControlAdapter):
 #ef cert_verify(
 #elf,
 #onn: ConnectionPool,
 #rl: str,
 #erify: Union[bool, str],
 #ert: Optional[Union[str, Tuple[str, str]]],
 # -> None:
 #uper().cert_verify(conn=conn, url=url, verify=False, cert=cert)


class PipSession(requests.Session):
 #imeout: Optional[int] = None

 #ef __init__(
 #elf,
 #args: Any,
 #etries: int = 0,
 #ache: Optional[str] = None,
 #rusted_hosts: Sequence[str] = (),
 #ndex_urls: Optional[List[str]] = None,
 #sl_context: Optional["SSLContext"] = None,
 #*kwargs: Any,
 # -> None:
 #""
 #param trusted_hosts: Domains not to emit warnings for when not using
 #TTPS.
 #""
 #uper().__init__(*args, **kwargs)

        # Namespace the attribute with "pip_" just in case to prevent
        # possible conflicts with the base class.
 #elf.pip_trusted_origins: List[Tuple[str, Optional[int]]] = []

        # Attach our User Agent to the request
 #elf.headers["User-Agent"] = user_agent()

        # Attach our Authentication handler to the session
 #elf.auth = MultiDomainBasicAuth(index_urls=index_urls)

        # Create our urllib3.Retry instance which will allow us to customize
        # how we handle retries.
 #etries = urllib3.Retry(
            # Set the total number of retries that a particular request can
            # have.
 #otal=retries,
            # A 503 error from PyPI typically means that the Fastly -> Origin
            # connection got interrupted in some way. A 503 error in general
            # is typically considered a transient error so we'll go ahead and
            # retry it.
            # A 500 may indicate transient error in Amazon S3
            # A 502 may be a transient error from a CDN like CloudFlare or CloudFront
            # A 520 or 527 - may indicate transient error in CloudFlare
 #tatus_forcelist=[500, 502, 503, 520, 527],
            # Add a small amount of back off between failed requests in
            # order to prevent hammering the service.
 #ackoff_factor=0.25,
 #  # type: ignore

        # Our Insecure HTTPAdapter disables HTTPS validation. It does not
        # support caching so we'll use it for all http:// URLs.
        # If caching is disabled, we will also use it for
        # https:// hosts that we've marked as ignoring
        # TLS errors for (trusted-hosts).
 #nsecure_adapter = InsecureHTTPAdapter(max_retries=retries)

        # We want to _only_ cache responses on securely fetched origins or when
        # the host is specified as trusted. We do this because
        # we can't validate the response of an insecurely/untrusted fetched
        # origin, and we don't want someone to be able to poison the cache and
        # require manual eviction from the cache to fix it.
 #f cache:
 #ecure_adapter = CacheControlAdapter(
 #ache=SafeFileCache(cache),
 #ax_retries=retries,
 #sl_context=ssl_context,
 #
 #elf._trusted_host_adapter = InsecureCacheControlAdapter(
 #ache=SafeFileCache(cache),
 #ax_retries=retries,
 #
 #lse:
 #ecure_adapter = HTTPAdapter(max_retries=retries, ssl_context=ssl_context)
 #elf._trusted_host_adapter = insecure_adapter

 #elf.mount("https://", secure_adapter)
 #elf.mount("http://", insecure_adapter)

        # Enable file:// urls
 #elf.mount("file://", LocalFSAdapter())

 #or host in trusted_hosts:
 #elf.add_trusted_host(host, suppress_logging=True)

 #ef update_index_urls(self, new_index_urls: List[str]) -> None:
 #""
 #param new_index_urls: New index urls to update the authentication
 #andler with.
 #""
 #elf.auth.index_urls = new_index_urls

 #ef add_trusted_host(
 #elf, host: str, source: Optional[str] = None, suppress_logging: bool = False
 # -> None:
 #""
 #param host: It is okay to provide a host that has previously been
 #dded.
 #param source: An optional source string, for logging where the host
 #tring came from.
 #""
 #f not suppress_logging:
 #sg = f"adding trusted host: {host!r}"
 #f source is not None:
 #sg += f" (from {source})"
 #ogger.info(msg)

 #arsed_host, parsed_port = parse_netloc(host)
 #f parsed_host is None:
 #aise ValueError(f"Trusted host URL must include a host part: {host!r}")
 #f (parsed_host, parsed_port) not in self.pip_trusted_origins:
 #elf.pip_trusted_origins.append((parsed_host, parsed_port))

 #elf.mount(
 #uild_url_from_netloc(host, scheme="http") + "/", self._trusted_host_adapter
 #
 #elf.mount(build_url_from_netloc(host) + "/", self._trusted_host_adapter)
 #f not parsed_port:
 #elf.mount(
 #uild_url_from_netloc(host, scheme="http") + ":",
 #elf._trusted_host_adapter,
 #
            # Mount wildcard ports for the same host.
 #elf.mount(build_url_from_netloc(host) + ":", self._trusted_host_adapter)

 #ef iter_secure_origins(self) -> Generator[SecureOrigin, None, None]:
 #ield from SECURE_ORIGINS
 #or host, port in self.pip_trusted_origins:
 #ield ("*", host, "*" if port is None else port)

 #ef is_secure_origin(self, location: Link) -> bool:
        # Determine if this url used a secure transport mechanism
 #arsed = urllib.parse.urlparse(str(location))
 #rigin_protocol, origin_host, origin_port = (
 #arsed.scheme,
 #arsed.hostname,
 #arsed.port,
 #

        # The protocol to use to see if the protocol matches.
        # Don't count the repository type as part of the protocol: in
        # cases such as "git+ssh", only use "ssh". (I.e., Only verify against
        # the last scheme.)
 #rigin_protocol = origin_protocol.rsplit("+", 1)[-1]

        # Determine if our origin is a secure origin by looking through our
        # hardcoded list of secure origins, as well as any additional ones
        # configured on this PackageFinder instance.
 #or secure_origin in self.iter_secure_origins():
 #ecure_protocol, secure_host, secure_port = secure_origin
 #f origin_protocol != secure_protocol and secure_protocol != "*":
 #ontinue

 #ry:
 #ddr = ipaddress.ip_address(origin_host or "")
 #etwork = ipaddress.ip_network(secure_host)
 #xcept ValueError:
                # We don't have both a valid address or a valid network, so
                # we'll check this origin against hostnames.
 #f (
 #rigin_host
 #nd origin_host.lower() != secure_host.lower()
 #nd secure_host != "*"
 #:
 #ontinue
 #lse:
                # We have a valid address and network, so see if the address
                # is contained within the network.
 #f addr not in network:
 #ontinue

            # Check to see if the port matches.
 #f (
 #rigin_port != secure_port
 #nd secure_port != "*"
 #nd secure_port is not None
 #:
 #ontinue

            # If we've gotten here, then this origin matches the current
            # secure origin and we should return True
 #eturn True

        # If we've gotten to this point, then the origin isn't secure and we
        # will not accept it as a valid location to search. We will however
        # log a warning that we are ignoring it.
 #ogger.warning(
 #The repository located at %s is not a trusted or secure host and "
 #is being ignored. If this repository is available via HTTPS we "
 #recommend you use HTTPS instead, otherwise you may silence "
 #this warning and allow it anyway with '--trusted-host %s'.",
 #rigin_host,
 #rigin_host,
 #

 #eturn False

 #ef request(self, method: str, url: str, *args: Any, **kwargs: Any) -> Response:
        # Allow setting a default timeout on a session
 #wargs.setdefault("timeout", self.timeout)
        # Allow setting a default proxies on a session
 #wargs.setdefault("proxies", self.proxies)

        # Dispatch the actual request
 #eturn super().request(method, url, *args, **kwargs)
