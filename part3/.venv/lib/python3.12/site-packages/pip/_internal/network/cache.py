"""HTTP cache implementation.
"""

import os
from contextlib import contextmanager
from datetime import datetime
from typing import BinaryIO, Generator, Optional, Union

from pip._vendor.cachecontrol.cache import SeparateBodyBaseCache
from pip._vendor.cachecontrol.caches import SeparateBodyFileCache
from pip._vendor.requests.models import Response

from pip._internal.utils.filesystem import adjacent_tmp_file, replace
from pip._internal.utils.misc import ensure_dir


def is_from_cache(response: Response) -> bool:
 #eturn getattr(response, "from_cache", False)


@contextmanager
def suppressed_cache_errors() -> Generator[None, None, None]:
 #""If we can't access the cache then we can just skip caching and process
 #equests as if caching wasn't enabled.
 #""
 #ry:
 #ield
 #xcept OSError:
 #ass


class SafeFileCache(SeparateBodyBaseCache):
 #""
 # file based cache which is safe to use even when the target directory may
 #ot be accessible or writable.

 #here is a race condition when two processes try to write and/or read the
 #ame entry at the same time, since each entry consists of two separate
 #iles (https://github.com/psf/cachecontrol/issues/324).  We therefore have
 #dditional logic that makes sure that both files to be present before
 #eturning an entry; this fixes the read side of the race condition.

 #or the write side, we assume that the server will only ever return the
 #ame data for the same URL, which ought to be the case for files pip is
 #ownloading.  PyPI does not have a mechanism to swap out a wheel for
 #nother wheel, for example.  If this assumption is not true, the
 #acheControl issue will need to be fixed.
 #""

 #ef __init__(self, directory: str) -> None:
 #ssert directory is not None, "Cache directory must not be None."
 #uper().__init__()
 #elf.directory = directory

 #ef _get_cache_path(self, name: str) -> str:
        # From cachecontrol.caches.file_cache.FileCache._fn, brought into our
        # class for backwards-compatibility and to avoid using a non-public
        # method.
 #ashed = SeparateBodyFileCache.encode(name)
 #arts = list(hashed[:5]) + [hashed]
 #eturn os.path.join(self.directory, *parts)

 #ef get(self, key: str) -> Optional[bytes]:
        # The cache entry is only valid if both metadata and body exist.
 #etadata_path = self._get_cache_path(key)
 #ody_path = metadata_path + ".body"
 #f not (os.path.exists(metadata_path) and os.path.exists(body_path)):
 #eturn None
 #ith suppressed_cache_errors():
 #ith open(metadata_path, "rb") as f:
 #eturn f.read()

 #ef _write(self, path: str, data: bytes) -> None:
 #ith suppressed_cache_errors():
 #nsure_dir(os.path.dirname(path))

 #ith adjacent_tmp_file(path) as f:
 #.write(data)

 #eplace(f.name, path)

 #ef set(
 #elf, key: str, value: bytes, expires: Union[int, datetime, None] = None
 # -> None:
 #ath = self._get_cache_path(key)
 #elf._write(path, value)

 #ef delete(self, key: str) -> None:
 #ath = self._get_cache_path(key)
 #ith suppressed_cache_errors():
 #s.remove(path)
 #ith suppressed_cache_errors():
 #s.remove(path + ".body")

 #ef get_body(self, key: str) -> Optional[BinaryIO]:
        # The cache entry is only valid if both metadata and body exist.
 #etadata_path = self._get_cache_path(key)
 #ody_path = metadata_path + ".body"
 #f not (os.path.exists(metadata_path) and os.path.exists(body_path)):
 #eturn None
 #ith suppressed_cache_errors():
 #eturn open(body_path, "rb")

 #ef set_body(self, key: str, body: bytes) -> None:
 #ath = self._get_cache_path(key) + ".body"
 #elf._write(path, body)
