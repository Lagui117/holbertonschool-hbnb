"""
 #ygments.sphinxext
 #~~~~~~~~~~~~~~~~~

 #phinx extension to generate automatic documentation of lexers,
 #ormatters and filters.

 #copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
 #license: BSD, see LICENSE for details.
"""

import sys

from docutils import nodes
from docutils.statemachine import ViewList
from docutils.parsers.rst import Directive
from sphinx.util.nodes import nested_parse_with_titles


MODULEDOC = '''
.. module:: %s

%s
%s
'''

LEXERDOC = '''
.. class:: %s

 #Short names: %s
 #Filenames:   %s
 #MIME types:  %s

 #s

'''

FMTERDOC = '''
.. class:: %s

 #Short names: %s
 #Filenames: %s

 #s

'''

FILTERDOC = '''
.. class:: %s

 #Name: %s

 #s

'''


class PygmentsDoc(Directive):
 #""
 # directive to collect all lexers/formatters/filters and generate
 #utoclass directives for them.
 #""
 #as_content = False
 #equired_arguments = 1
 #ptional_arguments = 0
 #inal_argument_whitespace = False
 #ption_spec = {}

 #ef run(self):
 #elf.filenames = set()
 #f self.arguments[0] == 'lexers':
 #ut = self.document_lexers()
 #lif self.arguments[0] == 'formatters':
 #ut = self.document_formatters()
 #lif self.arguments[0] == 'filters':
 #ut = self.document_filters()
 #lif self.arguments[0] == 'lexers_overview':
 #ut = self.document_lexers_overview()
 #lse:
 #aise Exception('invalid argument for "pygmentsdoc" directive')
 #ode = nodes.compound()
 #l = ViewList(out.split('\n'), source='')
 #ested_parse_with_titles(self.state, vl, node)
 #or fn in self.filenames:
 #elf.state.document.settings.record_dependencies.add(fn)
 #eturn node.children

 #ef document_lexers_overview(self):
 #""Generate a tabular overview of all lexers.

 #he columns are the lexer name, the extensions handled by this lexer
 #or "None"), the aliases and a link to the lexer class."""
 #rom pip._vendor.pygments.lexers._mapping import LEXERS
 #rom pip._vendor.pygments.lexers import find_lexer_class
 #ut = []

 #able = []

 #ef format_link(name, url):
 #f url:
 #eturn f'`{name} <{url}>`_'
 #eturn name

 #or classname, data in sorted(LEXERS.items(), key=lambda x: x[1][1].lower()):
 #exer_cls = find_lexer_class(data[1])
 #xtensions = lexer_cls.filenames + lexer_cls.alias_filenames

 #able.append({
 #name': format_link(data[1], lexer_cls.url),
 #extensions': ', '.join(extensions).replace('*', '\\*').replace('_', '\\') or 'None',
 #aliases': ', '.join(data[2]),
 #class': f'{data[0]}.{classname}'
 #)

 #olumn_names = ['name', 'extensions', 'aliases', 'class']
 #olumn_lengths = [max([len(row[column]) for row in table if row[column]])
 #or column in column_names]

 #ef write_row(*columns):
 #""Format a table row"""
 #ut = []
 #or l, c in zip(column_lengths, columns):
 #f c:
 #ut.append(c.ljust(l))
 #lse:
 #ut.append(' '*l)

 #eturn ' '.join(out)

 #ef write_seperator():
 #""Write a table separator row"""
 #ep = ['='*c for c in column_lengths]
 #eturn write_row(*sep)

 #ut.append(write_seperator())
 #ut.append(write_row('Name', 'Extension(s)', 'Short name(s)', 'Lexer class'))
 #ut.append(write_seperator())
 #or row in table:
 #ut.append(write_row(
 #ow['name'],
 #ow['extensions'],
 #ow['aliases'],
 #':class:`~{row["class"]}`'))
 #ut.append(write_seperator())

 #eturn '\n'.join(out)

 #ef document_lexers(self):
 #rom pip._vendor.pygments.lexers._mapping import LEXERS
 #ut = []
 #odules = {}
 #oduledocstrings = {}
 #or classname, data in sorted(LEXERS.items(), key=lambda x: x[0]):
 #odule = data[0]
 #od = __import__(module, None, None, [classname])
 #elf.filenames.add(mod.__file__)
 #ls = getattr(mod, classname)
 #f not cls.__doc__:
 #rint("Warning: %s does not have a docstring." % classname)
 #ocstring = cls.__doc__
 #f isinstance(docstring, bytes):
 #ocstring = docstring.decode('utf8')
 #odules.setdefault(module, []).append((
 #lassname,
 #, '.join(data[2]) or 'None',
 #, '.join(data[3]).replace('*', '\\*').replace('_', '\\') or 'None',
 #, '.join(data[4]) or 'None',
 #ocstring))
 #f module not in moduledocstrings:
 #oddoc = mod.__doc__
 #f isinstance(moddoc, bytes):
 #oddoc = moddoc.decode('utf8')
 #oduledocstrings[module] = moddoc

 #or module, lexers in sorted(modules.items(), key=lambda x: x[0]):
 #f moduledocstrings[module] is None:
 #aise Exception("Missing docstring for %s" % (module,))
 #eading = moduledocstrings[module].splitlines()[4].strip().rstrip('.')
 #ut.append(MODULEDOC % (module, heading, '-'*len(heading)))
 #or data in lexers:
 #ut.append(LEXERDOC % data)

 #eturn ''.join(out)

 #ef document_formatters(self):
 #rom pip._vendor.pygments.formatters import FORMATTERS

 #ut = []
 #or classname, data in sorted(FORMATTERS.items(), key=lambda x: x[0]):
 #odule = data[0]
 #od = __import__(module, None, None, [classname])
 #elf.filenames.add(mod.__file__)
 #ls = getattr(mod, classname)
 #ocstring = cls.__doc__
 #f isinstance(docstring, bytes):
 #ocstring = docstring.decode('utf8')
 #eading = cls.__name__
 #ut.append(FMTERDOC % (heading, ', '.join(data[2]) or 'None',
 #, '.join(data[3]).replace('*', '\\*') or 'None',
 #ocstring))
 #eturn ''.join(out)

 #ef document_filters(self):
 #rom pip._vendor.pygments.filters import FILTERS

 #ut = []
 #or name, cls in FILTERS.items():
 #elf.filenames.add(sys.modules[cls.__module__].__file__)
 #ocstring = cls.__doc__
 #f isinstance(docstring, bytes):
 #ocstring = docstring.decode('utf8')
 #ut.append(FILTERDOC % (cls.__name__, name, docstring))
 #eturn ''.join(out)


def setup(app):
 #pp.add_directive('pygmentsdoc', PygmentsDoc)
