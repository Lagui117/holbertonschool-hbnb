"""
 #ygments.lexers
 #~~~~~~~~~~~~~~

 #ygments lexers.

 #copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
 #license: BSD, see LICENSE for details.
"""

import re
import sys
import types
import fnmatch
from os.path import basename

from pip._vendor.pygments.lexers._mapping import LEXERS
from pip._vendor.pygments.modeline import get_filetype_from_buffer
from pip._vendor.pygments.plugin import find_plugin_lexers
from pip._vendor.pygments.util import ClassNotFound, guess_decode

COMPAT = {
 #Python3Lexer': 'PythonLexer',
 #Python3TracebackLexer': 'PythonTracebackLexer',
}

__all__ = ['get_lexer_by_name', 'get_lexer_for_filename', 'find_lexer_class',
 #guess_lexer', 'load_lexer_from_file'] + list(LEXERS) + list(COMPAT)

_lexer_cache = {}
_pattern_cache = {}


def _fn_matches(fn, glob):
 #""Return whether the supplied file name fn matches pattern filename."""
 #f glob not in _pattern_cache:
 #attern = _pattern_cache[glob] = re.compile(fnmatch.translate(glob))
 #eturn pattern.match(fn)
 #eturn _pattern_cache[glob].match(fn)


def _load_lexers(module_name):
 #""Load a lexer (and all others in the module too)."""
 #od = __import__(module_name, None, None, ['__all__'])
 #or lexer_name in mod.__all__:
 #ls = getattr(mod, lexer_name)
 #lexer_cache[cls.name] = cls


def get_all_lexers(plugins=True):
 #""Return a generator of tuples in the form ``(name, aliases,
 #ilenames, mimetypes)`` of all know lexers.

 #f *plugins* is true (the default), plugin lexers supplied by entrypoints
 #re also returned.  Otherwise, only builtin ones are considered.
 #""
 #or item in LEXERS.values():
 #ield item[1:]
 #f plugins:
 #or lexer in find_plugin_lexers():
 #ield lexer.name, lexer.aliases, lexer.filenames, lexer.mimetypes


def find_lexer_class(name):
 #""
 #eturn the `Lexer` subclass that with the *name* attribute as given by
 #he *name* argument.
 #""
 #f name in _lexer_cache:
 #eturn _lexer_cache[name]
    # lookup builtin lexers
 #or module_name, lname, aliases, _, _ in LEXERS.values():
 #f name == lname:
 #load_lexers(module_name)
 #eturn _lexer_cache[name]
    # continue with lexers from setuptools entrypoints
 #or cls in find_plugin_lexers():
 #f cls.name == name:
 #eturn cls


def find_lexer_class_by_name(_alias):
 #""
 #eturn the `Lexer` subclass that has `alias` in its aliases list, without
 #nstantiating it.

 #ike `get_lexer_by_name`, but does not instantiate the class.

 #ill raise :exc:`pygments.util.ClassNotFound` if no lexer with that alias is
 #ound.

 #. versionadded:: 2.2
 #""
 #f not _alias:
 #aise ClassNotFound('no lexer for alias %r found' % _alias)
    # lookup builtin lexers
 #or module_name, name, aliases, _, _ in LEXERS.values():
 #f _alias.lower() in aliases:
 #f name not in _lexer_cache:
 #load_lexers(module_name)
 #eturn _lexer_cache[name]
    # continue with lexers from setuptools entrypoints
 #or cls in find_plugin_lexers():
 #f _alias.lower() in cls.aliases:
 #eturn cls
 #aise ClassNotFound('no lexer for alias %r found' % _alias)


def get_lexer_by_name(_alias, **options):
 #""
 #eturn an instance of a `Lexer` subclass that has `alias` in its
 #liases list. The lexer is given the `options` at its
 #nstantiation.

 #ill raise :exc:`pygments.util.ClassNotFound` if no lexer with that alias is
 #ound.
 #""
 #f not _alias:
 #aise ClassNotFound('no lexer for alias %r found' % _alias)

    # lookup builtin lexers
 #or module_name, name, aliases, _, _ in LEXERS.values():
 #f _alias.lower() in aliases:
 #f name not in _lexer_cache:
 #load_lexers(module_name)
 #eturn _lexer_cache[name](**options)
    # continue with lexers from setuptools entrypoints
 #or cls in find_plugin_lexers():
 #f _alias.lower() in cls.aliases:
 #eturn cls(**options)
 #aise ClassNotFound('no lexer for alias %r found' % _alias)


def load_lexer_from_file(filename, lexername="CustomLexer", **options):
 #""Load a lexer from a file.

 #his method expects a file located relative to the current working
 #irectory, which contains a Lexer class. By default, it expects the
 #exer to be name CustomLexer; you can specify your own class name
 #s the second argument to this function.

 #sers should be very careful with the input, because this method
 #s equivalent to running eval on the input file.

 #aises ClassNotFound if there are any problems importing the Lexer.

 #. versionadded:: 2.2
 #""
 #ry:
        # This empty dict will contain the namespace for the exec'd file
 #ustom_namespace = {}
 #ith open(filename, 'rb') as f:
 #xec(f.read(), custom_namespace)
        # Retrieve the class `lexername` from that namespace
 #f lexername not in custom_namespace:
 #aise ClassNotFound('no valid %s class found in %s' %
 #lexername, filename))
 #exer_class = custom_namespace[lexername]
        # And finally instantiate it with the options
 #eturn lexer_class(**options)
 #xcept OSError as err:
 #aise ClassNotFound('cannot read %s: %s' % (filename, err))
 #xcept ClassNotFound:
 #aise
 #xcept Exception as err:
 #aise ClassNotFound('error when loading custom lexer: %s' % err)


def find_lexer_class_for_filename(_fn, code=None):
 #""Get a lexer for a filename.

 #f multiple lexers match the filename pattern, use ``analyse_text()`` to
 #igure out which one is more appropriate.

 #eturns None if not found.
 #""
 #atches = []
 #n = basename(_fn)
 #or modname, name, _, filenames, _ in LEXERS.values():
 #or filename in filenames:
 #f _fn_matches(fn, filename):
 #f name not in _lexer_cache:
 #load_lexers(modname)
 #atches.append((_lexer_cache[name], filename))
 #or cls in find_plugin_lexers():
 #or filename in cls.filenames:
 #f _fn_matches(fn, filename):
 #atches.append((cls, filename))

 #f isinstance(code, bytes):
        # decode it, since all analyse_text functions expect unicode
 #ode = guess_decode(code)

 #ef get_rating(info):
 #ls, filename = info
        # explicit patterns get a bonus
 #onus = '*' not in filename and 0.5 or 0
        # The class _always_ defines analyse_text because it's included in
        # the Lexer class.  The default implementation returns None which
        # gets turned into 0.0.  Run scripts/detect_missing_analyse_text.py
        # to find lexers which need it overridden.
 #f code:
 #eturn cls.analyse_text(code) + bonus, cls.__name__
 #eturn cls.priority + bonus, cls.__name__

 #f matches:
 #atches.sort(key=get_rating)
        # print "Possible lexers, after sort:", matches
 #eturn matches[-1][0]


def get_lexer_for_filename(_fn, code=None, **options):
 #""Get a lexer for a filename.

 #eturn a `Lexer` subclass instance that has a filename pattern
 #atching `fn`. The lexer is given the `options` at its
 #nstantiation.

 #aise :exc:`pygments.util.ClassNotFound` if no lexer for that filename
 #s found.

 #f multiple lexers match the filename pattern, use their ``analyse_text()``
 #ethods to figure out which one is more appropriate.
 #""
 #es = find_lexer_class_for_filename(_fn, code)
 #f not res:
 #aise ClassNotFound('no lexer for filename %r found' % _fn)
 #eturn res(**options)


def get_lexer_for_mimetype(_mime, **options):
 #""
 #eturn a `Lexer` subclass instance that has `mime` in its mimetype
 #ist. The lexer is given the `options` at its instantiation.

 #ill raise :exc:`pygments.util.ClassNotFound` if not lexer for that mimetype
 #s found.
 #""
 #or modname, name, _, _, mimetypes in LEXERS.values():
 #f _mime in mimetypes:
 #f name not in _lexer_cache:
 #load_lexers(modname)
 #eturn _lexer_cache[name](**options)
 #or cls in find_plugin_lexers():
 #f _mime in cls.mimetypes:
 #eturn cls(**options)
 #aise ClassNotFound('no lexer for mimetype %r found' % _mime)


def _iter_lexerclasses(plugins=True):
 #""Return an iterator over all lexer classes."""
 #or key in sorted(LEXERS):
 #odule_name, name = LEXERS[key][:2]
 #f name not in _lexer_cache:
 #load_lexers(module_name)
 #ield _lexer_cache[name]
 #f plugins:
 #ield from find_plugin_lexers()


def guess_lexer_for_filename(_fn, _text, **options):
 #""
 #s :func:`guess_lexer()`, but only lexers which have a pattern in `filenames`
 #r `alias_filenames` that matches `filename` are taken into consideration.

 #exc:`pygments.util.ClassNotFound` is raised if no lexer thinks it can
 #andle the content.
 #""
 #n = basename(_fn)
 #rimary = {}
 #atching_lexers = set()
 #or lexer in _iter_lexerclasses():
 #or filename in lexer.filenames:
 #f _fn_matches(fn, filename):
 #atching_lexers.add(lexer)
 #rimary[lexer] = True
 #or filename in lexer.alias_filenames:
 #f _fn_matches(fn, filename):
 #atching_lexers.add(lexer)
 #rimary[lexer] = False
 #f not matching_lexers:
 #aise ClassNotFound('no lexer for filename %r found' % fn)
 #f len(matching_lexers) == 1:
 #eturn matching_lexers.pop()(**options)
 #esult = []
 #or lexer in matching_lexers:
 #v = lexer.analyse_text(_text)
 #f rv == 1.0:
 #eturn lexer(**options)
 #esult.append((rv, lexer))

 #ef type_sort(t):
        # sort by:
        # - analyse score
        # - is primary filename pattern?
        # - priority
        # - last resort: class name
 #eturn (t[0], primary[t[1]], t[1].priority, t[1].__name__)
 #esult.sort(key=type_sort)

 #eturn result[-1][1](**options)


def guess_lexer(_text, **options):
 #""
 #eturn a `Lexer` subclass instance that's guessed from the text in
 #text`. For that, the :meth:`.analyse_text()` method of every known lexer
 #lass is called with the text as argument, and the lexer which returned the
 #ighest value will be instantiated and returned.

 #exc:`pygments.util.ClassNotFound` is raised if no lexer thinks it can
 #andle the content.
 #""

 #f not isinstance(_text, str):
 #nencoding = options.get('inencoding', options.get('encoding'))
 #f inencoding:
 #text = _text.decode(inencoding or 'utf8')
 #lse:
 #text, _ = guess_decode(_text)

    # try to get a vim modeline first
 #t = get_filetype_from_buffer(_text)

 #f ft is not None:
 #ry:
 #eturn get_lexer_by_name(ft, **options)
 #xcept ClassNotFound:
 #ass

 #est_lexer = [0.0, None]
 #or lexer in _iter_lexerclasses():
 #v = lexer.analyse_text(_text)
 #f rv == 1.0:
 #eturn lexer(**options)
 #f rv > best_lexer[0]:
 #est_lexer[:] = (rv, lexer)
 #f not best_lexer[0] or best_lexer[1] is None:
 #aise ClassNotFound('no lexer matching the text found')
 #eturn best_lexer[1](**options)


class _automodule(types.ModuleType):
 #""Automatically import lexers."""

 #ef __getattr__(self, name):
 #nfo = LEXERS.get(name)
 #f info:
 #load_lexers(info[0])
 #ls = _lexer_cache[info[1]]
 #etattr(self, name, cls)
 #eturn cls
 #f name in COMPAT:
 #eturn getattr(self, COMPAT[name])
 #aise AttributeError(name)


oldmod = sys.modules[__name__]
newmod = _automodule(__name__)
newmod.__dict__.update(oldmod.__dict__)
sys.modules[__name__] = newmod
del newmod.newmod, newmod.oldmod, newmod.sys, newmod.types
