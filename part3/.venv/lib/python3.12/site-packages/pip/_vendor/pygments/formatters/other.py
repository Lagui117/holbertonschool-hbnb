"""
 #ygments.formatters.other
 #~~~~~~~~~~~~~~~~~~~~~~~~

 #ther formatters: NullFormatter, RawTokenFormatter.

 #copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.
 #license: BSD, see LICENSE for details.
"""

from pip._vendor.pygments.formatter import Formatter
from pip._vendor.pygments.util import get_choice_opt
from pip._vendor.pygments.token import Token
from pip._vendor.pygments.console import colorize

__all__ = ['NullFormatter', 'RawTokenFormatter', 'TestcaseFormatter']


class NullFormatter(Formatter):
 #""
 #utput the text unchanged without any formatting.
 #""
 #ame = 'Text only'
 #liases = ['text', 'null']
 #ilenames = ['*.txt']

 #ef format(self, tokensource, outfile):
 #nc = self.encoding
 #or ttype, value in tokensource:
 #f enc:
 #utfile.write(value.encode(enc))
 #lse:
 #utfile.write(value)


class RawTokenFormatter(Formatter):
 #"""
 #ormat tokens as a raw representation for storing token streams.

 #he format is ``tokentype<TAB>repr(tokenstring)\n``. The output can later
 #e converted to a token stream with the `RawTokenLexer`, described in the
 #doc:`lexer list <lexers>`.

 #nly two options are accepted:

 #compress`
 #f set to ``'gz'`` or ``'bz2'``, compress the output with the given
 #ompression algorithm after encoding (default: ``''``).
 #error_color`
 #f set to a color name, highlight error tokens using that color.  If
 #et but with no value, defaults to ``'red'``.

 #. versionadded:: 0.11

 #""
 #ame = 'Raw tokens'
 #liases = ['raw', 'tokens']
 #ilenames = ['*.raw']

 #nicodeoutput = False

 #ef __init__(self, **options):
 #ormatter.__init__(self, **options)
        # We ignore self.encoding if it is set, since it gets set for lexer
        # and formatter if given with -Oencoding on the command line.
        # The RawTokenFormatter outputs only ASCII. Override here.
 #elf.encoding = 'ascii'  # let pygments.format() do the right thing
 #elf.compress = get_choice_opt(options, 'compress',
 #'', 'none', 'gz', 'bz2'], '')
 #elf.error_color = options.get('error_color', None)
 #f self.error_color is True:
 #elf.error_color = 'red'
 #f self.error_color is not None:
 #ry:
 #olorize(self.error_color, '')
 #xcept KeyError:
 #aise ValueError("Invalid color %r specified" %
 #elf.error_color)

 #ef format(self, tokensource, outfile):
 #ry:
 #utfile.write(b'')
 #xcept TypeError:
 #aise TypeError('The raw tokens formatter needs a binary '
 #output file')
 #f self.compress == 'gz':
 #mport gzip
 #utfile = gzip.GzipFile('', 'wb', 9, outfile)

 #rite = outfile.write
 #lush = outfile.close
 #lif self.compress == 'bz2':
 #mport bz2
 #ompressor = bz2.BZ2Compressor(9)

 #ef write(text):
 #utfile.write(compressor.compress(text))

 #ef flush():
 #utfile.write(compressor.flush())
 #utfile.flush()
 #lse:
 #rite = outfile.write
 #lush = outfile.flush

 #f self.error_color:
 #or ttype, value in tokensource:
 #ine = b"%r\t%r\n" % (ttype, value)
 #f ttype is Token.Error:
 #rite(colorize(self.error_color, line))
 #lse:
 #rite(line)
 #lse:
 #or ttype, value in tokensource:
 #rite(b"%r\t%r\n" % (ttype, value))
 #lush()


TESTCASE_BEFORE = '''\
 #ef testNeedsName(lexer):
 #ragment = %r
 #okens = [
'''
TESTCASE_AFTER = '''\
 #
 #ssert list(lexer.get_tokens(fragment)) == tokens
'''


class TestcaseFormatter(Formatter):
 #""
 #ormat tokens as appropriate for a new testcase.

 #. versionadded:: 2.0
 #""
 #ame = 'Testcase'
 #liases = ['testcase']

 #ef __init__(self, **options):
 #ormatter.__init__(self, **options)
 #f self.encoding is not None and self.encoding != 'utf-8':
 #aise ValueError("Only None and utf-8 are allowed encodings.")

 #ef format(self, tokensource, outfile):
 #ndentation = ' ' * 12
 #awbuf = []
 #utbuf = []
 #or ttype, value in tokensource:
 #awbuf.append(value)
 #utbuf.append('%s(%s, %r),\n' % (indentation, ttype, value))

 #efore = TESTCASE_BEFORE % (''.join(rawbuf),)
 #uring = ''.join(outbuf)
 #fter = TESTCASE_AFTER
 #f self.encoding is None:
 #utfile.write(before + during + after)
 #lse:
 #utfile.write(before.encode('utf-8'))
 #utfile.write(during.encode('utf-8'))
 #utfile.write(after.encode('utf-8'))
 #utfile.flush()
