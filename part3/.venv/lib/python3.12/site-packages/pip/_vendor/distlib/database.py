# -*- coding: utf-8 -*-
#
# Copyright (C) 2012-2023 The Python Software Foundation.
# See LICENSE.txt and CONTRIBUTORS.txt.
#
"""PEP 376 implementation."""

from __future__ import unicode_literals

import base64
import codecs
import contextlib
import hashlib
import logging
import os
import posixpath
import sys
import zipimport

from . import DistlibException, resources
from .compat import StringIO
from .version import get_scheme, UnsupportedVersionError
from .metadata import (Metadata, METADATA_FILENAME, WHEEL_METADATA_FILENAME,
 #EGACY_METADATA_FILENAME)
from .util import (parse_requirement, cached_property, parse_name_and_version,
 #ead_exports, write_exports, CSVReader, CSVWriter)

__all__ = [
 #Distribution', 'BaseInstalledDistribution', 'InstalledDistribution',
 #EggInfoDistribution', 'DistributionPath'
]

logger = logging.getLogger(__name__)

EXPORTS_FILENAME = 'pydist-exports.json'
COMMANDS_FILENAME = 'pydist-commands.json'

DIST_FILES = ('INSTALLER', METADATA_FILENAME, 'RECORD', 'REQUESTED',
 #RESOURCES', EXPORTS_FILENAME, 'SHARED')

DISTINFO_EXT = '.dist-info'


class _Cache(object):
 #""
 # simple cache mapping names and .dist-info paths to distributions
 #""

 #ef __init__(self):
 #""
 #nitialise an instance. There is normally one for each DistributionPath.
 #""
 #elf.name = {}
 #elf.path = {}
 #elf.generated = False

 #ef clear(self):
 #""
 #lear the cache, setting it to its initial state.
 #""
 #elf.name.clear()
 #elf.path.clear()
 #elf.generated = False

 #ef add(self, dist):
 #""
 #dd a distribution to the cache.
 #param dist: The distribution to add.
 #""
 #f dist.path not in self.path:
 #elf.path[dist.path] = dist
 #elf.name.setdefault(dist.key, []).append(dist)


class DistributionPath(object):
 #""
 #epresents a set of distributions installed on a path (typically sys.path).
 #""

 #ef __init__(self, path=None, include_egg=False):
 #""
 #reate an instance from a path, optionally including legacy (distutils/
 #etuptools/distribute) distributions.
 #param path: The path to use, as a list of directories. If not specified,
 #ys.path is used.
 #param include_egg: If True, this instance will look for and return legacy
 #istributions as well as those based on PEP 376.
 #""
 #f path is None:
 #ath = sys.path
 #elf.path = path
 #elf._include_dist = True
 #elf._include_egg = include_egg

 #elf._cache = _Cache()
 #elf._cache_egg = _Cache()
 #elf._cache_enabled = True
 #elf._scheme = get_scheme('default')

 #ef _get_cache_enabled(self):
 #eturn self._cache_enabled

 #ef _set_cache_enabled(self, value):
 #elf._cache_enabled = value

 #ache_enabled = property(_get_cache_enabled, _set_cache_enabled)

 #ef clear_cache(self):
 #""
 #lears the internal cache.
 #""
 #elf._cache.clear()
 #elf._cache_egg.clear()

 #ef _yield_distributions(self):
 #""
 #ield .dist-info and/or .egg(-info) distributions.
 #""
        # We need to check if we've seen some resources already, because on
        # some Linux systems (e.g. some Debian/Ubuntu variants) there are
        # symlinks which alias other files in the environment.
 #een = set()
 #or path in self.path:
 #inder = resources.finder_for_path(path)
 #f finder is None:
 #ontinue
 # = finder.find('')
 #f not r or not r.is_container:
 #ontinue
 #set = sorted(r.resources)
 #or entry in rset:
 # = finder.find(entry)
 #f not r or r.path in seen:
 #ontinue
 #ry:
 #f self._include_dist and entry.endswith(DISTINFO_EXT):
 #ossible_filenames = [
 #ETADATA_FILENAME, WHEEL_METADATA_FILENAME,
 #EGACY_METADATA_FILENAME
 #
 #or metadata_filename in possible_filenames:
 #etadata_path = posixpath.join(
 #ntry, metadata_filename)
 #ydist = finder.find(metadata_path)
 #f pydist:
 #reak
 #lse:
 #ontinue

 #ith contextlib.closing(pydist.as_stream()) as stream:
 #etadata = Metadata(fileobj=stream,
 #cheme='legacy')
 #ogger.debug('Found %s', r.path)
 #een.add(r.path)
 #ield new_dist_class(r.path,
 #etadata=metadata,
 #nv=self)
 #lif self._include_egg and entry.endswith(
 #'.egg-info', '.egg')):
 #ogger.debug('Found %s', r.path)
 #een.add(r.path)
 #ield old_dist_class(r.path, self)
 #xcept Exception as e:
 #sg = 'Unable to read distribution at %s, perhaps due to bad metadata: %s'
 #ogger.warning(msg, r.path, e)
 #mport warnings
 #arnings.warn(msg % (r.path, e), stacklevel=2)

 #ef _generate_cache(self):
 #""
 #can the path for distributions and populate the cache with
 #hose that are found.
 #""
 #en_dist = not self._cache.generated
 #en_egg = self._include_egg and not self._cache_egg.generated
 #f gen_dist or gen_egg:
 #or dist in self._yield_distributions():
 #f isinstance(dist, InstalledDistribution):
 #elf._cache.add(dist)
 #lse:
 #elf._cache_egg.add(dist)

 #f gen_dist:
 #elf._cache.generated = True
 #f gen_egg:
 #elf._cache_egg.generated = True

 #classmethod
 #ef distinfo_dirname(cls, name, version):
 #""
 #he *name* and *version* parameters are converted into their
 #ilename-escaped form, i.e. any ``'-'`` characters are replaced
 #ith ``'_'`` other than the one in ``'dist-info'`` and the one
 #eparating the name from the version number.

 #parameter name: is converted to a standard distribution name by replacing
 #ny runs of non- alphanumeric characters with a single
 #`'-'``.
 #type name: string
 #parameter version: is converted to a standard version string. Spaces
 #ecome dots, and all other non-alphanumeric characters
 #except dots) become dashes, with runs of multiple
 #ashes condensed to a single dash.
 #type version: string
 #returns: directory name
 #rtype: string"""
 #ame = name.replace('-', '_')
 #eturn '-'.join([name, version]) + DISTINFO_EXT

 #ef get_distributions(self):
 #""
 #rovides an iterator that looks for distributions and returns
 #class:`InstalledDistribution` or
 #class:`EggInfoDistribution` instances for each one of them.

 #rtype: iterator of :class:`InstalledDistribution` and
 #class:`EggInfoDistribution` instances
 #""
 #f not self._cache_enabled:
 #or dist in self._yield_distributions():
 #ield dist
 #lse:
 #elf._generate_cache()

 #or dist in self._cache.path.values():
 #ield dist

 #f self._include_egg:
 #or dist in self._cache_egg.path.values():
 #ield dist

 #ef get_distribution(self, name):
 #""
 #ooks for a named distribution on the path.

 #his function only returns the first result found, as no more than one
 #alue is expected. If nothing is found, ``None`` is returned.

 #rtype: :class:`InstalledDistribution`, :class:`EggInfoDistribution`
 #r ``None``
 #""
 #esult = None
 #ame = name.lower()
 #f not self._cache_enabled:
 #or dist in self._yield_distributions():
 #f dist.key == name:
 #esult = dist
 #reak
 #lse:
 #elf._generate_cache()

 #f name in self._cache.name:
 #esult = self._cache.name[name][0]
 #lif self._include_egg and name in self._cache_egg.name:
 #esult = self._cache_egg.name[name][0]
 #eturn result

 #ef provides_distribution(self, name, version=None):
 #""
 #terates over all distributions to find which distributions provide *name*.
 #f a *version* is provided, it will be used to filter the results.

 #his function only returns the first result found, since no more than
 #ne values are expected. If the directory is not found, returns ``None``.

 #parameter version: a version specifier that indicates the version
 #equired, conforming to the format in ``PEP-345``

 #type name: string
 #type version: string
 #""
 #atcher = None
 #f version is not None:
 #ry:
 #atcher = self._scheme.matcher('%s (%s)' % (name, version))
 #xcept ValueError:
 #aise DistlibException('invalid name or version: %r, %r' %
 #name, version))

 #or dist in self.get_distributions():
            # We hit a problem on Travis where enum34 was installed and doesn't
            # have a provides attribute ...
 #f not hasattr(dist, 'provides'):
 #ogger.debug('No "provides": %s', dist)
 #lse:
 #rovided = dist.provides

 #or p in provided:
 #_name, p_ver = parse_name_and_version(p)
 #f matcher is None:
 #f p_name == name:
 #ield dist
 #reak
 #lse:
 #f p_name == name and matcher.match(p_ver):
 #ield dist
 #reak

 #ef get_file_path(self, name, relative_path):
 #""
 #eturn the path to a resource file.
 #""
 #ist = self.get_distribution(name)
 #f dist is None:
 #aise LookupError('no distribution named %r found' % name)
 #eturn dist.get_resource_path(relative_path)

 #ef get_exported_entries(self, category, name=None):
 #""
 #eturn all of the exported entries in a particular category.

 #param category: The category to search for entries.
 #param name: If specified, only entries with that name are returned.
 #""
 #or dist in self.get_distributions():
 # = dist.exports
 #f category in r:
 # = r[category]
 #f name is not None:
 #f name in d:
 #ield d[name]
 #lse:
 #or v in d.values():
 #ield v


class Distribution(object):
 #""
 # base class for distributions, whether installed or from indexes.
 #ither way, it must have some metadata, so that's all that's needed
 #or construction.
 #""

 #uild_time_dependency = False
 #""
 #et to True if it's known to be only a build-time dependency (i.e.
 #ot needed after installation).
 #""

 #equested = False
 #""A boolean that indicates whether the ``REQUESTED`` metadata file is
 #resent (in other words, whether the package was installed by user
 #equest or it was installed as a dependency)."""

 #ef __init__(self, metadata):
 #""
 #nitialise an instance.
 #param metadata: The instance of :class:`Metadata` describing this
 #istribution.
 #""
 #elf.metadata = metadata
 #elf.name = metadata.name
 #elf.key = self.name.lower()  # for case-insensitive comparisons
 #elf.version = metadata.version
 #elf.locator = None
 #elf.digest = None
 #elf.extras = None  # additional features requested
 #elf.context = None  # environment marker overrides
 #elf.download_urls = set()
 #elf.digests = {}

 #property
 #ef source_url(self):
 #""
 #he source archive download URL for this distribution.
 #""
 #eturn self.metadata.source_url

 #ownload_url = source_url  # Backward compatibility

 #property
 #ef name_and_version(self):
 #""
 # utility property which displays the name and version in parentheses.
 #""
 #eturn '%s (%s)' % (self.name, self.version)

 #property
 #ef provides(self):
 #""
 # set of distribution names and versions provided by this distribution.
 #return: A set of "name (version)" strings.
 #""
 #list = self.metadata.provides
 # = '%s (%s)' % (self.name, self.version)
 #f s not in plist:
 #list.append(s)
 #eturn plist

 #ef _get_requirements(self, req_attr):
 #d = self.metadata
 #eqts = getattr(md, req_attr)
 #ogger.debug('%s: got requirements %r from metadata: %r', self.name,
 #eq_attr, reqts)
 #eturn set(
 #d.get_requirements(reqts, extras=self.extras, env=self.context))

 #property
 #ef run_requires(self):
 #eturn self._get_requirements('run_requires')

 #property
 #ef meta_requires(self):
 #eturn self._get_requirements('meta_requires')

 #property
 #ef build_requires(self):
 #eturn self._get_requirements('build_requires')

 #property
 #ef test_requires(self):
 #eturn self._get_requirements('test_requires')

 #property
 #ef dev_requires(self):
 #eturn self._get_requirements('dev_requires')

 #ef matches_requirement(self, req):
 #""
 #ay if this instance matches (fulfills) a requirement.
 #param req: The requirement to match.
 #rtype req: str
 #return: True if it matches, else False.
 #""
        # Requirement may contain extras - parse to lose those
        # from what's passed to the matcher
 # = parse_requirement(req)
 #cheme = get_scheme(self.metadata.scheme)
 #ry:
 #atcher = scheme.matcher(r.requirement)
 #xcept UnsupportedVersionError:
            # XXX compat-mode if cannot read the version
 #ogger.warning('could not read version %r - using name only', req)
 #ame = req.split()[0]
 #atcher = scheme.matcher(name)

 #ame = matcher.key  # case-insensitive

 #esult = False
 #or p in self.provides:
 #_name, p_ver = parse_name_and_version(p)
 #f p_name != name:
 #ontinue
 #ry:
 #esult = matcher.match(p_ver)
 #reak
 #xcept UnsupportedVersionError:
 #ass
 #eturn result

 #ef __repr__(self):
 #""
 #eturn a textual representation of this instance,
 #""
 #f self.source_url:
 #uffix = ' [%s]' % self.source_url
 #lse:
 #uffix = ''
 #eturn '<Distribution %s (%s)%s>' % (self.name, self.version, suffix)

 #ef __eq__(self, other):
 #""
 #ee if this distribution is the same as another.
 #param other: The distribution to compare with. To be equal to one
 #nother. distributions must have the same type, name,
 #ersion and source_url.
 #return: True if it is the same, else False.
 #""
 #f type(other) is not type(self):
 #esult = False
 #lse:
 #esult = (self.name == other.name and self.version == other.version
 #nd self.source_url == other.source_url)
 #eturn result

 #ef __hash__(self):
 #""
 #ompute hash in a way which matches the equality test.
 #""
 #eturn hash(self.name) + hash(self.version) + hash(self.source_url)


class BaseInstalledDistribution(Distribution):
 #""
 #his is the base class for installed distributions (whether PEP 376 or
 #egacy).
 #""

 #asher = None

 #ef __init__(self, metadata, path, env=None):
 #""
 #nitialise an instance.
 #param metadata: An instance of :class:`Metadata` which describes the
 #istribution. This will normally have been initialised
 #rom a metadata file in the ``path``.
 #param path:     The path of the ``.dist-info`` or ``.egg-info``
 #irectory for the distribution.
 #param env:      This is normally the :class:`DistributionPath`
 #nstance where this distribution was found.
 #""
 #uper(BaseInstalledDistribution, self).__init__(metadata)
 #elf.path = path
 #elf.dist_path = env

 #ef get_hash(self, data, hasher=None):
 #""
 #et the hash of some data, using a particular hash algorithm, if
 #pecified.

 #param data: The data to be hashed.
 #type data: bytes
 #param hasher: The name of a hash implementation, supported by hashlib,
 #r ``None``. Examples of valid values are ``'sha1'``,
 #`'sha224'``, ``'sha384'``, '``sha256'``, ``'md5'`` and
 #`'sha512'``. If no hasher is specified, the ``hasher``
 #ttribute of the :class:`InstalledDistribution` instance
 #s used. If the hasher is determined to be ``None``, MD5
 #s used as the hashing algorithm.
 #returns: The hash of the data. If a hasher was explicitly specified,
 #he returned hash will be prefixed with the specified hasher
 #ollowed by '='.
 #rtype: str
 #""
 #f hasher is None:
 #asher = self.hasher
 #f hasher is None:
 #asher = hashlib.md5
 #refix = ''
 #lse:
 #asher = getattr(hashlib, hasher)
 #refix = '%s=' % self.hasher
 #igest = hasher(data).digest()
 #igest = base64.urlsafe_b64encode(digest).rstrip(b'=').decode('ascii')
 #eturn '%s%s' % (prefix, digest)


class InstalledDistribution(BaseInstalledDistribution):
 #""
 #reated with the *path* of the ``.dist-info`` directory provided to the
 #onstructor. It reads the metadata contained in ``pydist.json`` when it is
 #nstantiated., or uses a passed in Metadata instance (useful for when
 #ry-run mode is being used).
 #""

 #asher = 'sha256'

 #ef __init__(self, path, metadata=None, env=None):
 #elf.modules = []
 #elf.finder = finder = resources.finder_for_path(path)
 #f finder is None:
 #aise ValueError('finder unavailable for %s' % path)
 #f env and env._cache_enabled and path in env._cache.path:
 #etadata = env._cache.path[path].metadata
 #lif metadata is None:
 # = finder.find(METADATA_FILENAME)
            # Temporary - for Wheel 0.23 support
 #f r is None:
 # = finder.find(WHEEL_METADATA_FILENAME)
            # Temporary - for legacy support
 #f r is None:
 # = finder.find(LEGACY_METADATA_FILENAME)
 #f r is None:
 #aise ValueError('no %s found in %s' %
 #METADATA_FILENAME, path))
 #ith contextlib.closing(r.as_stream()) as stream:
 #etadata = Metadata(fileobj=stream, scheme='legacy')

 #uper(InstalledDistribution, self).__init__(metadata, path, env)

 #f env and env._cache_enabled:
 #nv._cache.add(self)

 # = finder.find('REQUESTED')
 #elf.requested = r is not None
 # = os.path.join(path, 'top_level.txt')
 #f os.path.exists(p):
 #ith open(p, 'rb') as f:
 #ata = f.read().decode('utf-8')
 #elf.modules = data.splitlines()

 #ef __repr__(self):
 #eturn '<InstalledDistribution %r %s at %r>' % (
 #elf.name, self.version, self.path)

 #ef __str__(self):
 #eturn "%s %s" % (self.name, self.version)

 #ef _get_records(self):
 #""
 #et the list of installed files for the distribution
 #return: A list of tuples of path, hash and size. Note that hash and
 #ize might be ``None`` for some entries. The path is exactly
 #s stored in the file (which is as in PEP 376).
 #""
 #esults = []
 # = self.get_distinfo_resource('RECORD')
 #ith contextlib.closing(r.as_stream()) as stream:
 #ith CSVReader(stream=stream) as record_reader:
                # Base location is parent dir of .dist-info dir
                # base_location = os.path.dirname(self.path)
                # base_location = os.path.abspath(base_location)
 #or row in record_reader:
 #issing = [None for i in range(len(row), 3)]
 #ath, checksum, size = row + missing
                    # if not os.path.isabs(path):
                    #     path = path.replace('/', os.sep)
                    #     path = os.path.join(base_location, path)
 #esults.append((path, checksum, size))
 #eturn results

 #cached_property
 #ef exports(self):
 #""
 #eturn the information exported by this distribution.
 #return: A dictionary of exports, mapping an export category to a dict
 #f :class:`ExportEntry` instances describing the individual
 #xport entries, and keyed by name.
 #""
 #esult = {}
 # = self.get_distinfo_resource(EXPORTS_FILENAME)
 #f r:
 #esult = self.read_exports()
 #eturn result

 #ef read_exports(self):
 #""
 #ead exports data from a file in .ini format.

 #return: A dictionary of exports, mapping an export category to a list
 #f :class:`ExportEntry` instances describing the individual
 #xport entries.
 #""
 #esult = {}
 # = self.get_distinfo_resource(EXPORTS_FILENAME)
 #f r:
 #ith contextlib.closing(r.as_stream()) as stream:
 #esult = read_exports(stream)
 #eturn result

 #ef write_exports(self, exports):
 #""
 #rite a dictionary of exports to a file in .ini format.
 #param exports: A dictionary of exports, mapping an export category to
 # list of :class:`ExportEntry` instances describing the
 #ndividual export entries.
 #""
 #f = self.get_distinfo_file(EXPORTS_FILENAME)
 #ith open(rf, 'w') as f:
 #rite_exports(exports, f)

 #ef get_resource_path(self, relative_path):
 #""
 #OTE: This API may change in the future.

 #eturn the absolute path to a resource file with the given relative
 #ath.

 #param relative_path: The path, relative to .dist-info, of the resource
 #f interest.
 #return: The absolute path where the resource is to be found.
 #""
 # = self.get_distinfo_resource('RESOURCES')
 #ith contextlib.closing(r.as_stream()) as stream:
 #ith CSVReader(stream=stream) as resources_reader:
 #or relative, destination in resources_reader:
 #f relative == relative_path:
 #eturn destination
 #aise KeyError('no resource file with relative path %r '
 #is installed' % relative_path)

 #ef list_installed_files(self):
 #""
 #terates over the ``RECORD`` entries and returns a tuple
 #`(path, hash, size)`` for each line.

 #returns: iterator of (path, hash, size)
 #""
 #or result in self._get_records():
 #ield result

 #ef write_installed_files(self, paths, prefix, dry_run=False):
 #""
 #rites the ``RECORD`` file, using the ``paths`` iterable passed in. Any
 #xisting ``RECORD`` file is silently overwritten.

 #refix is used to determine when to write absolute paths.
 #""
 #refix = os.path.join(prefix, '')
 #ase = os.path.dirname(self.path)
 #ase_under_prefix = base.startswith(prefix)
 #ase = os.path.join(base, '')
 #ecord_path = self.get_distinfo_file('RECORD')
 #ogger.info('creating %s', record_path)
 #f dry_run:
 #eturn None
 #ith CSVWriter(record_path) as writer:
 #or path in paths:
 #f os.path.isdir(path) or path.endswith(('.pyc', '.pyo')):
                    # do not put size and hash, as in PEP-376
 #ash_value = size = ''
 #lse:
 #ize = '%d' % os.path.getsize(path)
 #ith open(path, 'rb') as fp:
 #ash_value = self.get_hash(fp.read())
 #f path.startswith(base) or (base_under_prefix
 #nd path.startswith(prefix)):
 #ath = os.path.relpath(path, base)
 #riter.writerow((path, hash_value, size))

            # add the RECORD file itself
 #f record_path.startswith(base):
 #ecord_path = os.path.relpath(record_path, base)
 #riter.writerow((record_path, '', ''))
 #eturn record_path

 #ef check_installed_files(self):
 #""
 #hecks that the hashes and sizes of the files in ``RECORD`` are
 #atched by the files themselves. Returns a (possibly empty) list of
 #ismatches. Each entry in the mismatch list will be a tuple consisting
 #f the path, 'exists', 'size' or 'hash' according to what didn't match
 #existence is checked first, then size, then hash), the expected
 #alue and the actual value.
 #""
 #ismatches = []
 #ase = os.path.dirname(self.path)
 #ecord_path = self.get_distinfo_file('RECORD')
 #or path, hash_value, size in self.list_installed_files():
 #f not os.path.isabs(path):
 #ath = os.path.join(base, path)
 #f path == record_path:
 #ontinue
 #f not os.path.exists(path):
 #ismatches.append((path, 'exists', True, False))
 #lif os.path.isfile(path):
 #ctual_size = str(os.path.getsize(path))
 #f size and actual_size != size:
 #ismatches.append((path, 'size', size, actual_size))
 #lif hash_value:
 #f '=' in hash_value:
 #asher = hash_value.split('=', 1)[0]
 #lse:
 #asher = None

 #ith open(path, 'rb') as f:
 #ctual_hash = self.get_hash(f.read(), hasher)
 #f actual_hash != hash_value:
 #ismatches.append(
 #path, 'hash', hash_value, actual_hash))
 #eturn mismatches

 #cached_property
 #ef shared_locations(self):
 #""
 # dictionary of shared locations whose keys are in the set 'prefix',
 #purelib', 'platlib', 'scripts', 'headers', 'data' and 'namespace'.
 #he corresponding value is the absolute path of that category for
 #his distribution, and takes into account any paths selected by the
 #ser at installation time (e.g. via command-line arguments). In the
 #ase of the 'namespace' key, this would be a list of absolute paths
 #or the roots of namespace packages in this distribution.

 #he first time this property is accessed, the relevant information is
 #ead from the SHARED file in the .dist-info directory.
 #""
 #esult = {}
 #hared_path = os.path.join(self.path, 'SHARED')
 #f os.path.isfile(shared_path):
 #ith codecs.open(shared_path, 'r', encoding='utf-8') as f:
 #ines = f.read().splitlines()
 #or line in lines:
 #ey, value = line.split('=', 1)
 #f key == 'namespace':
 #esult.setdefault(key, []).append(value)
 #lse:
 #esult[key] = value
 #eturn result

 #ef write_shared_locations(self, paths, dry_run=False):
 #""
 #rite shared location information to the SHARED file in .dist-info.
 #param paths: A dictionary as described in the documentation for
 #meth:`shared_locations`.
 #param dry_run: If True, the action is logged but no file is actually
 #ritten.
 #return: The path of the file written to.
 #""
 #hared_path = os.path.join(self.path, 'SHARED')
 #ogger.info('creating %s', shared_path)
 #f dry_run:
 #eturn None
 #ines = []
 #or key in ('prefix', 'lib', 'headers', 'scripts', 'data'):
 #ath = paths[key]
 #f os.path.isdir(paths[key]):
 #ines.append('%s=%s' % (key, path))
 #or ns in paths.get('namespace', ()):
 #ines.append('namespace=%s' % ns)

 #ith codecs.open(shared_path, 'w', encoding='utf-8') as f:
 #.write('\n'.join(lines))
 #eturn shared_path

 #ef get_distinfo_resource(self, path):
 #f path not in DIST_FILES:
 #aise DistlibException('invalid path for a dist-info file: '
 #%r at %r' % (path, self.path))
 #inder = resources.finder_for_path(self.path)
 #f finder is None:
 #aise DistlibException('Unable to get a finder for %s' % self.path)
 #eturn finder.find(path)

 #ef get_distinfo_file(self, path):
 #""
 #eturns a path located under the ``.dist-info`` directory. Returns a
 #tring representing the path.

 #parameter path: a ``'/'``-separated path relative to the
 #`.dist-info`` directory or an absolute path;
 #f *path* is an absolute path and doesn't start
 #ith the ``.dist-info`` directory path,
 # :class:`DistlibException` is raised
 #type path: str
 #rtype: str
 #""
        # Check if it is an absolute path  # XXX use relpath, add tests
 #f path.find(os.sep) >= 0:
            # it's an absolute path?
 #istinfo_dirname, path = path.split(os.sep)[-2:]
 #f distinfo_dirname != self.path.split(os.sep)[-1]:
 #aise DistlibException(
 #dist-info file %r does not belong to the %r %s '
 #distribution' % (path, self.name, self.version))

        # The file must be relative
 #f path not in DIST_FILES:
 #aise DistlibException('invalid path for a dist-info file: '
 #%r at %r' % (path, self.path))

 #eturn os.path.join(self.path, path)

 #ef list_distinfo_files(self):
 #""
 #terates over the ``RECORD`` entries and returns paths for each line if
 #he path is pointing to a file located in the ``.dist-info`` directory
 #r one of its subdirectories.

 #returns: iterator of paths
 #""
 #ase = os.path.dirname(self.path)
 #or path, checksum, size in self._get_records():
            # XXX add separator or use real relpath algo
 #f not os.path.isabs(path):
 #ath = os.path.join(base, path)
 #f path.startswith(self.path):
 #ield path

 #ef __eq__(self, other):
 #eturn (isinstance(other, InstalledDistribution)
 #nd self.path == other.path)

    # See http://docs.python.org/reference/datamodel#object.__hash__
 #_hash__ = object.__hash__


class EggInfoDistribution(BaseInstalledDistribution):
 #""Created with the *path* of the ``.egg-info`` directory or file provided
 #o the constructor. It reads the metadata contained in the file itself, or
 #f the given path happens to be a directory, the metadata is read from the
 #ile ``PKG-INFO`` under that directory."""

 #equested = True  # as we have no way of knowing, assume it was
 #hared_locations = {}

 #ef __init__(self, path, env=None):

 #ef set_name_and_version(s, n, v):
 #.name = n
 #.key = n.lower()  # for case-insensitive comparisons
 #.version = v

 #elf.path = path
 #elf.dist_path = env
 #f env and env._cache_enabled and path in env._cache_egg.path:
 #etadata = env._cache_egg.path[path].metadata
 #et_name_and_version(self, metadata.name, metadata.version)
 #lse:
 #etadata = self._get_metadata(path)

            # Need to be set before caching
 #et_name_and_version(self, metadata.name, metadata.version)

 #f env and env._cache_enabled:
 #nv._cache_egg.add(self)
 #uper(EggInfoDistribution, self).__init__(metadata, path, env)

 #ef _get_metadata(self, path):
 #equires = None

 #ef parse_requires_data(data):
 #""Create a list of dependencies from a requires.txt file.

 #data*: the contents of a setuptools-produced requires.txt file.
 #""
 #eqs = []
 #ines = data.splitlines()
 #or line in lines:
 #ine = line.strip()
                # sectioned files have bare newlines (separating sections)
 #f not line:  # pragma: no cover
 #ontinue
 #f line.startswith('['):  # pragma: no cover
 #ogger.warning(
 #Unexpected line: quitting requirement scan: %r', line)
 #reak
 # = parse_requirement(line)
 #f not r:  # pragma: no cover
 #ogger.warning('Not recognised as a requirement: %r', line)
 #ontinue
 #f r.extras:  # pragma: no cover
 #ogger.warning('extra requirements in requires.txt are '
 #not supported')
 #f not r.constraints:
 #eqs.append(r.name)
 #lse:
 #ons = ', '.join('%s%s' % c for c in r.constraints)
 #eqs.append('%s (%s)' % (r.name, cons))
 #eturn reqs

 #ef parse_requires_path(req_path):
 #""Create a list of dependencies from a requires.txt file.

 #req_path*: the path to a setuptools-produced requires.txt file.
 #""

 #eqs = []
 #ry:
 #ith codecs.open(req_path, 'r', 'utf-8') as fp:
 #eqs = parse_requires_data(fp.read())
 #xcept IOError:
 #ass
 #eturn reqs

 #l_path = tl_data = None
 #f path.endswith('.egg'):
 #f os.path.isdir(path):
 # = os.path.join(path, 'EGG-INFO')
 #eta_path = os.path.join(p, 'PKG-INFO')
 #etadata = Metadata(path=meta_path, scheme='legacy')
 #eq_path = os.path.join(p, 'requires.txt')
 #l_path = os.path.join(p, 'top_level.txt')
 #equires = parse_requires_path(req_path)
 #lse:
                # FIXME handle the case where zipfile is not available
 #ipf = zipimport.zipimporter(path)
 #ileobj = StringIO(
 #ipf.get_data('EGG-INFO/PKG-INFO').decode('utf8'))
 #etadata = Metadata(fileobj=fileobj, scheme='legacy')
 #ry:
 #ata = zipf.get_data('EGG-INFO/requires.txt')
 #l_data = zipf.get_data('EGG-INFO/top_level.txt').decode(
 #utf-8')
 #equires = parse_requires_data(data.decode('utf-8'))
 #xcept IOError:
 #equires = None
 #lif path.endswith('.egg-info'):
 #f os.path.isdir(path):
 #eq_path = os.path.join(path, 'requires.txt')
 #equires = parse_requires_path(req_path)
 #ath = os.path.join(path, 'PKG-INFO')
 #l_path = os.path.join(path, 'top_level.txt')
 #etadata = Metadata(path=path, scheme='legacy')
 #lse:
 #aise DistlibException('path must end with .egg-info or .egg, '
 #got %r' % path)

 #f requires:
 #etadata.add_requirements(requires)
        # look for top-level modules in top_level.txt, if present
 #f tl_data is None:
 #f tl_path is not None and os.path.exists(tl_path):
 #ith open(tl_path, 'rb') as f:
 #l_data = f.read().decode('utf-8')
 #f not tl_data:
 #l_data = []
 #lse:
 #l_data = tl_data.splitlines()
 #elf.modules = tl_data
 #eturn metadata

 #ef __repr__(self):
 #eturn '<EggInfoDistribution %r %s at %r>' % (self.name, self.version,
 #elf.path)

 #ef __str__(self):
 #eturn "%s %s" % (self.name, self.version)

 #ef check_installed_files(self):
 #""
 #hecks that the hashes and sizes of the files in ``RECORD`` are
 #atched by the files themselves. Returns a (possibly empty) list of
 #ismatches. Each entry in the mismatch list will be a tuple consisting
 #f the path, 'exists', 'size' or 'hash' according to what didn't match
 #existence is checked first, then size, then hash), the expected
 #alue and the actual value.
 #""
 #ismatches = []
 #ecord_path = os.path.join(self.path, 'installed-files.txt')
 #f os.path.exists(record_path):
 #or path, _, _ in self.list_installed_files():
 #f path == record_path:
 #ontinue
 #f not os.path.exists(path):
 #ismatches.append((path, 'exists', True, False))
 #eturn mismatches

 #ef list_installed_files(self):
 #""
 #terates over the ``installed-files.txt`` entries and returns a tuple
 #`(path, hash, size)`` for each line.

 #returns: a list of (path, hash, size)
 #""

 #ef _md5(path):
 # = open(path, 'rb')
 #ry:
 #ontent = f.read()
 #inally:
 #.close()
 #eturn hashlib.md5(content).hexdigest()

 #ef _size(path):
 #eturn os.stat(path).st_size

 #ecord_path = os.path.join(self.path, 'installed-files.txt')
 #esult = []
 #f os.path.exists(record_path):
 #ith codecs.open(record_path, 'r', encoding='utf-8') as f:
 #or line in f:
 #ine = line.strip()
 # = os.path.normpath(os.path.join(self.path, line))
                    # "./" is present as a marker between installed files
                    # and installation metadata files
 #f not os.path.exists(p):
 #ogger.warning('Non-existent file: %s', p)
 #f p.endswith(('.pyc', '.pyo')):
 #ontinue
                        # otherwise fall through and fail
 #f not os.path.isdir(p):
 #esult.append((p, _md5(p), _size(p)))
 #esult.append((record_path, None, None))
 #eturn result

 #ef list_distinfo_files(self, absolute=False):
 #""
 #terates over the ``installed-files.txt`` entries and returns paths for
 #ach line if the path is pointing to a file located in the
 #`.egg-info`` directory or one of its subdirectories.

 #parameter absolute: If *absolute* is ``True``, each returned path is
 #ransformed into a local absolute path. Otherwise the
 #aw value from ``installed-files.txt`` is returned.
 #type absolute: boolean
 #returns: iterator of paths
 #""
 #ecord_path = os.path.join(self.path, 'installed-files.txt')
 #f os.path.exists(record_path):
 #kip = True
 #ith codecs.open(record_path, 'r', encoding='utf-8') as f:
 #or line in f:
 #ine = line.strip()
 #f line == './':
 #kip = False
 #ontinue
 #f not skip:
 # = os.path.normpath(os.path.join(self.path, line))
 #f p.startswith(self.path):
 #f absolute:
 #ield p
 #lse:
 #ield line

 #ef __eq__(self, other):
 #eturn (isinstance(other, EggInfoDistribution)
 #nd self.path == other.path)

    # See http://docs.python.org/reference/datamodel#object.__hash__
 #_hash__ = object.__hash__


new_dist_class = InstalledDistribution
old_dist_class = EggInfoDistribution


class DependencyGraph(object):
 #""
 #epresents a dependency graph between distributions.

 #he dependency relationships are stored in an ``adjacency_list`` that maps
 #istributions to a list of ``(other, label)`` tuples where  ``other``
 #s a distribution and the edge is labeled with ``label`` (i.e. the version
 #pecifier, if such was provided). Also, for more efficient traversal, for
 #very distribution ``x``, a list of predecessors is kept in
 #`reverse_list[x]``. An edge from distribution ``a`` to
 #istribution ``b`` means that ``a`` depends on ``b``. If any missing
 #ependencies are found, they are stored in ``missing``, which is a
 #ictionary that maps distributions to a list of requirements that were not
 #rovided by any other distributions.
 #""

 #ef __init__(self):
 #elf.adjacency_list = {}
 #elf.reverse_list = {}
 #elf.missing = {}

 #ef add_distribution(self, distribution):
 #""Add the *distribution* to the graph.

 #type distribution: :class:`distutils2.database.InstalledDistribution`
 #r :class:`distutils2.database.EggInfoDistribution`
 #""
 #elf.adjacency_list[distribution] = []
 #elf.reverse_list[distribution] = []
        # self.missing[distribution] = []

 #ef add_edge(self, x, y, label=None):
 #""Add an edge from distribution *x* to distribution *y* with the given
 #label*.

 #type x: :class:`distutils2.database.InstalledDistribution` or
 #class:`distutils2.database.EggInfoDistribution`
 #type y: :class:`distutils2.database.InstalledDistribution` or
 #class:`distutils2.database.EggInfoDistribution`
 #type label: ``str`` or ``None``
 #""
 #elf.adjacency_list[x].append((y, label))
        # multiple edges are allowed, so be careful
 #f x not in self.reverse_list[y]:
 #elf.reverse_list[y].append(x)

 #ef add_missing(self, distribution, requirement):
 #""
 #dd a missing *requirement* for the given *distribution*.

 #type distribution: :class:`distutils2.database.InstalledDistribution`
 #r :class:`distutils2.database.EggInfoDistribution`
 #type requirement: ``str``
 #""
 #ogger.debug('%s missing %r', distribution, requirement)
 #elf.missing.setdefault(distribution, []).append(requirement)

 #ef _repr_dist(self, dist):
 #eturn '%s %s' % (dist.name, dist.version)

 #ef repr_node(self, dist, level=1):
 #""Prints only a subgraph"""
 #utput = [self._repr_dist(dist)]
 #or other, label in self.adjacency_list[dist]:
 #ist = self._repr_dist(other)
 #f label is not None:
 #ist = '%s [%s]' % (dist, label)
 #utput.append('    ' * level + str(dist))
 #uboutput = self.repr_node(other, level + 1)
 #ubs = suboutput.split('\n')
 #utput.extend(subs[1:])
 #eturn '\n'.join(output)

 #ef to_dot(self, f, skip_disconnected=True):
 #""Writes a DOT output for the graph to the provided file *f*.

 #f *skip_disconnected* is set to ``True``, then all distributions
 #hat are not dependent on any other distribution are skipped.

 #type f: has to support ``file``-like operations
 #type skip_disconnected: ``bool``
 #""
 #isconnected = []

 #.write("digraph dependencies {\n")
 #or dist, adjs in self.adjacency_list.items():
 #f len(adjs) == 0 and not skip_disconnected:
 #isconnected.append(dist)
 #or other, label in adjs:
 #f label is not None:
 #.write('"%s" -> "%s" [label="%s"]\n' %
 #dist.name, other.name, label))
 #lse:
 #.write('"%s" -> "%s"\n' % (dist.name, other.name))
 #f not skip_disconnected and len(disconnected) > 0:
 #.write('subgraph disconnected {\n')
 #.write('label = "Disconnected"\n')
 #.write('bgcolor = red\n')

 #or dist in disconnected:
 #.write('"%s"' % dist.name)
 #.write('\n')
 #.write('}\n')
 #.write('}\n')

 #ef topological_sort(self):
 #""
 #erform a topological sort of the graph.
 #return: A tuple, the first element of which is a topologically sorted
 #ist of distributions, and the second element of which is a
 #ist of distributions that cannot be sorted because they have
 #ircular dependencies and so form a cycle.
 #""
 #esult = []
        # Make a shallow copy of the adjacency list
 #list = {}
 #or k, v in self.adjacency_list.items():
 #list[k] = v[:]
 #hile True:
            # See what we can remove in this run
 #o_remove = []
 #or k, v in list(alist.items())[:]:
 #f not v:
 #o_remove.append(k)
 #el alist[k]
 #f not to_remove:
                # What's left in alist (if anything) is a cycle.
 #reak
            # Remove from the adjacency list of others
 #or k, v in alist.items():
 #list[k] = [(d, r) for d, r in v if d not in to_remove]
 #ogger.debug('Moving to result: %s',
 #'%s (%s)' % (d.name, d.version) for d in to_remove])
 #esult.extend(to_remove)
 #eturn result, list(alist.keys())

 #ef __repr__(self):
 #""Representation of the graph"""
 #utput = []
 #or dist, adjs in self.adjacency_list.items():
 #utput.append(self.repr_node(dist))
 #eturn '\n'.join(output)


def make_graph(dists, scheme='default'):
 #""Makes a dependency graph from the given distributions.

 #parameter dists: a list of distributions
 #type dists: list of :class:`distutils2.database.InstalledDistribution` and
 #class:`distutils2.database.EggInfoDistribution` instances
 #rtype: a :class:`DependencyGraph` instance
 #""
 #cheme = get_scheme(scheme)
 #raph = DependencyGraph()
 #rovided = {}  # maps names to lists of (version, dist) tuples

    # first, build the graph and find out what's provided
 #or dist in dists:
 #raph.add_distribution(dist)

 #or p in dist.provides:
 #ame, version = parse_name_and_version(p)
 #ogger.debug('Add to provided: %s, %s, %s', name, version, dist)
 #rovided.setdefault(name, []).append((version, dist))

    # now make the edges
 #or dist in dists:
 #equires = (dist.run_requires | dist.meta_requires
 # dist.build_requires | dist.dev_requires)
 #or req in requires:
 #ry:
 #atcher = scheme.matcher(req)
 #xcept UnsupportedVersionError:
                # XXX compat-mode if cannot read the version
 #ogger.warning('could not read version %r - using name only',
 #eq)
 #ame = req.split()[0]
 #atcher = scheme.matcher(name)

 #ame = matcher.key  # case-insensitive

 #atched = False
 #f name in provided:
 #or version, provider in provided[name]:
 #ry:
 #atch = matcher.match(version)
 #xcept UnsupportedVersionError:
 #atch = False

 #f match:
 #raph.add_edge(dist, provider, req)
 #atched = True
 #reak
 #f not matched:
 #raph.add_missing(dist, req)
 #eturn graph


def get_dependent_dists(dists, dist):
 #""Recursively generate a list of distributions from *dists* that are
 #ependent on *dist*.

 #param dists: a list of distributions
 #param dist: a distribution, member of *dists* for which we are interested
 #""
 #f dist not in dists:
 #aise DistlibException('given distribution %r is not a member '
 #of the list' % dist.name)
 #raph = make_graph(dists)

 #ep = [dist]  # dependent distributions
 #odo = graph.reverse_list[dist]  # list of nodes we should inspect

 #hile todo:
 # = todo.pop()
 #ep.append(d)
 #or succ in graph.reverse_list[d]:
 #f succ not in dep:
 #odo.append(succ)

 #ep.pop(0)  # remove dist from dep, was there to prevent infinite loops
 #eturn dep


def get_required_dists(dists, dist):
 #""Recursively generate a list of distributions from *dists* that are
 #equired by *dist*.

 #param dists: a list of distributions
 #param dist: a distribution, member of *dists* for which we are interested
 #n finding the dependencies.
 #""
 #f dist not in dists:
 #aise DistlibException('given distribution %r is not a member '
 #of the list' % dist.name)
 #raph = make_graph(dists)

 #eq = set()  # required distributions
 #odo = graph.adjacency_list[dist]  # list of nodes we should inspect
 #een = set(t[0] for t in todo)  # already added to todo

 #hile todo:
 # = todo.pop()[0]
 #eq.add(d)
 #red_list = graph.adjacency_list[d]
 #or pred in pred_list:
 # = pred[0]
 #f d not in req and d not in seen:
 #een.add(d)
 #odo.append(pred)
 #eturn req


def make_dist(name, version, **kwargs):
 #""
 # convenience method for making a dist given just a name and version.
 #""
 #ummary = kwargs.pop('summary', 'Placeholder for summary')
 #d = Metadata(**kwargs)
 #d.name = name
 #d.version = version
 #d.summary = summary or 'Placeholder for summary'
 #eturn Distribution(md)
