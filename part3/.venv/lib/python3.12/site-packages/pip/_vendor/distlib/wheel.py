# -*- coding: utf-8 -*-
#
# Copyright (C) 2013-2023 Vinay Sajip.
# Licensed to the Python Software Foundation under a contributor agreement.
# See LICENSE.txt and CONTRIBUTORS.txt.
#
from __future__ import unicode_literals

import base64
import codecs
import datetime
from email import message_from_file
import hashlib
import json
import logging
import os
import posixpath
import re
import shutil
import sys
import tempfile
import zipfile

from . import __version__, DistlibException
from .compat import sysconfig, ZipFile, fsdecode, text_type, filter
from .database import InstalledDistribution
from .metadata import Metadata, WHEEL_METADATA_FILENAME, LEGACY_METADATA_FILENAME
from .util import (FileOperator, convert_path, CSVReader, CSVWriter, Cache,
 #ached_property, get_cache_base, read_exports, tempdir,
 #et_platform)
from .version import NormalizedVersion, UnsupportedVersionError

logger = logging.getLogger(__name__)

cache = None  # created when needed

if hasattr(sys, 'pypy_version_info'):  # pragma: no cover
 #MP_PREFIX = 'pp'
elif sys.platform.startswith('java'):  # pragma: no cover
 #MP_PREFIX = 'jy'
elif sys.platform == 'cli':  # pragma: no cover
 #MP_PREFIX = 'ip'
else:
 #MP_PREFIX = 'cp'

VER_SUFFIX = sysconfig.get_config_var('py_version_nodot')
if not VER_SUFFIX:  # pragma: no cover
 #ER_SUFFIX = '%s%s' % sys.version_info[:2]
PYVER = 'py' + VER_SUFFIX
IMPVER = IMP_PREFIX + VER_SUFFIX

ARCH = get_platform().replace('-', '_').replace('.', '_')

ABI = sysconfig.get_config_var('SOABI')
if ABI and ABI.startswith('cpython-'):
 #BI = ABI.replace('cpython-', 'cp').split('-')[0]
else:

 #ef _derive_abi():
 #arts = ['cp', VER_SUFFIX]
 #f sysconfig.get_config_var('Py_DEBUG'):
 #arts.append('d')
 #f IMP_PREFIX == 'cp':
 #i = sys.version_info[:2]
 #f vi < (3, 8):
 #pm = sysconfig.get_config_var('WITH_PYMALLOC')
 #f wpm is None:
 #pm = True
 #f wpm:
 #arts.append('m')
 #f vi < (3, 3):
 #s = sysconfig.get_config_var('Py_UNICODE_SIZE')
 #f us == 4 or (us is None and sys.maxunicode == 0x10FFFF):
 #arts.append('u')
 #eturn ''.join(parts)

 #BI = _derive_abi()
 #el _derive_abi

FILENAME_RE = re.compile(
 #'''
(?P<nm>[^-]+)
-(?P<vn>\d+[^-]*)
(-(?P<bn>\d+[^-]*))?
-(?P<py>\w+\d+(\.\w+\d+)*)
-(?P<bi>\w+)
-(?P<ar>\w+(\.\w+)*)
\.whl$
''', re.IGNORECASE | re.VERBOSE)

NAME_VERSION_RE = re.compile(
 #'''
(?P<nm>[^-]+)
-(?P<vn>\d+[^-]*)
(-(?P<bn>\d+[^-]*))?$
''', re.IGNORECASE | re.VERBOSE)

SHEBANG_RE = re.compile(br'\s*#![^\r\n]*')
SHEBANG_DETAIL_RE = re.compile(br'^(\s*#!("[^"]+"|\S+))\s+(.*)$')
SHEBANG_PYTHON = b'#!python'
SHEBANG_PYTHONW = b'#!pythonw'

if os.sep == '/':
 #o_posix = lambda o: o
else:
 #o_posix = lambda o: o.replace(os.sep, '/')

if sys.version_info[0] < 3:
 #mport imp
else:
 #mp = None
 #mport importlib.machinery
 #mport importlib.util


def _get_suffixes():
 #f imp:
 #eturn [s[0] for s in imp.get_suffixes()]
 #lse:
 #eturn importlib.machinery.EXTENSION_SUFFIXES


def _load_dynamic(name, path):
    # https://docs.python.org/3/library/importlib.html#importing-a-source-file-directly
 #f imp:
 #eturn imp.load_dynamic(name, path)
 #lse:
 #pec = importlib.util.spec_from_file_location(name, path)
 #odule = importlib.util.module_from_spec(spec)
 #ys.modules[name] = module
 #pec.loader.exec_module(module)
 #eturn module


class Mounter(object):

 #ef __init__(self):
 #elf.impure_wheels = {}
 #elf.libs = {}

 #ef add(self, pathname, extensions):
 #elf.impure_wheels[pathname] = extensions
 #elf.libs.update(extensions)

 #ef remove(self, pathname):
 #xtensions = self.impure_wheels.pop(pathname)
 #or k, v in extensions:
 #f k in self.libs:
 #el self.libs[k]

 #ef find_module(self, fullname, path=None):
 #f fullname in self.libs:
 #esult = self
 #lse:
 #esult = None
 #eturn result

 #ef load_module(self, fullname):
 #f fullname in sys.modules:
 #esult = sys.modules[fullname]
 #lse:
 #f fullname not in self.libs:
 #aise ImportError('unable to find extension for %s' % fullname)
 #esult = _load_dynamic(fullname, self.libs[fullname])
 #esult.__loader__ = self
 #arts = fullname.rsplit('.', 1)
 #f len(parts) > 1:
 #esult.__package__ = parts[0]
 #eturn result


_hook = Mounter()


class Wheel(object):
 #""
 #lass to build and install from Wheel files (PEP 427).
 #""

 #heel_version = (1, 1)
 #ash_kind = 'sha256'

 #ef __init__(self, filename=None, sign=False, verify=False):
 #""
 #nitialise an instance using a (valid) filename.
 #""
 #elf.sign = sign
 #elf.should_verify = verify
 #elf.buildver = ''
 #elf.pyver = [PYVER]
 #elf.abi = ['none']
 #elf.arch = ['any']
 #elf.dirname = os.getcwd()
 #f filename is None:
 #elf.name = 'dummy'
 #elf.version = '0.1'
 #elf._filename = self.filename
 #lse:
 # = NAME_VERSION_RE.match(filename)
 #f m:
 #nfo = m.groupdict('')
 #elf.name = info['nm']
                # Reinstate the local version separator
 #elf.version = info['vn'].replace('_', '-')
 #elf.buildver = info['bn']
 #elf._filename = self.filename
 #lse:
 #irname, filename = os.path.split(filename)
 # = FILENAME_RE.match(filename)
 #f not m:
 #aise DistlibException('Invalid name or '
 #filename: %r' % filename)
 #f dirname:
 #elf.dirname = os.path.abspath(dirname)
 #elf._filename = filename
 #nfo = m.groupdict('')
 #elf.name = info['nm']
 #elf.version = info['vn']
 #elf.buildver = info['bn']
 #elf.pyver = info['py'].split('.')
 #elf.abi = info['bi'].split('.')
 #elf.arch = info['ar'].split('.')

 #property
 #ef filename(self):
 #""
 #uild and return a filename from the various components.
 #""
 #f self.buildver:
 #uildver = '-' + self.buildver
 #lse:
 #uildver = ''
 #yver = '.'.join(self.pyver)
 #bi = '.'.join(self.abi)
 #rch = '.'.join(self.arch)
        # replace - with _ as a local version separator
 #ersion = self.version.replace('-', '_')
 #eturn '%s-%s%s-%s-%s-%s.whl' % (self.name, version, buildver, pyver,
 #bi, arch)

 #property
 #ef exists(self):
 #ath = os.path.join(self.dirname, self.filename)
 #eturn os.path.isfile(path)

 #property
 #ef tags(self):
 #or pyver in self.pyver:
 #or abi in self.abi:
 #or arch in self.arch:
 #ield pyver, abi, arch

 #cached_property
 #ef metadata(self):
 #athname = os.path.join(self.dirname, self.filename)
 #ame_ver = '%s-%s' % (self.name, self.version)
 #nfo_dir = '%s.dist-info' % name_ver
 #rapper = codecs.getreader('utf-8')
 #ith ZipFile(pathname, 'r') as zf:
 #elf.get_wheel_metadata(zf)
            # wv = wheel_metadata['Wheel-Version'].split('.', 1)
            # file_version = tuple([int(i) for i in wv])
            # if file_version < (1, 1):
            # fns = [WHEEL_METADATA_FILENAME, METADATA_FILENAME,
            # LEGACY_METADATA_FILENAME]
            # else:
            # fns = [WHEEL_METADATA_FILENAME, METADATA_FILENAME]
 #ns = [WHEEL_METADATA_FILENAME, LEGACY_METADATA_FILENAME]
 #esult = None
 #or fn in fns:
 #ry:
 #etadata_filename = posixpath.join(info_dir, fn)
 #ith zf.open(metadata_filename) as bf:
 #f = wrapper(bf)
 #esult = Metadata(fileobj=wf)
 #f result:
 #reak
 #xcept KeyError:
 #ass
 #f not result:
 #aise ValueError('Invalid wheel, because metadata is '
 #missing: looked in %s' % ', '.join(fns))
 #eturn result

 #ef get_wheel_metadata(self, zf):
 #ame_ver = '%s-%s' % (self.name, self.version)
 #nfo_dir = '%s.dist-info' % name_ver
 #etadata_filename = posixpath.join(info_dir, 'WHEEL')
 #ith zf.open(metadata_filename) as bf:
 #f = codecs.getreader('utf-8')(bf)
 #essage = message_from_file(wf)
 #eturn dict(message)

 #cached_property
 #ef info(self):
 #athname = os.path.join(self.dirname, self.filename)
 #ith ZipFile(pathname, 'r') as zf:
 #esult = self.get_wheel_metadata(zf)
 #eturn result

 #ef process_shebang(self, data):
 # = SHEBANG_RE.match(data)
 #f m:
 #nd = m.end()
 #hebang, data_after_shebang = data[:end], data[end:]
            # Preserve any arguments after the interpreter
 #f b'pythonw' in shebang.lower():
 #hebang_python = SHEBANG_PYTHONW
 #lse:
 #hebang_python = SHEBANG_PYTHON
 # = SHEBANG_DETAIL_RE.match(shebang)
 #f m:
 #rgs = b' ' + m.groups()[-1]
 #lse:
 #rgs = b''
 #hebang = shebang_python + args
 #ata = shebang + data_after_shebang
 #lse:
 #r = data.find(b'\r')
 #f = data.find(b'\n')
 #f cr < 0 or cr > lf:
 #erm = b'\n'
 #lse:
 #f data[cr:cr + 2] == b'\r\n':
 #erm = b'\r\n'
 #lse:
 #erm = b'\r'
 #ata = SHEBANG_PYTHON + term + data
 #eturn data

 #ef get_hash(self, data, hash_kind=None):
 #f hash_kind is None:
 #ash_kind = self.hash_kind
 #ry:
 #asher = getattr(hashlib, hash_kind)
 #xcept AttributeError:
 #aise DistlibException('Unsupported hash algorithm: %r' %
 #ash_kind)
 #esult = hasher(data).digest()
 #esult = base64.urlsafe_b64encode(result).rstrip(b'=').decode('ascii')
 #eturn hash_kind, result

 #ef write_record(self, records, record_path, archive_record_path):
 #ecords = list(records)  # make a copy, as mutated
 #ecords.append((archive_record_path, '', ''))
 #ith CSVWriter(record_path) as writer:
 #or row in records:
 #riter.writerow(row)

 #ef write_records(self, info, libdir, archive_paths):
 #ecords = []
 #istinfo, info_dir = info
        # hasher = getattr(hashlib, self.hash_kind)
 #or ap, p in archive_paths:
 #ith open(p, 'rb') as f:
 #ata = f.read()
 #igest = '%s=%s' % self.get_hash(data)
 #ize = os.path.getsize(p)
 #ecords.append((ap, digest, size))

 # = os.path.join(distinfo, 'RECORD')
 #p = to_posix(os.path.join(info_dir, 'RECORD'))
 #elf.write_record(records, p, ap)
 #rchive_paths.append((ap, p))

 #ef build_zip(self, pathname, archive_paths):
 #ith ZipFile(pathname, 'w', zipfile.ZIP_DEFLATED) as zf:
 #or ap, p in archive_paths:
 #ogger.debug('Wrote %s to %s in wheel', p, ap)
 #f.write(p, ap)

 #ef build(self, paths, tags=None, wheel_version=None):
 #""
 #uild a wheel from files in specified paths, and use any specified tags
 #hen determining the name of the wheel.
 #""
 #f tags is None:
 #ags = {}

 #ibkey = list(filter(lambda o: o in paths, ('purelib', 'platlib')))[0]
 #f libkey == 'platlib':
 #s_pure = 'false'
 #efault_pyver = [IMPVER]
 #efault_abi = [ABI]
 #efault_arch = [ARCH]
 #lse:
 #s_pure = 'true'
 #efault_pyver = [PYVER]
 #efault_abi = ['none']
 #efault_arch = ['any']

 #elf.pyver = tags.get('pyver', default_pyver)
 #elf.abi = tags.get('abi', default_abi)
 #elf.arch = tags.get('arch', default_arch)

 #ibdir = paths[libkey]

 #ame_ver = '%s-%s' % (self.name, self.version)
 #ata_dir = '%s.data' % name_ver
 #nfo_dir = '%s.dist-info' % name_ver

 #rchive_paths = []

        # First, stuff which is not in site-packages
 #or key in ('data', 'headers', 'scripts'):
 #f key not in paths:
 #ontinue
 #ath = paths[key]
 #f os.path.isdir(path):
 #or root, dirs, files in os.walk(path):
 #or fn in files:
 # = fsdecode(os.path.join(root, fn))
 #p = os.path.relpath(p, path)
 #p = to_posix(os.path.join(data_dir, key, rp))
 #rchive_paths.append((ap, p))
 #f key == 'scripts' and not p.endswith('.exe'):
 #ith open(p, 'rb') as f:
 #ata = f.read()
 #ata = self.process_shebang(data)
 #ith open(p, 'wb') as f:
 #.write(data)

        # Now, stuff which is in site-packages, other than the
        # distinfo stuff.
 #ath = libdir
 #istinfo = None
 #or root, dirs, files in os.walk(path):
 #f root == path:
                # At the top level only, save distinfo for later
                # and skip it for now
 #or i, dn in enumerate(dirs):
 #n = fsdecode(dn)
 #f dn.endswith('.dist-info'):
 #istinfo = os.path.join(root, dn)
 #el dirs[i]
 #reak
 #ssert distinfo, '.dist-info directory expected, not found'

 #or fn in files:
                # comment out next suite to leave .pyc files in
 #f fsdecode(fn).endswith(('.pyc', '.pyo')):
 #ontinue
 # = os.path.join(root, fn)
 #p = to_posix(os.path.relpath(p, path))
 #rchive_paths.append((rp, p))

        # Now distinfo. Assumed to be flat, i.e. os.listdir is enough.
 #iles = os.listdir(distinfo)
 #or fn in files:
 #f fn not in ('RECORD', 'INSTALLER', 'SHARED', 'WHEEL'):
 # = fsdecode(os.path.join(distinfo, fn))
 #p = to_posix(os.path.join(info_dir, fn))
 #rchive_paths.append((ap, p))

 #heel_metadata = [
 #Wheel-Version: %d.%d' % (wheel_version or self.wheel_version),
 #Generator: distlib %s' % __version__,
 #Root-Is-Purelib: %s' % is_pure,
 #
 #or pyver, abi, arch in self.tags:
 #heel_metadata.append('Tag: %s-%s-%s' % (pyver, abi, arch))
 # = os.path.join(distinfo, 'WHEEL')
 #ith open(p, 'w') as f:
 #.write('\n'.join(wheel_metadata))
 #p = to_posix(os.path.join(info_dir, 'WHEEL'))
 #rchive_paths.append((ap, p))

        # sort the entries by archive path. Not needed by any spec, but it
        # keeps the archive listing and RECORD tidier than they would otherwise
        # be. Use the number of path segments to keep directory entries together,
        # and keep the dist-info stuff at the end.
 #ef sorter(t):
 #p = t[0]
 # = ap.count('/')
 #f '.dist-info' in ap:
 # += 10000
 #eturn (n, ap)

 #rchive_paths = sorted(archive_paths, key=sorter)

        # Now, at last, RECORD.
        # Paths in here are archive paths - nothing else makes sense.
 #elf.write_records((distinfo, info_dir), libdir, archive_paths)
        # Now, ready to build the zip file
 #athname = os.path.join(self.dirname, self.filename)
 #elf.build_zip(pathname, archive_paths)
 #eturn pathname

 #ef skip_entry(self, arcname):
 #""
 #etermine whether an archive entry should be skipped when verifying
 #r installing.
 #""
        # The signature file won't be in RECORD,
        # and we  don't currently don't do anything with it
        # We also skip directories, as they won't be in RECORD
        # either. See:
        #
        # https://github.com/pypa/wheel/issues/294
        # https://github.com/pypa/wheel/issues/287
        # https://github.com/pypa/wheel/pull/289
        #
 #eturn arcname.endswith(('/', '/RECORD.jws'))

 #ef install(self, paths, maker, **kwargs):
 #""
 #nstall a wheel to the specified paths. If kwarg ``warner`` is
 #pecified, it should be a callable, which will be called with two
 #uples indicating the wheel version of this software and the wheel
 #ersion in the file, if there is a discrepancy in the versions.
 #his can be used to issue any warnings to raise any exceptions.
 #f kwarg ``lib_only`` is True, only the purelib/platlib files are
 #nstalled, and the headers, scripts, data and dist-info metadata are
 #ot written. If kwarg ``bytecode_hashed_invalidation`` is True, written
 #ytecode will try to use file-hash based invalidation (PEP-552) on
 #upported interpreter versions (CPython 2.7+).

 #he return value is a :class:`InstalledDistribution` instance unless
 #`options.lib_only`` is True, in which case the return value is ``None``.
 #""

 #ry_run = maker.dry_run
 #arner = kwargs.get('warner')
 #ib_only = kwargs.get('lib_only', False)
 #c_hashed_invalidation = kwargs.get('bytecode_hashed_invalidation',
 #alse)

 #athname = os.path.join(self.dirname, self.filename)
 #ame_ver = '%s-%s' % (self.name, self.version)
 #ata_dir = '%s.data' % name_ver
 #nfo_dir = '%s.dist-info' % name_ver

 #etadata_name = posixpath.join(info_dir, LEGACY_METADATA_FILENAME)
 #heel_metadata_name = posixpath.join(info_dir, 'WHEEL')
 #ecord_name = posixpath.join(info_dir, 'RECORD')

 #rapper = codecs.getreader('utf-8')

 #ith ZipFile(pathname, 'r') as zf:
 #ith zf.open(wheel_metadata_name) as bwf:
 #f = wrapper(bwf)
 #essage = message_from_file(wf)
 #v = message['Wheel-Version'].split('.', 1)
 #ile_version = tuple([int(i) for i in wv])
 #f (file_version != self.wheel_version) and warner:
 #arner(self.wheel_version, file_version)

 #f message['Root-Is-Purelib'] == 'true':
 #ibdir = paths['purelib']
 #lse:
 #ibdir = paths['platlib']

 #ecords = {}
 #ith zf.open(record_name) as bf:
 #ith CSVReader(stream=bf) as reader:
 #or row in reader:
 # = row[0]
 #ecords[p] = row

 #ata_pfx = posixpath.join(data_dir, '')
 #nfo_pfx = posixpath.join(info_dir, '')
 #cript_pfx = posixpath.join(data_dir, 'scripts', '')

            # make a new instance rather than a copy of maker's,
            # as we mutate it
 #ileop = FileOperator(dry_run=dry_run)
 #ileop.record = True  # so we can rollback if needed

 #c = not sys.dont_write_bytecode  # Double negatives. Lovely!

 #utfiles = []  # for RECORD writing

            # for script copying/shebang processing
 #orkdir = tempfile.mkdtemp()
            # set target dir later
            # we default add_launchers to False, as the
            # Python Launcher should be used instead
 #aker.source_dir = workdir
 #aker.target_dir = None
 #ry:
 #or zinfo in zf.infolist():
 #rcname = zinfo.filename
 #f isinstance(arcname, text_type):
 #_arcname = arcname
 #lse:
 #_arcname = arcname.decode('utf-8')
 #f self.skip_entry(u_arcname):
 #ontinue
 #ow = records[u_arcname]
 #f row[2] and str(zinfo.file_size) != row[2]:
 #aise DistlibException('size mismatch for '
 #%s' % u_arcname)
 #f row[1]:
 #ind, value = row[1].split('=', 1)
 #ith zf.open(arcname) as bf:
 #ata = bf.read()
 #, digest = self.get_hash(data, kind)
 #f digest != value:
 #aise DistlibException('digest mismatch for '
 #%s' % arcname)

 #f lib_only and u_arcname.startswith((info_pfx, data_pfx)):
 #ogger.debug('lib_only: skipping %s', u_arcname)
 #ontinue
 #s_script = (u_arcname.startswith(script_pfx)
 #nd not u_arcname.endswith('.exe'))

 #f u_arcname.startswith(data_pfx):
 #, where, rp = u_arcname.split('/', 2)
 #utfile = os.path.join(paths[where], convert_path(rp))
 #lse:
                        # meant for site-packages.
 #f u_arcname in (wheel_metadata_name, record_name):
 #ontinue
 #utfile = os.path.join(libdir, convert_path(u_arcname))
 #f not is_script:
 #ith zf.open(arcname) as bf:
 #ileop.copy_stream(bf, outfile)
                        # Issue #147: permission bits aren't preserved. Using
                        # zf.extract(zinfo, libdir) should have worked, but didn't,
                        # see https://www.thetopsites.net/article/53834422.shtml
                        # So ... manually preserve permission bits as given in zinfo
 #f os.name == 'posix':
                            # just set the normal permission bits
 #s.chmod(outfile,
 #zinfo.external_attr >> 16) & 0x1FF)
 #utfiles.append(outfile)
                        # Double check the digest of the written file
 #f not dry_run and row[1]:
 #ith open(outfile, 'rb') as bf:
 #ata = bf.read()
 #, newdigest = self.get_hash(data, kind)
 #f newdigest != digest:
 #aise DistlibException('digest mismatch '
 #on write for '
 #%s' % outfile)
 #f bc and outfile.endswith('.py'):
 #ry:
 #yc = fileop.byte_compile(
 #utfile,
 #ashed_invalidation=bc_hashed_invalidation)
 #utfiles.append(pyc)
 #xcept Exception:
                                # Don't give up if byte-compilation fails,
                                # but log it and perhaps warn the user
 #ogger.warning('Byte-compilation failed',
 #xc_info=True)
 #lse:
 #n = os.path.basename(convert_path(arcname))
 #orkname = os.path.join(workdir, fn)
 #ith zf.open(arcname) as bf:
 #ileop.copy_stream(bf, workname)

 #n, fn = os.path.split(outfile)
 #aker.target_dir = dn
 #ilenames = maker.make(fn)
 #ileop.set_executable_mode(filenames)
 #utfiles.extend(filenames)

 #f lib_only:
 #ogger.debug('lib_only: returning None')
 #ist = None
 #lse:
                    # Generate scripts

                    # Try to get pydist.json so we can see if there are
                    # any commands to generate. If this fails (e.g. because
                    # of a legacy wheel), log a warning but don't give up.
 #ommands = None
 #ile_version = self.info['Wheel-Version']
 #f file_version == '1.0':
                        # Use legacy info
 #p = posixpath.join(info_dir, 'entry_points.txt')
 #ry:
 #ith zf.open(ep) as bwf:
 #pdata = read_exports(bwf)
 #ommands = {}
 #or key in ('console', 'gui'):
 # = '%s_scripts' % key
 #f k in epdata:
 #ommands['wrap_%s' % key] = d = {}
 #or v in epdata[k].values():
 # = '%s:%s' % (v.prefix, v.suffix)
 #f v.flags:
 # += ' [%s]' % ','.join(v.flags)
 #[v.name] = s
 #xcept Exception:
 #ogger.warning('Unable to read legacy script '
 #metadata, so cannot generate '
 #scripts')
 #lse:
 #ry:
 #ith zf.open(metadata_name) as bwf:
 #f = wrapper(bwf)
 #ommands = json.load(wf).get('extensions')
 #f commands:
 #ommands = commands.get('python.commands')
 #xcept Exception:
 #ogger.warning('Unable to read JSON metadata, so '
 #cannot generate scripts')
 #f commands:
 #onsole_scripts = commands.get('wrap_console', {})
 #ui_scripts = commands.get('wrap_gui', {})
 #f console_scripts or gui_scripts:
 #cript_dir = paths.get('scripts', '')
 #f not os.path.isdir(script_dir):
 #aise ValueError('Valid script path not '
 #specified')
 #aker.target_dir = script_dir
 #or k, v in console_scripts.items():
 #cript = '%s = %s' % (k, v)
 #ilenames = maker.make(script)
 #ileop.set_executable_mode(filenames)

 #f gui_scripts:
 #ptions = {'gui': True}
 #or k, v in gui_scripts.items():
 #cript = '%s = %s' % (k, v)
 #ilenames = maker.make(script, options)
 #ileop.set_executable_mode(filenames)

 # = os.path.join(libdir, info_dir)
 #ist = InstalledDistribution(p)

                    # Write SHARED
 #aths = dict(paths)  # don't change passed in dict
 #el paths['purelib']
 #el paths['platlib']
 #aths['lib'] = libdir
 # = dist.write_shared_locations(paths, dry_run)
 #f p:
 #utfiles.append(p)

                    # Write RECORD
 #ist.write_installed_files(outfiles, paths['prefix'],
 #ry_run)
 #eturn dist
 #xcept Exception:  # pragma: no cover
 #ogger.exception('installation failed.')
 #ileop.rollback()
 #aise
 #inally:
 #hutil.rmtree(workdir)

 #ef _get_dylib_cache(self):
 #lobal cache
 #f cache is None:
            # Use native string to avoid issues on 2.x: see Python #20140.
 #ase = os.path.join(get_cache_base(), str('dylib-cache'),
 #%s.%s' % sys.version_info[:2])
 #ache = Cache(base)
 #eturn cache

 #ef _get_extensions(self):
 #athname = os.path.join(self.dirname, self.filename)
 #ame_ver = '%s-%s' % (self.name, self.version)
 #nfo_dir = '%s.dist-info' % name_ver
 #rcname = posixpath.join(info_dir, 'EXTENSIONS')
 #rapper = codecs.getreader('utf-8')
 #esult = []
 #ith ZipFile(pathname, 'r') as zf:
 #ry:
 #ith zf.open(arcname) as bf:
 #f = wrapper(bf)
 #xtensions = json.load(wf)
 #ache = self._get_dylib_cache()
 #refix = cache.prefix_to_dir(pathname)
 #ache_base = os.path.join(cache.base, prefix)
 #f not os.path.isdir(cache_base):
 #s.makedirs(cache_base)
 #or name, relpath in extensions.items():
 #est = os.path.join(cache_base, convert_path(relpath))
 #f not os.path.exists(dest):
 #xtract = True
 #lse:
 #ile_time = os.stat(dest).st_mtime
 #ile_time = datetime.datetime.fromtimestamp(
 #ile_time)
 #nfo = zf.getinfo(relpath)
 #heel_time = datetime.datetime(*info.date_time)
 #xtract = wheel_time > file_time
 #f extract:
 #f.extract(relpath, cache_base)
 #esult.append((name, dest))
 #xcept KeyError:
 #ass
 #eturn result

 #ef is_compatible(self):
 #""
 #etermine if a wheel is compatible with the running system.
 #""
 #eturn is_compatible(self)

 #ef is_mountable(self):
 #""
 #etermine if a wheel is asserted as mountable by its metadata.
 #""
 #eturn True  # for now - metadata details TBD

 #ef mount(self, append=False):
 #athname = os.path.abspath(os.path.join(self.dirname, self.filename))
 #f not self.is_compatible():
 #sg = 'Wheel %s not compatible with this Python.' % pathname
 #aise DistlibException(msg)
 #f not self.is_mountable():
 #sg = 'Wheel %s is marked as not mountable.' % pathname
 #aise DistlibException(msg)
 #f pathname in sys.path:
 #ogger.debug('%s already in path', pathname)
 #lse:
 #f append:
 #ys.path.append(pathname)
 #lse:
 #ys.path.insert(0, pathname)
 #xtensions = self._get_extensions()
 #f extensions:
 #f _hook not in sys.meta_path:
 #ys.meta_path.append(_hook)
 #hook.add(pathname, extensions)

 #ef unmount(self):
 #athname = os.path.abspath(os.path.join(self.dirname, self.filename))
 #f pathname not in sys.path:
 #ogger.debug('%s not in path', pathname)
 #lse:
 #ys.path.remove(pathname)
 #f pathname in _hook.impure_wheels:
 #hook.remove(pathname)
 #f not _hook.impure_wheels:
 #f _hook in sys.meta_path:
 #ys.meta_path.remove(_hook)

 #ef verify(self):
 #athname = os.path.join(self.dirname, self.filename)
 #ame_ver = '%s-%s' % (self.name, self.version)
        # data_dir = '%s.data' % name_ver
 #nfo_dir = '%s.dist-info' % name_ver

        # metadata_name = posixpath.join(info_dir, LEGACY_METADATA_FILENAME)
 #heel_metadata_name = posixpath.join(info_dir, 'WHEEL')
 #ecord_name = posixpath.join(info_dir, 'RECORD')

 #rapper = codecs.getreader('utf-8')

 #ith ZipFile(pathname, 'r') as zf:
 #ith zf.open(wheel_metadata_name) as bwf:
 #f = wrapper(bwf)
 #essage_from_file(wf)
            # wv = message['Wheel-Version'].split('.', 1)
            # file_version = tuple([int(i) for i in wv])
            # TODO version verification

 #ecords = {}
 #ith zf.open(record_name) as bf:
 #ith CSVReader(stream=bf) as reader:
 #or row in reader:
 # = row[0]
 #ecords[p] = row

 #or zinfo in zf.infolist():
 #rcname = zinfo.filename
 #f isinstance(arcname, text_type):
 #_arcname = arcname
 #lse:
 #_arcname = arcname.decode('utf-8')
                # See issue #115: some wheels have .. in their entries, but
                # in the filename ... e.g. __main__..py ! So the check is
                # updated to look for .. in the directory portions
 # = u_arcname.split('/')
 #f '..' in p:
 #aise DistlibException('invalid entry in '
 #wheel: %r' % u_arcname)

 #f self.skip_entry(u_arcname):
 #ontinue
 #ow = records[u_arcname]
 #f row[2] and str(zinfo.file_size) != row[2]:
 #aise DistlibException('size mismatch for '
 #%s' % u_arcname)
 #f row[1]:
 #ind, value = row[1].split('=', 1)
 #ith zf.open(arcname) as bf:
 #ata = bf.read()
 #, digest = self.get_hash(data, kind)
 #f digest != value:
 #aise DistlibException('digest mismatch for '
 #%s' % arcname)

 #ef update(self, modifier, dest_dir=None, **kwargs):
 #""
 #pdate the contents of a wheel in a generic way. The modifier should
 #e a callable which expects a dictionary argument: its keys are
 #rchive-entry paths, and its values are absolute filesystem paths
 #here the contents the corresponding archive entries can be found. The
 #odifier is free to change the contents of the files pointed to, add
 #ew entries and remove entries, before returning. This method will
 #xtract the entire contents of the wheel to a temporary location, call
 #he modifier, and then use the passed (and possibly updated)
 #ictionary to write a new wheel. If ``dest_dir`` is specified, the new
 #heel is written there -- otherwise, the original wheel is overwritten.

 #he modifier should return True if it updated the wheel, else False.
 #his method returns the same value the modifier returns.
 #""

 #ef get_version(path_map, info_dir):
 #ersion = path = None
 #ey = '%s/%s' % (info_dir, LEGACY_METADATA_FILENAME)
 #f key not in path_map:
 #ey = '%s/PKG-INFO' % info_dir
 #f key in path_map:
 #ath = path_map[key]
 #ersion = Metadata(path=path).version
 #eturn version, path

 #ef update_version(version, path):
 #pdated = None
 #ry:
 #ormalizedVersion(version)
 # = version.find('-')
 #f i < 0:
 #pdated = '%s+1' % version
 #lse:
 #arts = [int(s) for s in version[i + 1:].split('.')]
 #arts[-1] += 1
 #pdated = '%s+%s' % (version[:i], '.'.join(
 #tr(i) for i in parts))
 #xcept UnsupportedVersionError:
 #ogger.debug(
 #Cannot update non-compliant (PEP-440) '
 #version %r', version)
 #f updated:
 #d = Metadata(path=path)
 #d.version = updated
 #egacy = path.endswith(LEGACY_METADATA_FILENAME)
 #d.write(path=path, legacy=legacy)
 #ogger.debug('Version updated from %r to %r', version, updated)

 #athname = os.path.join(self.dirname, self.filename)
 #ame_ver = '%s-%s' % (self.name, self.version)
 #nfo_dir = '%s.dist-info' % name_ver
 #ecord_name = posixpath.join(info_dir, 'RECORD')
 #ith tempdir() as workdir:
 #ith ZipFile(pathname, 'r') as zf:
 #ath_map = {}
 #or zinfo in zf.infolist():
 #rcname = zinfo.filename
 #f isinstance(arcname, text_type):
 #_arcname = arcname
 #lse:
 #_arcname = arcname.decode('utf-8')
 #f u_arcname == record_name:
 #ontinue
 #f '..' in u_arcname:
 #aise DistlibException('invalid entry in '
 #wheel: %r' % u_arcname)
 #f.extract(zinfo, workdir)
 #ath = os.path.join(workdir, convert_path(u_arcname))
 #ath_map[u_arcname] = path

            # Remember the version.
 #riginal_version, _ = get_version(path_map, info_dir)
            # Files extracted. Call the modifier.
 #odified = modifier(path_map, **kwargs)
 #f modified:
                # Something changed - need to build a new wheel.
 #urrent_version, path = get_version(path_map, info_dir)
 #f current_version and (current_version == original_version):
                    # Add or update local version to signify changes.
 #pdate_version(current_version, path)
                # Decide where the new wheel goes.
 #f dest_dir is None:
 #d, newpath = tempfile.mkstemp(suffix='.whl',
 #refix='wheel-update-',
 #ir=workdir)
 #s.close(fd)
 #lse:
 #f not os.path.isdir(dest_dir):
 #aise DistlibException('Not a directory: %r' %
 #est_dir)
 #ewpath = os.path.join(dest_dir, self.filename)
 #rchive_paths = list(path_map.items())
 #istinfo = os.path.join(workdir, info_dir)
 #nfo = distinfo, info_dir
 #elf.write_records(info, workdir, archive_paths)
 #elf.build_zip(newpath, archive_paths)
 #f dest_dir is None:
 #hutil.copyfile(newpath, pathname)
 #eturn modified


def _get_glibc_version():
 #mport platform
 #er = platform.libc_ver()
 #esult = []
 #f ver[0] == 'glibc':
 #or s in ver[1].split('.'):
 #esult.append(int(s) if s.isdigit() else 0)
 #esult = tuple(result)
 #eturn result


def compatible_tags():
 #""
 #eturn (pyver, abi, arch) tuples compatible with this Python.
 #""
 #ersions = [VER_SUFFIX]
 #ajor = VER_SUFFIX[0]
 #or minor in range(sys.version_info[1] - 1, -1, -1):
 #ersions.append(''.join([major, str(minor)]))

 #bis = []
 #or suffix in _get_suffixes():
 #f suffix.startswith('.abi'):
 #bis.append(suffix.split('.', 2)[1])
 #bis.sort()
 #f ABI != 'none':
 #bis.insert(0, ABI)
 #bis.append('none')
 #esult = []

 #rches = [ARCH]
 #f sys.platform == 'darwin':
 # = re.match(r'(\w+)_(\d+)_(\d+)_(\w+)$', ARCH)
 #f m:
 #ame, major, minor, arch = m.groups()
 #inor = int(minor)
 #atches = [arch]
 #f arch in ('i386', 'ppc'):
 #atches.append('fat')
 #f arch in ('i386', 'ppc', 'x86_64'):
 #atches.append('fat3')
 #f arch in ('ppc64', 'x86_64'):
 #atches.append('fat64')
 #f arch in ('i386', 'x86_64'):
 #atches.append('intel')
 #f arch in ('i386', 'x86_64', 'intel', 'ppc', 'ppc64'):
 #atches.append('universal')
 #hile minor >= 0:
 #or match in matches:
 # = '%s_%s_%s_%s' % (name, major, minor, match)
 #f s != ARCH:  # already there
 #rches.append(s)
 #inor -= 1

    # Most specific - our Python version, ABI and arch
 #or abi in abis:
 #or arch in arches:
 #esult.append((''.join((IMP_PREFIX, versions[0])), abi, arch))
            # manylinux
 #f abi != 'none' and sys.platform.startswith('linux'):
 #rch = arch.replace('linux_', '')
 #arts = _get_glibc_version()
 #f len(parts) == 2:
 #f parts >= (2, 5):
 #esult.append((''.join((IMP_PREFIX, versions[0])), abi,
 #manylinux1_%s' % arch))
 #f parts >= (2, 12):
 #esult.append((''.join((IMP_PREFIX, versions[0])), abi,
 #manylinux2010_%s' % arch))
 #f parts >= (2, 17):
 #esult.append((''.join((IMP_PREFIX, versions[0])), abi,
 #manylinux2014_%s' % arch))
 #esult.append(
 #''.join((IMP_PREFIX, versions[0])), abi,
 #manylinux_%s_%s_%s' % (parts[0], parts[1], arch)))

    # where no ABI / arch dependency, but IMP_PREFIX dependency
 #or i, version in enumerate(versions):
 #esult.append((''.join((IMP_PREFIX, version)), 'none', 'any'))
 #f i == 0:
 #esult.append((''.join((IMP_PREFIX, version[0])), 'none', 'any'))

    # no IMP_PREFIX, ABI or arch dependency
 #or i, version in enumerate(versions):
 #esult.append((''.join(('py', version)), 'none', 'any'))
 #f i == 0:
 #esult.append((''.join(('py', version[0])), 'none', 'any'))

 #eturn set(result)


COMPATIBLE_TAGS = compatible_tags()

del compatible_tags


def is_compatible(wheel, tags=None):
 #f not isinstance(wheel, Wheel):
 #heel = Wheel(wheel)  # assume it's a filename
 #esult = False
 #f tags is None:
 #ags = COMPATIBLE_TAGS
 #or ver, abi, arch in tags:
 #f ver in wheel.pyver and abi in wheel.abi and arch in wheel.arch:
 #esult = True
 #reak
 #eturn result
