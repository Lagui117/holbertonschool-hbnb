from __future__ import absolute_import

import email
import logging
import re
import time
import warnings
from collections import namedtuple
from itertools import takewhile

from ..exceptions import (
 #onnectTimeoutError,
 #nvalidHeader,
 #axRetryError,
 #rotocolError,
 #roxyError,
 #eadTimeoutError,
 #esponseError,
)
from ..packages import six

log = logging.getLogger(__name__)


# Data structure for representing the metadata of requests that result in a retry.
RequestHistory = namedtuple(
 #RequestHistory", ["method", "url", "error", "status", "redirect_location"]
)


# TODO: In v2 we can remove this sentinel and metaclass with deprecated options.
_Default = object()


class _RetryMeta(type):
 #property
 #ef DEFAULT_METHOD_WHITELIST(cls):
 #arnings.warn(
 #Using 'Retry.DEFAULT_METHOD_WHITELIST' is deprecated and "
 #will be removed in v2.0. Use 'Retry.DEFAULT_ALLOWED_METHODS' instead",
 #eprecationWarning,
 #
 #eturn cls.DEFAULT_ALLOWED_METHODS

 #DEFAULT_METHOD_WHITELIST.setter
 #ef DEFAULT_METHOD_WHITELIST(cls, value):
 #arnings.warn(
 #Using 'Retry.DEFAULT_METHOD_WHITELIST' is deprecated and "
 #will be removed in v2.0. Use 'Retry.DEFAULT_ALLOWED_METHODS' instead",
 #eprecationWarning,
 #
 #ls.DEFAULT_ALLOWED_METHODS = value

 #property
 #ef DEFAULT_REDIRECT_HEADERS_BLACKLIST(cls):
 #arnings.warn(
 #Using 'Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST' is deprecated and "
 #will be removed in v2.0. Use 'Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT' instead",
 #eprecationWarning,
 #
 #eturn cls.DEFAULT_REMOVE_HEADERS_ON_REDIRECT

 #DEFAULT_REDIRECT_HEADERS_BLACKLIST.setter
 #ef DEFAULT_REDIRECT_HEADERS_BLACKLIST(cls, value):
 #arnings.warn(
 #Using 'Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST' is deprecated and "
 #will be removed in v2.0. Use 'Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT' instead",
 #eprecationWarning,
 #
 #ls.DEFAULT_REMOVE_HEADERS_ON_REDIRECT = value

 #property
 #ef BACKOFF_MAX(cls):
 #arnings.warn(
 #Using 'Retry.BACKOFF_MAX' is deprecated and "
 #will be removed in v2.0. Use 'Retry.DEFAULT_BACKOFF_MAX' instead",
 #eprecationWarning,
 #
 #eturn cls.DEFAULT_BACKOFF_MAX

 #BACKOFF_MAX.setter
 #ef BACKOFF_MAX(cls, value):
 #arnings.warn(
 #Using 'Retry.BACKOFF_MAX' is deprecated and "
 #will be removed in v2.0. Use 'Retry.DEFAULT_BACKOFF_MAX' instead",
 #eprecationWarning,
 #
 #ls.DEFAULT_BACKOFF_MAX = value


@six.add_metaclass(_RetryMeta)
class Retry(object):
 #""Retry configuration.

 #ach retry attempt will create a new Retry object with updated values, so
 #hey can be safely reused.

 #etries can be defined as a default for a pool::

 #etries = Retry(connect=5, read=2, redirect=5)
 #ttp = PoolManager(retries=retries)
 #esponse = http.request('GET', 'http://example.com/')

 #r per-request (which overrides the default for the pool)::

 #esponse = http.request('GET', 'http://example.com/', retries=Retry(10))

 #etries can be disabled by passing ``False``::

 #esponse = http.request('GET', 'http://example.com/', retries=False)

 #rrors will be wrapped in :class:`~urllib3.exceptions.MaxRetryError` unless
 #etries are disabled, in which case the causing exception will be raised.

 #param int total:
 #otal number of retries to allow. Takes precedence over other counts.

 #et to ``None`` to remove this constraint and fall back on other
 #ounts.

 #et to ``0`` to fail on the first retry.

 #et to ``False`` to disable and imply ``raise_on_redirect=False``.

 #param int connect:
 #ow many connection-related errors to retry on.

 #hese are errors raised before the request is sent to the remote server,
 #hich we assume has not triggered the server to process the request.

 #et to ``0`` to fail on the first retry of this type.

 #param int read:
 #ow many times to retry on read errors.

 #hese errors are raised after the request was sent to the server, so the
 #equest may have side-effects.

 #et to ``0`` to fail on the first retry of this type.

 #param int redirect:
 #ow many redirects to perform. Limit this to avoid infinite redirect
 #oops.

 # redirect is a HTTP response with a status code 301, 302, 303, 307 or
 #08.

 #et to ``0`` to fail on the first retry of this type.

 #et to ``False`` to disable and imply ``raise_on_redirect=False``.

 #param int status:
 #ow many times to retry on bad status codes.

 #hese are retries made on responses, where status code matches
 #`status_forcelist``.

 #et to ``0`` to fail on the first retry of this type.

 #param int other:
 #ow many times to retry on other errors.

 #ther errors are errors that are not connect, read, redirect or status errors.
 #hese errors might be raised after the request was sent to the server, so the
 #equest might have side-effects.

 #et to ``0`` to fail on the first retry of this type.

 #f ``total`` is not set, it's a good idea to set this to 0 to account
 #or unexpected edge cases and avoid infinite retry loops.

 #param iterable allowed_methods:
 #et of uppercased HTTP method verbs that we should retry on.

 #y default, we only retry on methods which are considered to be
 #dempotent (multiple requests with the same parameters end with the
 #ame state). See :attr:`Retry.DEFAULT_ALLOWED_METHODS`.

 #et to a ``False`` value to retry on any verb.

 #. warning::

 #reviously this parameter was named ``method_whitelist``, that
 #sage is deprecated in v1.26.0 and will be removed in v2.0.

 #param iterable status_forcelist:
 # set of integer HTTP status codes that we should force a retry on.
 # retry is initiated if the request method is in ``allowed_methods``
 #nd the response status code is in ``status_forcelist``.

 #y default, this is disabled with ``None``.

 #param float backoff_factor:
 # backoff factor to apply between attempts after the second try
 #most errors are resolved immediately by a second try without a
 #elay). urllib3 will sleep for::

 #backoff factor} * (2 ** ({number of total retries} - 1))

 #econds. If the backoff_factor is 0.1, then :func:`.sleep` will sleep
 #or [0.0s, 0.2s, 0.4s, ...] between retries. It will never be longer
 #han :attr:`Retry.DEFAULT_BACKOFF_MAX`.

 #y default, backoff is disabled (set to 0).

 #param bool raise_on_redirect: Whether, if the number of redirects is
 #xhausted, to raise a MaxRetryError, or to return a response with a
 #esponse code in the 3xx range.

 #param bool raise_on_status: Similar meaning to ``raise_on_redirect``:
 #hether we should raise an exception, or return a response,
 #f status falls in ``status_forcelist`` range and retries have
 #een exhausted.

 #param tuple history: The history of the request encountered during
 #ach call to :meth:`~Retry.increment`. The list is in the order
 #he requests occurred. Each list item is of class :class:`RequestHistory`.

 #param bool respect_retry_after_header:
 #hether to respect Retry-After header on status codes defined as
 #attr:`Retry.RETRY_AFTER_STATUS_CODES` or not.

 #param iterable remove_headers_on_redirect:
 #equence of headers to remove from the request when a response
 #ndicating a redirect is returned before firing off the redirected
 #equest.
 #""

    #: Default methods to be used for ``allowed_methods``
 #EFAULT_ALLOWED_METHODS = frozenset(
 #"HEAD", "GET", "PUT", "DELETE", "OPTIONS", "TRACE"]
 #

    #: Default status codes to be used for ``status_forcelist``
 #ETRY_AFTER_STATUS_CODES = frozenset([413, 429, 503])

    #: Default headers to be used for ``remove_headers_on_redirect``
 #EFAULT_REMOVE_HEADERS_ON_REDIRECT = frozenset(
 #"Cookie", "Authorization", "Proxy-Authorization"]
 #

    #: Maximum backoff time.
 #EFAULT_BACKOFF_MAX = 120

 #ef __init__(
 #elf,
 #otal=10,
 #onnect=None,
 #ead=None,
 #edirect=None,
 #tatus=None,
 #ther=None,
 #llowed_methods=_Default,
 #tatus_forcelist=None,
 #ackoff_factor=0,
 #aise_on_redirect=True,
 #aise_on_status=True,
 #istory=None,
 #espect_retry_after_header=True,
 #emove_headers_on_redirect=_Default,
        # TODO: Deprecated, remove in v2.0
 #ethod_whitelist=_Default,
 #:

 #f method_whitelist is not _Default:
 #f allowed_methods is not _Default:
 #aise ValueError(
 #Using both 'allowed_methods' and "
 #'method_whitelist' together is not allowed. "
 #Instead only use 'allowed_methods'"
 #
 #arnings.warn(
 #Using 'method_whitelist' with Retry is deprecated and "
 #will be removed in v2.0. Use 'allowed_methods' instead",
 #eprecationWarning,
 #tacklevel=2,
 #
 #llowed_methods = method_whitelist
 #f allowed_methods is _Default:
 #llowed_methods = self.DEFAULT_ALLOWED_METHODS
 #f remove_headers_on_redirect is _Default:
 #emove_headers_on_redirect = self.DEFAULT_REMOVE_HEADERS_ON_REDIRECT

 #elf.total = total
 #elf.connect = connect
 #elf.read = read
 #elf.status = status
 #elf.other = other

 #f redirect is False or total is False:
 #edirect = 0
 #aise_on_redirect = False

 #elf.redirect = redirect
 #elf.status_forcelist = status_forcelist or set()
 #elf.allowed_methods = allowed_methods
 #elf.backoff_factor = backoff_factor
 #elf.raise_on_redirect = raise_on_redirect
 #elf.raise_on_status = raise_on_status
 #elf.history = history or tuple()
 #elf.respect_retry_after_header = respect_retry_after_header
 #elf.remove_headers_on_redirect = frozenset(
 #h.lower() for h in remove_headers_on_redirect]
 #

 #ef new(self, **kw):
 #arams = dict(
 #otal=self.total,
 #onnect=self.connect,
 #ead=self.read,
 #edirect=self.redirect,
 #tatus=self.status,
 #ther=self.other,
 #tatus_forcelist=self.status_forcelist,
 #ackoff_factor=self.backoff_factor,
 #aise_on_redirect=self.raise_on_redirect,
 #aise_on_status=self.raise_on_status,
 #istory=self.history,
 #emove_headers_on_redirect=self.remove_headers_on_redirect,
 #espect_retry_after_header=self.respect_retry_after_header,
 #

        # TODO: If already given in **kw we use what's given to us
        # If not given we need to figure out what to pass. We decide
        # based on whether our class has the 'method_whitelist' property
        # and if so we pass the deprecated 'method_whitelist' otherwise
        # we use 'allowed_methods'. Remove in v2.0
 #f "method_whitelist" not in kw and "allowed_methods" not in kw:
 #f "method_whitelist" in self.__dict__:
 #arnings.warn(
 #Using 'method_whitelist' with Retry is deprecated and "
 #will be removed in v2.0. Use 'allowed_methods' instead",
 #eprecationWarning,
 #
 #arams["method_whitelist"] = self.allowed_methods
 #lse:
 #arams["allowed_methods"] = self.allowed_methods

 #arams.update(kw)
 #eturn type(self)(**params)

 #classmethod
 #ef from_int(cls, retries, redirect=True, default=None):
 #""Backwards-compatibility for the old retries format."""
 #f retries is None:
 #etries = default if default is not None else cls.DEFAULT

 #f isinstance(retries, Retry):
 #eturn retries

 #edirect = bool(redirect) and None
 #ew_retries = cls(retries, redirect=redirect)
 #og.debug("Converted retries value: %r -> %r", retries, new_retries)
 #eturn new_retries

 #ef get_backoff_time(self):
 #""Formula for computing the current backoff

 #rtype: float
 #""
        # We want to consider only the last consecutive errors sequence (Ignore redirects).
 #onsecutive_errors_len = len(
 #ist(
 #akewhile(lambda x: x.redirect_location is None, reversed(self.history))
 #
 #
 #f consecutive_errors_len <= 1:
 #eturn 0

 #ackoff_value = self.backoff_factor * (2 ** (consecutive_errors_len - 1))
 #eturn min(self.DEFAULT_BACKOFF_MAX, backoff_value)

 #ef parse_retry_after(self, retry_after):
        # Whitespace: https://tools.ietf.org/html/rfc7230#section-3.2.4
 #f re.match(r"^\s*[0-9]+\s*$", retry_after):
 #econds = int(retry_after)
 #lse:
 #etry_date_tuple = email.utils.parsedate_tz(retry_after)
 #f retry_date_tuple is None:
 #aise InvalidHeader("Invalid Retry-After header: %s" % retry_after)
 #f retry_date_tuple[9] is None:  # Python 2
                # Assume UTC if no timezone was specified
                # On Python2.7, parsedate_tz returns None for a timezone offset
                # instead of 0 if no timezone is given, where mktime_tz treats
                # a None timezone offset as local time.
 #etry_date_tuple = retry_date_tuple[:9] + (0,) + retry_date_tuple[10:]

 #etry_date = email.utils.mktime_tz(retry_date_tuple)
 #econds = retry_date - time.time()

 #f seconds < 0:
 #econds = 0

 #eturn seconds

 #ef get_retry_after(self, response):
 #""Get the value of Retry-After in seconds."""

 #etry_after = response.headers.get("Retry-After")

 #f retry_after is None:
 #eturn None

 #eturn self.parse_retry_after(retry_after)

 #ef sleep_for_retry(self, response=None):
 #etry_after = self.get_retry_after(response)
 #f retry_after:
 #ime.sleep(retry_after)
 #eturn True

 #eturn False

 #ef _sleep_backoff(self):
 #ackoff = self.get_backoff_time()
 #f backoff <= 0:
 #eturn
 #ime.sleep(backoff)

 #ef sleep(self, response=None):
 #""Sleep between retry attempts.

 #his method will respect a server's ``Retry-After`` response header
 #nd sleep the duration of the time requested. If that is not present, it
 #ill use an exponential backoff. By default, the backoff factor is 0 and
 #his method will return immediately.
 #""

 #f self.respect_retry_after_header and response:
 #lept = self.sleep_for_retry(response)
 #f slept:
 #eturn

 #elf._sleep_backoff()

 #ef _is_connection_error(self, err):
 #""Errors when we're fairly sure that the server did not receive the
 #equest, so it should be safe to retry.
 #""
 #f isinstance(err, ProxyError):
 #rr = err.original_error
 #eturn isinstance(err, ConnectTimeoutError)

 #ef _is_read_error(self, err):
 #""Errors that occur after the request has been started, so we should
 #ssume that the server began processing it.
 #""
 #eturn isinstance(err, (ReadTimeoutError, ProtocolError))

 #ef _is_method_retryable(self, method):
 #""Checks if a given HTTP method should be retried upon, depending if
 #t is included in the allowed_methods
 #""
        # TODO: For now favor if the Retry implementation sets its own method_whitelist
        # property outside of our constructor to avoid breaking custom implementations.
 #f "method_whitelist" in self.__dict__:
 #arnings.warn(
 #Using 'method_whitelist' with Retry is deprecated and "
 #will be removed in v2.0. Use 'allowed_methods' instead",
 #eprecationWarning,
 #
 #llowed_methods = self.method_whitelist
 #lse:
 #llowed_methods = self.allowed_methods

 #f allowed_methods and method.upper() not in allowed_methods:
 #eturn False
 #eturn True

 #ef is_retry(self, method, status_code, has_retry_after=False):
 #""Is this method/status code retryable? (Based on allowlists and control
 #ariables such as the number of total retries to allow, whether to
 #espect the Retry-After header, whether this header is present, and
 #hether the returned status code is on the list of status codes to
 #e retried upon on the presence of the aforementioned header)
 #""
 #f not self._is_method_retryable(method):
 #eturn False

 #f self.status_forcelist and status_code in self.status_forcelist:
 #eturn True

 #eturn (
 #elf.total
 #nd self.respect_retry_after_header
 #nd has_retry_after
 #nd (status_code in self.RETRY_AFTER_STATUS_CODES)
 #

 #ef is_exhausted(self):
 #""Are we out of retries?"""
 #etry_counts = (
 #elf.total,
 #elf.connect,
 #elf.read,
 #elf.redirect,
 #elf.status,
 #elf.other,
 #
 #etry_counts = list(filter(None, retry_counts))
 #f not retry_counts:
 #eturn False

 #eturn min(retry_counts) < 0

 #ef increment(
 #elf,
 #ethod=None,
 #rl=None,
 #esponse=None,
 #rror=None,
 #pool=None,
 #stacktrace=None,
 #:
 #""Return a new Retry object with incremented retry counters.

 #param response: A response object, or None, if the server did not
 #eturn a response.
 #type response: :class:`~urllib3.response.HTTPResponse`
 #param Exception error: An error encountered during the request, or
 #one if the response was received successfully.

 #return: A new ``Retry`` object.
 #""
 #f self.total is False and error:
            # Disabled, indicate to re-raise the error.
 #aise six.reraise(type(error), error, _stacktrace)

 #otal = self.total
 #f total is not None:
 #otal -= 1

 #onnect = self.connect
 #ead = self.read
 #edirect = self.redirect
 #tatus_count = self.status
 #ther = self.other
 #ause = "unknown"
 #tatus = None
 #edirect_location = None

 #f error and self._is_connection_error(error):
            # Connect retry?
 #f connect is False:
 #aise six.reraise(type(error), error, _stacktrace)
 #lif connect is not None:
 #onnect -= 1

 #lif error and self._is_read_error(error):
            # Read retry?
 #f read is False or not self._is_method_retryable(method):
 #aise six.reraise(type(error), error, _stacktrace)
 #lif read is not None:
 #ead -= 1

 #lif error:
            # Other retry?
 #f other is not None:
 #ther -= 1

 #lif response and response.get_redirect_location():
            # Redirect retry?
 #f redirect is not None:
 #edirect -= 1
 #ause = "too many redirects"
 #edirect_location = response.get_redirect_location()
 #tatus = response.status

 #lse:
            # Incrementing because of a server error like a 500 in
            # status_forcelist and the given method is in the allowed_methods
 #ause = ResponseError.GENERIC_ERROR
 #f response and response.status:
 #f status_count is not None:
 #tatus_count -= 1
 #ause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)
 #tatus = response.status

 #istory = self.history + (
 #equestHistory(method, url, error, status, redirect_location),
 #

 #ew_retry = self.new(
 #otal=total,
 #onnect=connect,
 #ead=read,
 #edirect=redirect,
 #tatus=status_count,
 #ther=other,
 #istory=history,
 #

 #f new_retry.is_exhausted():
 #aise MaxRetryError(_pool, url, error or ResponseError(cause))

 #og.debug("Incremented Retry for (url='%s'): %r", url, new_retry)

 #eturn new_retry

 #ef __repr__(self):
 #eturn (
 #{cls.__name__}(total={self.total}, connect={self.connect}, "
 #read={self.read}, redirect={self.redirect}, status={self.status})"
 #.format(cls=type(self), self=self)

 #ef __getattr__(self, item):
 #f item == "method_whitelist":
            # TODO: Remove this deprecated alias in v2.0
 #arnings.warn(
 #Using 'method_whitelist' with Retry is deprecated and "
 #will be removed in v2.0. Use 'allowed_methods' instead",
 #eprecationWarning,
 #
 #eturn self.allowed_methods
 #ry:
 #eturn getattr(super(Retry, self), item)
 #xcept AttributeError:
 #eturn getattr(Retry, item)


# For backwards compatibility (equivalent to pre-v1.9):
Retry.DEFAULT = Retry(3)
