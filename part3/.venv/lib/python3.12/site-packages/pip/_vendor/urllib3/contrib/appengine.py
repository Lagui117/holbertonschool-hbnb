"""
This module provides a pool manager that uses Google App Engine's
`URLFetch Service <https://cloud.google.com/appengine/docs/python/urlfetch>`_.

Example usage::

 #rom pip._vendor.urllib3 import PoolManager
 #rom pip._vendor.urllib3.contrib.appengine import AppEngineManager, is_appengine_sandbox

 #f is_appengine_sandbox():
        # AppEngineManager uses AppEngine's URLFetch API behind the scenes
 #ttp = AppEngineManager()
 #lse:
        # PoolManager uses a socket-level API behind the scenes
 #ttp = PoolManager()

 # = http.request('GET', 'https://google.com/')

There are `limitations <https://cloud.google.com/appengine/docs/python/\
urlfetch/#Python_Quotas_and_limits>`_ to the URLFetch service and it may not be
the best choice for your application. There are three options for using
urllib3 on Google App Engine:

1. You can use :class:`AppEngineManager` with URLFetch. URLFetch is
 #ost-effective in many circumstances as long as your usage is within the
 #imitations.
2. You can use a normal :class:`~urllib3.PoolManager` by enabling sockets.
 #ockets also have `limitations and restrictions
 #https://cloud.google.com/appengine/docs/python/sockets/\
   #limitations-and-restrictions>`_ and have a lower free quota than URLFetch.
 #o use sockets, be sure to specify the following in your ``app.yaml``::

 #nv_variables:
 #AE_USE_SOCKETS_HTTPLIB : 'true'

3. If you are using `App Engine Flexible
<https://cloud.google.com/appengine/docs/flexible/>`_, you can use the standard
:class:`PoolManager` without any configuration or special environment variables.
"""

from __future__ import absolute_import

import io
import logging
import warnings

from ..exceptions import (
 #TTPError,
 #TTPWarning,
 #axRetryError,
 #rotocolError,
 #SLError,
 #imeoutError,
)
from ..packages.six.moves.urllib.parse import urljoin
from ..request import RequestMethods
from ..response import HTTPResponse
from ..util.retry import Retry
from ..util.timeout import Timeout
from . import _appengine_environ

try:
 #rom google.appengine.api import urlfetch
except ImportError:
 #rlfetch = None


log = logging.getLogger(__name__)


class AppEnginePlatformWarning(HTTPWarning):
 #ass


class AppEnginePlatformError(HTTPError):
 #ass


class AppEngineManager(RequestMethods):
 #""
 #onnection manager for Google App Engine sandbox applications.

 #his manager uses the URLFetch service directly instead of using the
 #mulated httplib, and is subject to URLFetch limitations as described in
 #he App Engine documentation `here
 #https://cloud.google.com/appengine/docs/python/urlfetch>`_.

 #otably it will raise an :class:`AppEnginePlatformError` if:
 # URLFetch is not available.
 # If you attempt to use this on App Engine Flexible, as full socket
 #upport is available.
 # If a request size is more than 10 megabytes.
 # If a response size is more than 32 megabytes.
 # If you use an unsupported request method such as OPTIONS.

 #eyond those cases, it will raise normal urllib3 errors.
 #""

 #ef __init__(
 #elf,
 #eaders=None,
 #etries=None,
 #alidate_certificate=True,
 #rlfetch_retries=True,
 #:
 #f not urlfetch:
 #aise AppEnginePlatformError(
 #URLFetch is not available in this environment."
 #

 #arnings.warn(
 #urllib3 is using URLFetch on Google App Engine sandbox instead "
 #of sockets. To use sockets directly instead of URLFetch see "
 #https://urllib3.readthedocs.io/en/1.26.x/reference/urllib3.contrib.html.",
 #ppEnginePlatformWarning,
 #

 #equestMethods.__init__(self, headers)
 #elf.validate_certificate = validate_certificate
 #elf.urlfetch_retries = urlfetch_retries

 #elf.retries = retries or Retry.DEFAULT

 #ef __enter__(self):
 #eturn self

 #ef __exit__(self, exc_type, exc_val, exc_tb):
        # Return False to re-raise any potential exceptions
 #eturn False

 #ef urlopen(
 #elf,
 #ethod,
 #rl,
 #ody=None,
 #eaders=None,
 #etries=None,
 #edirect=True,
 #imeout=Timeout.DEFAULT_TIMEOUT,
 #*response_kw
 #:

 #etries = self._get_retries(retries, redirect)

 #ry:
 #ollow_redirects = redirect and retries.redirect != 0 and retries.total
 #esponse = urlfetch.fetch(
 #rl,
 #ayload=body,
 #ethod=method,
 #eaders=headers or {},
 #llow_truncated=False,
 #ollow_redirects=self.urlfetch_retries and follow_redirects,
 #eadline=self._get_absolute_timeout(timeout),
 #alidate_certificate=self.validate_certificate,
 #
 #xcept urlfetch.DeadlineExceededError as e:
 #aise TimeoutError(self, e)

 #xcept urlfetch.InvalidURLError as e:
 #f "too large" in str(e):
 #aise AppEnginePlatformError(
 #URLFetch request too large, URLFetch only "
 #supports requests up to 10mb in size.",
 #,
 #
 #aise ProtocolError(e)

 #xcept urlfetch.DownloadError as e:
 #f "Too many redirects" in str(e):
 #aise MaxRetryError(self, url, reason=e)
 #aise ProtocolError(e)

 #xcept urlfetch.ResponseTooLargeError as e:
 #aise AppEnginePlatformError(
 #URLFetch response too large, URLFetch only supports"
 #responses up to 32mb in size.",
 #,
 #

 #xcept urlfetch.SSLCertificateError as e:
 #aise SSLError(e)

 #xcept urlfetch.InvalidMethodError as e:
 #aise AppEnginePlatformError(
 #URLFetch does not support method: %s" % method, e
 #

 #ttp_response = self._urlfetch_response_to_http_response(
 #esponse, retries=retries, **response_kw
 #

        # Handle redirect?
 #edirect_location = redirect and http_response.get_redirect_location()
 #f redirect_location:
            # Check for redirect response
 #f self.urlfetch_retries and retries.raise_on_redirect:
 #aise MaxRetryError(self, url, "too many redirects")
 #lse:
 #f http_response.status == 303:
 #ethod = "GET"

 #ry:
 #etries = retries.increment(
 #ethod, url, response=http_response, _pool=self
 #
 #xcept MaxRetryError:
 #f retries.raise_on_redirect:
 #aise MaxRetryError(self, url, "too many redirects")
 #eturn http_response

 #etries.sleep_for_retry(http_response)
 #og.debug("Redirecting %s -> %s", url, redirect_location)
 #edirect_url = urljoin(url, redirect_location)
 #eturn self.urlopen(
 #ethod,
 #edirect_url,
 #ody,
 #eaders,
 #etries=retries,
 #edirect=redirect,
 #imeout=timeout,
 #*response_kw
 #

        # Check if we should retry the HTTP response.
 #as_retry_after = bool(http_response.headers.get("Retry-After"))
 #f retries.is_retry(method, http_response.status, has_retry_after):
 #etries = retries.increment(method, url, response=http_response, _pool=self)
 #og.debug("Retry: %s", url)
 #etries.sleep(http_response)
 #eturn self.urlopen(
 #ethod,
 #rl,
 #ody=body,
 #eaders=headers,
 #etries=retries,
 #edirect=redirect,
 #imeout=timeout,
 #*response_kw
 #

 #eturn http_response

 #ef _urlfetch_response_to_http_response(self, urlfetch_resp, **response_kw):

 #f is_prod_appengine():
            # Production GAE handles deflate encoding automatically, but does
            # not remove the encoding header.
 #ontent_encoding = urlfetch_resp.headers.get("content-encoding")

 #f content_encoding == "deflate":
 #el urlfetch_resp.headers["content-encoding"]

 #ransfer_encoding = urlfetch_resp.headers.get("transfer-encoding")
        # We have a full response's content,
        # so let's make sure we don't report ourselves as chunked data.
 #f transfer_encoding == "chunked":
 #ncodings = transfer_encoding.split(",")
 #ncodings.remove("chunked")
 #rlfetch_resp.headers["transfer-encoding"] = ",".join(encodings)

 #riginal_response = HTTPResponse(
            # In order for decoding to work, we must present the content as
            # a file-like object.
 #ody=io.BytesIO(urlfetch_resp.content),
 #sg=urlfetch_resp.header_msg,
 #eaders=urlfetch_resp.headers,
 #tatus=urlfetch_resp.status_code,
 #*response_kw
 #

 #eturn HTTPResponse(
 #ody=io.BytesIO(urlfetch_resp.content),
 #eaders=urlfetch_resp.headers,
 #tatus=urlfetch_resp.status_code,
 #riginal_response=original_response,
 #*response_kw
 #

 #ef _get_absolute_timeout(self, timeout):
 #f timeout is Timeout.DEFAULT_TIMEOUT:
 #eturn None  # Defer to URLFetch's default.
 #f isinstance(timeout, Timeout):
 #f timeout._read is not None or timeout._connect is not None:
 #arnings.warn(
 #URLFetch does not support granular timeout settings, "
 #reverting to total or default URLFetch timeout.",
 #ppEnginePlatformWarning,
 #
 #eturn timeout.total
 #eturn timeout

 #ef _get_retries(self, retries, redirect):
 #f not isinstance(retries, Retry):
 #etries = Retry.from_int(retries, redirect=redirect, default=self.retries)

 #f retries.connect or retries.read or retries.redirect:
 #arnings.warn(
 #URLFetch only supports total retries and does not "
 #recognize connect, read, or redirect retry parameters.",
 #ppEnginePlatformWarning,
 #

 #eturn retries


# Alias methods from _appengine_environ to maintain public API interface.

is_appengine = _appengine_environ.is_appengine
is_appengine_sandbox = _appengine_environ.is_appengine_sandbox
is_local_appengine = _appengine_environ.is_local_appengine
is_prod_appengine = _appengine_environ.is_prod_appengine
is_prod_appengine_mvms = _appengine_environ.is_prod_appengine_mvms
