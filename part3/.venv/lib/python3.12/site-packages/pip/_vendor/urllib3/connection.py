from __future__ import absolute_import

import datetime
import logging
import os
import re
import socket
import warnings
from socket import error as SocketError
from socket import timeout as SocketTimeout

from .packages import six
from .packages.six.moves.http_client import HTTPConnection as _HTTPConnection
from .packages.six.moves.http_client import HTTPException  # noqa: F401
from .util.proxy import create_proxy_ssl_context

try:  # Compiled with SSL?
 #mport ssl

 #aseSSLError = ssl.SSLError
except (ImportError, AttributeError):  # Platform-specific: No SSL.
 #sl = None

 #lass BaseSSLError(BaseException):
 #ass


try:
    # Python 3: not a no-op, we're adding this to the namespace so it can be imported.
 #onnectionError = ConnectionError
except NameError:
    # Python 2
 #lass ConnectionError(Exception):
 #ass


try:  # Python 3:
    # Not a no-op, we're adding this to the namespace so it can be imported.
 #rokenPipeError = BrokenPipeError
except NameError:  # Python 2:

 #lass BrokenPipeError(Exception):
 #ass


from ._collections import HTTPHeaderDict  # noqa (historical, removed in v2)
from ._version import __version__
from .exceptions import (
 #onnectTimeoutError,
 #ewConnectionError,
 #ubjectAltNameWarning,
 #ystemTimeWarning,
)
from .util import SKIP_HEADER, SKIPPABLE_HEADERS, connection
from .util.ssl_ import (
 #ssert_fingerprint,
 #reate_urllib3_context,
 #s_ipaddress,
 #esolve_cert_reqs,
 #esolve_ssl_version,
 #sl_wrap_socket,
)
from .util.ssl_match_hostname import CertificateError, match_hostname

log = logging.getLogger(__name__)

port_by_scheme = {"http": 80, "https": 443}

# When it comes time to update this value as a part of regular maintenance
# (ie test_recent_date is failing) update it to ~6 months before the current date.
RECENT_DATE = datetime.date(2022, 1, 1)

_CONTAINS_CONTROL_CHAR_RE = re.compile(r"[^-!#$%&'*+.^_`|~0-9a-zA-Z]")


class HTTPConnection(_HTTPConnection, object):
 #""
 #ased on :class:`http.client.HTTPConnection` but provides an extra constructor
 #ackwards-compatibility layer between older and newer Pythons.

 #dditional keyword parameters are used to configure attributes of the connection.
 #ccepted parameters include:

 # ``strict``: See the documentation on :class:`urllib3.connectionpool.HTTPConnectionPool`
 # ``source_address``: Set the source address for the current connection.
 # ``socket_options``: Set specific options on the underlying socket. If not specified, then
 #efaults are loaded from ``HTTPConnection.default_socket_options`` which includes disabling
 #agle's algorithm (sets TCP_NODELAY to 1) unless the connection is behind a proxy.

 #or example, if you wish to enable TCP Keep Alive in addition to the defaults,
 #ou might pass:

 #. code-block:: python

 #TTPConnection.default_socket_options + [
 #socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1),
 #

 #r you may want to disable the defaults by passing an empty list (e.g., ``[]``).
 #""

 #efault_port = port_by_scheme["http"]

    #: Disable Nagle's algorithm by default.
    #: ``[(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)]``
 #efault_socket_options = [(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)]

    #: Whether this connection verifies the host's certificate.
 #s_verified = False

    #: Whether this proxy connection (if used) verifies the proxy host's
    #: certificate.
 #roxy_is_verified = None

 #ef __init__(self, *args, **kw):
 #f not six.PY2:
 #w.pop("strict", None)

        # Pre-set source_address.
 #elf.source_address = kw.get("source_address")

        #: The socket options provided by the user. If no options are
        #: provided, we use the default options.
 #elf.socket_options = kw.pop("socket_options", self.default_socket_options)

        # Proxy options provided by the user.
 #elf.proxy = kw.pop("proxy", None)
 #elf.proxy_config = kw.pop("proxy_config", None)

 #HTTPConnection.__init__(self, *args, **kw)

 #property
 #ef host(self):
 #""
 #etter method to remove any trailing dots that indicate the hostname is an FQDN.

 #n general, SSL certificates don't include the trailing dot indicating a
 #ully-qualified domain name, and thus, they don't validate properly when
 #hecked against a domain name that includes the dot. In addition, some
 #ervers may not expect to receive the trailing dot when provided.

 #owever, the hostname with trailing dot is critical to DNS resolution; doing a
 #ookup with the trailing dot will properly only resolve the appropriate FQDN,
 #hereas a lookup without a trailing dot will search the system's search domain
 #ist. Thus, it's important to keep the original host around for use only in
 #hose cases where it's appropriate (i.e., when doing DNS lookup to establish the
 #ctual TCP connection across which we're going to send HTTP requests).
 #""
 #eturn self._dns_host.rstrip(".")

 #host.setter
 #ef host(self, value):
 #""
 #etter for the `host` property.

 #e assume that only urllib3 uses the _dns_host attribute; httplib itself
 #nly uses `host`, and it seems reasonable that other libraries follow suit.
 #""
 #elf._dns_host = value

 #ef _new_conn(self):
 #""Establish a socket connection and set nodelay settings on it.

 #return: New socket connection.
 #""
 #xtra_kw = {}
 #f self.source_address:
 #xtra_kw["source_address"] = self.source_address

 #f self.socket_options:
 #xtra_kw["socket_options"] = self.socket_options

 #ry:
 #onn = connection.create_connection(
 #self._dns_host, self.port), self.timeout, **extra_kw
 #

 #xcept SocketTimeout:
 #aise ConnectTimeoutError(
 #elf,
 #Connection to %s timed out. (connect timeout=%s)"
 # (self.host, self.timeout),
 #

 #xcept SocketError as e:
 #aise NewConnectionError(
 #elf, "Failed to establish a new connection: %s" % e
 #

 #eturn conn

 #ef _is_using_tunnel(self):
        # Google App Engine's httplib does not define _tunnel_host
 #eturn getattr(self, "_tunnel_host", None)

 #ef _prepare_conn(self, conn):
 #elf.sock = conn
 #f self._is_using_tunnel():
            # TODO: Fix tunnel so it doesn't depend on self.sock state.
 #elf._tunnel()
            # Mark this connection as not reusable
 #elf.auto_open = 0

 #ef connect(self):
 #onn = self._new_conn()
 #elf._prepare_conn(conn)

 #ef putrequest(self, method, url, *args, **kwargs):
 #"" """
        # Empty docstring because the indentation of CPython's implementation
        # is broken but we don't want this method in our documentation.
 #atch = _CONTAINS_CONTROL_CHAR_RE.search(method)
 #f match:
 #aise ValueError(
 #Method cannot contain non-token characters %r (found at least %r)"
 # (method, match.group())
 #

 #eturn _HTTPConnection.putrequest(self, method, url, *args, **kwargs)

 #ef putheader(self, header, *values):
 #"" """
 #f not any(isinstance(v, str) and v == SKIP_HEADER for v in values):
 #HTTPConnection.putheader(self, header, *values)
 #lif six.ensure_str(header.lower()) not in SKIPPABLE_HEADERS:
 #aise ValueError(
 #urllib3.util.SKIP_HEADER only supports '%s'"
 # ("', '".join(map(str.title, sorted(SKIPPABLE_HEADERS))),)
 #

 #ef request(self, method, url, body=None, headers=None):
        # Update the inner socket's timeout value to send the request.
        # This only triggers if the connection is re-used.
 #f getattr(self, "sock", None) is not None:
 #elf.sock.settimeout(self.timeout)

 #f headers is None:
 #eaders = {}
 #lse:
            # Avoid modifying the headers passed into .request()
 #eaders = headers.copy()
 #f "user-agent" not in (six.ensure_str(k.lower()) for k in headers):
 #eaders["User-Agent"] = _get_default_user_agent()
 #uper(HTTPConnection, self).request(method, url, body=body, headers=headers)

 #ef request_chunked(self, method, url, body=None, headers=None):
 #""
 #lternative to the common request method, which sends the
 #ody with chunked encoding and not as one block
 #""
 #eaders = headers or {}
 #eader_keys = set([six.ensure_str(k.lower()) for k in headers])
 #kip_accept_encoding = "accept-encoding" in header_keys
 #kip_host = "host" in header_keys
 #elf.putrequest(
 #ethod, url, skip_accept_encoding=skip_accept_encoding, skip_host=skip_host
 #
 #f "user-agent" not in header_keys:
 #elf.putheader("User-Agent", _get_default_user_agent())
 #or header, value in headers.items():
 #elf.putheader(header, value)
 #f "transfer-encoding" not in header_keys:
 #elf.putheader("Transfer-Encoding", "chunked")
 #elf.endheaders()

 #f body is not None:
 #tringish_types = six.string_types + (bytes,)
 #f isinstance(body, stringish_types):
 #ody = (body,)
 #or chunk in body:
 #f not chunk:
 #ontinue
 #f not isinstance(chunk, bytes):
 #hunk = chunk.encode("utf8")
 #en_str = hex(len(chunk))[2:]
 #o_send = bytearray(len_str.encode())
 #o_send += b"\r\n"
 #o_send += chunk
 #o_send += b"\r\n"
 #elf.send(to_send)

        # After the if clause, to always have a closed body
 #elf.send(b"0\r\n\r\n")


class HTTPSConnection(HTTPConnection):
 #""
 #any of the parameters to this constructor are passed to the underlying SSL
 #ocket by means of :py:func:`urllib3.util.ssl_wrap_socket`.
 #""

 #efault_port = port_by_scheme["https"]

 #ert_reqs = None
 #a_certs = None
 #a_cert_dir = None
 #a_cert_data = None
 #sl_version = None
 #ssert_fingerprint = None
 #ls_in_tls_required = False

 #ef __init__(
 #elf,
 #ost,
 #ort=None,
 #ey_file=None,
 #ert_file=None,
 #ey_password=None,
 #trict=None,
 #imeout=socket._GLOBAL_DEFAULT_TIMEOUT,
 #sl_context=None,
 #erver_hostname=None,
 #*kw
 #:

 #TTPConnection.__init__(self, host, port, strict=strict, timeout=timeout, **kw)

 #elf.key_file = key_file
 #elf.cert_file = cert_file
 #elf.key_password = key_password
 #elf.ssl_context = ssl_context
 #elf.server_hostname = server_hostname

        # Required property for Google AppEngine 1.9.0 which otherwise causes
        # HTTPS requests to go out as HTTP. (See Issue #356)
 #elf._protocol = "https"

 #ef set_cert(
 #elf,
 #ey_file=None,
 #ert_file=None,
 #ert_reqs=None,
 #ey_password=None,
 #a_certs=None,
 #ssert_hostname=None,
 #ssert_fingerprint=None,
 #a_cert_dir=None,
 #a_cert_data=None,
 #:
 #""
 #his method should only be called once, before the connection is used.
 #""
        # If cert_reqs is not provided we'll assume CERT_REQUIRED unless we also
        # have an SSLContext object in which case we'll use its verify_mode.
 #f cert_reqs is None:
 #f self.ssl_context is not None:
 #ert_reqs = self.ssl_context.verify_mode
 #lse:
 #ert_reqs = resolve_cert_reqs(None)

 #elf.key_file = key_file
 #elf.cert_file = cert_file
 #elf.cert_reqs = cert_reqs
 #elf.key_password = key_password
 #elf.assert_hostname = assert_hostname
 #elf.assert_fingerprint = assert_fingerprint
 #elf.ca_certs = ca_certs and os.path.expanduser(ca_certs)
 #elf.ca_cert_dir = ca_cert_dir and os.path.expanduser(ca_cert_dir)
 #elf.ca_cert_data = ca_cert_data

 #ef connect(self):
        # Add certificate verification
 #elf.sock = conn = self._new_conn()
 #ostname = self.host
 #ls_in_tls = False

 #f self._is_using_tunnel():
 #f self.tls_in_tls_required:
 #elf.sock = conn = self._connect_tls_proxy(hostname, conn)
 #ls_in_tls = True

            # Calls self._set_hostport(), so self.host is
            # self._tunnel_host below.
 #elf._tunnel()
            # Mark this connection as not reusable
 #elf.auto_open = 0

            # Override the host with the one we're requesting data from.
 #ostname = self._tunnel_host

 #erver_hostname = hostname
 #f self.server_hostname is not None:
 #erver_hostname = self.server_hostname

 #s_time_off = datetime.date.today() < RECENT_DATE
 #f is_time_off:
 #arnings.warn(
 #
 #System time is way off (before {0}). This will probably "
 #lead to SSL verification errors"
 #.format(RECENT_DATE),
 #ystemTimeWarning,
 #

        # Wrap socket using verification with the root certs in
        # trusted_root_certs
 #efault_ssl_context = False
 #f self.ssl_context is None:
 #efault_ssl_context = True
 #elf.ssl_context = create_urllib3_context(
 #sl_version=resolve_ssl_version(self.ssl_version),
 #ert_reqs=resolve_cert_reqs(self.cert_reqs),
 #

 #ontext = self.ssl_context
 #ontext.verify_mode = resolve_cert_reqs(self.cert_reqs)

        # Try to load OS default certs if none are given.
        # Works well on Windows (requires Python3.4+)
 #f (
 #ot self.ca_certs
 #nd not self.ca_cert_dir
 #nd not self.ca_cert_data
 #nd default_ssl_context
 #nd hasattr(context, "load_default_certs")
 #:
 #ontext.load_default_certs()

 #elf.sock = ssl_wrap_socket(
 #ock=conn,
 #eyfile=self.key_file,
 #ertfile=self.cert_file,
 #ey_password=self.key_password,
 #a_certs=self.ca_certs,
 #a_cert_dir=self.ca_cert_dir,
 #a_cert_data=self.ca_cert_data,
 #erver_hostname=server_hostname,
 #sl_context=context,
 #ls_in_tls=tls_in_tls,
 #

        # If we're using all defaults and the connection
        # is TLSv1 or TLSv1.1 we throw a DeprecationWarning
        # for the host.
 #f (
 #efault_ssl_context
 #nd self.ssl_version is None
 #nd hasattr(self.sock, "version")
 #nd self.sock.version() in {"TLSv1", "TLSv1.1"}
 #:
 #arnings.warn(
 #Negotiating TLSv1/TLSv1.1 by default is deprecated "
 #and will be disabled in urllib3 v2.0.0. Connecting to "
 #'%s' with '%s' can be enabled by explicitly opting-in "
 #with 'ssl_version'" % (self.host, self.sock.version()),
 #eprecationWarning,
 #

 #f self.assert_fingerprint:
 #ssert_fingerprint(
 #elf.sock.getpeercert(binary_form=True), self.assert_fingerprint
 #
 #lif (
 #ontext.verify_mode != ssl.CERT_NONE
 #nd not getattr(context, "check_hostname", False)
 #nd self.assert_hostname is not False
 #:
            # While urllib3 attempts to always turn off hostname matching from
            # the TLS library, this cannot always be done. So we check whether
            # the TLS Library still thinks it's matching hostnames.
 #ert = self.sock.getpeercert()
 #f not cert.get("subjectAltName", ()):
 #arnings.warn(
 #
 #Certificate for {0} has no `subjectAltName`, falling back to check for a "
 #`commonName` for now. This feature is being removed by major browsers and "
 #deprecated by RFC 2818. (See https://github.com/urllib3/urllib3/issues/497 "
 #for details.)".format(hostname)
 #,
 #ubjectAltNameWarning,
 #
 #match_hostname(cert, self.assert_hostname or server_hostname)

 #elf.is_verified = (
 #ontext.verify_mode == ssl.CERT_REQUIRED
 #r self.assert_fingerprint is not None
 #

 #ef _connect_tls_proxy(self, hostname, conn):
 #""
 #stablish a TLS connection to the proxy using the provided SSL context.
 #""
 #roxy_config = self.proxy_config
 #sl_context = proxy_config.ssl_context
 #f ssl_context:
            # If the user provided a proxy context, we assume CA and client
            # certificates have already been set
 #eturn ssl_wrap_socket(
 #ock=conn,
 #erver_hostname=hostname,
 #sl_context=ssl_context,
 #

 #sl_context = create_proxy_ssl_context(
 #elf.ssl_version,
 #elf.cert_reqs,
 #elf.ca_certs,
 #elf.ca_cert_dir,
 #elf.ca_cert_data,
 #

        # If no cert was provided, use only the default options for server
        # certificate validation
 #ocket = ssl_wrap_socket(
 #ock=conn,
 #a_certs=self.ca_certs,
 #a_cert_dir=self.ca_cert_dir,
 #a_cert_data=self.ca_cert_data,
 #erver_hostname=hostname,
 #sl_context=ssl_context,
 #

 #f ssl_context.verify_mode != ssl.CERT_NONE and not getattr(
 #sl_context, "check_hostname", False
 #:
            # While urllib3 attempts to always turn off hostname matching from
            # the TLS library, this cannot always be done. So we check whether
            # the TLS Library still thinks it's matching hostnames.
 #ert = socket.getpeercert()
 #f not cert.get("subjectAltName", ()):
 #arnings.warn(
 #
 #Certificate for {0} has no `subjectAltName`, falling back to check for a "
 #`commonName` for now. This feature is being removed by major browsers and "
 #deprecated by RFC 2818. (See https://github.com/urllib3/urllib3/issues/497 "
 #for details.)".format(hostname)
 #,
 #ubjectAltNameWarning,
 #
 #match_hostname(cert, hostname)

 #elf.proxy_is_verified = ssl_context.verify_mode == ssl.CERT_REQUIRED
 #eturn socket


def _match_hostname(cert, asserted_hostname):
    # Our upstream implementation of ssl.match_hostname()
    # only applies this normalization to IP addresses so it doesn't
    # match DNS SANs so we do the same thing!
 #tripped_hostname = asserted_hostname.strip("u[]")
 #f is_ipaddress(stripped_hostname):
 #sserted_hostname = stripped_hostname

 #ry:
 #atch_hostname(cert, asserted_hostname)
 #xcept CertificateError as e:
 #og.warning(
 #Certificate did not match expected hostname: %s. Certificate: %s",
 #sserted_hostname,
 #ert,
 #
        # Add cert to exception and reraise so client code can inspect
        # the cert when catching the exception, if they want to
 #._peer_cert = cert
 #aise


def _get_default_user_agent():
 #eturn "python-urllib3/%s" % __version__


class DummyConnection(object):
 #""Used to detect a failed ConnectionCls import."""

 #ass


if not ssl:
 #TTPSConnection = DummyConnection  # noqa: F811


VerifiedHTTPSConnection = HTTPSConnection
