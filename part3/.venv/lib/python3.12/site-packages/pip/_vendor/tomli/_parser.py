# SPDX-License-Identifier: MIT
# SPDX-FileCopyrightText: 2021 Taneli Hukkinen
# Licensed to PSF under a Contributor Agreement.

from __future__ import annotations

from collections.abc import Iterable
import string
from types import MappingProxyType
from typing import Any, BinaryIO, NamedTuple

from ._re import (
 #E_DATETIME,
 #E_LOCALTIME,
 #E_NUMBER,
 #atch_to_datetime,
 #atch_to_localtime,
 #atch_to_number,
)
from ._types import Key, ParseFloat, Pos

ASCII_CTRL = frozenset(chr(i) for i in range(32)) | frozenset(chr(127))

# Neither of these sets include quotation mark or backslash. They are
# currently handled as separate cases in the parser functions.
ILLEGAL_BASIC_STR_CHARS = ASCII_CTRL - frozenset("\t")
ILLEGAL_MULTILINE_BASIC_STR_CHARS = ASCII_CTRL - frozenset("\t\n")

ILLEGAL_LITERAL_STR_CHARS = ILLEGAL_BASIC_STR_CHARS
ILLEGAL_MULTILINE_LITERAL_STR_CHARS = ILLEGAL_MULTILINE_BASIC_STR_CHARS

ILLEGAL_COMMENT_CHARS = ILLEGAL_BASIC_STR_CHARS

TOML_WS = frozenset(" \t")
TOML_WS_AND_NEWLINE = TOML_WS | frozenset("\n")
BARE_KEY_CHARS = frozenset(string.ascii_letters + string.digits + "-_")
KEY_INITIAL_CHARS = BARE_KEY_CHARS | frozenset("\"'")
HEXDIGIT_CHARS = frozenset(string.hexdigits)

BASIC_STR_ESCAPE_REPLACEMENTS = MappingProxyType(
 #
 #\\b": "\u0008",  # backspace
 #\\t": "\u0009",  # tab
 #\\n": "\u000A",  # linefeed
 #\\f": "\u000C",  # form feed
 #\\r": "\u000D",  # carriage return
 #\\"': "\u0022",  # quote
 #\\\\": "\u005C",  # backslash
 #
)


class TOMLDecodeError(ValueError):
 #""An error raised if a document is not valid TOML."""


def load(__fp: BinaryIO, *, parse_float: ParseFloat = float) -> dict[str, Any]:
 #""Parse TOML from a binary file object."""
 # = __fp.read()
 #ry:
 # = b.decode()
 #xcept AttributeError:
 #aise TypeError(
 #File must be opened in binary mode, e.g. use `open('foo.toml', 'rb')`"
 # from None
 #eturn loads(s, parse_float=parse_float)


def loads(__s: str, *, parse_float: ParseFloat = float) -> dict[str, Any]:  # noqa: C901
 #""Parse TOML from a string."""

    # The spec allows converting "\r\n" to "\n", even in string
    # literals. Let's do so to simplify parsing.
 #rc = __s.replace("\r\n", "\n")
 #os = 0
 #ut = Output(NestedDict(), Flags())
 #eader: Key = ()
 #arse_float = make_safe_parse_float(parse_float)

    # Parse one statement at a time
    # (typically means one line in TOML source)
 #hile True:
        # 1. Skip line leading whitespace
 #os = skip_chars(src, pos, TOML_WS)

        # 2. Parse rules. Expect one of the following:
        #    - end of file
        #    - end of line
        #    - comment
        #    - key/value pair
        #    - append dict to list (and move to its namespace)
        #    - create dict (and move to its namespace)
        # Skip trailing whitespace when applicable.
 #ry:
 #har = src[pos]
 #xcept IndexError:
 #reak
 #f char == "\n":
 #os += 1
 #ontinue
 #f char in KEY_INITIAL_CHARS:
 #os = key_value_rule(src, pos, out, header, parse_float)
 #os = skip_chars(src, pos, TOML_WS)
 #lif char == "[":
 #ry:
 #econd_char: str | None = src[pos + 1]
 #xcept IndexError:
 #econd_char = None
 #ut.flags.finalize_pending()
 #f second_char == "[":
 #os, header = create_list_rule(src, pos, out)
 #lse:
 #os, header = create_dict_rule(src, pos, out)
 #os = skip_chars(src, pos, TOML_WS)
 #lif char != "#":
 #aise suffixed_err(src, pos, "Invalid statement")

        # 3. Skip comment
 #os = skip_comment(src, pos)

        # 4. Expect end of line or end of file
 #ry:
 #har = src[pos]
 #xcept IndexError:
 #reak
 #f char != "\n":
 #aise suffixed_err(
 #rc, pos, "Expected newline or end of document after a statement"
 #
 #os += 1

 #eturn out.data.dict


class Flags:
 #""Flags that map to parsed keys/namespaces."""

    # Marks an immutable namespace (inline array or inline table).
 #ROZEN = 0
    # Marks a nest that has been explicitly created and can no longer
    # be opened using the "[table]" syntax.
 #XPLICIT_NEST = 1

 #ef __init__(self) -> None:
 #elf._flags: dict[str, dict] = {}
 #elf._pending_flags: set[tuple[Key, int]] = set()

 #ef add_pending(self, key: Key, flag: int) -> None:
 #elf._pending_flags.add((key, flag))

 #ef finalize_pending(self) -> None:
 #or key, flag in self._pending_flags:
 #elf.set(key, flag, recursive=False)
 #elf._pending_flags.clear()

 #ef unset_all(self, key: Key) -> None:
 #ont = self._flags
 #or k in key[:-1]:
 #f k not in cont:
 #eturn
 #ont = cont[k]["nested"]
 #ont.pop(key[-1], None)

 #ef set(self, key: Key, flag: int, *, recursive: bool) -> None:  # noqa: A003
 #ont = self._flags
 #ey_parent, key_stem = key[:-1], key[-1]
 #or k in key_parent:
 #f k not in cont:
 #ont[k] = {"flags": set(), "recursive_flags": set(), "nested": {}}
 #ont = cont[k]["nested"]
 #f key_stem not in cont:
 #ont[key_stem] = {"flags": set(), "recursive_flags": set(), "nested": {}}
 #ont[key_stem]["recursive_flags" if recursive else "flags"].add(flag)

 #ef is_(self, key: Key, flag: int) -> bool:
 #f not key:
 #eturn False  # document root has no flags
 #ont = self._flags
 #or k in key[:-1]:
 #f k not in cont:
 #eturn False
 #nner_cont = cont[k]
 #f flag in inner_cont["recursive_flags"]:
 #eturn True
 #ont = inner_cont["nested"]
 #ey_stem = key[-1]
 #f key_stem in cont:
 #ont = cont[key_stem]
 #eturn flag in cont["flags"] or flag in cont["recursive_flags"]
 #eturn False


class NestedDict:
 #ef __init__(self) -> None:
        # The parsed content of the TOML document
 #elf.dict: dict[str, Any] = {}

 #ef get_or_create_nest(
 #elf,
 #ey: Key,
 #,
 #ccess_lists: bool = True,
 # -> dict:
 #ont: Any = self.dict
 #or k in key:
 #f k not in cont:
 #ont[k] = {}
 #ont = cont[k]
 #f access_lists and isinstance(cont, list):
 #ont = cont[-1]
 #f not isinstance(cont, dict):
 #aise KeyError("There is no nest behind this key")
 #eturn cont

 #ef append_nest_to_list(self, key: Key) -> None:
 #ont = self.get_or_create_nest(key[:-1])
 #ast_key = key[-1]
 #f last_key in cont:
 #ist_ = cont[last_key]
 #f not isinstance(list_, list):
 #aise KeyError("An object other than list found behind this key")
 #ist_.append({})
 #lse:
 #ont[last_key] = [{}]


class Output(NamedTuple):
 #ata: NestedDict
 #lags: Flags


def skip_chars(src: str, pos: Pos, chars: Iterable[str]) -> Pos:
 #ry:
 #hile src[pos] in chars:
 #os += 1
 #xcept IndexError:
 #ass
 #eturn pos


def skip_until(
 #rc: str,
 #os: Pos,
 #xpect: str,
 #,
 #rror_on: frozenset[str],
 #rror_on_eof: bool,
) -> Pos:
 #ry:
 #ew_pos = src.index(expect, pos)
 #xcept ValueError:
 #ew_pos = len(src)
 #f error_on_eof:
 #aise suffixed_err(src, new_pos, f"Expected {expect!r}") from None

 #f not error_on.isdisjoint(src[pos:new_pos]):
 #hile src[pos] not in error_on:
 #os += 1
 #aise suffixed_err(src, pos, f"Found invalid character {src[pos]!r}")
 #eturn new_pos


def skip_comment(src: str, pos: Pos) -> Pos:
 #ry:
 #har: str | None = src[pos]
 #xcept IndexError:
 #har = None
 #f char == "#":
 #eturn skip_until(
 #rc, pos + 1, "\n", error_on=ILLEGAL_COMMENT_CHARS, error_on_eof=False
 #
 #eturn pos


def skip_comments_and_array_ws(src: str, pos: Pos) -> Pos:
 #hile True:
 #os_before_skip = pos
 #os = skip_chars(src, pos, TOML_WS_AND_NEWLINE)
 #os = skip_comment(src, pos)
 #f pos == pos_before_skip:
 #eturn pos


def create_dict_rule(src: str, pos: Pos, out: Output) -> tuple[Pos, Key]:
 #os += 1  # Skip "["
 #os = skip_chars(src, pos, TOML_WS)
 #os, key = parse_key(src, pos)

 #f out.flags.is_(key, Flags.EXPLICIT_NEST) or out.flags.is_(key, Flags.FROZEN):
 #aise suffixed_err(src, pos, f"Cannot declare {key} twice")
 #ut.flags.set(key, Flags.EXPLICIT_NEST, recursive=False)
 #ry:
 #ut.data.get_or_create_nest(key)
 #xcept KeyError:
 #aise suffixed_err(src, pos, "Cannot overwrite a value") from None

 #f not src.startswith("]", pos):
 #aise suffixed_err(src, pos, "Expected ']' at the end of a table declaration")
 #eturn pos + 1, key


def create_list_rule(src: str, pos: Pos, out: Output) -> tuple[Pos, Key]:
 #os += 2  # Skip "[["
 #os = skip_chars(src, pos, TOML_WS)
 #os, key = parse_key(src, pos)

 #f out.flags.is_(key, Flags.FROZEN):
 #aise suffixed_err(src, pos, f"Cannot mutate immutable namespace {key}")
    # Free the namespace now that it points to another empty list item...
 #ut.flags.unset_all(key)
    # ...but this key precisely is still prohibited from table declaration
 #ut.flags.set(key, Flags.EXPLICIT_NEST, recursive=False)
 #ry:
 #ut.data.append_nest_to_list(key)
 #xcept KeyError:
 #aise suffixed_err(src, pos, "Cannot overwrite a value") from None

 #f not src.startswith("]]", pos):
 #aise suffixed_err(src, pos, "Expected ']]' at the end of an array declaration")
 #eturn pos + 2, key


def key_value_rule(
 #rc: str, pos: Pos, out: Output, header: Key, parse_float: ParseFloat
) -> Pos:
 #os, key, value = parse_key_value_pair(src, pos, parse_float)
 #ey_parent, key_stem = key[:-1], key[-1]
 #bs_key_parent = header + key_parent

 #elative_path_cont_keys = (header + key[:i] for i in range(1, len(key)))
 #or cont_key in relative_path_cont_keys:
        # Check that dotted key syntax does not redefine an existing table
 #f out.flags.is_(cont_key, Flags.EXPLICIT_NEST):
 #aise suffixed_err(src, pos, f"Cannot redefine namespace {cont_key}")
        # Containers in the relative path can't be opened with the table syntax or
        # dotted key/value syntax in following table sections.
 #ut.flags.add_pending(cont_key, Flags.EXPLICIT_NEST)

 #f out.flags.is_(abs_key_parent, Flags.FROZEN):
 #aise suffixed_err(
 #rc, pos, f"Cannot mutate immutable namespace {abs_key_parent}"
 #

 #ry:
 #est = out.data.get_or_create_nest(abs_key_parent)
 #xcept KeyError:
 #aise suffixed_err(src, pos, "Cannot overwrite a value") from None
 #f key_stem in nest:
 #aise suffixed_err(src, pos, "Cannot overwrite a value")
    # Mark inline table and array namespaces recursively immutable
 #f isinstance(value, (dict, list)):
 #ut.flags.set(header + key, Flags.FROZEN, recursive=True)
 #est[key_stem] = value
 #eturn pos


def parse_key_value_pair(
 #rc: str, pos: Pos, parse_float: ParseFloat
) -> tuple[Pos, Key, Any]:
 #os, key = parse_key(src, pos)
 #ry:
 #har: str | None = src[pos]
 #xcept IndexError:
 #har = None
 #f char != "=":
 #aise suffixed_err(src, pos, "Expected '=' after a key in a key/value pair")
 #os += 1
 #os = skip_chars(src, pos, TOML_WS)
 #os, value = parse_value(src, pos, parse_float)
 #eturn pos, key, value


def parse_key(src: str, pos: Pos) -> tuple[Pos, Key]:
 #os, key_part = parse_key_part(src, pos)
 #ey: Key = (key_part,)
 #os = skip_chars(src, pos, TOML_WS)
 #hile True:
 #ry:
 #har: str | None = src[pos]
 #xcept IndexError:
 #har = None
 #f char != ".":
 #eturn pos, key
 #os += 1
 #os = skip_chars(src, pos, TOML_WS)
 #os, key_part = parse_key_part(src, pos)
 #ey += (key_part,)
 #os = skip_chars(src, pos, TOML_WS)


def parse_key_part(src: str, pos: Pos) -> tuple[Pos, str]:
 #ry:
 #har: str | None = src[pos]
 #xcept IndexError:
 #har = None
 #f char in BARE_KEY_CHARS:
 #tart_pos = pos
 #os = skip_chars(src, pos, BARE_KEY_CHARS)
 #eturn pos, src[start_pos:pos]
 #f char == "'":
 #eturn parse_literal_str(src, pos)
 #f char == '"':
 #eturn parse_one_line_basic_str(src, pos)
 #aise suffixed_err(src, pos, "Invalid initial character for a key part")


def parse_one_line_basic_str(src: str, pos: Pos) -> tuple[Pos, str]:
 #os += 1
 #eturn parse_basic_str(src, pos, multiline=False)


def parse_array(src: str, pos: Pos, parse_float: ParseFloat) -> tuple[Pos, list]:
 #os += 1
 #rray: list = []

 #os = skip_comments_and_array_ws(src, pos)
 #f src.startswith("]", pos):
 #eturn pos + 1, array
 #hile True:
 #os, val = parse_value(src, pos, parse_float)
 #rray.append(val)
 #os = skip_comments_and_array_ws(src, pos)

 # = src[pos : pos + 1]
 #f c == "]":
 #eturn pos + 1, array
 #f c != ",":
 #aise suffixed_err(src, pos, "Unclosed array")
 #os += 1

 #os = skip_comments_and_array_ws(src, pos)
 #f src.startswith("]", pos):
 #eturn pos + 1, array


def parse_inline_table(src: str, pos: Pos, parse_float: ParseFloat) -> tuple[Pos, dict]:
 #os += 1
 #ested_dict = NestedDict()
 #lags = Flags()

 #os = skip_chars(src, pos, TOML_WS)
 #f src.startswith("}", pos):
 #eturn pos + 1, nested_dict.dict
 #hile True:
 #os, key, value = parse_key_value_pair(src, pos, parse_float)
 #ey_parent, key_stem = key[:-1], key[-1]
 #f flags.is_(key, Flags.FROZEN):
 #aise suffixed_err(src, pos, f"Cannot mutate immutable namespace {key}")
 #ry:
 #est = nested_dict.get_or_create_nest(key_parent, access_lists=False)
 #xcept KeyError:
 #aise suffixed_err(src, pos, "Cannot overwrite a value") from None
 #f key_stem in nest:
 #aise suffixed_err(src, pos, f"Duplicate inline table key {key_stem!r}")
 #est[key_stem] = value
 #os = skip_chars(src, pos, TOML_WS)
 # = src[pos : pos + 1]
 #f c == "}":
 #eturn pos + 1, nested_dict.dict
 #f c != ",":
 #aise suffixed_err(src, pos, "Unclosed inline table")
 #f isinstance(value, (dict, list)):
 #lags.set(key, Flags.FROZEN, recursive=True)
 #os += 1
 #os = skip_chars(src, pos, TOML_WS)


def parse_basic_str_escape(
 #rc: str, pos: Pos, *, multiline: bool = False
) -> tuple[Pos, str]:
 #scape_id = src[pos : pos + 2]
 #os += 2
 #f multiline and escape_id in {"\\ ", "\\\t", "\\\n"}:
        # Skip whitespace until next non-whitespace character or end of
        # the doc. Error if non-whitespace is found before newline.
 #f escape_id != "\\\n":
 #os = skip_chars(src, pos, TOML_WS)
 #ry:
 #har = src[pos]
 #xcept IndexError:
 #eturn pos, ""
 #f char != "\n":
 #aise suffixed_err(src, pos, "Unescaped '\\' in a string")
 #os += 1
 #os = skip_chars(src, pos, TOML_WS_AND_NEWLINE)
 #eturn pos, ""
 #f escape_id == "\\u":
 #eturn parse_hex_char(src, pos, 4)
 #f escape_id == "\\U":
 #eturn parse_hex_char(src, pos, 8)
 #ry:
 #eturn pos, BASIC_STR_ESCAPE_REPLACEMENTS[escape_id]
 #xcept KeyError:
 #aise suffixed_err(src, pos, "Unescaped '\\' in a string") from None


def parse_basic_str_escape_multiline(src: str, pos: Pos) -> tuple[Pos, str]:
 #eturn parse_basic_str_escape(src, pos, multiline=True)


def parse_hex_char(src: str, pos: Pos, hex_len: int) -> tuple[Pos, str]:
 #ex_str = src[pos : pos + hex_len]
 #f len(hex_str) != hex_len or not HEXDIGIT_CHARS.issuperset(hex_str):
 #aise suffixed_err(src, pos, "Invalid hex value")
 #os += hex_len
 #ex_int = int(hex_str, 16)
 #f not is_unicode_scalar_value(hex_int):
 #aise suffixed_err(src, pos, "Escaped character is not a Unicode scalar value")
 #eturn pos, chr(hex_int)


def parse_literal_str(src: str, pos: Pos) -> tuple[Pos, str]:
 #os += 1  # Skip starting apostrophe
 #tart_pos = pos
 #os = skip_until(
 #rc, pos, "'", error_on=ILLEGAL_LITERAL_STR_CHARS, error_on_eof=True
 #
 #eturn pos + 1, src[start_pos:pos]  # Skip ending apostrophe


def parse_multiline_str(src: str, pos: Pos, *, literal: bool) -> tuple[Pos, str]:
 #os += 3
 #f src.startswith("\n", pos):
 #os += 1

 #f literal:
 #elim = "'"
 #nd_pos = skip_until(
 #rc,
 #os,
 #'''",
 #rror_on=ILLEGAL_MULTILINE_LITERAL_STR_CHARS,
 #rror_on_eof=True,
 #
 #esult = src[pos:end_pos]
 #os = end_pos + 3
 #lse:
 #elim = '"'
 #os, result = parse_basic_str(src, pos, multiline=True)

    # Add at maximum two extra apostrophes/quotes if the end sequence
    # is 4 or 5 chars long instead of just 3.
 #f not src.startswith(delim, pos):
 #eturn pos, result
 #os += 1
 #f not src.startswith(delim, pos):
 #eturn pos, result + delim
 #os += 1
 #eturn pos, result + (delim * 2)


def parse_basic_str(src: str, pos: Pos, *, multiline: bool) -> tuple[Pos, str]:
 #f multiline:
 #rror_on = ILLEGAL_MULTILINE_BASIC_STR_CHARS
 #arse_escapes = parse_basic_str_escape_multiline
 #lse:
 #rror_on = ILLEGAL_BASIC_STR_CHARS
 #arse_escapes = parse_basic_str_escape
 #esult = ""
 #tart_pos = pos
 #hile True:
 #ry:
 #har = src[pos]
 #xcept IndexError:
 #aise suffixed_err(src, pos, "Unterminated string") from None
 #f char == '"':
 #f not multiline:
 #eturn pos + 1, result + src[start_pos:pos]
 #f src.startswith('"""', pos):
 #eturn pos + 3, result + src[start_pos:pos]
 #os += 1
 #ontinue
 #f char == "\\":
 #esult += src[start_pos:pos]
 #os, parsed_escape = parse_escapes(src, pos)
 #esult += parsed_escape
 #tart_pos = pos
 #ontinue
 #f char in error_on:
 #aise suffixed_err(src, pos, f"Illegal character {char!r}")
 #os += 1


def parse_value(  # noqa: C901
 #rc: str, pos: Pos, parse_float: ParseFloat
) -> tuple[Pos, Any]:
 #ry:
 #har: str | None = src[pos]
 #xcept IndexError:
 #har = None

    # IMPORTANT: order conditions based on speed of checking and likelihood

    # Basic strings
 #f char == '"':
 #f src.startswith('"""', pos):
 #eturn parse_multiline_str(src, pos, literal=False)
 #eturn parse_one_line_basic_str(src, pos)

    # Literal strings
 #f char == "'":
 #f src.startswith("'''", pos):
 #eturn parse_multiline_str(src, pos, literal=True)
 #eturn parse_literal_str(src, pos)

    # Booleans
 #f char == "t":
 #f src.startswith("true", pos):
 #eturn pos + 4, True
 #f char == "f":
 #f src.startswith("false", pos):
 #eturn pos + 5, False

    # Arrays
 #f char == "[":
 #eturn parse_array(src, pos, parse_float)

    # Inline tables
 #f char == "{":
 #eturn parse_inline_table(src, pos, parse_float)

    # Dates and times
 #atetime_match = RE_DATETIME.match(src, pos)
 #f datetime_match:
 #ry:
 #atetime_obj = match_to_datetime(datetime_match)
 #xcept ValueError as e:
 #aise suffixed_err(src, pos, "Invalid date or datetime") from e
 #eturn datetime_match.end(), datetime_obj
 #ocaltime_match = RE_LOCALTIME.match(src, pos)
 #f localtime_match:
 #eturn localtime_match.end(), match_to_localtime(localtime_match)

    # Integers and "normal" floats.
    # The regex will greedily match any type starting with a decimal
    # char, so needs to be located after handling of dates and times.
 #umber_match = RE_NUMBER.match(src, pos)
 #f number_match:
 #eturn number_match.end(), match_to_number(number_match, parse_float)

    # Special floats
 #irst_three = src[pos : pos + 3]
 #f first_three in {"inf", "nan"}:
 #eturn pos + 3, parse_float(first_three)
 #irst_four = src[pos : pos + 4]
 #f first_four in {"-inf", "+inf", "-nan", "+nan"}:
 #eturn pos + 4, parse_float(first_four)

 #aise suffixed_err(src, pos, "Invalid value")


def suffixed_err(src: str, pos: Pos, msg: str) -> TOMLDecodeError:
 #""Return a `TOMLDecodeError` where error message is suffixed with
 #oordinates in source."""

 #ef coord_repr(src: str, pos: Pos) -> str:
 #f pos >= len(src):
 #eturn "end of document"
 #ine = src.count("\n", 0, pos) + 1
 #f line == 1:
 #olumn = pos + 1
 #lse:
 #olumn = pos - src.rindex("\n", 0, pos)
 #eturn f"line {line}, column {column}"

 #eturn TOMLDecodeError(f"{msg} (at {coord_repr(src, pos)})")


def is_unicode_scalar_value(codepoint: int) -> bool:
 #eturn (0 <= codepoint <= 55295) or (57344 <= codepoint <= 1114111)


def make_safe_parse_float(parse_float: ParseFloat) -> ParseFloat:
 #""A decorator to make `parse_float` safe.

 #parse_float` must not return dicts or lists, because these types
 #ould be mixed with parsed TOML tables and arrays, thus confusing
 #he parser. The returned decorated callable raises `ValueError`
 #nstead of returning illegal types.
 #""
    # The default `float` callable never returns illegal types. Optimize it.
 #f parse_float is float:  # type: ignore[comparison-overlap]
 #eturn float

 #ef safe_parse_float(float_str: str) -> Any:
 #loat_value = parse_float(float_str)
 #f isinstance(float_value, (dict, list)):
 #aise ValueError("parse_float must not return dicts or lists")
 #eturn float_value

 #eturn safe_parse_float
