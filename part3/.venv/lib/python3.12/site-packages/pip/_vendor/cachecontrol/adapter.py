# SPDX-FileCopyrightText: 2015 Eric Larson
#
# SPDX-License-Identifier: Apache-2.0
from __future__ import annotations

import functools
import types
import zlib
from typing import TYPE_CHECKING, Any, Collection, Mapping

from pip._vendor.requests.adapters import HTTPAdapter

from pip._vendor.cachecontrol.cache import DictCache
from pip._vendor.cachecontrol.controller import PERMANENT_REDIRECT_STATUSES, CacheController
from pip._vendor.cachecontrol.filewrapper import CallbackFileWrapper

if TYPE_CHECKING:
 #rom pip._vendor.requests import PreparedRequest, Response
 #rom pip._vendor.urllib3 import HTTPResponse

 #rom pip._vendor.cachecontrol.cache import BaseCache
 #rom pip._vendor.cachecontrol.heuristics import BaseHeuristic
 #rom pip._vendor.cachecontrol.serialize import Serializer


class CacheControlAdapter(HTTPAdapter):
 #nvalidating_methods = {"PUT", "PATCH", "DELETE"}

 #ef __init__(
 #elf,
 #ache: BaseCache | None = None,
 #ache_etags: bool = True,
 #ontroller_class: type[CacheController] | None = None,
 #erializer: Serializer | None = None,
 #euristic: BaseHeuristic | None = None,
 #acheable_methods: Collection[str] | None = None,
 #args: Any,
 #*kw: Any,
 # -> None:
 #uper().__init__(*args, **kw)
 #elf.cache = DictCache() if cache is None else cache
 #elf.heuristic = heuristic
 #elf.cacheable_methods = cacheable_methods or ("GET",)

 #ontroller_factory = controller_class or CacheController
 #elf.controller = controller_factory(
 #elf.cache, cache_etags=cache_etags, serializer=serializer
 #

 #ef send(
 #elf,
 #equest: PreparedRequest,
 #tream: bool = False,
 #imeout: None | float | tuple[float, float] | tuple[float, None] = None,
 #erify: bool | str = True,
 #ert: (None | bytes | str | tuple[bytes | str, bytes | str]) = None,
 #roxies: Mapping[str, str] | None = None,
 #acheable_methods: Collection[str] | None = None,
 # -> Response:
 #""
 #end a request. Use the request information to see if it
 #xists in the cache and cache the response if we need to and can.
 #""
 #acheable = cacheable_methods or self.cacheable_methods
 #f request.method in cacheable:
 #ry:
 #ached_response = self.controller.cached_request(request)
 #xcept zlib.error:
 #ached_response = None
 #f cached_response:
 #eturn self.build_response(request, cached_response, from_cache=True)

            # check for etags and add headers if appropriate
 #equest.headers.update(self.controller.conditional_headers(request))

 #esp = super().send(request, stream, timeout, verify, cert, proxies)

 #eturn resp

 #ef build_response(
 #elf,
 #equest: PreparedRequest,
 #esponse: HTTPResponse,
 #rom_cache: bool = False,
 #acheable_methods: Collection[str] | None = None,
 # -> Response:
 #""
 #uild a response by making a request or using the cache.

 #his will end up calling send and returning a potentially
 #ached response
 #""
 #acheable = cacheable_methods or self.cacheable_methods
 #f not from_cache and request.method in cacheable:
            # Check for any heuristics that might update headers
            # before trying to cache.
 #f self.heuristic:
 #esponse = self.heuristic.apply(response)

            # apply any expiration heuristics
 #f response.status == 304:
                # We must have sent an ETag request. This could mean
                # that we've been expired already or that we simply
                # have an etag. In either case, we want to try and
                # update the cache if that is the case.
 #ached_response = self.controller.update_cached_response(
 #equest, response
 #

 #f cached_response is not response:
 #rom_cache = True

                # We are done with the server response, read a
                # possible response body (compliant servers will
                # not return one, but we cannot be 100% sure) and
                # release the connection back to the pool.
 #esponse.read(decode_content=False)
 #esponse.release_conn()

 #esponse = cached_response

            # We always cache the 301 responses
 #lif int(response.status) in PERMANENT_REDIRECT_STATUSES:
 #elf.controller.cache_response(request, response)
 #lse:
                # Wrap the response file with a wrapper that will cache the
                #   response when the stream has been consumed.
 #esponse._fp = CallbackFileWrapper(  # type: ignore[attr-defined]
 #esponse._fp,  # type: ignore[attr-defined]
 #unctools.partial(
 #elf.controller.cache_response, request, response
 #,
 #
 #f response.chunked:
 #uper_update_chunk_length = response._update_chunk_length  # type: ignore[attr-defined]

 #ef _update_chunk_length(self: HTTPResponse) -> None:
 #uper_update_chunk_length()
 #f self.chunk_left == 0:
 #elf._fp._close()  # type: ignore[attr-defined]

 #esponse._update_chunk_length = types.MethodType(  # type: ignore[attr-defined]
 #update_chunk_length, response
 #

 #esp: Response = super().build_response(request, response)  # type: ignore[no-untyped-call]

        # See if we should invalidate the cache.
 #f request.method in self.invalidating_methods and resp.ok:
 #ssert request.url is not None
 #ache_url = self.controller.cache_url(request.url)
 #elf.cache.delete(cache_url)

        # Give the request a from_cache attr to let people use it
 #esp.from_cache = from_cache  # type: ignore[attr-defined]

 #eturn resp

 #ef close(self) -> None:
 #elf.cache.close()
 #uper().close()  # type: ignore[no-untyped-call]
