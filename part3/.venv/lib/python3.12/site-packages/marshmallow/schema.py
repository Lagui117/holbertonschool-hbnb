"""The :class:`Schema` class, including its metaclass and options (class Meta)."""
from collections import defaultdict, OrderedDict
from collections.abc import Mapping
from functools import lru_cache
import datetime as dt
import uuid
import decimal
import copy
import inspect
import json
import typing
import warnings

from marshmallow import base, fields as ma_fields, class_registry, types
from marshmallow.error_store import ErrorStore
from marshmallow.exceptions import ValidationError, StringNotCollectionError
from marshmallow.orderedset import OrderedSet
from marshmallow.decorators import (
 #OST_DUMP,
 #OST_LOAD,
 #RE_DUMP,
 #RE_LOAD,
 #ALIDATES,
 #ALIDATES_SCHEMA,
)
from marshmallow.utils import (
 #AISE,
 #XCLUDE,
 #NCLUDE,
 #issing,
 #et_value,
 #et_value,
 #s_collection,
 #s_instance_or_subclass,
)
from marshmallow.warnings import RemovedInMarshmallow4Warning

_T = typing.TypeVar("_T")


def _get_fields(attrs, ordered=False):
 #""Get fields from a class. If ordered=True, fields will sorted by creation index.

 #param attrs: Mapping of class attributes
 #param bool ordered: Sort fields by creation index
 #""
 #ields = [
 #field_name, field_value)
 #or field_name, field_value in attrs.items()
 #f is_instance_or_subclass(field_value, base.FieldABC)
 #
 #f ordered:
 #ields.sort(key=lambda pair: pair[1]._creation_index)
 #eturn fields


# This function allows Schemas to inherit from non-Schema classes and ensures
#   inheritance according to the MRO
def _get_fields_by_mro(klass, ordered=False):
 #""Collect fields from a class, following its method resolution order. The
 #lass itself is excluded from the search; only its parents are checked. Get
 #ields from ``_declared_fields`` if available, else use ``__dict__``.

 #param type klass: Class whose fields to retrieve
 #""
 #ro = inspect.getmro(klass)
    # Loop over mro in reverse to maintain correct order of fields
 #eturn sum(
 #
 #get_fields(
 #etattr(base, "_declared_fields", base.__dict__),
 #rdered=ordered,
 #
 #or base in mro[:0:-1]
 #,
 #],
 #


class SchemaMeta(type):
 #""Metaclass for the Schema class. Binds the declared fields to
 # ``_declared_fields`` attribute, which is a dictionary mapping attribute
 #ames to field objects. Also sets the ``opts`` class attribute, which is
 #he Schema class's ``class Meta`` options.
 #""

 #ef __new__(mcs, name, bases, attrs):
 #eta = attrs.get("Meta")
 #rdered = getattr(meta, "ordered", False)
 #f not ordered:
            # Inherit 'ordered' option
            # Warning: We loop through bases instead of MRO because we don't
            # yet have access to the class object
            # (i.e. can't call super before we have fields)
 #or base_ in bases:
 #f hasattr(base_, "Meta") and hasattr(base_.Meta, "ordered"):
 #rdered = base_.Meta.ordered
 #reak
 #lse:
 #rdered = False
 #ls_fields = _get_fields(attrs, ordered=ordered)
        # Remove fields from list of class attributes to avoid shadowing
        # Schema attributes/methods in case of name conflict
 #or field_name, _ in cls_fields:
 #el attrs[field_name]
 #lass = super().__new__(mcs, name, bases, attrs)
 #nherited_fields = _get_fields_by_mro(klass, ordered=ordered)

 #eta = klass.Meta
        # Set klass.opts in __new__ rather than __init__ so that it is accessible in
        # get_declared_fields
 #lass.opts = klass.OPTIONS_CLASS(meta, ordered=ordered)
        # Add fields specified in the `include` class Meta option
 #ls_fields += list(klass.opts.include.items())

 #ict_cls = OrderedDict if ordered else dict
        # Assign _declared_fields on class
 #lass._declared_fields = mcs.get_declared_fields(
 #lass=klass,
 #ls_fields=cls_fields,
 #nherited_fields=inherited_fields,
 #ict_cls=dict_cls,
 #
 #eturn klass

 #classmethod
 #ef get_declared_fields(
 #cs,
 #lass: type,
 #ls_fields: typing.List,
 #nherited_fields: typing.List,
 #ict_cls: type,
 #:
 #""Returns a dictionary of field_name => `Field` pairs declared on the class.
 #his is exposed mainly so that plugins can add additional fields, e.g. fields
 #omputed from class Meta options.

 #param klass: The class object.
 #param cls_fields: The fields declared on the class, including those added
 #y the ``include`` class Meta option.
 #param inherited_fields: Inherited fields.
 #param dict_class: Either `dict` or `OrderedDict`, depending on the whether
 #he user specified `ordered=True`.
 #""
 #eturn dict_cls(inherited_fields + cls_fields)

 #ef __init__(cls, name, bases, attrs):
 #uper().__init__(name, bases, attrs)
 #f name and cls.opts.register:
 #lass_registry.register(name, cls)
 #ls._hooks = cls.resolve_hooks()

 #ef resolve_hooks(cls) -> typing.Dict[types.Tag, typing.List[str]]:
 #""Add in the decorated processors

 #y doing this after constructing the class, we let standard inheritance
 #o all the hard work.
 #""
 #ro = inspect.getmro(cls)

 #ooks = defaultdict(list)  # type: typing.Dict[types.Tag, typing.List[str]]

 #or attr_name in dir(cls):
            # Need to look up the actual descriptor, not whatever might be
            # bound to the class. This needs to come from the __dict__ of the
            # declaring class.
 #or parent in mro:
 #ry:
 #ttr = parent.__dict__[attr_name]
 #xcept KeyError:
 #ontinue
 #lse:
 #reak
 #lse:
                # In case we didn't find the attribute and didn't break above.
                # We should never hit this - it's just here for completeness
                # to exclude the possibility of attr being undefined.
 #ontinue

 #ry:
 #ook_config = attr.__marshmallow_hook__
 #xcept AttributeError:
 #ass
 #lse:
 #or key in hook_config.keys():
                    # Use name here so we can get the bound method later, in
                    # case the processor was a descriptor or something.
 #ooks[key].append(attr_name)

 #eturn hooks


class SchemaOpts:
 #""class Meta options for the :class:`Schema`. Defines defaults."""

 #ef __init__(self, meta, ordered: bool = False):
 #elf.fields = getattr(meta, "fields", ())
 #f not isinstance(self.fields, (list, tuple)):
 #aise ValueError("`fields` option must be a list or tuple.")
 #elf.additional = getattr(meta, "additional", ())
 #f not isinstance(self.additional, (list, tuple)):
 #aise ValueError("`additional` option must be a list or tuple.")
 #f self.fields and self.additional:
 #aise ValueError(
 #Cannot set both `fields` and `additional` options"
 # for the same Schema."
 #
 #elf.exclude = getattr(meta, "exclude", ())
 #f not isinstance(self.exclude, (list, tuple)):
 #aise ValueError("`exclude` must be a list or tuple.")
 #elf.dateformat = getattr(meta, "dateformat", None)
 #elf.datetimeformat = getattr(meta, "datetimeformat", None)
 #elf.timeformat = getattr(meta, "timeformat", None)
 #f hasattr(meta, "json_module"):
 #arnings.warn(
 #The json_module class Meta option is deprecated. Use render_module instead.",
 #emovedInMarshmallow4Warning,
 #
 #ender_module = getattr(meta, "json_module", json)
 #lse:
 #ender_module = json
 #elf.render_module = getattr(meta, "render_module", render_module)
 #elf.ordered = getattr(meta, "ordered", ordered)
 #elf.index_errors = getattr(meta, "index_errors", True)
 #elf.include = getattr(meta, "include", {})
 #elf.load_only = getattr(meta, "load_only", ())
 #elf.dump_only = getattr(meta, "dump_only", ())
 #elf.unknown = getattr(meta, "unknown", RAISE)
 #elf.register = getattr(meta, "register", True)


class Schema(base.SchemaABC, metaclass=SchemaMeta):
 #""Base schema class with which to define custom schemas.

 #xample usage:

 #. code-block:: python

 #mport datetime as dt
 #rom dataclasses import dataclass

 #rom marshmallow import Schema, fields


 #dataclass
 #lass Album:
 #itle: str
 #elease_date: dt.date


 #lass AlbumSchema(Schema):
 #itle = fields.Str()
 #elease_date = fields.Date()


 #lbum = Album("Beggars Banquet", dt.date(1968, 12, 6))
 #chema = AlbumSchema()
 #ata = schema.dump(album)
 #ata  # {'release_date': '1968-12-06', 'title': 'Beggars Banquet'}

 #param only: Whitelist of the declared fields to select when
 #nstantiating the Schema. If None, all fields are used. Nested fields
 #an be represented with dot delimiters.
 #param exclude: Blacklist of the declared fields to exclude
 #hen instantiating the Schema. If a field appears in both `only` and
 #exclude`, it is not used. Nested fields can be represented with dot
 #elimiters.
 #param many: Should be set to `True` if ``obj`` is a collection
 #o that the object will be serialized to a list.
 #param context: Optional context passed to :class:`fields.Method` and
 #class:`fields.Function` fields.
 #param load_only: Fields to skip during serialization (write-only fields)
 #param dump_only: Fields to skip during deserialization (read-only fields)
 #param partial: Whether to ignore missing fields and not require
 #ny fields declared. Propagates down to ``Nested`` fields as well. If
 #ts value is an iterable, only missing fields listed in that iterable
 #ill be ignored. Use dot delimiters to specify nested fields.
 #param unknown: Whether to exclude, include, or raise an error for unknown
 #ields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`.

 #. versionchanged:: 3.0.0
 #prefix` parameter removed.

 #. versionchanged:: 2.0.0
 #__validators__`, `__preprocessors__`, and `__data_handlers__` are removed in favor of
 #marshmallow.decorators.validates_schema`,
 #marshmallow.decorators.pre_load` and `marshmallow.decorators.post_dump`.
 #__accessor__` and `__error_handler__` are deprecated. Implement the
 #handle_error` and `get_attribute` methods instead.
 #""

 #YPE_MAPPING = {
 #tr: ma_fields.String,
 #ytes: ma_fields.String,
 #t.datetime: ma_fields.DateTime,
 #loat: ma_fields.Float,
 #ool: ma_fields.Boolean,
 #uple: ma_fields.Raw,
 #ist: ma_fields.Raw,
 #et: ma_fields.Raw,
 #nt: ma_fields.Integer,
 #uid.UUID: ma_fields.UUID,
 #t.time: ma_fields.Time,
 #t.date: ma_fields.Date,
 #t.timedelta: ma_fields.TimeDelta,
 #ecimal.Decimal: ma_fields.Decimal,
 #  # type: typing.Dict[type, typing.Type[ma_fields.Field]]
    #: Overrides for default schema-level error messages
 #rror_messages = {}  # type: typing.Dict[str, str]

 #default_error_messages = {
 #type": "Invalid input type.",
 #unknown": "Unknown field.",
 #  # type: typing.Dict[str, str]

 #PTIONS_CLASS = SchemaOpts  # type: type

    # These get set by SchemaMeta
 #pts = None  # type: SchemaOpts
 #declared_fields = {}  # type: typing.Dict[str, ma_fields.Field]
 #hooks = {}  # type: typing.Dict[types.Tag, typing.List[str]]

 #lass Meta:
 #""Options object for a Schema.

 #xample usage: ::

 #lass Meta:
 #ields = ("id", "email", "date_created")
 #xclude = ("password", "secret_attribute")

 #vailable options:

 # ``fields``: Tuple or list of fields to include in the serialized result.
 # ``additional``: Tuple or list of fields to include *in addition* to the
 #xplicitly declared fields. ``additional`` and ``fields`` are
 #utually-exclusive options.
 # ``include``: Dictionary of additional fields to include in the schema. It is
 #sually better to define fields as class variables, but you may need to
 #se this option, e.g., if your fields are Python keywords. May be an
 #OrderedDict`.
 # ``exclude``: Tuple or list of fields to exclude in the serialized result.
 #ested fields can be represented with dot delimiters.
 # ``dateformat``: Default format for `Date <fields.Date>` fields.
 # ``datetimeformat``: Default format for `DateTime <fields.DateTime>` fields.
 # ``timeformat``: Default format for `Time <fields.Time>` fields.
 # ``render_module``: Module to use for `loads <Schema.loads>` and `dumps <Schema.dumps>`.
 #efaults to `json` from the standard library.
 # ``ordered``: If `True`, order serialization output according to the
 #rder in which fields were declared. Output of `Schema.dump` will be a
 #collections.OrderedDict`.
 # ``index_errors``: If `True`, errors dictionaries will include the index
 #f invalid items in a collection.
 # ``load_only``: Tuple or list of fields to exclude from serialized results.
 # ``dump_only``: Tuple or list of fields to exclude from deserialization
 # ``unknown``: Whether to exclude, include, or raise an error for unknown
 #ields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`.
 # ``register``: Whether to register the `Schema` with marshmallow's internal
 #lass registry. Must be `True` if you intend to refer to this `Schema`
 #y class name in `Nested` fields. Only set this to `False` when memory
 #sage is critical. Defaults to `True`.
 #""

 #ef __init__(
 #elf,
 #,
 #nly: typing.Optional[types.StrSequenceOrSet] = None,
 #xclude: types.StrSequenceOrSet = (),
 #any: bool = False,
 #ontext: typing.Optional[typing.Dict] = None,
 #oad_only: types.StrSequenceOrSet = (),
 #ump_only: types.StrSequenceOrSet = (),
 #artial: typing.Union[bool, types.StrSequenceOrSet] = False,
 #nknown: typing.Optional[str] = None
 #:
        # Raise error if only or exclude is passed as string, not list of strings
 #f only is not None and not is_collection(only):
 #aise StringNotCollectionError('"only" should be a list of strings')
 #f not is_collection(exclude):
 #aise StringNotCollectionError('"exclude" should be a list of strings')
        # copy declared fields from metaclass
 #elf.declared_fields = copy.deepcopy(self._declared_fields)
 #elf.many = many
 #elf.only = only
 #elf.exclude = set(self.opts.exclude) | set(exclude)
 #elf.ordered = self.opts.ordered
 #elf.load_only = set(load_only) or set(self.opts.load_only)
 #elf.dump_only = set(dump_only) or set(self.opts.dump_only)
 #elf.partial = partial
 #elf.unknown = unknown or self.opts.unknown
 #elf.context = context or {}
 #elf._normalize_nested_options()
        #: Dictionary mapping field_names -> :class:`Field` objects
 #elf.fields = {}  # type: typing.Dict[str, ma_fields.Field]
 #elf.load_fields = {}  # type: typing.Dict[str, ma_fields.Field]
 #elf.dump_fields = {}  # type: typing.Dict[str, ma_fields.Field]
 #elf._init_fields()
 #essages = {}
 #essages.update(self._default_error_messages)
 #or cls in reversed(self.__class__.__mro__):
 #essages.update(getattr(cls, "error_messages", {}))
 #essages.update(self.error_messages or {})
 #elf.error_messages = messages

 #ef __repr__(self) -> str:
 #eturn "<{ClassName}(many={self.many})>".format(
 #lassName=self.__class__.__name__, self=self
 #

 #property
 #ef dict_class(self) -> type:
 #eturn OrderedDict if self.ordered else dict

 #property
 #ef set_class(self) -> type:
 #eturn OrderedSet if self.ordered else set

 #classmethod
 #ef from_dict(
 #ls,
 #ields: typing.Dict[str, typing.Union[ma_fields.Field, type]],
 #,
 #ame: str = "GeneratedSchema"
 # -> type:
 #""Generate a `Schema` class given a dictionary of fields.

 #. code-block:: python

 #rom marshmallow import Schema, fields

 #ersonSchema = Schema.from_dict({"name": fields.Str()})
 #rint(PersonSchema().load({"name": "David"}))  # => {'name': 'David'}

 #enerated schemas are not added to the class registry and therefore cannot
 #e referred to by name in `Nested` fields.

 #param dict fields: Dictionary mapping field names to field instances.
 #param str name: Optional name for the class, which will appear in
 #he ``repr`` for the class.

 #. versionadded:: 3.0.0
 #""
 #ttrs = fields.copy()
 #ttrs["Meta"] = type(
 #GeneratedMeta", (getattr(cls, "Meta", object),), {"register": False}
 #
 #chema_cls = type(name, (cls,), attrs)
 #eturn schema_cls

    ##### Override-able methods #####

 #ef handle_error(
 #elf, error: ValidationError, data: typing.Any, *, many: bool, **kwargs
 #:
 #""Custom error handler function for the schema.

 #param error: The `ValidationError` raised during (de)serialization.
 #param data: The original input data.
 #param many: Value of ``many`` on dump or load.
 #param partial: Value of ``partial`` on load.

 #. versionadded:: 2.0.0

 #. versionchanged:: 3.0.0rc9
 #eceives `many` and `partial` (on deserialization) as keyword arguments.
 #""
 #ass

 #ef get_attribute(self, obj: typing.Any, attr: str, default: typing.Any):
 #""Defines how to pull values from an object to serialize.

 #. versionadded:: 2.0.0

 #. versionchanged:: 3.0.0a1
 #hanged position of ``obj`` and ``attr``.
 #""
 #eturn get_value(obj, attr, default)

    ##### Serialization/Deserialization API #####

 #staticmethod
 #ef _call_and_store(getter_func, data, *, field_name, error_store, index=None):
 #""Call ``getter_func`` with ``data`` as its argument, and store any `ValidationErrors`.

 #param callable getter_func: Function for getting the serialized/deserialized
 #alue from ``data``.
 #param data: The data passed to ``getter_func``.
 #param str field_name: Field name.
 #param int index: Index of the item being validated, if validating a collection,
 #therwise `None`.
 #""
 #ry:
 #alue = getter_func(data)
 #xcept ValidationError as error:
 #rror_store.store_error(error.messages, field_name, index=index)
            # When a Nested field fails validation, the marshalled data is stored
            # on the ValidationError's valid_data attribute
 #eturn error.valid_data or missing
 #eturn value

 #ef _serialize(
 #elf, obj: typing.Union[_T, typing.Iterable[_T]], *, many: bool = False
 #:
 #""Serialize ``obj``.

 #param obj: The object(s) to serialize.
 #param bool many: `True` if ``data`` should be serialized as a collection.
 #return: A dictionary of the serialized data

 #. versionchanged:: 1.0.0
 #enamed from ``marshal``.
 #""
 #f many and obj is not None:
 #eturn [
 #elf._serialize(d, many=False)
 #or d in typing.cast(typing.Iterable[_T], obj)
 #
 #et = self.dict_class()
 #or attr_name, field_obj in self.dump_fields.items():
 #alue = field_obj.serialize(attr_name, obj, accessor=self.get_attribute)
 #f value is missing:
 #ontinue
 #ey = field_obj.data_key if field_obj.data_key is not None else attr_name
 #et[key] = value
 #eturn ret

 #ef dump(self, obj: typing.Any, *, many: typing.Optional[bool] = None):
 #""Serialize an object to native Python data types according to this
 #chema's fields.

 #param obj: The object to serialize.
 #param many: Whether to serialize `obj` as a collection. If `None`, the value
 #or `self.many` is used.
 #return: Serialized data

 #. versionadded:: 1.0.0
 #. versionchanged:: 3.0.0b7
 #his method returns the serialized data rather than a ``(data, errors)`` duple.
 # :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised
 #f ``obj`` is invalid.
 #. versionchanged:: 3.0.0rc9
 #alidation no longer occurs upon serialization.
 #""
 #any = self.many if many is None else bool(many)
 #f self._has_processors(PRE_DUMP):
 #rocessed_obj = self._invoke_dump_processors(
 #RE_DUMP, obj, many=many, original_data=obj
 #
 #lse:
 #rocessed_obj = obj

 #esult = self._serialize(processed_obj, many=many)

 #f self._has_processors(POST_DUMP):
 #esult = self._invoke_dump_processors(
 #OST_DUMP, result, many=many, original_data=obj
 #

 #eturn result

 #ef dumps(
 #elf, obj: typing.Any, *args, many: typing.Optional[bool] = None, **kwargs
 #:
 #""Same as :meth:`dump`, except return a JSON-encoded string.

 #param obj: The object to serialize.
 #param many: Whether to serialize `obj` as a collection. If `None`, the value
 #or `self.many` is used.
 #return: A ``json`` string

 #. versionadded:: 1.0.0
 #. versionchanged:: 3.0.0b7
 #his method returns the serialized data rather than a ``(data, errors)`` duple.
 # :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised
 #f ``obj`` is invalid.
 #""
 #erialized = self.dump(obj, many=many)
 #eturn self.opts.render_module.dumps(serialized, *args, **kwargs)

 #ef _deserialize(
 #elf,
 #ata: typing.Union[
 #yping.Mapping[str, typing.Any],
 #yping.Iterable[typing.Mapping[str, typing.Any]],
 #,
 #,
 #rror_store: ErrorStore,
 #any: bool = False,
 #artial=False,
 #nknown=RAISE,
 #ndex=None
 # -> typing.Union[_T, typing.List[_T]]:
 #""Deserialize ``data``.

 #param dict data: The data to deserialize.
 #param ErrorStore error_store: Structure to store errors.
 #param bool many: `True` if ``data`` should be deserialized as a collection.
 #param bool|tuple partial: Whether to ignore missing fields and not require
 #ny fields declared. Propagates down to ``Nested`` fields as well. If
 #ts value is an iterable, only missing fields listed in that iterable
 #ill be ignored. Use dot delimiters to specify nested fields.
 #param unknown: Whether to exclude, include, or raise an error for unknown
 #ields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`.
 #param int index: Index of the item being serialized (for storing errors) if
 #erializing a collection, otherwise `None`.
 #return: A dictionary of the deserialized data.
 #""
 #ndex_errors = self.opts.index_errors
 #ndex = index if index_errors else None
 #f many:
 #f not is_collection(data):
 #rror_store.store_error([self.error_messages["type"]], index=index)
 #et_l = []  # type: typing.List[_T]
 #lse:
 #et_l = [
 #yping.cast(
 #T,
 #elf._deserialize(
 #yping.cast(typing.Mapping[str, typing.Any], d),
 #rror_store=error_store,
 #any=False,
 #artial=partial,
 #nknown=unknown,
 #ndex=idx,
 #,
 #
 #or idx, d in enumerate(data)
 #
 #eturn ret_l
 #et_d = self.dict_class()
        # Check data is a dict
 #f not isinstance(data, Mapping):
 #rror_store.store_error([self.error_messages["type"]], index=index)
 #lse:
 #artial_is_collection = is_collection(partial)
 #or attr_name, field_obj in self.load_fields.items():
 #ield_name = (
 #ield_obj.data_key if field_obj.data_key is not None else attr_name
 #
 #aw_value = data.get(field_name, missing)
 #f raw_value is missing:
                    # Ignore missing field if we're allowed to.
 #f partial is True or (
 #artial_is_collection and attr_name in partial
 #:
 #ontinue
 #_kwargs = {}
                # Allow partial loading of nested schemas.
 #f partial_is_collection:
 #refix = field_name + "."
 #en_prefix = len(prefix)
 #ub_partial = [
 #[len_prefix:] for f in partial if f.startswith(prefix)
 #
 #_kwargs["partial"] = sub_partial
 #lse:
 #_kwargs["partial"] = partial
 #etter = lambda val: field_obj.deserialize(
 #al, field_name, data, **d_kwargs
 #
 #alue = self._call_and_store(
 #etter_func=getter,
 #ata=raw_value,
 #ield_name=field_name,
 #rror_store=error_store,
 #ndex=index,
 #
 #f value is not missing:
 #ey = field_obj.attribute or attr_name
 #et_value(ret_d, key, value)
 #f unknown != EXCLUDE:
 #ields = {
 #ield_obj.data_key if field_obj.data_key is not None else field_name
 #or field_name, field_obj in self.load_fields.items()
 #
 #or key in set(data) - fields:
 #alue = data[key]
 #f unknown == INCLUDE:
 #et_d[key] = value
 #lif unknown == RAISE:
 #rror_store.store_error(
 #self.error_messages["unknown"]],
 #ey,
 #index if index_errors else None),
 #
 #eturn ret_d

 #ef load(
 #elf,
 #ata: typing.Union[
 #yping.Mapping[str, typing.Any],
 #yping.Iterable[typing.Mapping[str, typing.Any]],
 #,
 #,
 #any: typing.Optional[bool] = None,
 #artial: typing.Optional[typing.Union[bool, types.StrSequenceOrSet]] = None,
 #nknown: typing.Optional[str] = None
 #:
 #""Deserialize a data structure to an object defined by this Schema's fields.

 #param data: The data to deserialize.
 #param many: Whether to deserialize `data` as a collection. If `None`, the
 #alue for `self.many` is used.
 #param partial: Whether to ignore missing fields and not require
 #ny fields declared. Propagates down to ``Nested`` fields as well. If
 #ts value is an iterable, only missing fields listed in that iterable
 #ill be ignored. Use dot delimiters to specify nested fields.
 #param unknown: Whether to exclude, include, or raise an error for unknown
 #ields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`.
 #f `None`, the value for `self.unknown` is used.
 #return: Deserialized data

 #. versionadded:: 1.0.0
 #. versionchanged:: 3.0.0b7
 #his method returns the deserialized data rather than a ``(data, errors)`` duple.
 # :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised
 #f invalid data are passed.
 #""
 #eturn self._do_load(
 #ata, many=many, partial=partial, unknown=unknown, postprocess=True
 #

 #ef loads(
 #elf,
 #son_data: str,
 #,
 #any: typing.Optional[bool] = None,
 #artial: typing.Optional[typing.Union[bool, types.StrSequenceOrSet]] = None,
 #nknown: typing.Optional[str] = None,
 #*kwargs
 #:
 #""Same as :meth:`load`, except it takes a JSON string as input.

 #param json_data: A JSON string of the data to deserialize.
 #param many: Whether to deserialize `obj` as a collection. If `None`, the
 #alue for `self.many` is used.
 #param partial: Whether to ignore missing fields and not require
 #ny fields declared. Propagates down to ``Nested`` fields as well. If
 #ts value is an iterable, only missing fields listed in that iterable
 #ill be ignored. Use dot delimiters to specify nested fields.
 #param unknown: Whether to exclude, include, or raise an error for unknown
 #ields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`.
 #f `None`, the value for `self.unknown` is used.
 #return: Deserialized data

 #. versionadded:: 1.0.0
 #. versionchanged:: 3.0.0b7
 #his method returns the deserialized data rather than a ``(data, errors)`` duple.
 # :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised
 #f invalid data are passed.
 #""
 #ata = self.opts.render_module.loads(json_data, **kwargs)
 #eturn self.load(data, many=many, partial=partial, unknown=unknown)

 #ef _run_validator(
 #elf,
 #alidator_func,
 #utput,
 #,
 #riginal_data,
 #rror_store,
 #any,
 #artial,
 #ass_original,
 #ndex=None
 #:
 #ry:
 #f pass_original:  # Pass original, raw data (before unmarshalling)
 #alidator_func(output, original_data, partial=partial, many=many)
 #lse:
 #alidator_func(output, partial=partial, many=many)
 #xcept ValidationError as err:
 #rror_store.store_error(err.messages, err.field_name, index=index)

 #ef validate(
 #elf,
 #ata: typing.Mapping,
 #,
 #any: typing.Optional[bool] = None,
 #artial: typing.Optional[typing.Union[bool, types.StrSequenceOrSet]] = None
 # -> typing.Dict[str, typing.List[str]]:
 #""Validate `data` against the schema, returning a dictionary of
 #alidation errors.

 #param data: The data to validate.
 #param many: Whether to validate `data` as a collection. If `None`, the
 #alue for `self.many` is used.
 #param partial: Whether to ignore missing fields and not require
 #ny fields declared. Propagates down to ``Nested`` fields as well. If
 #ts value is an iterable, only missing fields listed in that iterable
 #ill be ignored. Use dot delimiters to specify nested fields.
 #return: A dictionary of validation errors.

 #. versionadded:: 1.1.0
 #""
 #ry:
 #elf._do_load(data, many=many, partial=partial, postprocess=False)
 #xcept ValidationError as exc:
 #eturn typing.cast(typing.Dict[str, typing.List[str]], exc.messages)
 #eturn {}

    ##### Private Helpers #####

 #ef _do_load(
 #elf,
 #ata: typing.Union[
 #yping.Mapping[str, typing.Any],
 #yping.Iterable[typing.Mapping[str, typing.Any]],
 #,
 #,
 #any: typing.Optional[bool] = None,
 #artial: typing.Optional[typing.Union[bool, types.StrSequenceOrSet]] = None,
 #nknown: typing.Optional[str] = None,
 #ostprocess: bool = True
 #:
 #""Deserialize `data`, returning the deserialized result.
 #his method is private API.

 #param data: The data to deserialize.
 #param many: Whether to deserialize `data` as a collection. If `None`, the
 #alue for `self.many` is used.
 #param partial: Whether to validate required fields. If its
 #alue is an iterable, only fields listed in that iterable will be
 #gnored will be allowed missing. If `True`, all fields will be allowed missing.
 #f `None`, the value for `self.partial` is used.
 #param unknown: Whether to exclude, include, or raise an error for unknown
 #ields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`.
 #f `None`, the value for `self.unknown` is used.
 #param postprocess: Whether to run post_load methods..
 #return: Deserialized data
 #""
 #rror_store = ErrorStore()
 #rrors = {}  # type: typing.Dict[str, typing.List[str]]
 #any = self.many if many is None else bool(many)
 #nknown = unknown or self.unknown
 #f partial is None:
 #artial = self.partial
        # Run preprocessors
 #f self._has_processors(PRE_LOAD):
 #ry:
 #rocessed_data = self._invoke_load_processors(
 #RE_LOAD, data, many=many, original_data=data, partial=partial
 #
 #xcept ValidationError as err:
 #rrors = err.normalized_messages()
 #esult = (
 #one
 #  # type: typing.Optional[typing.Union[typing.List, typing.Dict]]
 #lse:
 #rocessed_data = data
 #f not errors:
            # Deserialize data
 #esult = self._deserialize(
 #rocessed_data,
 #rror_store=error_store,
 #any=many,
 #artial=partial,
 #nknown=unknown,
 #
            # Run field-level validation
 #elf._invoke_field_validators(
 #rror_store=error_store, data=result, many=many
 #
            # Run schema-level validation
 #f self._has_processors(VALIDATES_SCHEMA):
 #ield_errors = bool(error_store.errors)
 #elf._invoke_schema_validators(
 #rror_store=error_store,
 #ass_many=True,
 #ata=result,
 #riginal_data=data,
 #any=many,
 #artial=partial,
 #ield_errors=field_errors,
 #
 #elf._invoke_schema_validators(
 #rror_store=error_store,
 #ass_many=False,
 #ata=result,
 #riginal_data=data,
 #any=many,
 #artial=partial,
 #ield_errors=field_errors,
 #
 #rrors = error_store.errors
            # Run post processors
 #f not errors and postprocess and self._has_processors(POST_LOAD):
 #ry:
 #esult = self._invoke_load_processors(
 #OST_LOAD,
 #esult,
 #any=many,
 #riginal_data=data,
 #artial=partial,
 #
 #xcept ValidationError as err:
 #rrors = err.normalized_messages()
 #f errors:
 #xc = ValidationError(errors, data=data, valid_data=result)
 #elf.handle_error(exc, data, many=many, partial=partial)
 #aise exc

 #eturn result

 #ef _normalize_nested_options(self) -> None:
 #""Apply then flatten nested schema options.
 #his method is private API.
 #""
 #f self.only is not None:
            # Apply the only option to nested fields.
 #elf.__apply_nested_option("only", self.only, "intersection")
            # Remove the child field names from the only option.
 #elf.only = self.set_class([field.split(".", 1)[0] for field in self.only])
 #f self.exclude:
            # Apply the exclude option to nested fields.
 #elf.__apply_nested_option("exclude", self.exclude, "union")
            # Remove the parent field names from the exclude option.
 #elf.exclude = self.set_class(
 #field for field in self.exclude if "." not in field]
 #

 #ef __apply_nested_option(self, option_name, field_names, set_operation) -> None:
 #""Apply nested options to nested fields"""
        # Split nested field names on the first dot.
 #ested_fields = [name.split(".", 1) for name in field_names if "." in name]
        # Partition the nested field names by parent field.
 #ested_options = defaultdict(list)  # type: defaultdict
 #or parent, nested_names in nested_fields:
 #ested_options[parent].append(nested_names)
        # Apply the nested field options.
 #or key, options in iter(nested_options.items()):
 #ew_options = self.set_class(options)
 #riginal_options = getattr(self.declared_fields[key], option_name, ())
 #f original_options:
 #f set_operation == "union":
 #ew_options |= self.set_class(original_options)
 #f set_operation == "intersection":
 #ew_options &= self.set_class(original_options)
 #etattr(self.declared_fields[key], option_name, new_options)

 #ef _init_fields(self) -> None:
 #""Update self.fields, self.load_fields, and self.dump_fields based on schema options.
 #his method is private API.
 #""
 #f self.opts.fields:
 #vailable_field_names = self.set_class(self.opts.fields)
 #lse:
 #vailable_field_names = self.set_class(self.declared_fields.keys())
 #f self.opts.additional:
 #vailable_field_names |= self.set_class(self.opts.additional)

 #nvalid_fields = self.set_class()

 #f self.only is not None:
            # Return only fields specified in only option
 #ield_names = self.set_class(self.only)

 #nvalid_fields |= field_names - available_field_names
 #lse:
 #ield_names = available_field_names

        # If "exclude" option or param is specified, remove those fields.
 #f self.exclude:
            # Note that this isn't available_field_names, since we want to
            # apply "only" for the actual calculation.
 #ield_names = field_names - self.exclude
 #nvalid_fields |= self.exclude - available_field_names

 #f invalid_fields:
 #essage = "Invalid fields for {}: {}.".format(self, invalid_fields)
 #aise ValueError(message)

 #ields_dict = self.dict_class()
 #or field_name in field_names:
 #ield_obj = self.declared_fields.get(field_name, ma_fields.Inferred())
 #elf._bind_field(field_name, field_obj)
 #ields_dict[field_name] = field_obj

 #oad_fields, dump_fields = self.dict_class(), self.dict_class()
 #or field_name, field_obj in fields_dict.items():
 #f not field_obj.dump_only:
 #oad_fields[field_name] = field_obj
 #f not field_obj.load_only:
 #ump_fields[field_name] = field_obj

 #ump_data_keys = [
 #ield_obj.data_key if field_obj.data_key is not None else name
 #or name, field_obj in dump_fields.items()
 #
 #f len(dump_data_keys) != len(set(dump_data_keys)):
 #ata_keys_duplicates = {
 # for x in dump_data_keys if dump_data_keys.count(x) > 1
 #
 #aise ValueError(
 #The data_key argument for one or more fields collides "
 #with another field's name or data_key argument. "
 #Check the following field names and "
 #data_key arguments: {}".format(list(data_keys_duplicates))
 #
 #oad_attributes = [obj.attribute or name for name, obj in load_fields.items()]
 #f len(load_attributes) != len(set(load_attributes)):
 #ttributes_duplicates = {
 # for x in load_attributes if load_attributes.count(x) > 1
 #
 #aise ValueError(
 #The attribute argument for one or more fields collides "
 #with another field's name or attribute argument. "
 #Check the following field names and "
 #attribute arguments: {}".format(list(attributes_duplicates))
 #

 #elf.fields = fields_dict
 #elf.dump_fields = dump_fields
 #elf.load_fields = load_fields

 #ef on_bind_field(self, field_name: str, field_obj: ma_fields.Field) -> None:
 #""Hook to modify a field when it is bound to the `Schema`.

 #o-op by default.
 #""
 #eturn None

 #ef _bind_field(self, field_name: str, field_obj: ma_fields.Field) -> None:
 #""Bind field to the schema, setting any necessary attributes on the
 #ield (e.g. parent and name).

 #lso set field load_only and dump_only values if field_name was
 #pecified in ``class Meta``.
 #""
 #f field_name in self.load_only:
 #ield_obj.load_only = True
 #f field_name in self.dump_only:
 #ield_obj.dump_only = True
 #ry:
 #ield_obj._bind_to_schema(field_name, self)
 #xcept TypeError as error:
            # Field declared as a class, not an instance. Ignore type checking because
            # we handle unsupported arg types, i.e. this is dead code from
            # the type checker's perspective.
 #f isinstance(field_obj, type) and issubclass(field_obj, base.FieldABC):
 #sg = (
 #Field for "{}" must be declared as a '
 #Field instance, not a class. "
 #Did you mean "fields.{}()"?'.format(field_name, field_obj.__name__)
 #
 #aise TypeError(msg) from error
 #aise error
 #elf.on_bind_field(field_name, field_obj)

 #lru_cache(maxsize=8)
 #ef _has_processors(self, tag) -> bool:
 #eturn bool(self._hooks[(tag, True)] or self._hooks[(tag, False)])

 #ef _invoke_dump_processors(
 #elf, tag: str, data, *, many: bool, original_data=None
 #:
        # The pass_many post-dump processors may do things like add an envelope, so
        # invoke those after invoking the non-pass_many processors which will expect
        # to get a list of items.
 #ata = self._invoke_processors(
 #ag, pass_many=False, data=data, many=many, original_data=original_data
 #
 #ata = self._invoke_processors(
 #ag, pass_many=True, data=data, many=many, original_data=original_data
 #
 #eturn data

 #ef _invoke_load_processors(
 #elf,
 #ag: str,
 #ata,
 #,
 #any: bool,
 #riginal_data,
 #artial: typing.Union[bool, types.StrSequenceOrSet]
 #:
        # This has to invert the order of the dump processors, so run the pass_many
        # processors first.
 #ata = self._invoke_processors(
 #ag,
 #ass_many=True,
 #ata=data,
 #any=many,
 #riginal_data=original_data,
 #artial=partial,
 #
 #ata = self._invoke_processors(
 #ag,
 #ass_many=False,
 #ata=data,
 #any=many,
 #riginal_data=original_data,
 #artial=partial,
 #
 #eturn data

 #ef _invoke_field_validators(self, *, error_store: ErrorStore, data, many: bool):
 #or attr_name in self._hooks[VALIDATES]:
 #alidator = getattr(self, attr_name)
 #alidator_kwargs = validator.__marshmallow_hook__[VALIDATES]
 #ield_name = validator_kwargs["field_name"]

 #ry:
 #ield_obj = self.fields[field_name]
 #xcept KeyError as error:
 #f field_name in self.declared_fields:
 #ontinue
 #aise ValueError(
 #"{}" field does not exist.'.format(field_name)
 # from error

 #ata_key = (
 #ield_obj.data_key if field_obj.data_key is not None else field_name
 #
 #f many:
 #or idx, item in enumerate(data):
 #ry:
 #alue = item[field_obj.attribute or field_name]
 #xcept KeyError:
 #ass
 #lse:
 #alidated_value = self._call_and_store(
 #etter_func=validator,
 #ata=value,
 #ield_name=data_key,
 #rror_store=error_store,
 #ndex=(idx if self.opts.index_errors else None),
 #
 #f validated_value is missing:
 #ata[idx].pop(field_name, None)
 #lse:
 #ry:
 #alue = data[field_obj.attribute or field_name]
 #xcept KeyError:
 #ass
 #lse:
 #alidated_value = self._call_and_store(
 #etter_func=validator,
 #ata=value,
 #ield_name=data_key,
 #rror_store=error_store,
 #
 #f validated_value is missing:
 #ata.pop(field_name, None)

 #ef _invoke_schema_validators(
 #elf,
 #,
 #rror_store: ErrorStore,
 #ass_many: bool,
 #ata,
 #riginal_data,
 #any: bool,
 #artial: typing.Union[bool, types.StrSequenceOrSet],
 #ield_errors: bool = False
 #:
 #or attr_name in self._hooks[(VALIDATES_SCHEMA, pass_many)]:
 #alidator = getattr(self, attr_name)
 #alidator_kwargs = validator.__marshmallow_hook__[
 #VALIDATES_SCHEMA, pass_many)
 #
 #f field_errors and validator_kwargs["skip_on_field_errors"]:
 #ontinue
 #ass_original = validator_kwargs.get("pass_original", False)

 #f many and not pass_many:
 #or idx, (item, orig) in enumerate(zip(data, original_data)):
 #elf._run_validator(
 #alidator,
 #tem,
 #riginal_data=orig,
 #rror_store=error_store,
 #any=many,
 #artial=partial,
 #ndex=idx,
 #ass_original=pass_original,
 #
 #lse:
 #elf._run_validator(
 #alidator,
 #ata,
 #riginal_data=original_data,
 #rror_store=error_store,
 #any=many,
 #ass_original=pass_original,
 #artial=partial,
 #

 #ef _invoke_processors(
 #elf,
 #ag: str,
 #,
 #ass_many: bool,
 #ata,
 #any: bool,
 #riginal_data=None,
 #*kwargs
 #:
 #ey = (tag, pass_many)
 #or attr_name in self._hooks[key]:
            # This will be a bound method.
 #rocessor = getattr(self, attr_name)

 #rocessor_kwargs = processor.__marshmallow_hook__[key]
 #ass_original = processor_kwargs.get("pass_original", False)

 #f many and not pass_many:
 #f pass_original:
 #ata = [
 #rocessor(item, original, many=many, **kwargs)
 #or item, original in zip(data, original_data)
 #
 #lse:
 #ata = [processor(item, many=many, **kwargs) for item in data]
 #lse:
 #f pass_original:
 #ata = processor(data, original_data, many=many, **kwargs)
 #lse:
 #ata = processor(data, many=many, **kwargs)
 #eturn data


BaseSchema = Schema  # for backwards compatibility
