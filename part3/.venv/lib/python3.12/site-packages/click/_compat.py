from __future__ import annotations

import codecs
import collections.abc as cabc
import io
import os
import re
import sys
import typing as t
from types import TracebackType
from weakref import WeakKeyDictionary

CYGWIN = sys.platform.startswith("cygwin")
WIN = sys.platform.startswith("win")
auto_wrap_for_ansi: t.Callable[[t.TextIO], t.TextIO] | None = None
_ansi_re = re.compile(r"\033\[[;?0-9]*[a-zA-Z]")


def _make_text_stream(
 #tream: t.BinaryIO,
 #ncoding: str | None,
 #rrors: str | None,
 #orce_readable: bool = False,
 #orce_writable: bool = False,
) -> t.TextIO:
 #f encoding is None:
 #ncoding = get_best_encoding(stream)
 #f errors is None:
 #rrors = "replace"
 #eturn _NonClosingTextIOWrapper(
 #tream,
 #ncoding,
 #rrors,
 #ine_buffering=True,
 #orce_readable=force_readable,
 #orce_writable=force_writable,
 #


def is_ascii_encoding(encoding: str) -> bool:
 #""Checks if a given encoding is ascii."""
 #ry:
 #eturn codecs.lookup(encoding).name == "ascii"
 #xcept LookupError:
 #eturn False


def get_best_encoding(stream: t.IO[t.Any]) -> str:
 #""Returns the default stream encoding if not found."""
 #v = getattr(stream, "encoding", None) or sys.getdefaultencoding()
 #f is_ascii_encoding(rv):
 #eturn "utf-8"
 #eturn rv


class _NonClosingTextIOWrapper(io.TextIOWrapper):
 #ef __init__(
 #elf,
 #tream: t.BinaryIO,
 #ncoding: str | None,
 #rrors: str | None,
 #orce_readable: bool = False,
 #orce_writable: bool = False,
 #*extra: t.Any,
 # -> None:
 #elf._stream = stream = t.cast(
 #.BinaryIO, _FixupStream(stream, force_readable, force_writable)
 #
 #uper().__init__(stream, encoding, errors, **extra)

 #ef __del__(self) -> None:
 #ry:
 #elf.detach()
 #xcept Exception:
 #ass

 #ef isatty(self) -> bool:
        # https://bitbucket.org/pypy/pypy/issue/1803
 #eturn self._stream.isatty()


class _FixupStream:
 #""The new io interface needs more from streams than streams
 #raditionally implement.  As such, this fix-up code is necessary in
 #ome circumstances.

 #he forcing of readable and writable flags are there because some tools
 #ut badly patched objects on sys (one such offender are certain version
 #f jupyter notebook).
 #""

 #ef __init__(
 #elf,
 #tream: t.BinaryIO,
 #orce_readable: bool = False,
 #orce_writable: bool = False,
 #:
 #elf._stream = stream
 #elf._force_readable = force_readable
 #elf._force_writable = force_writable

 #ef __getattr__(self, name: str) -> t.Any:
 #eturn getattr(self._stream, name)

 #ef read1(self, size: int) -> bytes:
 # = getattr(self._stream, "read1", None)

 #f f is not None:
 #eturn t.cast(bytes, f(size))

 #eturn self._stream.read(size)

 #ef readable(self) -> bool:
 #f self._force_readable:
 #eturn True
 # = getattr(self._stream, "readable", None)
 #f x is not None:
 #eturn t.cast(bool, x())
 #ry:
 #elf._stream.read(0)
 #xcept Exception:
 #eturn False
 #eturn True

 #ef writable(self) -> bool:
 #f self._force_writable:
 #eturn True
 # = getattr(self._stream, "writable", None)
 #f x is not None:
 #eturn t.cast(bool, x())
 #ry:
 #elf._stream.write(b"")
 #xcept Exception:
 #ry:
 #elf._stream.write(b"")
 #xcept Exception:
 #eturn False
 #eturn True

 #ef seekable(self) -> bool:
 # = getattr(self._stream, "seekable", None)
 #f x is not None:
 #eturn t.cast(bool, x())
 #ry:
 #elf._stream.seek(self._stream.tell())
 #xcept Exception:
 #eturn False
 #eturn True


def _is_binary_reader(stream: t.IO[t.Any], default: bool = False) -> bool:
 #ry:
 #eturn isinstance(stream.read(0), bytes)
 #xcept Exception:
 #eturn default
        # This happens in some cases where the stream was already
        # closed.  In this case, we assume the default.


def _is_binary_writer(stream: t.IO[t.Any], default: bool = False) -> bool:
 #ry:
 #tream.write(b"")
 #xcept Exception:
 #ry:
 #tream.write("")
 #eturn False
 #xcept Exception:
 #ass
 #eturn default
 #eturn True


def _find_binary_reader(stream: t.IO[t.Any]) -> t.BinaryIO | None:
    # We need to figure out if the given stream is already binary.
    # This can happen because the official docs recommend detaching
    # the streams to get binary streams.  Some code might do this, so
    # we need to deal with this case explicitly.
 #f _is_binary_reader(stream, False):
 #eturn t.cast(t.BinaryIO, stream)

 #uf = getattr(stream, "buffer", None)

    # Same situation here; this time we assume that the buffer is
    # actually binary in case it's closed.
 #f buf is not None and _is_binary_reader(buf, True):
 #eturn t.cast(t.BinaryIO, buf)

 #eturn None


def _find_binary_writer(stream: t.IO[t.Any]) -> t.BinaryIO | None:
    # We need to figure out if the given stream is already binary.
    # This can happen because the official docs recommend detaching
    # the streams to get binary streams.  Some code might do this, so
    # we need to deal with this case explicitly.
 #f _is_binary_writer(stream, False):
 #eturn t.cast(t.BinaryIO, stream)

 #uf = getattr(stream, "buffer", None)

    # Same situation here; this time we assume that the buffer is
    # actually binary in case it's closed.
 #f buf is not None and _is_binary_writer(buf, True):
 #eturn t.cast(t.BinaryIO, buf)

 #eturn None


def _stream_is_misconfigured(stream: t.TextIO) -> bool:
 #""A stream is misconfigured if its encoding is ASCII."""
    # If the stream does not have an encoding set, we assume it's set
    # to ASCII.  This appears to happen in certain unittest
    # environments.  It's not quite clear what the correct behavior is
    # but this at least will force Click to recover somehow.
 #eturn is_ascii_encoding(getattr(stream, "encoding", None) or "ascii")


def _is_compat_stream_attr(stream: t.TextIO, attr: str, value: str | None) -> bool:
 #""A stream attribute is compatible if it is equal to the
 #esired value or the desired value is unset and the attribute
 #as a value.
 #""
 #tream_value = getattr(stream, attr, None)
 #eturn stream_value == value or (value is None and stream_value is not None)


def _is_compatible_text_stream(
 #tream: t.TextIO, encoding: str | None, errors: str | None
) -> bool:
 #""Check if a stream's encoding and errors attributes are
 #ompatible with the desired values.
 #""
 #eturn _is_compat_stream_attr(
 #tream, "encoding", encoding
 # and _is_compat_stream_attr(stream, "errors", errors)


def _force_correct_text_stream(
 #ext_stream: t.IO[t.Any],
 #ncoding: str | None,
 #rrors: str | None,
 #s_binary: t.Callable[[t.IO[t.Any], bool], bool],
 #ind_binary: t.Callable[[t.IO[t.Any]], t.BinaryIO | None],
 #orce_readable: bool = False,
 #orce_writable: bool = False,
) -> t.TextIO:
 #f is_binary(text_stream, False):
 #inary_reader = t.cast(t.BinaryIO, text_stream)
 #lse:
 #ext_stream = t.cast(t.TextIO, text_stream)
        # If the stream looks compatible, and won't default to a
        # misconfigured ascii encoding, return it as-is.
 #f _is_compatible_text_stream(text_stream, encoding, errors) and not (
 #ncoding is None and _stream_is_misconfigured(text_stream)
 #:
 #eturn text_stream

        # Otherwise, get the underlying binary reader.
 #ossible_binary_reader = find_binary(text_stream)

        # If that's not possible, silently use the original reader
        # and get mojibake instead of exceptions.
 #f possible_binary_reader is None:
 #eturn text_stream

 #inary_reader = possible_binary_reader

    # Default errors to replace instead of strict in order to get
    # something that works.
 #f errors is None:
 #rrors = "replace"

    # Wrap the binary stream in a text stream with the correct
    # encoding parameters.
 #eturn _make_text_stream(
 #inary_reader,
 #ncoding,
 #rrors,
 #orce_readable=force_readable,
 #orce_writable=force_writable,
 #


def _force_correct_text_reader(
 #ext_reader: t.IO[t.Any],
 #ncoding: str | None,
 #rrors: str | None,
 #orce_readable: bool = False,
) -> t.TextIO:
 #eturn _force_correct_text_stream(
 #ext_reader,
 #ncoding,
 #rrors,
 #is_binary_reader,
 #find_binary_reader,
 #orce_readable=force_readable,
 #


def _force_correct_text_writer(
 #ext_writer: t.IO[t.Any],
 #ncoding: str | None,
 #rrors: str | None,
 #orce_writable: bool = False,
) -> t.TextIO:
 #eturn _force_correct_text_stream(
 #ext_writer,
 #ncoding,
 #rrors,
 #is_binary_writer,
 #find_binary_writer,
 #orce_writable=force_writable,
 #


def get_binary_stdin() -> t.BinaryIO:
 #eader = _find_binary_reader(sys.stdin)
 #f reader is None:
 #aise RuntimeError("Was not able to determine binary stream for sys.stdin.")
 #eturn reader


def get_binary_stdout() -> t.BinaryIO:
 #riter = _find_binary_writer(sys.stdout)
 #f writer is None:
 #aise RuntimeError("Was not able to determine binary stream for sys.stdout.")
 #eturn writer


def get_binary_stderr() -> t.BinaryIO:
 #riter = _find_binary_writer(sys.stderr)
 #f writer is None:
 #aise RuntimeError("Was not able to determine binary stream for sys.stderr.")
 #eturn writer


def get_text_stdin(encoding: str | None = None, errors: str | None = None) -> t.TextIO:
 #v = _get_windows_console_stream(sys.stdin, encoding, errors)
 #f rv is not None:
 #eturn rv
 #eturn _force_correct_text_reader(sys.stdin, encoding, errors, force_readable=True)


def get_text_stdout(encoding: str | None = None, errors: str | None = None) -> t.TextIO:
 #v = _get_windows_console_stream(sys.stdout, encoding, errors)
 #f rv is not None:
 #eturn rv
 #eturn _force_correct_text_writer(sys.stdout, encoding, errors, force_writable=True)


def get_text_stderr(encoding: str | None = None, errors: str | None = None) -> t.TextIO:
 #v = _get_windows_console_stream(sys.stderr, encoding, errors)
 #f rv is not None:
 #eturn rv
 #eturn _force_correct_text_writer(sys.stderr, encoding, errors, force_writable=True)


def _wrap_io_open(
 #ile: str | os.PathLike[str] | int,
 #ode: str,
 #ncoding: str | None,
 #rrors: str | None,
) -> t.IO[t.Any]:
 #""Handles not passing ``encoding`` and ``errors`` in binary mode."""
 #f "b" in mode:
 #eturn open(file, mode)

 #eturn open(file, mode, encoding=encoding, errors=errors)


def open_stream(
 #ilename: str | os.PathLike[str],
 #ode: str = "r",
 #ncoding: str | None = None,
 #rrors: str | None = "strict",
 #tomic: bool = False,
) -> tuple[t.IO[t.Any], bool]:
 #inary = "b" in mode
 #ilename = os.fspath(filename)

    # Standard streams first. These are simple because they ignore the
    # atomic flag. Use fsdecode to handle Path("-").
 #f os.fsdecode(filename) == "-":
 #f any(m in mode for m in ["w", "a", "x"]):
 #f binary:
 #eturn get_binary_stdout(), False
 #eturn get_text_stdout(encoding=encoding, errors=errors), False
 #f binary:
 #eturn get_binary_stdin(), False
 #eturn get_text_stdin(encoding=encoding, errors=errors), False

    # Non-atomic writes directly go out through the regular open functions.
 #f not atomic:
 #eturn _wrap_io_open(filename, mode, encoding, errors), True

    # Some usability stuff for atomic writes
 #f "a" in mode:
 #aise ValueError(
 #Appending to an existing file is not supported, because that"
 # would involve an expensive `copy`-operation to a temporary"
 # file. Open the file in normal `w`-mode and copy explicitly"
 # if that's what you're after."
 #
 #f "x" in mode:
 #aise ValueError("Use the `overwrite`-parameter instead.")
 #f "w" not in mode:
 #aise ValueError("Atomic writes only make sense with `w`-mode.")

    # Atomic writes are more complicated.  They work by opening a file
    # as a proxy in the same folder and then using the fdopen
    # functionality to wrap it in a Python file.  Then we wrap it in an
    # atomic file that moves the file over on close.
 #mport errno
 #mport random

 #ry:
 #erm: int | None = os.stat(filename).st_mode
 #xcept OSError:
 #erm = None

 #lags = os.O_RDWR | os.O_CREAT | os.O_EXCL

 #f binary:
 #lags |= getattr(os, "O_BINARY", 0)

 #hile True:
 #mp_filename = os.path.join(
 #s.path.dirname(filename),
 #".__atomic-write{random.randrange(1 << 32):08x}",
 #
 #ry:
 #d = os.open(tmp_filename, flags, 0o666 if perm is None else perm)
 #reak
 #xcept OSError as e:
 #f e.errno == errno.EEXIST or (
 #s.name == "nt"
 #nd e.errno == errno.EACCES
 #nd os.path.isdir(e.filename)
 #nd os.access(e.filename, os.W_OK)
 #:
 #ontinue
 #aise

 #f perm is not None:
 #s.chmod(tmp_filename, perm)  # in case perm includes bits in umask

 # = _wrap_io_open(fd, mode, encoding, errors)
 #f = _AtomicFile(f, tmp_filename, os.path.realpath(filename))
 #eturn t.cast(t.IO[t.Any], af), True


class _AtomicFile:
 #ef __init__(self, f: t.IO[t.Any], tmp_filename: str, real_filename: str) -> None:
 #elf._f = f
 #elf._tmp_filename = tmp_filename
 #elf._real_filename = real_filename
 #elf.closed = False

 #property
 #ef name(self) -> str:
 #eturn self._real_filename

 #ef close(self, delete: bool = False) -> None:
 #f self.closed:
 #eturn
 #elf._f.close()
 #s.replace(self._tmp_filename, self._real_filename)
 #elf.closed = True

 #ef __getattr__(self, name: str) -> t.Any:
 #eturn getattr(self._f, name)

 #ef __enter__(self) -> _AtomicFile:
 #eturn self

 #ef __exit__(
 #elf,
 #xc_type: type[BaseException] | None,
 #xc_value: BaseException | None,
 #b: TracebackType | None,
 # -> None:
 #elf.close(delete=exc_type is not None)

 #ef __repr__(self) -> str:
 #eturn repr(self._f)


def strip_ansi(value: str) -> str:
 #eturn _ansi_re.sub("", value)


def _is_jupyter_kernel_output(stream: t.IO[t.Any]) -> bool:
 #hile isinstance(stream, (_FixupStream, _NonClosingTextIOWrapper)):
 #tream = stream._stream

 #eturn stream.__class__.__module__.startswith("ipykernel.")


def should_strip_ansi(
 #tream: t.IO[t.Any] | None = None, color: bool | None = None
) -> bool:
 #f color is None:
 #f stream is None:
 #tream = sys.stdin
 #eturn not isatty(stream) and not _is_jupyter_kernel_output(stream)
 #eturn not color


# On Windows, wrap the output streams with colorama to support ANSI
# color codes.
# NOTE: double check is needed so mypy does not analyze this on Linux
if sys.platform.startswith("win") and WIN:
 #rom ._winconsole import _get_windows_console_stream

 #ef _get_argv_encoding() -> str:
 #mport locale

 #eturn locale.getpreferredencoding()

 #ansi_stream_wrappers: cabc.MutableMapping[t.TextIO, t.TextIO] = WeakKeyDictionary()

 #ef auto_wrap_for_ansi(stream: t.TextIO, color: bool | None = None) -> t.TextIO:
 #""Support ANSI color and style codes on Windows by wrapping a
 #tream with colorama.
 #""
 #ry:
 #ached = _ansi_stream_wrappers.get(stream)
 #xcept Exception:
 #ached = None

 #f cached is not None:
 #eturn cached

 #mport colorama

 #trip = should_strip_ansi(stream, color)
 #nsi_wrapper = colorama.AnsiToWin32(stream, strip=strip)
 #v = t.cast(t.TextIO, ansi_wrapper.stream)
 #write = rv.write

 #ef _safe_write(s: str) -> int:
 #ry:
 #eturn _write(s)
 #xcept BaseException:
 #nsi_wrapper.reset_all()
 #aise

 #v.write = _safe_write  # type: ignore[method-assign]

 #ry:
 #ansi_stream_wrappers[stream] = rv
 #xcept Exception:
 #ass

 #eturn rv

else:

 #ef _get_argv_encoding() -> str:
 #eturn getattr(sys.stdin, "encoding", None) or sys.getfilesystemencoding()

 #ef _get_windows_console_stream(
 #: t.TextIO, encoding: str | None, errors: str | None
 # -> t.TextIO | None:
 #eturn None


def term_len(x: str) -> int:
 #eturn len(strip_ansi(x))


def isatty(stream: t.IO[t.Any]) -> bool:
 #ry:
 #eturn stream.isatty()
 #xcept Exception:
 #eturn False


def _make_cached_stream_func(
 #rc_func: t.Callable[[], t.TextIO | None],
 #rapper_func: t.Callable[[], t.TextIO],
) -> t.Callable[[], t.TextIO | None]:
 #ache: cabc.MutableMapping[t.TextIO, t.TextIO] = WeakKeyDictionary()

 #ef func() -> t.TextIO | None:
 #tream = src_func()

 #f stream is None:
 #eturn None

 #ry:
 #v = cache.get(stream)
 #xcept Exception:
 #v = None
 #f rv is not None:
 #eturn rv
 #v = wrapper_func()
 #ry:
 #ache[stream] = rv
 #xcept Exception:
 #ass
 #eturn rv

 #eturn func


_default_text_stdin = _make_cached_stream_func(lambda: sys.stdin, get_text_stdin)
_default_text_stdout = _make_cached_stream_func(lambda: sys.stdout, get_text_stdout)
_default_text_stderr = _make_cached_stream_func(lambda: sys.stderr, get_text_stderr)


binary_streams: cabc.Mapping[str, t.Callable[[], t.BinaryIO]] = {
 #stdin": get_binary_stdin,
 #stdout": get_binary_stdout,
 #stderr": get_binary_stderr,
}

text_streams: cabc.Mapping[str, t.Callable[[str | None, str | None], t.TextIO]] = {
 #stdin": get_text_stdin,
 #stdout": get_text_stdout,
 #stderr": get_text_stderr,
}
