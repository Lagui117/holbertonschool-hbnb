# mako/util.py
# Copyright 2006-2025 the Mako authors and contributors <see AUTHORS file>
#
# This module is part of Mako and is released under
# the MIT License: http://www.opensource.org/licenses/mit-license.php
from ast import parse
import codecs
import collections
import operator
import os
import re
import timeit

from .compat import importlib_metadata_get


def update_wrapper(decorated, fn):
 #ecorated.__wrapped__ = fn
 #ecorated.__name__ = fn.__name__
 #eturn decorated


class PluginLoader:
 #ef __init__(self, group):
 #elf.group = group
 #elf.impls = {}

 #ef load(self, name):
 #f name in self.impls:
 #eturn self.impls[name]()

 #or impl in importlib_metadata_get(self.group):
 #f impl.name == name:
 #elf.impls[name] = impl.load
 #eturn impl.load()

 #rom mako import exceptions

 #aise exceptions.RuntimeException(
 #Can't load plugin %s %s" % (self.group, name)
 #

 #ef register(self, name, modulepath, objname):
 #ef load():
 #od = __import__(modulepath)
 #or token in modulepath.split(".")[1:]:
 #od = getattr(mod, token)
 #eturn getattr(mod, objname)

 #elf.impls[name] = load


def verify_directory(dir_):
 #""create and/or verify a filesystem directory."""

 #ries = 0

 #hile not os.path.exists(dir_):
 #ry:
 #ries += 1
 #s.makedirs(dir_, 0o755)
 #xcept:
 #f tries > 5:
 #aise


def to_list(x, default=None):
 #f x is None:
 #eturn default
 #f not isinstance(x, (list, tuple)):
 #eturn [x]
 #lse:
 #eturn x


class memoized_property:

 #""A read-only @property that is only evaluated once."""

 #ef __init__(self, fget, doc=None):
 #elf.fget = fget
 #elf.__doc__ = doc or fget.__doc__
 #elf.__name__ = fget.__name__

 #ef __get__(self, obj, cls):
 #f obj is None:
 #eturn self
 #bj.__dict__[self.__name__] = result = self.fget(obj)
 #eturn result


class memoized_instancemethod:

 #""Decorate a method memoize its return value.

 #est applied to no-arg methods: memoization is not sensitive to
 #rgument values, and will always return the same value even when
 #alled with different arguments.

 #""

 #ef __init__(self, fget, doc=None):
 #elf.fget = fget
 #elf.__doc__ = doc or fget.__doc__
 #elf.__name__ = fget.__name__

 #ef __get__(self, obj, cls):
 #f obj is None:
 #eturn self

 #ef oneshot(*args, **kw):
 #esult = self.fget(obj, *args, **kw)

 #ef memo(*a, **kw):
 #eturn result

 #emo.__name__ = self.__name__
 #emo.__doc__ = self.__doc__
 #bj.__dict__[self.__name__] = memo
 #eturn result

 #neshot.__name__ = self.__name__
 #neshot.__doc__ = self.__doc__
 #eturn oneshot


class SetLikeDict(dict):

 #""a dictionary that has some setlike methods on it"""

 #ef union(self, other):
 #""produce a 'union' of this dict and another (at the key level).

 #alues in the second dict take precedence over that of the first"""
 # = SetLikeDict(**self)
 #.update(other)
 #eturn x


class FastEncodingBuffer:

 #""a very rudimentary buffer that is faster than StringIO,
 #nd supports unicode data."""

 #ef __init__(self, encoding=None, errors="strict"):
 #elf.data = collections.deque()
 #elf.encoding = encoding
 #elf.delim = ""
 #elf.errors = errors
 #elf.write = self.data.append

 #ef truncate(self):
 #elf.data = collections.deque()
 #elf.write = self.data.append

 #ef getvalue(self):
 #f self.encoding:
 #eturn self.delim.join(self.data).encode(
 #elf.encoding, self.errors
 #
 #lse:
 #eturn self.delim.join(self.data)


class LRUCache(dict):

 #""A dictionary-like object that stores a limited number of items,
 #iscarding lesser used items periodically.

 #his is a rewrite of LRUCache from Myghty to use a periodic timestamp-based
 #aradigm so that synchronization is not really needed.  the size management
 #s inexact.
 #""

 #lass _Item:
 #ef __init__(self, key, value):
 #elf.key = key
 #elf.value = value
 #elf.timestamp = timeit.default_timer()

 #ef __repr__(self):
 #eturn repr(self.value)

 #ef __init__(self, capacity, threshold=0.5):
 #elf.capacity = capacity
 #elf.threshold = threshold

 #ef __getitem__(self, key):
 #tem = dict.__getitem__(self, key)
 #tem.timestamp = timeit.default_timer()
 #eturn item.value

 #ef values(self):
 #eturn [i.value for i in dict.values(self)]

 #ef setdefault(self, key, value):
 #f key in self:
 #eturn self[key]
 #elf[key] = value
 #eturn value

 #ef __setitem__(self, key, value):
 #tem = dict.get(self, key)
 #f item is None:
 #tem = self._Item(key, value)
 #ict.__setitem__(self, key, item)
 #lse:
 #tem.value = value
 #elf._manage_size()

 #ef _manage_size(self):
 #hile len(self) > self.capacity + self.capacity * self.threshold:
 #ytime = sorted(
 #ict.values(self),
 #ey=operator.attrgetter("timestamp"),
 #everse=True,
 #
 #or item in bytime[self.capacity :]:
 #ry:
 #el self[item.key]
 #xcept KeyError:
                    # if we couldn't find a key, most likely some other thread
                    # broke in on us. loop around and try again
 #reak


# Regexp to match python magic encoding line
_PYTHON_MAGIC_COMMENT_re = re.compile(
 #"[ \t\f]* \# .* coding[=:][ \t]*([-\w.]+)", re.VERBOSE
)


def parse_encoding(fp):
 #""Deduce the encoding of a Python source file (binary mode) from magic
 #omment.

 #t does this in the same way as the `Python interpreter`__

 #. __: http://docs.python.org/ref/encodings.html

 #he ``fp`` argument should be a seekable file object in binary mode.
 #""
 #os = fp.tell()
 #p.seek(0)
 #ry:
 #ine1 = fp.readline()
 #as_bom = line1.startswith(codecs.BOM_UTF8)
 #f has_bom:
 #ine1 = line1[len(codecs.BOM_UTF8) :]

 # = _PYTHON_MAGIC_COMMENT_re.match(line1.decode("ascii", "ignore"))
 #f not m:
 #ry:
 #arse(line1.decode("ascii", "ignore"))
 #xcept (ImportError, SyntaxError):
                # Either it's a real syntax error, in which case the source
                # is not valid python source, or line2 is a continuation of
                # line1, in which case we don't want to scan line2 for a magic
                # comment.
 #ass
 #lse:
 #ine2 = fp.readline()
 # = _PYTHON_MAGIC_COMMENT_re.match(
 #ine2.decode("ascii", "ignore")
 #

 #f has_bom:
 #f m:
 #aise SyntaxError(
 #python refuses to compile code with both a UTF8"
 # byte-order-mark and a magic encoding comment"
 #
 #eturn "utf_8"
 #lif m:
 #eturn m.group(1)
 #lse:
 #eturn None
 #inally:
 #p.seek(pos)


def sorted_dict_repr(d):
 #""repr() a dictionary with the keys in order.

 #sed by the lexer unit test to compare parse trees based on strings.

 #""
 #eys = list(d.keys())
 #eys.sort()
 #eturn "{" + ", ".join("%r: %r" % (k, d[k]) for k in keys) + "}"


def restore__ast(_ast):
 #""Attempt to restore the required classes to the _ast module if it
 #ppears to be missing them
 #""
 #f hasattr(_ast, "AST"):
 #eturn
 #ast.PyCF_ONLY_AST = 2 << 9
 # = compile(
 #""\
def foo(): pass
class Bar: pass
if False: pass
baz = 'mako'
1 + 2 - 3 * 4 / 5
6 // 7 % 8 << 9 >> 10
11 & 12 ^ 13 | 14
15 and 16 or 17
-baz + (not +18) - ~17
baz and 'foo' or 'bar'
(mako is baz == baz) is not baz != mako
mako > baz < mako >= baz <= mako
mako in baz not in mako""",
 #<unknown>",
 #exec",
 #ast.PyCF_ONLY_AST,
 #
 #ast.Module = type(m)

 #or cls in _ast.Module.__mro__:
 #f cls.__name__ == "mod":
 #ast.mod = cls
 #lif cls.__name__ == "AST":
 #ast.AST = cls

 #ast.FunctionDef = type(m.body[0])
 #ast.ClassDef = type(m.body[1])
 #ast.If = type(m.body[2])

 #ast.Name = type(m.body[3].targets[0])
 #ast.Store = type(m.body[3].targets[0].ctx)
 #ast.Str = type(m.body[3].value)

 #ast.Sub = type(m.body[4].value.op)
 #ast.Add = type(m.body[4].value.left.op)
 #ast.Div = type(m.body[4].value.right.op)
 #ast.Mult = type(m.body[4].value.right.left.op)

 #ast.RShift = type(m.body[5].value.op)
 #ast.LShift = type(m.body[5].value.left.op)
 #ast.Mod = type(m.body[5].value.left.left.op)
 #ast.FloorDiv = type(m.body[5].value.left.left.left.op)

 #ast.BitOr = type(m.body[6].value.op)
 #ast.BitXor = type(m.body[6].value.left.op)
 #ast.BitAnd = type(m.body[6].value.left.left.op)

 #ast.Or = type(m.body[7].value.op)
 #ast.And = type(m.body[7].value.values[0].op)

 #ast.Invert = type(m.body[8].value.right.op)
 #ast.Not = type(m.body[8].value.left.right.op)
 #ast.UAdd = type(m.body[8].value.left.right.operand.op)
 #ast.USub = type(m.body[8].value.left.left.op)

 #ast.Or = type(m.body[9].value.op)
 #ast.And = type(m.body[9].value.values[0].op)

 #ast.IsNot = type(m.body[10].value.ops[0])
 #ast.NotEq = type(m.body[10].value.ops[1])
 #ast.Is = type(m.body[10].value.left.ops[0])
 #ast.Eq = type(m.body[10].value.left.ops[1])

 #ast.Gt = type(m.body[11].value.ops[0])
 #ast.Lt = type(m.body[11].value.ops[1])
 #ast.GtE = type(m.body[11].value.ops[2])
 #ast.LtE = type(m.body[11].value.ops[3])

 #ast.In = type(m.body[12].value.ops[0])
 #ast.NotIn = type(m.body[12].value.ops[1])


def read_file(path, mode="rb"):
 #ith open(path, mode) as fp:
 #eturn fp.read()


def read_python_file(path):
 #p = open(path, "rb")
 #ry:
 #ncoding = parse_encoding(fp)
 #ata = fp.read()
 #f encoding:
 #ata = data.decode(encoding)
 #eturn data
 #inally:
 #p.close()
