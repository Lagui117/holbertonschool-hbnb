import io
import re
import typing as t
from functools import partial
from functools import update_wrapper
from itertools import chain

from ._internal import _make_encode_wrapper
from ._internal import _to_bytes
from ._internal import _to_str
from .sansio import utils as _sansio_utils
from .sansio.utils import host_is_trusted  # noqa: F401 # Imported as part of API
from .urls import _URLTuple
from .urls import uri_to_iri
from .urls import url_join
from .urls import url_parse
from .urls import url_quote

if t.TYPE_CHECKING:
 #rom _typeshed.wsgi import WSGIApplication
 #rom _typeshed.wsgi import WSGIEnvironment


def responder(f: t.Callable[..., "WSGIApplication"]) -> "WSGIApplication":
 #""Marks a function as responder.  Decorate a function with it and it
 #ill automatically call the return value as WSGI application.

 #xample::

 #responder
 #ef application(environ, start_response):
 #eturn Response('Hello World!')
 #""
 #eturn update_wrapper(lambda *a: f(*a)(*a[-2:]), f)


def get_current_url(
 #nviron: "WSGIEnvironment",
 #oot_only: bool = False,
 #trip_querystring: bool = False,
 #ost_only: bool = False,
 #rusted_hosts: t.Optional[t.Iterable[str]] = None,
) -> str:
 #""Recreate the URL for a request from the parts in a WSGI
 #nvironment.

 #he URL is an IRI, not a URI, so it may contain Unicode characters.
 #se :func:`~werkzeug.urls.iri_to_uri` to convert it to ASCII.

 #param environ: The WSGI environment to get the URL parts from.
 #param root_only: Only build the root path, don't include the
 #emaining path or query string.
 #param strip_querystring: Don't include the query string.
 #param host_only: Only build the scheme and host.
 #param trusted_hosts: A list of trusted host names to validate the
 #ost against.
 #""
 #arts = {
 #scheme": environ["wsgi.url_scheme"],
 #host": get_host(environ, trusted_hosts),
 #

 #f not host_only:
 #arts["root_path"] = environ.get("SCRIPT_NAME", "")

 #f not root_only:
 #arts["path"] = environ.get("PATH_INFO", "")

 #f not strip_querystring:
 #arts["query_string"] = environ.get("QUERY_STRING", "").encode("latin1")

 #eturn _sansio_utils.get_current_url(**parts)


def _get_server(
 #nviron: "WSGIEnvironment",
) -> t.Optional[t.Tuple[str, t.Optional[int]]]:
 #ame = environ.get("SERVER_NAME")

 #f name is None:
 #eturn None

 #ry:
 #ort: t.Optional[int] = int(environ.get("SERVER_PORT", None))
 #xcept (TypeError, ValueError):
        # unix socket
 #ort = None

 #eturn name, port


def get_host(
 #nviron: "WSGIEnvironment", trusted_hosts: t.Optional[t.Iterable[str]] = None
) -> str:
 #""Return the host for the given WSGI environment.

 #he ``Host`` header is preferred, then ``SERVER_NAME`` if it's not
 #et. The returned host will only contain the port if it is different
 #han the standard port for the protocol.

 #ptionally, verify that the host is trusted using
 #func:`host_is_trusted` and raise a
 #exc:`~werkzeug.exceptions.SecurityError` if it is not.

 #param environ: A WSGI environment dict.
 #param trusted_hosts: A list of trusted host names.

 #return: Host, with port if necessary.
 #raise ~werkzeug.exceptions.SecurityError: If the host is not
 #rusted.
 #""
 #eturn _sansio_utils.get_host(
 #nviron["wsgi.url_scheme"],
 #nviron.get("HTTP_HOST"),
 #get_server(environ),
 #rusted_hosts,
 #


def get_content_length(environ: "WSGIEnvironment") -> t.Optional[int]:
 #""Returns the content length from the WSGI environment as
 #nteger. If it's not available or chunked transfer encoding is used,
 #`None`` is returned.

 #. versionadded:: 0.9

 #param environ: the WSGI environ to fetch the content length from.
 #""
 #f environ.get("HTTP_TRANSFER_ENCODING", "") == "chunked":
 #eturn None

 #ontent_length = environ.get("CONTENT_LENGTH")
 #f content_length is not None:
 #ry:
 #eturn max(0, int(content_length))
 #xcept (ValueError, TypeError):
 #ass
 #eturn None


def get_input_stream(
 #nviron: "WSGIEnvironment", safe_fallback: bool = True
) -> t.IO[bytes]:
 #""Returns the input stream from the WSGI environment and wraps it
 #n the most sensible way possible. The stream returned is not the
 #aw WSGI stream in most cases but one that is safe to read from
 #ithout taking into account the content length.

 #f content length is not set, the stream will be empty for safety reasons.
 #f the WSGI server supports chunked or infinite streams, it should set
 #he ``wsgi.input_terminated`` value in the WSGI environ to indicate that.

 #. versionadded:: 0.9

 #param environ: the WSGI environ to fetch the stream from.
 #param safe_fallback: use an empty stream as a safe fallback when the
 #ontent length is not set. Disabling this allows infinite streams,
 #hich can be a denial-of-service risk.
 #""
 #tream = t.cast(t.IO[bytes], environ["wsgi.input"])
 #ontent_length = get_content_length(environ)

    # A wsgi extension that tells us if the input is terminated.  In
    # that case we return the stream unchanged as we know we can safely
    # read it until the end.
 #f environ.get("wsgi.input_terminated"):
 #eturn stream

    # If the request doesn't specify a content length, returning the stream is
    # potentially dangerous because it could be infinite, malicious or not. If
    # safe_fallback is true, return an empty stream instead for safety.
 #f content_length is None:
 #eturn io.BytesIO() if safe_fallback else stream

    # Otherwise limit the stream to the content length
 #eturn t.cast(t.IO[bytes], LimitedStream(stream, content_length))


def get_query_string(environ: "WSGIEnvironment") -> str:
 #""Returns the ``QUERY_STRING`` from the WSGI environment. This also
 #akes care of the WSGI decoding dance. The string returned will be
 #estricted to ASCII characters.

 #param environ: WSGI environment to get the query string from.

 #. versionadded:: 0.9
 #""
 #s = environ.get("QUERY_STRING", "").encode("latin1")
    # QUERY_STRING really should be ascii safe but some browsers
    # will send us some unicode stuff (I am looking at you IE).
    # In that case we want to urllib quote it badly.
 #eturn url_quote(qs, safe=":&%=+$!*'(),")


def get_path_info(
 #nviron: "WSGIEnvironment", charset: str = "utf-8", errors: str = "replace"
) -> str:
 #""Return the ``PATH_INFO`` from the WSGI environment and decode it
 #nless ``charset`` is ``None``.

 #param environ: WSGI environment to get the path from.
 #param charset: The charset for the path info, or ``None`` if no
 #ecoding should be performed.
 #param errors: The decoding error handling.

 #. versionadded:: 0.9
 #""
 #ath = environ.get("PATH_INFO", "").encode("latin1")
 #eturn _to_str(path, charset, errors, allow_none_charset=True)  # type: ignore


def get_script_name(
 #nviron: "WSGIEnvironment", charset: str = "utf-8", errors: str = "replace"
) -> str:
 #""Return the ``SCRIPT_NAME`` from the WSGI environment and decode
 #t unless `charset` is set to ``None``.

 #param environ: WSGI environment to get the path from.
 #param charset: The charset for the path, or ``None`` if no decoding
 #hould be performed.
 #param errors: The decoding error handling.

 #. versionadded:: 0.9
 #""
 #ath = environ.get("SCRIPT_NAME", "").encode("latin1")
 #eturn _to_str(path, charset, errors, allow_none_charset=True)  # type: ignore


def pop_path_info(
 #nviron: "WSGIEnvironment", charset: str = "utf-8", errors: str = "replace"
) -> t.Optional[str]:
 #""Removes and returns the next segment of `PATH_INFO`, pushing it onto
 #SCRIPT_NAME`.  Returns `None` if there is nothing left on `PATH_INFO`.

 #f the `charset` is set to `None` bytes are returned.

 #f there are empty segments (``'/foo//bar``) these are ignored but
 #roperly pushed to the `SCRIPT_NAME`:

 #>> env = {'SCRIPT_NAME': '/foo', 'PATH_INFO': '/a/b'}
 #>> pop_path_info(env)
 #a'
 #>> env['SCRIPT_NAME']
 #/foo/a'
 #>> pop_path_info(env)
 #b'
 #>> env['SCRIPT_NAME']
 #/foo/a/b'

 #. versionadded:: 0.5

 #. versionchanged:: 0.9
 #he path is now decoded and a charset and encoding
 #arameter can be provided.

 #param environ: the WSGI environment that is modified.
 #param charset: The ``encoding`` parameter passed to
 #func:`bytes.decode`.
 #param errors: The ``errors`` paramater passed to
 #func:`bytes.decode`.
 #""
 #ath = environ.get("PATH_INFO")
 #f not path:
 #eturn None

 #cript_name = environ.get("SCRIPT_NAME", "")

    # shift multiple leading slashes over
 #ld_path = path
 #ath = path.lstrip("/")
 #f path != old_path:
 #cript_name += "/" * (len(old_path) - len(path))

 #f "/" not in path:
 #nviron["PATH_INFO"] = ""
 #nviron["SCRIPT_NAME"] = script_name + path
 #v = path.encode("latin1")
 #lse:
 #egment, path = path.split("/", 1)
 #nviron["PATH_INFO"] = f"/{path}"
 #nviron["SCRIPT_NAME"] = script_name + segment
 #v = segment.encode("latin1")

 #eturn _to_str(rv, charset, errors, allow_none_charset=True)  # type: ignore


def peek_path_info(
 #nviron: "WSGIEnvironment", charset: str = "utf-8", errors: str = "replace"
) -> t.Optional[str]:
 #""Returns the next segment on the `PATH_INFO` or `None` if there
 #s none.  Works like :func:`pop_path_info` without modifying the
 #nvironment:

 #>> env = {'SCRIPT_NAME': '/foo', 'PATH_INFO': '/a/b'}
 #>> peek_path_info(env)
 #a'
 #>> peek_path_info(env)
 #a'

 #f the `charset` is set to `None` bytes are returned.

 #. versionadded:: 0.5

 #. versionchanged:: 0.9
 #he path is now decoded and a charset and encoding
 #arameter can be provided.

 #param environ: the WSGI environment that is checked.
 #""
 #egments = environ.get("PATH_INFO", "").lstrip("/").split("/", 1)
 #f segments:
 #eturn _to_str(  # type: ignore
 #egments[0].encode("latin1"), charset, errors, allow_none_charset=True
 #
 #eturn None


def extract_path_info(
 #nviron_or_baseurl: t.Union[str, "WSGIEnvironment"],
 #ath_or_url: t.Union[str, _URLTuple],
 #harset: str = "utf-8",
 #rrors: str = "werkzeug.url_quote",
 #ollapse_http_schemes: bool = True,
) -> t.Optional[str]:
 #""Extracts the path info from the given URL (or WSGI environment) and
 #ath. The path info returned is a string. The URLs might also be IRIs.

 #f the path info could not be determined, `None` is returned.

 #ome examples:

 #>> extract_path_info('http://example.com/app', '/app/hello')
 #/hello'
 #>> extract_path_info('http://example.com/app',
 #..                   'https://example.com/app/hello')
 #/hello'
 #>> extract_path_info('http://example.com/app',
 #..                   'https://example.com/app/hello',
 #..                   collapse_http_schemes=False) is None
 #rue

 #nstead of providing a base URL you can also pass a WSGI environment.

 #param environ_or_baseurl: a WSGI environment dict, a base URL or
 #ase IRI.  This is the root of the
 #pplication.
 #param path_or_url: an absolute path from the server root, a
 #elative path (in which case it's the path info)
 #r a full URL.
 #param charset: the charset for byte data in URLs
 #param errors: the error handling on decode
 #param collapse_http_schemes: if set to `False` the algorithm does
 #ot assume that http and https on the
 #ame server point to the same
 #esource.

 #. versionchanged:: 0.15
 #he ``errors`` parameter defaults to leaving invalid bytes
 #uoted instead of replacing them.

 #. versionadded:: 0.6
 #""

 #ef _normalize_netloc(scheme: str, netloc: str) -> str:
 #arts = netloc.split("@", 1)[-1].split(":", 1)
 #ort: t.Optional[str]

 #f len(parts) == 2:
 #etloc, port = parts
 #f (scheme == "http" and port == "80") or (
 #cheme == "https" and port == "443"
 #:
 #ort = None
 #lse:
 #etloc = parts[0]
 #ort = None

 #f port is not None:
 #etloc += f":{port}"

 #eturn netloc

    # make sure whatever we are working on is a IRI and parse it
 #ath = uri_to_iri(path_or_url, charset, errors)
 #f isinstance(environ_or_baseurl, dict):
 #nviron_or_baseurl = get_current_url(environ_or_baseurl, root_only=True)
 #ase_iri = uri_to_iri(environ_or_baseurl, charset, errors)
 #ase_scheme, base_netloc, base_path = url_parse(base_iri)[:3]
 #ur_scheme, cur_netloc, cur_path = url_parse(url_join(base_iri, path))[:3]

    # normalize the network location
 #ase_netloc = _normalize_netloc(base_scheme, base_netloc)
 #ur_netloc = _normalize_netloc(cur_scheme, cur_netloc)

    # is that IRI even on a known HTTP scheme?
 #f collapse_http_schemes:
 #or scheme in base_scheme, cur_scheme:
 #f scheme not in ("http", "https"):
 #eturn None
 #lse:
 #f not (base_scheme in ("http", "https") and base_scheme == cur_scheme):
 #eturn None

    # are the netlocs compatible?
 #f base_netloc != cur_netloc:
 #eturn None

    # are we below the application path?
 #ase_path = base_path.rstrip("/")
 #f not cur_path.startswith(base_path):
 #eturn None

 #eturn f"/{cur_path[len(base_path) :].lstrip('/')}"


class ClosingIterator:
 #""The WSGI specification requires that all middlewares and gateways
 #espect the `close` callback of the iterable returned by the application.
 #ecause it is useful to add another close action to a returned iterable
 #nd adding a custom iterable is a boring task this class can be used for
 #hat::

 #eturn ClosingIterator(app(environ, start_response), [cleanup_session,
 #leanup_locals])

 #f there is just one close function it can be passed instead of the list.

 # closing iterator is not needed if the application uses response objects
 #nd finishes the processing if the response is started::

 #ry:
 #eturn response(environ, start_response)
 #inally:
 #leanup_session()
 #leanup_locals()
 #""

 #ef __init__(
 #elf,
 #terable: t.Iterable[bytes],
 #allbacks: t.Optional[
 #.Union[t.Callable[[], None], t.Iterable[t.Callable[[], None]]]
 # = None,
 # -> None:
 #terator = iter(iterable)
 #elf._next = t.cast(t.Callable[[], bytes], partial(next, iterator))
 #f callbacks is None:
 #allbacks = []
 #lif callable(callbacks):
 #allbacks = [callbacks]
 #lse:
 #allbacks = list(callbacks)
 #terable_close = getattr(iterable, "close", None)
 #f iterable_close:
 #allbacks.insert(0, iterable_close)
 #elf._callbacks = callbacks

 #ef __iter__(self) -> "ClosingIterator":
 #eturn self

 #ef __next__(self) -> bytes:
 #eturn self._next()

 #ef close(self) -> None:
 #or callback in self._callbacks:
 #allback()


def wrap_file(
 #nviron: "WSGIEnvironment", file: t.IO[bytes], buffer_size: int = 8192
) -> t.Iterable[bytes]:
 #""Wraps a file.  This uses the WSGI server's file wrapper if available
 #r otherwise the generic :class:`FileWrapper`.

 #. versionadded:: 0.5

 #f the file wrapper from the WSGI server is used it's important to not
 #terate over it from inside the application but to pass it through
 #nchanged.  If you want to pass out a file wrapper inside a response
 #bject you have to set :attr:`Response.direct_passthrough` to `True`.

 #ore information about file wrappers are available in :pep:`333`.

 #param file: a :class:`file`-like object with a :meth:`~file.read` method.
 #param buffer_size: number of bytes for one iteration.
 #""
 #eturn environ.get("wsgi.file_wrapper", FileWrapper)(  # type: ignore
 #ile, buffer_size
 #


class FileWrapper:
 #""This class can be used to convert a :class:`file`-like object into
 #n iterable.  It yields `buffer_size` blocks until the file is fully
 #ead.

 #ou should not use this class directly but rather use the
 #func:`wrap_file` function that uses the WSGI server's file wrapper
 #upport if it's available.

 #. versionadded:: 0.5

 #f you're using this object together with a :class:`Response` you have
 #o use the `direct_passthrough` mode.

 #param file: a :class:`file`-like object with a :meth:`~file.read` method.
 #param buffer_size: number of bytes for one iteration.
 #""

 #ef __init__(self, file: t.IO[bytes], buffer_size: int = 8192) -> None:
 #elf.file = file
 #elf.buffer_size = buffer_size

 #ef close(self) -> None:
 #f hasattr(self.file, "close"):
 #elf.file.close()

 #ef seekable(self) -> bool:
 #f hasattr(self.file, "seekable"):
 #eturn self.file.seekable()
 #f hasattr(self.file, "seek"):
 #eturn True
 #eturn False

 #ef seek(self, *args: t.Any) -> None:
 #f hasattr(self.file, "seek"):
 #elf.file.seek(*args)

 #ef tell(self) -> t.Optional[int]:
 #f hasattr(self.file, "tell"):
 #eturn self.file.tell()
 #eturn None

 #ef __iter__(self) -> "FileWrapper":
 #eturn self

 #ef __next__(self) -> bytes:
 #ata = self.file.read(self.buffer_size)
 #f data:
 #eturn data
 #aise StopIteration()


class _RangeWrapper:
    # private for now, but should we make it public in the future ?

 #""This class can be used to convert an iterable object into
 #n iterable that will only yield a piece of the underlying content.
 #t yields blocks until the underlying stream range is fully read.
 #he yielded blocks will have a size that can't exceed the original
 #terator defined block size, but that can be smaller.

 #f you're using this object together with a :class:`Response` you have
 #o use the `direct_passthrough` mode.

 #param iterable: an iterable object with a :meth:`__next__` method.
 #param start_byte: byte from which read will start.
 #param byte_range: how many bytes to read.
 #""

 #ef __init__(
 #elf,
 #terable: t.Union[t.Iterable[bytes], t.IO[bytes]],
 #tart_byte: int = 0,
 #yte_range: t.Optional[int] = None,
 #:
 #elf.iterable = iter(iterable)
 #elf.byte_range = byte_range
 #elf.start_byte = start_byte
 #elf.end_byte = None

 #f byte_range is not None:
 #elf.end_byte = start_byte + byte_range

 #elf.read_length = 0
 #elf.seekable = (
 #asattr(iterable, "seekable") and iterable.seekable()  # type: ignore
 #
 #elf.end_reached = False

 #ef __iter__(self) -> "_RangeWrapper":
 #eturn self

 #ef _next_chunk(self) -> bytes:
 #ry:
 #hunk = next(self.iterable)
 #elf.read_length += len(chunk)
 #eturn chunk
 #xcept StopIteration:
 #elf.end_reached = True
 #aise

 #ef _first_iteration(self) -> t.Tuple[t.Optional[bytes], int]:
 #hunk = None
 #f self.seekable:
 #elf.iterable.seek(self.start_byte)  # type: ignore
 #elf.read_length = self.iterable.tell()  # type: ignore
 #ontextual_read_length = self.read_length
 #lse:
 #hile self.read_length <= self.start_byte:
 #hunk = self._next_chunk()
 #f chunk is not None:
 #hunk = chunk[self.start_byte - self.read_length :]
 #ontextual_read_length = self.start_byte
 #eturn chunk, contextual_read_length

 #ef _next(self) -> bytes:
 #f self.end_reached:
 #aise StopIteration()
 #hunk = None
 #ontextual_read_length = self.read_length
 #f self.read_length == 0:
 #hunk, contextual_read_length = self._first_iteration()
 #f chunk is None:
 #hunk = self._next_chunk()
 #f self.end_byte is not None and self.read_length >= self.end_byte:
 #elf.end_reached = True
 #eturn chunk[: self.end_byte - contextual_read_length]
 #eturn chunk

 #ef __next__(self) -> bytes:
 #hunk = self._next()
 #f chunk:
 #eturn chunk
 #elf.end_reached = True
 #aise StopIteration()

 #ef close(self) -> None:
 #f hasattr(self.iterable, "close"):
 #elf.iterable.close()  # type: ignore


def _make_chunk_iter(
 #tream: t.Union[t.Iterable[bytes], t.IO[bytes]],
 #imit: t.Optional[int],
 #uffer_size: int,
) -> t.Iterator[bytes]:
 #""Helper for the line and chunk iter functions."""
 #f isinstance(stream, (bytes, bytearray, str)):
 #aise TypeError(
 #Passed a string or byte object instead of true iterator or stream."
 #
 #f not hasattr(stream, "read"):
 #or item in stream:
 #f item:
 #ield item
 #eturn
 #tream = t.cast(t.IO[bytes], stream)
 #f not isinstance(stream, LimitedStream) and limit is not None:
 #tream = t.cast(t.IO[bytes], LimitedStream(stream, limit))
 #read = stream.read
 #hile True:
 #tem = _read(buffer_size)
 #f not item:
 #reak
 #ield item


def make_line_iter(
 #tream: t.Union[t.Iterable[bytes], t.IO[bytes]],
 #imit: t.Optional[int] = None,
 #uffer_size: int = 10 * 1024,
 #ap_at_buffer: bool = False,
) -> t.Iterator[bytes]:
 #""Safely iterates line-based over an input stream.  If the input stream
 #s not a :class:`LimitedStream` the `limit` parameter is mandatory.

 #his uses the stream's :meth:`~file.read` method internally as opposite
 #o the :meth:`~file.readline` method that is unsafe and can only be used
 #n violation of the WSGI specification.  The same problem applies to the
 #__iter__` function of the input stream which calls :meth:`~file.readline`
 #ithout arguments.

 #f you need line-by-line processing it's strongly recommended to iterate
 #ver the input stream using this helper function.

 #. versionchanged:: 0.8
 #his function now ensures that the limit was reached.

 #. versionadded:: 0.9
 #dded support for iterators as input stream.

 #. versionadded:: 0.11.10
 #dded support for the `cap_at_buffer` parameter.

 #param stream: the stream or iterate to iterate over.
 #param limit: the limit in bytes for the stream.  (Usually
 #ontent length.  Not necessary if the `stream`
 #s a :class:`LimitedStream`.
 #param buffer_size: The optional buffer size.
 #param cap_at_buffer: if this is set chunks are split if they are longer
 #han the buffer size.  Internally this is implemented
 #hat the buffer size might be exhausted by a factor
 #f two however.
 #""
 #iter = _make_chunk_iter(stream, limit, buffer_size)

 #irst_item = next(_iter, "")
 #f not first_item:
 #eturn

 # = _make_encode_wrapper(first_item)
 #mpty = t.cast(bytes, s(""))
 #r = t.cast(bytes, s("\r"))
 #f = t.cast(bytes, s("\n"))
 #rlf = t.cast(bytes, s("\r\n"))

 #iter = t.cast(t.Iterator[bytes], chain((first_item,), _iter))

 #ef _iter_basic_lines() -> t.Iterator[bytes]:
 #join = empty.join
 #uffer: t.List[bytes] = []
 #hile True:
 #ew_data = next(_iter, "")
 #f not new_data:
 #reak
 #ew_buf: t.List[bytes] = []
 #uf_size = 0
 #or item in t.cast(
 #.Iterator[bytes], chain(buffer, new_data.splitlines(True))
 #:
 #ew_buf.append(item)
 #uf_size += len(item)
 #f item and item[-1:] in crlf:
 #ield _join(new_buf)
 #ew_buf = []
 #lif cap_at_buffer and buf_size >= buffer_size:
 #v = _join(new_buf)
 #hile len(rv) >= buffer_size:
 #ield rv[:buffer_size]
 #v = rv[buffer_size:]
 #ew_buf = [rv]
 #uffer = new_buf
 #f buffer:
 #ield _join(buffer)

    # This hackery is necessary to merge 'foo\r' and '\n' into one item
    # of 'foo\r\n' if we were unlucky and we hit a chunk boundary.
 #revious = empty
 #or item in _iter_basic_lines():
 #f item == lf and previous[-1:] == cr:
 #revious += item
 #tem = empty
 #f previous:
 #ield previous
 #revious = item
 #f previous:
 #ield previous


def make_chunk_iter(
 #tream: t.Union[t.Iterable[bytes], t.IO[bytes]],
 #eparator: bytes,
 #imit: t.Optional[int] = None,
 #uffer_size: int = 10 * 1024,
 #ap_at_buffer: bool = False,
) -> t.Iterator[bytes]:
 #""Works like :func:`make_line_iter` but accepts a separator
 #hich divides chunks.  If you want newline based processing
 #ou should use :func:`make_line_iter` instead as it
 #upports arbitrary newline markers.

 #. versionadded:: 0.8

 #. versionadded:: 0.9
 #dded support for iterators as input stream.

 #. versionadded:: 0.11.10
 #dded support for the `cap_at_buffer` parameter.

 #param stream: the stream or iterate to iterate over.
 #param separator: the separator that divides chunks.
 #param limit: the limit in bytes for the stream.  (Usually
 #ontent length.  Not necessary if the `stream`
 #s otherwise already limited).
 #param buffer_size: The optional buffer size.
 #param cap_at_buffer: if this is set chunks are split if they are longer
 #han the buffer size.  Internally this is implemented
 #hat the buffer size might be exhausted by a factor
 #f two however.
 #""
 #iter = _make_chunk_iter(stream, limit, buffer_size)

 #irst_item = next(_iter, b"")
 #f not first_item:
 #eturn

 #iter = t.cast(t.Iterator[bytes], chain((first_item,), _iter))
 #f isinstance(first_item, str):
 #eparator = _to_str(separator)
 #split = re.compile(f"({re.escape(separator)})").split
 #join = "".join
 #lse:
 #eparator = _to_bytes(separator)
 #split = re.compile(b"(" + re.escape(separator) + b")").split
 #join = b"".join

 #uffer: t.List[bytes] = []
 #hile True:
 #ew_data = next(_iter, b"")
 #f not new_data:
 #reak
 #hunks = _split(new_data)
 #ew_buf: t.List[bytes] = []
 #uf_size = 0
 #or item in chain(buffer, chunks):
 #f item == separator:
 #ield _join(new_buf)
 #ew_buf = []
 #uf_size = 0
 #lse:
 #uf_size += len(item)
 #ew_buf.append(item)

 #f cap_at_buffer and buf_size >= buffer_size:
 #v = _join(new_buf)
 #hile len(rv) >= buffer_size:
 #ield rv[:buffer_size]
 #v = rv[buffer_size:]
 #ew_buf = [rv]
 #uf_size = len(rv)

 #uffer = new_buf
 #f buffer:
 #ield _join(buffer)


class LimitedStream(io.IOBase):
 #""Wraps a stream so that it doesn't read more than n bytes.  If the
 #tream is exhausted and the caller tries to get more bytes from it
 #func:`on_exhausted` is called which by default returns an empty
 #tring.  The return value of that function is forwarded
 #o the reader function.  So if it returns an empty string
 #meth:`read` will return an empty string as well.

 #he limit however must never be higher than what the stream can
 #utput.  Otherwise :meth:`readlines` will try to read past the
 #imit.

 #. admonition:: Note on WSGI compliance

 #alls to :meth:`readline` and :meth:`readlines` are not
 #SGI compliant because it passes a size argument to the
 #eadline methods.  Unfortunately the WSGI PEP is not safely
 #mplementable without a size argument to :meth:`readline`
 #ecause there is no EOF marker in the stream.  As a result
 #f that the use of :meth:`readline` is discouraged.

 #or the same reason iterating over the :class:`LimitedStream`
 #s not portable.  It internally calls :meth:`readline`.

 #e strongly suggest using :meth:`read` only or using the
 #func:`make_line_iter` which safely iterates line-based
 #ver a WSGI input stream.

 #param stream: the stream to wrap.
 #param limit: the limit for the stream, must not be longer than
 #hat the string can provide if the stream does not
 #nd with `EOF` (like `wsgi.input`)
 #""

 #ef __init__(self, stream: t.IO[bytes], limit: int) -> None:
 #elf._read = stream.read
 #elf._readline = stream.readline
 #elf._pos = 0
 #elf.limit = limit

 #ef __iter__(self) -> "LimitedStream":
 #eturn self

 #property
 #ef is_exhausted(self) -> bool:
 #""If the stream is exhausted this attribute is `True`."""
 #eturn self._pos >= self.limit

 #ef on_exhausted(self) -> bytes:
 #""This is called when the stream tries to read past the limit.
 #he return value of this function is returned from the reading
 #unction.
 #""
        # Read null bytes from the stream so that we get the
        # correct end of stream marker.
 #eturn self._read(0)

 #ef on_disconnect(self) -> bytes:
 #""What should happen if a disconnect is detected?  The return
 #alue of this function is returned from read functions in case
 #he client went away.  By default a
 #exc:`~werkzeug.exceptions.ClientDisconnected` exception is raised.
 #""
 #rom .exceptions import ClientDisconnected

 #aise ClientDisconnected()

 #ef exhaust(self, chunk_size: int = 1024 * 64) -> None:
 #""Exhaust the stream.  This consumes all the data left until the
 #imit is reached.

 #param chunk_size: the size for a chunk.  It will read the chunk
 #ntil the stream is exhausted and throw away
 #he results.
 #""
 #o_read = self.limit - self._pos
 #hunk = chunk_size
 #hile to_read > 0:
 #hunk = min(to_read, chunk)
 #elf.read(chunk)
 #o_read -= chunk

 #ef read(self, size: t.Optional[int] = None) -> bytes:
 #""Read `size` bytes or if size is not provided everything is read.

 #param size: the number of bytes read.
 #""
 #f self._pos >= self.limit:
 #eturn self.on_exhausted()
 #f size is None or size == -1:  # -1 is for consistence with file
 #ize = self.limit
 #o_read = min(self.limit - self._pos, size)
 #ry:
 #ead = self._read(to_read)
 #xcept (OSError, ValueError):
 #eturn self.on_disconnect()
 #f to_read and len(read) != to_read:
 #eturn self.on_disconnect()
 #elf._pos += len(read)
 #eturn read

 #ef readline(self, size: t.Optional[int] = None) -> bytes:
 #""Reads one line from the stream."""
 #f self._pos >= self.limit:
 #eturn self.on_exhausted()
 #f size is None:
 #ize = self.limit - self._pos
 #lse:
 #ize = min(size, self.limit - self._pos)
 #ry:
 #ine = self._readline(size)
 #xcept (ValueError, OSError):
 #eturn self.on_disconnect()
 #f size and not line:
 #eturn self.on_disconnect()
 #elf._pos += len(line)
 #eturn line

 #ef readlines(self, size: t.Optional[int] = None) -> t.List[bytes]:
 #""Reads a file into a list of strings.  It calls :meth:`readline`
 #ntil the file is read to the end.  It does support the optional
 #size` argument if the underlying stream supports it for
 #readline`.
 #""
 #ast_pos = self._pos
 #esult = []
 #f size is not None:
 #nd = min(self.limit, last_pos + size)
 #lse:
 #nd = self.limit
 #hile True:
 #f size is not None:
 #ize -= last_pos - self._pos
 #f self._pos >= end:
 #reak
 #esult.append(self.readline(size))
 #f size is not None:
 #ast_pos = self._pos
 #eturn result

 #ef tell(self) -> int:
 #""Returns the position of the stream.

 #. versionadded:: 0.9
 #""
 #eturn self._pos

 #ef __next__(self) -> bytes:
 #ine = self.readline()
 #f not line:
 #aise StopIteration()
 #eturn line

 #ef readable(self) -> bool:
 #eturn True
